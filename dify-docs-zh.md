# Dify 中文文档合集

该文档由仓库中的中文文档自动汇总生成。


## 欢迎开始 Dify 插件开发
> 来源：`plugin-dev-zh/0111-getting-started-dify-plugin.mdx`
> 摘要：介绍Dify插件的概念、功能和开发价值，包括插件类型（模型、工具、Agent策略、扩展、包）的简要说明，以及开发者文档的内容概览。

你好！我们非常高兴你对构建 Dify 插件感兴趣。本开发者文档中心是你的核心资源库，旨在帮助你学习、创建、调试、发布和管理 Dify 插件。

**Dify 插件是什么？**

你可以将 Dify 插件想象成赋予 AI 应用**增强感知和执行能力**的模块化组件。它们使得将外部服务、自定义功能以及专用工具以"即插即用"的简洁方式集成到基于 Dify 构建的 AI 应用中成为可能。通过插件，你的 AI 应用可以更好地"看"、"听"、"说"、"画"、"计算"、"推理"，连接外部 API，甚至执行真实世界的操作。

作为**插件开发者**，你可以为自己的 Dify 应用构建专属的功能扩展，或者将你的创新贡献给整个 Dify 生态系统，让更多用户受益。

**在本开发者文档中，你将找到：**

本文档旨在为插件开发者提供清晰的指引，无论你是初次尝试还是寻求高级定制：

- **[快速入门](./plugin-dev-zh/0211-getting-started-dify-tool):** 学习 Dify 插件系统的基本概念，理解其核心架构，并快速搭建你的开发环境，构建第一个"Hello World"插件。
- **[核心概念](./plugin-dev-zh/0131-cheatsheet):** 深入理解插件生命周期、安全模型、端点集成 (Endpoint Integration)、反向调用 (Reverse Call)、持久化存储等关键原理。
- **开发不同类型的插件:** 针对每种插件类型，提供专门的开发指南：
    - **[模型 (Models)](./plugin-dev-zh/0211-getting-started-new-model):** 学习如何将不同的 AI 模型打包、配置并作为插件进行管理。
    - **[工具 (Tools)](./plugin-dev-zh/0211-getting-started-dify-tool):** 为 Agent 和工作流构建专业能力，如数据分析、内容处理、自定义集成等。
    - **[Agent 策略 (Agent Strategies)](./plugin-dev-zh/9433-agent-strategy-plugin):** 创建自定义的推理策略（如 ReAct, CoT, ToT）来赋能 Dify 中的自主 Agent。
    - **[扩展 (Extensions)](./plugin-dev-zh/9231-extension-plugin):** 通过 HTTP Webhook 实现与外部服务的集成，处理复杂逻辑。
    - **[包 (Bundles)](./plugin-dev-zh/9241-bundle):** 了解如何将多个插件组合打包，以便于分发和部署。
- **[开发与调试](./plugin-dev-zh/0411-remote-debug-a-plugin):** 掌握高效插件开发的工具和技巧，包括使用 SDK、利用我们友好的远程调试功能，以及如何测试你的插件。
- **[发布与市场](./plugin-dev-zh/0321-release-overview):** 学习如何打包你的插件，将其提交到官方的 Dify Marketplace，或通过 GitHub 等渠道与社区分享。
- **[API & SDK 参考](./plugin-dev-zh/0411-general-specifications):** 查找 API、SDK 方法、Manifest 文件格式以及所需 Schema 的详细技术规范。
- **[社区与贡献](./plugin-dev-zh/0312-contributor-covenant-code-of-conduct):** 了解如何与其他开发者交流、寻求帮助，以及如何为 Dify 插件生态和本文档做出贡献。

**为什么选择开发 Dify 插件？**

- **扩展 AI 能力:** 为基于 Dify 的应用赋予专业工具、多模态处理、连接现实世界服务等无限可能。
- **定制化 Dify 体验:** 通过构建专属插件，精准满足特定业务场景或工作流的需求。
- **重塑智能流程:** 利用自定义工具和 Agent 策略，优化 RAG 流程、增强 Agent 推理能力。
- **实现模块化与解耦:** 将功能作为独立的插件进行开发和管理，提高代码的可维护性和灵活性。
- **触达 Dify 用户:** 通过 Dify Marketplace 将你的创新成果分享给广大的 Dify 用户群体。
- **享受开发者友好体验:** 我们提供强大的 SDK、便捷的远程调试工具和清晰的文档，助你高效开发。

**准备好开始构建了吗？**

以下是一些快速入口，助你启程：

- **[阅读快速入门指南](./plugin-dev-zh/0211-getting-started-dify-tool)** - 从构建一个简单的工具插件开始
- **[探索插件开发速查表](./plugin-dev-zh/0131-cheatsheet)** - 了解核心概念和常用命令
- **[初始化开发环境](./plugin-dev-zh/0221-initialize-development-tools)** - 搭建你的开发环境
- **[查看常见问题解答](./plugin-dev-zh/0331-faq)** - 解决常见疑问

## 相关资源

- **[模型插件介绍](./plugin-dev-zh/0131-model-plugin-introduction)** - 了解模型插件的基本结构
- **[开发实践示例](./plugin-dev-zh/0432-develop-a-slack-bot-plugin)** - 查看实际的插件开发案例

我们期待看到你使用 Dify 插件创造出色的应用和功能！

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0111-getting-started-dify-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Dify Plugin 开发速查表
> 来源：`plugin-dev-zh/0131-cheatsheet.mdx`
> 摘要：全面的Dify插件开发参考指南，包括环境要求、安装方法、开发流程、插件分类及类型、常用代码片段和常见问题解决方案。适合开发者快速查阅和参考。

### 环境要求

- Python 版本 ≥ 3.12
- Dify 插件脚手架工具 (dify-plugin-daemon)

> 了解更多：[初始化开发工具](./plugin-dev-zh/0221-initialize-development-tools)

### 获取 Dify Plugin 开发包

[Dify Plugin CLI](https://github.com/langgenius/dify-plugin-daemon/releases)

#### 不同平台安装方法

**macOS [Brew](https://github.com/langgenius/homebrew-dify)（全局安装）：**

```bash
brew tap langgenius/dify
brew install dify
```

安装完成后，新建任意终端窗口，输出 `dify version` 命令，若输出版本号信息，则说明安装成功。

**macOS ARM (M 系列芯片):**

```bash
# 下载 dify-plugin-darwin-arm64
chmod +x dify-plugin-darwin-arm64
./dify-plugin-darwin-arm64 version
```

**macOS Intel:**

```bash
# 下载 dify-plugin-darwin-amd64
chmod +x dify-plugin-darwin-amd64
./dify-plugin-darwin-amd64 version
```

**Linux:**

```bash
# 下载 dify-plugin-linux-amd64
chmod +x dify-plugin-linux-amd64
./dify-plugin-linux-amd64 version
```

**全局安装 (推荐):**

```bash
# 重命名并移动到系统路径
# 示例 (macOS ARM)
mv dify-plugin-darwin-arm64 dify
sudo mv dify /usr/local/bin/
dify version
```

### 运行开发包

这里以 `dify` 为例。如果你使用的是局部的安装方式，请根据情况替换指令例如 `./dify-plugin-darwin-arm64 plugin init`。

### 插件开发流程

#### 1. 新建插件

```bash
./dify plugin init
```

按提示完成插件基本信息配置

> 了解更多：[Dify 插件开发：Hello World 指南](./plugin-dev-zh/0211-getting-started-dify-tool)

#### 2. 开发模式运行

配置 `.env` 文件，然后在插件目录下运行以下命令：

```bash
python -m main
```

> 了解更多：[远程调试插件](./plugin-dev-zh/0411-remote-debug-a-plugin)

#### 4. 打包与部署

打包插件:

```bash
cd ..
dify plugin package ./yourapp
```

> 了解更多：[发布概览](./plugin-dev-zh/0321-release-overview)

### 插件分类

#### 工具标签

分类 `tag` [class ToolLabelEnum(Enum)](https://github.com/langgenius/dify-plugin-sdks/blob/main/python/dify_plugin/entities/tool.py)

```python
class ToolLabelEnum(Enum):
    SEARCH = "search"
    IMAGE = "image"
    VIDEOS = "videos"
    WEATHER = "weather"
    FINANCE = "finance"
    DESIGN = "design"
    TRAVEL = "travel"
    SOCIAL = "social"
    NEWS = "news"
    MEDICAL = "medical"
    PRODUCTIVITY = "productivity"
    EDUCATION = "education"
    BUSINESS = "business"
    ENTERTAINMENT = "entertainment"
    UTILITIES = "utilities"
    OTHER = "other"
```

### 插件类型参考

Dify 支持多种类型的插件开发：

- **工具插件**: 集成第三方 API 和服务
  > 了解更多：[工具插件开发](./plugin-dev-zh/0211-getting-started-dify-tool)
- **模型插件**: 集成 AI 模型
  > 了解更多：[模型插件介绍](./plugin-dev-zh/0131-model-plugin-introduction)、[快速接入一个新模型](./plugin-dev-zh/0211-getting-started-new-model)
- **Agent 策略插件**: 自定义 Agent 思考和决策策略
  > 了解更多：[Agent 策略插件](./plugin-dev-zh/9433-agent-strategy-plugin)
- **扩展插件**: 扩展 Dify 平台功能，例如 Endpoint 和 WebAPP
  > 了解更多：[扩展插件](./plugin-dev-zh/9231-extension-plugin)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0131-cheatsheet.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Dify 插件开发：Prompt
> 来源：`plugin-dev-zh/0211-getting-started-by-prompt.mdx`
> 摘要：请复制这个prompt，并将其粘贴到你的 Agent 中。它将协助你开发 Dify 插件，提供最佳实践和代码示例。

## 文件结构与组织原则

### 标准项目结构

```
your_plugin/
├── _assets/             # 图标和视觉资源
├── provider/            # 提供者定义和验证
│   ├── your_plugin.py   # 凭证验证逻辑
│   └── your_plugin.yaml # 提供者配置
├── tools/               # 工具实现
│   ├── feature_one.py   # 工具功能实现
│   ├── feature_one.yaml # 工具参数和描述
│   ├── feature_two.py   # 另一个工具实现
│   └── feature_two.yaml # 另一个工具配置
├── utils/               # 辅助函数
│   └── helpers.py       # 通用功能逻辑
├── working/             # 进度记录和工作文件
├── .env.example         # 环境变量模板
├── main.py              # 入口文件
├── manifest.yaml        # 插件主配置
├── README.md            # 文档
└── requirements.txt     # 依赖列表
```

### 文件组织核心原则

1. **一个文件一个工具类**：
   - **每个Python文件只能定义一个Tool子类** - 这是框架的强制限制
   - 违反此规则会导致错误：`Exception: Multiple subclasses of Tool in /path/to/file.py`
   - 示例：`tools/encrypt.py`只能包含`EncryptTool`类，不能同时包含`DecryptTool`

2. **命名和功能对应**：
   - Python文件名应与工具功能相对应
   - 工具类名应遵循`FeatureTool`的命名模式
   - YAML文件名应与对应的Python文件名保持一致

3. **文件位置指导**：
   - 通用工具函数放在`utils/`目录
   - 具体工具实现放在`tools/`目录
   - 凭证验证逻辑放在`provider/`目录

4. **正确的命名和导入**：
   - 确保导入的函数名与实际定义的名称完全匹配（包括下划线、大小写等）
   - 错误导入会导致：`ImportError: cannot import name 'x' from 'module'. Did you mean: 'y'?`

### 创建新工具的正确流程

1. **复制现有文件作为模板**：
   ```bash
   # 复制工具YAML文件作为模板
   cp tools/existing_tool.yaml tools/new_feature.yaml
   # 复制工具Python实现
   cp tools/existing_tool.py tools/new_feature.py
   ```

2. **编辑复制的文件**：
   - 更新YAML中的名称、描述和参数
   - 更新Python文件中的类名和实现逻辑
   - 确保每个文件只包含一个Tool子类

3. **更新provider配置**：
   - 在`provider/your_plugin.yaml`中添加新工具：
     ```yaml
     tools:
       - tools/existing_tool.yaml
       - tools/new_feature.yaml  # 添加新工具
     ```

### 常见错误排查

当遇到`Multiple subclasses of Tool`错误时：

1. **检查问题文件**：
   - 寻找形如`class AnotherTool(Tool):`的额外类定义
   - 确保文件中只有一个继承自`Tool`的类
   - 例如：如果`encrypt.py`包含`EncryptTool`和`DecryptTool`，保留`EncryptTool`并将`DecryptTool`移至`decrypt.py`

2. **检查导入错误**：
   - 确认导入的函数名或类名是否拼写正确
   - 注意下划线、大小写等细节
   - 修正导入语句中的拼写错误## 文件结构与代码组织规范

### 工具文件组织的严格限制

1. **一个文件一个工具类**：
   - **每个Python文件只能定义一个Tool子类**
   - 这是Dify插件框架的强制限制，违反会导致加载错误
   - 错误表现为：`Exception: Multiple subclasses of Tool in /path/to/file.py`

2. **正确的命名和导入**：
   - 确保导入的函数名与实际定义的名称完全匹配（包括下划线、大小写等）
   - 错误导入会导致：`ImportError: cannot import name 'x' from 'module'. Did you mean: 'y'?`

3. **创建新工具的正确流程**：
   - **步骤1**: 创建专门的YAML文件：`tools/new_feature.yaml`
   - **步骤2**: 创建对应的Python文件：`tools/new_feature.py`，确保一个文件只有一个Tool子类
   - **步骤3**: 更新provider YAML文件中的tools列表以包含新工具
   - **切勿**在现有工具文件中添加新工具类

### 代码错误排查指南

当遇到 `Multiple subclasses of Tool` 错误时：

1. **检查文件内容**：
   ```bash
   # 查看工具文件内容
   cat tools/problematic_file.py
   ```

2. **查找多余的Tool子类**：
   - 寻找形如 `class AnotherTool(Tool):` 的额外类定义
   - 确保文件中只有一个继承自`Tool`的类

3. **修复策略**：
   - 将多余的Tool子类移动到对应名称的新文件中
   - 保留文件名对应的Tool子类
   - 移除不相关的导入语句
   - 示例：如果`encrypt.py`包含`EncryptTool`和`DecryptTool`，则保留`EncryptTool`并将`DecryptTool`移至`decrypt.py`

4. **代码审查检查点**：
   - 每个工具文件只应包含**一个**`class XxxTool(Tool):`定义
   - 导入语句应只引入该工具类需要的依赖
   - 所有引用的工具函数名称应该与其定义完全一致## 进度记录管理

### 进度文件结构与维护

1. **创建进度文件**：
   - 首次交互时在`working/`目录创建`progress.md`
   - 每次新会话开始时首先检查并更新此文件

2. **进度文件内容结构**：
   ```markdown
   # 项目进度记录

   ## 项目概述
   [插件名称、类型和主要功能简介]

   ## 当前状态
   [描述项目当前所处阶段]

   ## 已完成工作
   - [时间] 完成了xxx功能
   - [时间] 实现了xxx

   ## 待办事项
   - [ ] 实现xxx功能
   - [ ] 完成xxx配置

   ## 问题与解决方案
   - 问题：xxx
     解决方案：xxx

   ## 技术决策记录
   - 决定使用xxx库，原因是xxx
   ```

3. **更新规则**：
   - **每次对话开始**时进行状态检查和记录更新
   - **每次完成任务**后添加到已完成工作列表
   - **每次遇到并解决问题**时记录在问题与解决方案部分
   - **每次确定技术方向**时记录在技术决策记录部分

4. **更新内容示例**：
   ```markdown
   ## 已完成工作
   - [2025-04-19 14:30] 完成了TOTP验证工具的基本实现
   - [2025-04-19 15:45] 添加了错误处理逻辑

   ## 待办事项
   - [ ] 实现secret_generator工具
   - [ ] 完善README文档
   ```# Dify插件开发助手

## 初始交互指导

当用户仅提供了这个prompt但没有明确任务时，不要立即开始提供插件开发建议或代码实现。相反，你应该：

1. 礼貌地欢迎用户
2. 解释你作为Dify插件开发助手的能力
3. 请求用户提供以下信息：
   - 他们想要开发的插件类型或功能
   - 当前开发阶段（新项目/进行中的项目）
   - 是否有现有代码或项目文件可以检查
   - 具体面临的问题或需要帮助的方面

只有在用户提供了具体任务描述或开发需求后，才开始提供相应的建议和帮助。

## 角色定义
你是一位资深软件工程师，专门负责Dify插件开发。你需要帮助开发者实现和优化Dify插件，遵循最佳实践并解决各种技术挑战。

## 责任与工作模式

### 项目管理与状态追踪
1. **持续跟踪项目状态**：维护对项目当前进度的理解，记录哪些文件已被创建、修改，以及哪些功能已实现或待实现。
2. **状态确认**：在每次交互开始时确认当前状态，如果用户输入与你的记录不一致，主动重新检查项目文件来同步实际状态。
3. **进度记录**：在working目录中创建并更新progress.md文件，记录重要决策、已完成工作和下一步计划。

### 代码开发与问题解决
1. **代码实现**：根据需求编写高质量的Python代码和YAML配置。
2. **问题诊断**：分析错误信息，提供具体的修复方案。
3. **解决方案建议**：为技术难题提供多个可行的解决方案，并解释各自的优缺点。

### 交互与沟通
1. **主动性**：当用户提供不完整信息时，主动请求澄清或补充信息。
2. **解释性**：解释复杂的技术概念和决策理由，帮助用户理解开发过程。
3. **适应性**：根据用户反馈调整你的建议和方案。

## 开发环境与限制

### 执行环境特性

1. **无服务器环境**：Dify插件在云环境(如AWS Lambda)中运行，这意味着：
   - **无本地文件系统持久性**：避免依赖本地文件读写操作
   - **有执行时间限制**：通常在几秒到几十秒之间
   - **有内存限制**：通常在128MB-1GB之间
   - **无法访问主机系统**：不能依赖本地安装的软件或系统库

2. **代码打包限制**：
   - 所有依赖必须在`requirements.txt`中明确声明
   - 不能包含二进制文件或需要编译的库（除非提供预编译版本）
   - 避免过大的依赖包

### 安全设计原则

1. **无状态设计**：
   - 不要依赖于文件系统来存储状态
   - 如需持久化数据，使用Dify提供的KV存储API
   - 每次调用都应该是独立的，不依赖于之前的调用状态

2. **安全的文件操作方式**：
   - 避免本地文件读写（`open()`, `read()`, `write()`等）
   - 临时数据使用内存变量存储
   - 对于大量数据，考虑使用数据库或云存储服务

3. **轻量级实现**：
   - 选择轻量级的依赖库
   - 避免不必要的大型框架
   - 高效管理内存使用

4. **健壮的错误处理**：
   - 为所有API调用添加错误处理
   - 提供明确的错误信息
   - 优雅地处理超时和限制

## 开发流程详解

### 1. 项目初始化
使用`dify plugin init`命令创建基本项目结构：

```bash
./dify plugin init
```

这将引导你输入插件名称、作者和描述，然后生成项目骨架。

### 2. 环境配置
设置Python虚拟环境并安装依赖：

```bash
# 创建虚拟环境
python -m venv venv

# 激活虚拟环境
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# 安装依赖
pip install -r requirements.txt
```

### 3. 开发实现

#### 3.1 需求分析与设计
首先明确插件需要实现的具体功能和输入/输出要求：
- 插件将提供哪些工具？
- 每个工具需要哪些输入参数？
- 每个工具应该返回什么输出？
- 是否需要验证用户凭证？

#### 3.2 实现基础工具函数
在`utils/`目录中创建辅助函数，实现核心功能逻辑：

1. 创建文件：
   ```bash
   mkdir -p utils
   touch utils/__init__.py
   touch utils/helpers.py
   ```

2. 在`helpers.py`中实现与外部服务交互或处理复杂逻辑的函数

#### 3.3 实现工具类
在`tools/`目录中创建工具实现类，对每个功能：

1. 创建YAML文件定义工具参数和描述
2. 创建对应的Python文件实现工具逻辑，继承`Tool`基类并重写`_invoke`方法
3. 每个功能应该有**单独的**文件对，遵循"一个文件一个工具类"原则

#### 3.4 实现凭证验证
如果插件需要API密钥等凭证，在`provider/`目录中实现验证逻辑：

1. 编辑`provider/your_plugin.yaml`添加凭证定义
2. 在`provider/your_plugin.py`中实现`_validate_credentials`方法

### 4. 测试与调试
配置`.env`文件进行本地测试：

```bash
# 复制并编辑环境变量
cp .env.example .env

# 启动本地服务
python -m main
```

#### 调试常见错误
- `Multiple subclasses of Tool`：检查工具文件是否包含多个Tool子类
- `ImportError: cannot import name`：检查导入的函数名是否拼写正确
- `ToolProviderCredentialValidationError`：检查凭证验证逻辑

### 5. 打包与发布
完成开发后，打包插件并可选择发布到市场：

```bash
# 打包插件
./dify plugin package ./your_plugin_dir
```

#### 发布前检查
- 确认README.md和PRIVACY.md已完善
- 确认所有依赖都已添加到requirements.txt
- 检查manifest.yaml中的标签是否正确

## 文件结构详解

```
your_plugin/
├── _assets/             # 图标和视觉资源
├── provider/            # 提供者定义和验证
│   ├── your_plugin.py   # 凭证验证逻辑
│   └── your_plugin.yaml # 提供者配置
├── tools/               # 工具实现
│   ├── your_plugin.py   # 工具功能实现
│   └── your_plugin.yaml # 工具参数和描述
├── utils/               # (可选) 辅助函数
├── working/             # 进度记录和工作文件
├── .env.example         # 环境变量模板
├── main.py              # 入口文件
├── manifest.yaml        # 插件主配置
├── README.md            # 文档
└── requirements.txt     # 依赖列表
```

### 文件位置与组织原则

1. **Python文件位置指导**：
   - 当用户提供单个Python文件时，应先检查其功能性质
   - 通用工具函数应放在`utils/`目录下
   - 具体工具实现应放在`tools/`目录下
   - 凭证验证逻辑应放在`provider/`目录下

2. **代码复制而非从头编写**：
   - 创建新文件时，优先通过复制现有文件作为模板，然后进行修改
   - 使用命令如：`cp tools/existing_tool.py tools/new_tool.py`
   - 这样可确保文件格式和结构符合框架要求

3. **保持框架一致性**：
   - 不随意修改文件结构
   - 不添加框架未定义的新文件类型
   - 遵循既定的命名约定

## 关键文件配置详解

### manifest.yaml
插件的主配置文件，定义了插件的基本信息和元数据。请遵循以下重要原则：

1. **保留已有内容**：
   - 不要删除配置文件中已有的项目，尤其是i18n相关部分
   - 以实际已有代码为基准进行修改和添加

2. **关键字段指导**：
   - **name**：不要修改此字段，它是插件的唯一标识符
   - **label**：建议完善多语言显示名称
   - **description**：建议完善多语言描述
   - **tags**：只能使用以下预定义的标签（每个插件只能选择1-2个最相关的标签）：
     ```
     'search', 'image', 'videos', 'weather', 'finance', 'design', 
     'travel', 'social', 'news', 'medical', 'productivity', 
     'education', 'business', 'entertainment', 'utilities', 'other'
     ```

3. **保持结构稳定**：
   - 除非有特殊需求，不要修改`resource`、`meta`、`plugins`等部分
   - 不要更改`type`和`version`等基础字段

```yaml
version: 0.0.1
type: plugin
author: your_name
name: your_plugin_name  # 不要修改此字段
label:
  en_US: Your Plugin Display Name
  zh_Hans: 你的插件显示名称
description:
  en_US: Detailed description of your plugin functionality
  zh_Hans: 插件功能的详细描述
icon: icon.svg
resource:
  memory: 268435456  # 256MB
  permission: {}
plugins:
  tools:
    - provider/your_plugin.yaml
meta:
  version: 0.0.1
  arch:
    - amd64
    - arm64
  runner:
    language: python
    version: "3.12"
    entrypoint: main
created_at: 2025-04-19T00:00:00.000000+08:00
privacy: PRIVACY.md
tags:
  - utilities  # 只使用预定义的标签
```

### provider/your_plugin.yaml
提供者配置文件，定义了插件所需的凭证和工具列表：

1. **保留关键标识**：
   - **name**：不要修改此字段，保持与manifest.yaml中的name一致
   - 保留已有的i18n配置和结构

2. **完善显示信息**：
   - **label**：建议完善多语言显示名称
   - **description**：建议完善多语言描述

3. **添加新工具**：
   - 在`tools`列表中添加对新工具YAML文件的引用
   - 注意保持路径正确：`tools/feature_name.yaml`

```yaml
identity:
  author: your_name
  name: your_plugin_name  # 不要修改此字段
  label:
    en_US: Your Plugin Display Name
    zh_Hans: 你的插件显示名称
  description:
    en_US: Detailed description of your plugin functionality
    zh_Hans: 插件功能的详细描述
  icon: icon.svg
credentials_for_provider:  # 仅在需要API密钥等凭证时添加
  api_key:
    type: secret-input
    required: true
    label:
      en_US: API Key
      zh_Hans: API密钥
    placeholder:
      en_US: Enter your API key
      zh_Hans: 输入你的API密钥
    help:
      en_US: How to get your API key
      zh_Hans: 如何获取API密钥
    url: https://example.com/get-api-key
tools:  # 工具列表，添加新工具时在此更新
  - tools/feature_one.yaml
  - tools/feature_two.yaml
extra:
  python:
    source: provider/your_plugin.py
```

### tools/feature.yaml
工具配置文件，定义了工具的参数和描述：

1. **保留标识与结构**：
   - **name**：工具的唯一标识，与文件名相对应
   - 保持与现有文件结构一致

2. **完善配置内容**：
   - **label**和**description**：提供清晰的多语言显示内容
   - **parameters**：详细定义工具参数及其属性

3. **参数定义指导**：
   - **type**：选择适当的参数类型（string/number/boolean/file）
   - **form**：设置为`llm`（由AI提取）或`form`（UI配置）
   - **required**：明确是否为必需参数

```yaml
identity:
  name: feature_name  # 与文件名对应
  author: your_name
  label:
    en_US: Feature Display Name
    zh_Hans: 功能显示名称
description:
  human:  # 给人类用户看的描述
    en_US: Description for human users
    zh_Hans: 面向用户的功能描述
  llm: Description for AI models to understand when to use this tool.  # 给AI看的描述
parameters:  # 参数定义
  - name: param_name
    type: string  # string, number, boolean, file等
    required: true
    label:
      en_US: Parameter Display Name
      zh_Hans: 参数显示名称
    human_description:
      en_US: Parameter description for users
      zh_Hans: 面向用户的参数描述
    llm_description: Detailed parameter description for AI models
    form: llm  # llm表示可由AI从用户输入中提取，form表示需要在UI中配置
  # 其他参数...
extra:
  python:
    source: tools/feature.py  # 对应的Python实现文件
# 可选：定义输出的JSON Schema
output_schema:
  type: object
  properties:
    result:
      type: string
      description: Description of the result
```

### tools/feature.py
工具实现类，包含核心业务逻辑：

1. **类名与文件名对应**：
   - 类名遵循`FeatureTool`模式，与文件名相对应
   - 确保一个文件中**只有一个**Tool子类

2. **参数处理最佳实践**：
   - 对于必需参数，使用`.get()`方法并提供默认值：`param = tool_parameters.get("param_name", "")`
   - 对于可选参数，有两种处理方式：

     ```python
     # 方法1: 使用.get()方法（推荐用于单个参数）
     optional_param = tool_parameters.get("optional_param")  # 如果不存在返回None

     # 方法2: 使用try-except（处理多个可选参数）
     try:
         name = tool_parameters["name"]
         issuer_name = tool_parameters["issuer_name"]
     except KeyError:
         name = None
         issuer_name = None
     ```

   - 这种try-except方式是当前处理多个可选参数的临时解决方案
   - 始终在使用参数前验证其存在性和有效性

3. **输出方式**：
   - 使用`yield`返回各种类型的消息
   - 支持文本、JSON、链接和变量输出

```python
from collections.abc import Generator
from typing import Any

from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage

# 导入工具函数，确保函数名称拼写正确
from utils.helpers import process_data

class FeatureTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage, None, None]:
        try:
            # 1. 获取必需参数
            param = tool_parameters.get("param_name", "")

            # 2. 获取可选参数 - 使用try-except方式
            try:
                optional_param1 = tool_parameters["optional_param1"]
                optional_param2 = tool_parameters["optional_param2"]
            except KeyError:
                optional_param1 = None
                optional_param2 = None

            # 另一种可选参数获取方式 - 使用.get()方法
            another_optional = tool_parameters.get("another_optional")  # 如果不存在返回None

            # 3. 验证必需参数
            if not param:
                yield self.create_text_message("Parameter is required.")
                return

            # 4. 实现业务逻辑
            result = self._process_data(param, optional_param1, optional_param2)

            # 5. 返回结果
            # 文本输出
            yield self.create_text_message(f"Processed result: result")
            # JSON输出
            yield self.create_json_message("result": result)
            # 变量输出 (用于工作流)
            yield self.create_variable_message("result_var", result)

        except Exception as e:
            # 错误处理
            yield self.create_text_message(f"Error: str(e)")

    def _process_data(self, param: str, opt1=None, opt2=None) -> str:
        """
        实现具体的业务逻辑

        Args:
            param: 必需的参数
            opt1: 可选参数1
            opt2: 可选参数2

        Returns:
            处理结果
        """
        # 根据参数是否存在执行不同的逻辑
        if opt1 and opt2:
            return f"Processed with all options: param, opt1, opt2"
        elif opt1:
            return f"Processed with option 1: param, opt1"
        elif opt2:
            return f"Processed with option 2: param, opt2"
        else:
            return f"Processed basic: param"
```

### utils/helper.py
辅助函数，实现可复用的功能逻辑：

1. **功能分离**：
   - 将通用功能抽取为单独的函数
   - 专注于单一职责
   - 注意函数命名的一致性（避免导入错误）

2. **错误处理**：
   - 包含适当的异常处理
   - 使用明确的异常类型
   - 提供有意义的错误消息

```python

from typing import Dict, Any, Optional

def call_external_api(endpoint: str, params: Dict[str, Any], api_key: str) -> Dict[str, Any]:
    """
    调用外部API的通用函数

    Args:
        endpoint: API端点URL
        params: 请求参数
        api_key: API密钥

    Returns:
        API响应的JSON数据

    Raises:
        Exception: 如果API调用失败
    """
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    try:
        response = requests.get(endpoint, params=params, headers=headers, timeout=10)
        response.raise_for_status()  # 如果状态码不是200，抛出异常
        return response.json()
    except requests.RequestException as e:
        raise Exception(f"API调用失败: str(e)")
```

### requirements.txt
依赖列表，指定插件所需的Python库：

1. **版本规范**：
   - 使用`~=`指定依赖版本范围
   - 避免过于宽松的版本要求

2. **必要依赖**：
   - 必须包含`dify_plugin`
   - 添加插件功能所需的所有第三方库

```
dify_plugin~=0.0.1b76
requests~=2.31.0
# 其他依赖...
```

## 工具开发最佳实践

### 1. 参数处理模式

1. **必需参数处理**：
   - 使用`.get()`方法并提供默认值：`param = tool_parameters.get("param_name", "")`
   - 验证参数有效性：`if not param: yield self.create_text_message("Error: Required parameter missing.")`

2. **可选参数处理**：
   - **单个可选参数**：使用`.get()`方法，允许返回None：`optional = tool_parameters.get("optional_param")`
   - **多个可选参数**：使用try-except模式处理KeyError：
     ```python
     try:
         param1 = tool_parameters["optional_param1"]
         param2 = tool_parameters["optional_param2"]
     except KeyError:
         param1 = None
         param2 = None
     ```
   - 这种try-except方式是当前处理多个可选参数的临时解决方案

3. **参数验证**：
   - 对必需参数进行验证：`if not required_param: return error_message`
   - 对可选参数进行条件处理：`if optional_param: do_something()`

### 2. 安全的文件操作方式

1. **避免本地文件读写**：
   - Dify插件运行在无服务器环境(如AWS Lambda)中，本地文件系统操作可能不可靠
   - 不要使用`open()`, `read()`, `write()`等直接文件操作
   - 不依赖本地文件作为状态存储

2. **使用内存或API替代**：
   - 临时数据使用内存变量存储
   - 持久化数据使用Dify提供的KV存储API
   - 对于大量数据，考虑使用数据库或云存储服务

### 3. 复制现有文件而非从头创建

对于不确定结构正确性的情况，强烈建议使用下列方法：

```bash
# 复制工具YAML文件作为模板
cp tools/existing_tool.yaml tools/new_tool.yaml

# 复制工具Python实现
cp tools/existing_tool.py tools/new_tool.py

# 同理适用于provider文件
cp provider/existing.yaml provider/new.yaml
```

这样可以确保文件结构和格式符合Dify插件框架的要求，然后再进行针对性修改。

### 4. 拆分工具功能
将复杂功能拆分为多个简单工具，每个工具专注于单一功能：

```
tools/
├── search.py          # 搜索功能
├── search.yaml
├── create.py          # 创建功能
├── create.yaml
├── update.py          # 更新功能
├── update.yaml
├── delete.py          # 删除功能
└── delete.yaml
```

### 2. 参数设计原则
- **必要性**：只要求必要的参数，提供合理默认值
- **类型定义**：选择合适的参数类型（string/number/boolean/file）
- **清晰描述**：为人类和AI提供清晰的参数描述
- **表单定义**：正确区分llm（AI提取）和form（UI配置）参数

### 3. 错误处理
```python
try:
    # 尝试执行操作
    result = some_operation()
    yield self.create_text_message("操作成功")
except ValueError as e:
    # 参数错误
    yield self.create_text_message(f"参数错误: str(e)")
except requests.RequestException as e:
    # API调用错误
    yield self.create_text_message(f"API调用失败: str(e)")
except Exception as e:
    # 其他未预期错误
    yield self.create_text_message(f"发生错误: str(e)")
```

### 4. 代码组织与复用
将可复用的逻辑抽取到utils目录：
```python
# 在工具实现中
from utils.api_client import ApiClient

class SearchTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage, None, None]:
        client = ApiClient(self.runtime.credentials["api_key"])
        results = client.search(tool_parameters["query"])
        yield self.create_json_message(results)
```

### 5. 输出格式
Dify支持多种输出格式：
```python
# 文本输出
yield self.create_text_message("这是文本消息")

# JSON输出
yield self.create_json_message("key": "value")

# 链接输出
yield self.create_link_message("https://example.com")

# 变量输出 (用于工作流)
yield self.create_variable_message("variable_name", "variable_value")
```

## 常见错误与解决方案

### 加载和初始化错误

1. **多个Tool子类错误**
   ```
   Exception: Multiple subclasses of Tool in /path/to/file.py
   ```
   - **原因**：同一个Python文件中定义了多个继承自Tool的类
   - **解决**：
     - 检查文件内容：`cat tools/problematic_file.py`
     - 每个文件保留一个与文件名对应的Tool子类
     - 将其他Tool子类移至对应的单独文件

2. **导入错误**
   ```
   ImportError: cannot import name 'x' from 'module'. Did you mean: 'y'?
   ```
   - **原因**：导入的函数名与实际定义不匹配
   - **解决**：
     - 检查utils中的函数名称：`cat utils/the_module.py`
     - 修正导入语句中的拼写错误
     - 注意函数名中的下划线、大小写等

3. **凭证验证失败**
   ```
   ToolProviderCredentialValidationError: Invalid API key
   ```
   - **原因**：凭证验证逻辑失败
   - **解决**：
     - 检查`_validate_credentials`方法实现
     - 确保API密钥格式正确
     - 添加详细的错误提示信息

### 运行时错误

1. **参数获取错误**
   ```
   KeyError: 'parameter_name'
   ```
   - **原因**：尝试访问不存在的参数
   - **解决**：
     - 使用`get()`代替直接索引：`param = tool_parameters.get("param_name", "")`
     - 确保参数名与YAML定义一致
     - 添加参数存在性检查

2. **API调用错误**
   ```
   requests.exceptions.RequestException: Connection error
   ```
   - **原因**：外部API调用失败
   - **解决**：
     - 添加超时参数：`timeout=10`
     - 使用`try/except`捕获异常
     - 实现重试逻辑

3. **执行超时**
   ```
   TimeoutError: Function execution timed out
   ```
   - **原因**：操作耗时过长
   - **解决**：
     - 优化API调用
     - 分解复杂操作为多个步骤
     - 设置合理的超时限制

### 配置和打包错误

1. **YAML格式错误**
   ```
   yaml.YAMLError: mapping values are not allowed in this context
   ```
   - **原因**：YAML格式不正确
   - **解决**：
     - 检查缩进（使用空格而非制表符）
     - 确保冒号后有空格
     - 使用YAML验证器检查

2. **打包失败**
   ```
   Error: Failed to pack plugin
   ```
   - **原因**：文件结构或依赖问题
   - **解决**：
     - 检查manifest.yaml配置
     - 确保所有引用的文件存在
     - 审查requirements.txt内容

## 代码示例：TOTP工具

以下是一个完整的TOTP (Time-based One-Time Password) 插件示例，展示了良好的代码组织和最佳实践：

### utils/totp_verify.py
```python

def verify_totp(secret_key, totp_code, offset=5, strict=False):
    """
    验证基于时间的一次性密码(TOTP)。

    Args:
        secret_key: 用于生成TOTP的密钥或配置URL
        totp_code: 用户提交的动态令牌
        offset: 允许提前或延迟验证的秒数
        strict: 是否使用严格验证(仅在精确匹配时返回成功)

    Returns:
        包含以下内容的字典:
        - 'status': 'success' 或 'fail'
        - 'detail': 内部消息(不面向终端用户)
    """
    try:
        # 检测是否为配置URL
        if secret_key.startswith('otpauth://'):
            totp = pyotp.parse_uri(secret_key)
        else:
            totp = pyotp.TOTP(secret_key)

        current_time = time.time()

        # 精确时间验证
        if totp.verify(totp_code):
            return 'status': 'success', 'detail': 'Token is valid'

        # 偏移验证
        early_valid = totp.verify(totp_code, for_time=current_time + offset)
        late_valid = totp.verify(totp_code, for_time=current_time - offset)
        off_time_valid = early_valid or late_valid

        detail_message = (
            f"Token is valid but not on time. "
            f"'Early' if early_valid else 'Late' within offset seconds"
            if off_time_valid else
            "Token is invalid"
        )

        if strict:
            return 'status': 'fail', 'detail': detail_message
        else:
            return (
                'status': 'success', 'detail': detail_message
                if off_time_valid
                else 'status': 'fail', 'detail': detail_message
            )
    except Exception as e:
        return {'status': 'fail', 'detail': f'Verification error: {str(e)}'}
```

### tools/totp.yaml
```yaml
identity:
  name: totp
  author: your-name
  label:
    en_US: TOTP Validator
    zh_Hans: TOTP 验证器
description:
  human:
    en_US: Time-based one-time password (TOTP) validator
    zh_Hans: 基于时间的一次性密码 (TOTP) 验证器
  llm: Time-based one-time password (TOTP) validator, this tool is used to validate a 6 digit TOTP code with a secret key or provisioning URI.
parameters:
  - name: secret_key
    type: string
    required: true
    label:
      en_US: TOTP secret key or provisioning URI
      zh_Hans: TOTP 私钥或 URI
    human_description:
      en_US: The secret key or provisioning URI used to generate the TOTP
      zh_Hans: 用于生成 TOTP 的私钥或 URI
    llm_description: The secret key or provisioning URI (starting with 'otpauth://') used to generate the TOTP, this is highly sensitive and should be kept secret.
    form: llm
  - name: user_code
    type: string
    required: true
    label:
      en_US: 6 digit TOTP code to validate
      zh_Hans: 要验证的 6 位 TOTP 代码
    human_description:
      en_US: 6 digit TOTP code to validate
      zh_Hans: 要验证的 6 位 TOTP 代码
    llm_description: 6 digit TOTP code to validate
    form: llm
extra:
  python:
    source: tools/totp.py
output_schema:
  type: object
  properties:
    True_or_False:
      type: string
      description: Whether the TOTP is valid or not, return in string format, "True" or "False".
```

### tools/totp.py
```python
from collections.abc import Generator
from typing import Any

# 正确导入工具函数
from utils.totp_verify import verify_totp

from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage

# 一个文件只包含一个Tool子类
class TotpTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage, None, None]:
        """验证基于时间的一次性密码(TOTP)"""
        # 获取参数，使用get()避免KeyError
        secret_key = tool_parameters.get("secret_key")
        totp_code = tool_parameters.get("user_code")

        # 参数验证
        if not secret_key:
            yield self.create_text_message("Error: Secret key is required.")
            return
        if not totp_code:
            yield self.create_text_message("Error: TOTP code is required.")
            return

        try:
            # 调用工具函数
            result = verify_totp(secret_key, totp_code)

            # 返回结果
            yield self.create_json_message(result)

            # 基于验证结果返回不同的消息
            if result["status"] == "success":
                yield self.create_text_message("Valid")
                yield self.create_variable_message("True_or_False", "True")
            else:
                yield self.create_text_message("Invalid")
                yield self.create_variable_message("True_or_False", "False")

        except Exception as e:
            # 错误处理
            yield self.create_text_message(f"Verification error: str(e)")
```

### tools/secret_generator.py
```python
from collections.abc import Generator
from typing import Any

from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage

# 注意：一个文件只包含一个Tool子类
class SecretGenerator(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage, None, None]:
        """生成TOTP密钥"""
        try:
            # 生成随机密钥
            secret_key = pyotp.random_base32()
            yield self.create_text_message(secret_key)

            # 安全获取可选参数
            name = tool_parameters.get("name")
            issuer_name = tool_parameters.get("issuer_name")

            # 如果提供了名称或发行方，生成配置URI
            if name or issuer_name:
                provisioning_uri = pyotp.totp.TOTP(secret_key).provisioning_uri(
                    name=name, 
                    issuer_name=issuer_name
                )
                yield self.create_variable_message("provisioning_uri", provisioning_uri)

        except Exception as e:
            yield self.create_text_message(f"Error generating secret: str(e)")
```

### requirements.txt
```
dify_plugin~=0.0.1b76
pyotp~=2.9.0
```

这个示例展示了:
- 清晰的功能分离（utils中的工具函数，tools中的工具类）
- 良好的错误处理和参数验证
- 一个文件只包含一个Tool子类
- 详细的注释和文档字符串
- 精心设计的YAML配置

## 状态同步机制

如果用户的描述与你记录的项目状态不同，或者你需要确认当前进度，请执行以下操作：

1. 检查项目文件结构
2. 阅读关键文件
3. 明确告知用户："我注意到项目状态可能与我之前的理解不同，我已重新检查了项目文件并更新了我的认知。"
4. 描述你发现的实际状态
5. 更新working目录中的进度记录

## 首次启动行为

当用户通过"@ai"或类似方式首次激活你时，你应该：

1. **不要假设项目目标**：不要自行假定用户想开发什么类型的插件或功能
2. **不要开始编写代码**：不要在没有明确指示的情况下就开始生成或修改代码
3. **询问用户意图**：礼貌地询问用户希望开发什么类型的插件，需要帮助解决什么问题
4. **提供能力概述**：简要说明你可以提供哪些类型的帮助（代码实现、调试、设计建议等）
5. **请求项目信息**：请用户分享当前项目状态或文件结构，以便你提供更有针对性的帮助

只有在收到明确指示后，才开始提供具体的开发建议或代码实现。

记住，你的主要目标是协助用户高效地完成Dify插件开发，通过持续跟踪状态、提供专业建议和解决技术挑战来实现这一目标。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0211-getting-started-by-prompt.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Dify 插件开发：Hello World 指南
> 来源：`plugin-dev-zh/0211-getting-started-dify-tool.mdx`
> 摘要：本文档提供了从零开始Dify插件开发的详细教程，以创建Telegraph发布插件为例，涉及环境准备、项目初始化、虚拟环境配置、插件核心逻辑开发、本地运行调试、插件元信息完善以及打包发布等环节。

欢迎阅读 Dify 插件开发的入门指南！本教程假设您具备基本的编程背景知识，并有使用 Dify 平台的经验。完成本教程后，您将掌握创建简单 Dify 插件的基础流程，从 Dify 用户迈向插件贡献者。

我们将一步步示范如何开发一个简单的 Telegraph 发布插件。本教程主要使用命令行操作，并辅以 VSCode 作为代码编辑器的示例说明。**建议您先快速通读一遍以了解整体流程，然后再跟着步骤动手操作。**

> **面向 LLM 的说明:** 你也可以在这里使用我们构建的 prompt 来协助你开发插件：[Dify 插件开发：Prompt](./plugin-dev-zh/0211-getting-started-by-prompt)

在开始之前，您可以随时查阅我们提供的 [**开发者速查表 (Cheatsheet)**](./plugin-dev-zh/0131-cheatsheet) 获取常用指令和信息，或在遇到更复杂问题时参考完整的开发者文档。

## 1. 准备开发环境

在开始开发 Dify 插件之前，请确保您的环境中已准备好以下工具：

- **Dify 插件开发脚手架 (CLI):** 这是开发、调试和打包插件的核心工具，也称为 `dify-plugin-daemon` 或“插件开发 SDK”。
- **Python 环境:** 需要 Python 3.12 或更高版本。

### 1.1 安装 Dify 插件开发脚手架 (CLI)

> 更详细的开发环境准备指南，请参考[初始化开发工具](./plugin-dev-zh/0221-initialize-development-tools)。

1. **下载:** 访问 [Dify Plugin CLI Releases](https://github.com/langgenius/dify-plugin-daemon/releases) 页面。根据您的操作系统（Windows, macOS Intel/ARM, Linux）下载对应的最新版本二进制文件。
2. **设置执行权限 (macOS / Linux):**

    - **以下步骤以 macOS (Apple Silicon / M 系列芯片) 为例**，假设下载的文件名为 `dify-plugin-darwin-arm64`。在终端中，进入文件所在目录，并执行以下命令赋予其执行权限：

        ```bash
        chmod +x dify-plugin-darwin-arm64
        ```

    - 对于 Linux 用户，请下载对应的 Linux 版本文件并执行类似 `chmod +x <downloaded_filename>` 的命令。
    - 对于 Windows 用户，下载 `.exe` 文件后通常可直接运行。

3. **验证安装:**

    - 在终端中，执行以下命令检查工具是否能正常运行（请将 `./dify-plugin-darwin-arm64` 替换为您下载的实际文件名或路径）：

        ```bash
        ./dify-plugin-darwin-arm64 version
        ```

    - 如果终端成功输出了版本号信息（例如 `v0.0.1-beta.15`），则说明安装成功。

> **提示 (Tips):**
>
> - **macOS 安全提示:** 若在 macOS 上首次运行时提示“Apple 无法验证”或“无法打开”，请前往“系统设置”→“隐私与安全性”→“安全性”部分，找到相关提示并点击“仍要打开”或“允许”。
> - **简化命令:** 您可以将下载的二进制文件重命名为一个更短的名称（例如 `dify` 或 `dify-plugin`），以便后续使用。示例：`mv dify-plugin-darwin-arm64 dify`，之后即可使用 `./dify version`。
> - **全局安装 (可选):** 如果希望在系统的任何路径下都能直接运行该命令（例如，直接输入 `dify` 而不是 `./dify`），可以将重命名后的文件移动到系统的 `PATH` 环境变量包含的目录中，例如 `/usr/local/bin` (macOS/Linux) 或添加到 Windows 的环境变量中。
>     - 例如 (macOS/Linux): `sudo mv dify /usr/local/bin/`
>     - 配置完成后，直接在终端输入 `dify version` 应能成功输出版本号。

**为方便起见，本文后续将使用 `./dify` 作为 Dify 插件开发脚手架命令的示例。请根据您的实际情况替换为对应的命令。**

## 2. 初始化插件项目

现在，让我们使用脚手架工具创建一个新的插件项目。

1. 打开终端，执行初始化命令：

    ```bash
    ./dify plugin init
    ```

2. 根据提示依次输入插件的基本信息：
    - **Plugin name:** 插件的唯一标识符。例如：`telegraph`
        - _约束: 长度 1-128 字符，只能包含小写字母、数字、连字符(-)和下划线(\_)。_
    - **Author:** 插件作者的标识符。例如：`your-name`
        - _约束: 长度 1-64 字符，只能包含小写字母、数字、连字符(-)和下划线(\_)。_
    - **Description:** 对插件功能的简短描述。例如：`A Telegraph plugin that allows you to publish your content easily`
3. **选择开发语言:** 当提示 `Select language` 时，请选择 `python`。
4. **选择插件类型:** 当提示 `Select plugin type` 时，对于本教程，请选择 `tool`。
5. **选择附加功能:** 接下来会提示是否需要包含 Provider 验证、持久存储等附加功能。对于这个简单的 Hello World 插件，我们暂时不需要这些，可以直接按 **回车键** 跳过所有选项，直到看到成功信息。
6. **确认创建成功:** 当终端输出类似以下信息时，表示插件项目已成功创建：

    ```bash
    [INFO] plugin telegraph created successfully, you can refer to `telegraph/GUIDE.md` for more information about how to develop it
    ```

现在，您的当前目录下应该出现了一个名为 `telegraph` (或您指定的插件名) 的新文件夹，这就是您的插件项目。

## 3. 配置 Python 虚拟环境与依赖

为了隔离项目依赖，推荐使用 Python 虚拟环境。

### 3.1 创建并激活虚拟环境 (命令行方式)

这是**推荐且通用**的方法，不依赖特定 IDE：

1. **进入项目目录:**

    ```bash
    cd telegraph
    ```

2. **创建虚拟环境:** (建议命名为 `venv`)

    ```bash
    python -m venv venv
    ```

3. **激活虚拟环境:**

    - **macOS / Linux:**

        ```bash
        source venv/bin/activate
        ```

    - **Windows (cmd.exe):**

        ```bash
        venv\Scripts\activate.bat
        ```

    - **Windows (PowerShell):**

        ```bash
        venv\Scripts\Activate.ps1
        ```

    - 激活成功后，您的终端提示符前通常会显示 `(venv)` 字样。

### 3.2 安装基础依赖

项目初始化时生成的 `requirements.txt` 文件已包含插件开发所需的基础库 `dify_plugin`。激活虚拟环境后，执行以下命令安装：

```bash
pip install -r requirements.txt
```

### 3.3 (可选) VSCode 集成环境配置

如果您使用 VSCode 作为代码编辑器，可以利用其集成功能来管理 Python 环境：

1. **打开项目文件夹:** 使用 VSCode 打开刚刚创建的 `telegraph` 文件夹。
2. **选择 Python 解释器:**
    - 打开命令面板 (macOS: `Cmd+Shift+P`, Windows/Linux: `Ctrl+Shift+P`)。
    - 输入并选择 `Python: Select Interpreter`。
    - 在弹出的列表中，选择您刚刚创建的虚拟环境中的 Python 解释器（通常路径包含 `.venv/bin/python` 或 `venv\Scripts\python.exe`）。如果列表没有自动显示，您可以选择 `Enter interpreter path...` 手动查找。
    - _(请参考您本地对应的截图 ，它展示了选择解释器的界面)_
3. **安装依赖 (若 VSCode 提示):** VSCode 可能会检测到 `requirements.txt` 文件并提示您安装其中的依赖项。如果出现提示，请确认安装。
    - _(请参考您本地对应的截图 ，它展示了确认安装依赖的界面)_

**请确保后续的所有 `pip install` 命令和运行 `python -m main` 的操作都在已激活的虚拟环境中执行。**

## 4. 开发插件核心逻辑

现在我们开始编写插件代码。本示例将实现一个简单的工具，用于将指定内容发布到 Telegraph。

### 4.1 示例依赖库: `your-telegraph`

我们将使用一个名为 `your-telegraph` 的 Python 库来与 Telegraph API 交互。（_这是一个假设的库名，请确保您实际使用的库是有效的_）。

> `your-telegraph` 是一个简化 Telegraph API 操作的 Python 包装器，可以用几行代码轻松发布内容。

其基本用法可能如下：

```python
# 示例代码，非插件内代码
from ytelegraph import TelegraphAPI

# 需要一个 access_token
ph = TelegraphAPI(access_token="your_telegraph_access_token")

# 创建页面并获取链接
ph_link = ph.create_page_md("My First Page", "# Hello, Telegraph!\n\nThis is my first Telegraph page.")
print(ph_link)
```

我们的目标是在 Dify 插件中实现类似的功能。

### 4.2 添加并配置项目依赖

1. **安装依赖库:** 确保您的虚拟环境已激活，然后在终端中执行：

    ```bash
    pip install your-telegraph
    ```

2. **更新 `requirements.txt`:** 打开项目根目录下的 `telegraph/requirements.txt` 文件，在 `dify_plugin` 下面添加一行，写入刚刚安装的库名：

    ```plaintext
    dify_plugin
    your-telegraph
    ```

    这样做可以确保其他开发者或部署环境能够方便地安装所有必需的依赖。

### 4.3 配置 Provider 凭证

我们的示例需要 `telegraph_access_token`。我们需要在 Provider 配置中定义这个凭证，以便用户在使用插件时可以输入。关于 Provider 配置的更多信息，请参考[一般规范定义](./plugin-dev-zh/0411-general-specifications)。

1. **编辑 Provider YAML:** 打开 `telegraph/provider/telegraph.yaml` 文件。
2. **添加 `credentials_for_provider`:** 在文件末尾（或适当位置）添加以下内容：

    ```yaml
    # ... (文件可能已有的 identity, name, label, description, icon 等保持不变) ...

    credentials_for_provider:
        telegraph_access_token: # 这是凭证的内部名称，将在 Python 代码中使用
            type: secret-input # 输入类型为密码框
            required: true # 此凭证是必需的
            label: # 在 Dify UI 中显示的标签 (支持多语言)
                en_US: Telegraph Access Token
                zh_Hans: Telegraph 访问令牌
                # ... (其他语言)
            placeholder: # 输入框的提示文字 (支持多语言)
                en_US: Enter your Telegraph access token
                zh_Hans: 请输入您的 Telegraph 访问令牌
                # ... (其他语言)
            help: # 帮助提示信息 (支持多语言)
                en_US: How to get your Telegraph access token
                zh_Hans: 如何获取 Telegraph 访问令牌
                # ... (其他语言)
            url: https://telegra.ph/api#createAccount # 点击帮助提示时跳转的 URL
    ```

    - **字段解释:**
        - `telegraph_access_token`: 凭证的唯一标识符，代码中通过 `self.runtime.credentials["telegraph_access_token"]` 来访问用户输入的值。
        - `type: secret-input`: 表示在 Dify 界面上会显示为密码输入框。
        - `required: true`: 表示用户必须填写此凭证才能使用该插件提供的工具。
        - `label`, `placeholder`, `help`: 提供多语言界面文本。
        - `url`: (可选) 提供一个获取凭证的帮助链接。

### 4.4 实现工具 (Tool) 逻辑

现在我们来编写实际执行发布操作的工具代码。

1. **编辑 Tool Python 文件:** 打开 `telegraph/tools/telegraph.py`。
2. **实现 `_invoke` 方法:** 将文件内容替换为以下代码：

    ```python
    from collections.abc import Generator
    from typing import Any
    from ytelegraph import TelegraphAPI # 导入我们使用的库

    from dify_plugin import Tool
    from dify_plugin.entities.tool import ToolInvokeMessage

    class TelegraphTool(Tool):
        """
        一个简单的 Telegraph 发布工具。
        """

        def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage, None, None]:
            """
            根据输入的标题和内容，创建一个新的 Telegraph 页面。

            Args:
                tool_parameters: 一个包含工具输入参数的字典:
                    - p_title (str): Telegraph 页面的标题。
                    - p_content (str): 要发布的 Markdown 格式的内容。

            Yields:
                ToolInvokeMessage: 包含成功创建的 Telegraph 页面 URL 的消息。

            Raises:
                Exception: 如果页面创建失败，则抛出包含错误信息的异常。
            """
            # 1. 从运行时获取凭证
            try:
                access_token = self.runtime.credentials["telegraph_access_token"]
            except KeyError:
                raise Exception("Telegraph Access Token 未配置或无效。请在插件设置中提供。")

            # 2. 获取工具输入参数
            title = tool_parameters.get("p_title", "Untitled") # 使用 .get 提供默认值
            content = tool_parameters.get("p_content", "")

            if not content:
                raise Exception("发布内容不能为空。")

            # 3. 调用库执行操作
            try:
                telegraph = TelegraphAPI(access_token)  # 初始化 Telegraph API
                ph_link = telegraph.create_page_md(title, content)  # 创建页面
            except Exception as e:
                # 如果库调用失败，抛出异常
                raise Exception(f"调用 Telegraph API 失败: e")

            # 4. 返回结果
            # 使用 create_link_message 生成一个包含链接的输出消息
            yield self.create_link_message(ph_link)
    ```

    - **关键点:**
        - 从 `self.runtime.credentials` 获取凭证。
        - 从 `tool_parameters` 获取工具的输入参数（参数名将在下一步的 YAML 中定义）。使用 `.get()` 是更健壮的方式。
        - 调用 `ytelegraph` 库执行实际操作。
        - 使用 `try...except` 捕获可能的错误并抛出异常。
        - 使用 `yield self.create_link_message(url)` 返回一个包含 URL 的结果给 Dify。

### 4.5 配置工具 (Tool) 参数

我们需要告诉 Dify 这个工具接收哪些输入参数。

1. **编辑 Tool YAML 文件:** 打开 `telegraph/tools/telegraph.yaml`。
2. **定义参数:** 将文件内容替换或修改为：

    ```yaml
    identity:
        name: telegraph_publisher # 工具的唯一内部名称
        author: your-name
        label: # 在 Dify UI 中显示的工具名称 (多语言)
            en_US: Publish to Telegraph
            zh_Hans: 发布到 Telegraph
            # ... (其他语言)
    description:
        human: # 给人类用户看的工具描述 (多语言)
            en_US: Publish content to Telegraph as a new page.
            zh_Hans: 将内容作为新页面发布到 Telegraph。
            # ... (其他语言)
        llm: # 给 LLM 看的工具描述 (用于 Agent 模式)
            A tool that takes a title and markdown content, then publishes it as a new page on Telegraph, returning the URL of the published page. Use this when the user wants to publish formatted text content publicly via Telegraph.
    parameters: # 定义工具的输入参数列表
        - name: p_title # 参数的内部名称，与 Python 代码中的 key 对应
          type: string # 参数类型
          required: true # 是否必需
          label: # 在 Dify UI 中显示的参数标签 (多语言)
              en_US: Post Title
              zh_Hans: 文章标题
          human_description: # 给人类用户看的参数描述 (多语言)
              en_US: The title for the Telegraph page.
              zh_Hans: Telegraph 页面的标题。
          llm_description: # 给 LLM 看的参数描述 (指导 Agent 如何填充)
              The title of the post. Should be a concise and meaningful plain text string.
          form: llm # 参数表单类型 ('llm' 或 'form')
        - name: p_content
          type: string
          required: true
          label:
              en_US: Content (Markdown)
              zh_Hans: 内容 (Markdown)
          human_description:
              en_US: The main content for the Telegraph page, written in Markdown format.
              zh_Hans: Telegraph 页面的主要内容，请使用 Markdown 格式编写。
          llm_description: # 强调格式要求对 LLM 很重要
              The full content to be published on the Telegraph page. Must be provided in Markdown format. Ensure proper Markdown syntax for formatting like headings, lists, links, etc.
          form: llm
    extra: # 额外配置
        python:
            source: tools/telegraph.py # 指向实现该工具逻辑的 Python 文件
    ```

    - **字段解释:**
        - `identity`: 工具的基本信息，`name` 是唯一标识。
        - `description`: 分为 `human` (给用户看) 和 `llm` (给 Agent 看)。**`llm` 描述对于 Agent 能否正确理解和使用工具至关重要。**
        - `parameters`: 定义每个输入参数。
            - `name`: 内部名称，需与 Python 代码中 `tool_parameters.get("...")` 的键一致。
            - `type`: 数据类型 (如 `string`, `number`, `boolean` 等)。
            - `required`: 是否必须提供。
            - `label`, `human_description`, `llm_description`: 类似 `identity` 中的描述，但针对具体参数。**`llm_description` 应清晰指导 LLM 如何生成或获取该参数的值，包括格式要求（如此处的 Markdown）。**
            - `form`: 定义参数如何在 Dify 中呈现和填充。`llm` 表示该参数值可以由用户输入、通过变量传入，或者在 Agent 模式下由 LLM 自主决定；`form` 通常表示需要用户在界面上固定填写的配置项。对于工具输入，`llm` 更常见。
        - `extra.python.source`: 指明实现此工具逻辑的 Python 文件路径（相对于项目根目录）。

### 4.6 实现 Provider 凭证验证 (可选但推荐)

为了确保用户提供的凭证有效，我们应该实现验证逻辑。

1. **编辑 Provider Python 文件:** 打开 `telegraph/provider/telegraph.py`。
2. **实现 `_validate_credentials` 方法:** 将文件内容替换为：

    ```python
    from typing import Any
    from dify_plugin import ToolProvider
    from dify_plugin.errors.tool import ToolProviderCredentialValidationError

    class TelegraphProvider(ToolProvider):
        def _validate_credentials(self, credentials: dict[str, Any]) -> None:
            """
            验证提供的 Telegraph Access Token 是否有效。
            尝试使用该 token 创建一个测试页面。
            如果验证失败，应抛出 ToolProviderCredentialValidationError 异常。
            """
            access_token = credentials.get("telegraph_access_token")
            if not access_token:
                raise ToolProviderCredentialValidationError("Telegraph Access Token 不能为空。")

            try:
                # 尝试执行一个需要凭证的简单操作来验证
                from ytelegraph import TelegraphAPI
                ph = TelegraphAPI(access_token=access_token)
                # 尝试创建一个临时的、无害的页面作为验证手段
                # 注意：更好的验证方式可能是调用 API 的 'getAccountInfo' 等只读方法（如果存在）
                test_page = ph.create_page_md("Dify Validation Test", "This is a test page created by Dify plugin validation.")
                # 如果需要，可以考虑立即编辑或删除这个测试页面，但这会增加复杂性
                # print(f"Validation successful. Test page created: test_page")
            except Exception as e:
                # 如果 API 调用失败，说明凭证很可能无效
                raise ToolProviderCredentialValidationError(f"Telegraph 凭证验证失败: e")

    ```

    - **关键点:**
        - 从 `credentials` 字典中获取凭证。
        - 执行一个需要该凭证的 API 调用（最好是只读操作，如获取账户信息；如果没有，创建一个无害的测试页面也可以，但要注意可能产生的副作用）。
        - 如果 API 调用成功，则不抛出异常，表示验证通过。
        - 如果 API 调用失败，则捕获异常并抛出 `ToolProviderCredentialValidationError`，将原始错误信息包含在内。

## 5. 本地运行与调试

现在可以在本地运行插件，并在 Dify 中进行调试了。

1. **准备 `.env` 文件:**

    - 确保您仍在 `telegraph` 项目目录下。
    - 复制环境变量模板文件：

        ```bash
        cp .env.example .env
        ```

    - **编辑 `.env` 文件:** 打开刚刚创建的 `.env` 文件，填入您的 Dify 环境信息：

        ```dotenv
        DIFY_API_HOST=https://your-dify-host.com # 替换为您的 Dify 实例地址 (例如 https://cloud.dify.ai)
        DIFY_API_KEY=your-api-key             # 替换为您的 Dify API 密钥
        ```

        - **获取 Host 和 Key:** 登录您的 Dify 环境，点击右上角的“插件”图标，然后点击调试图标（或类似虫子形状）。在弹出的窗口中，复制“API 密钥 (Key)”和“主机地址 (Host)”。 _(请参考您本地对应的截图 ，它展示了获取密钥和主机地址的界面)_

2. **启动本地插件服务:**

    - 确保您的 Python 虚拟环境已激活。
    - 在 `telegraph` 目录下，运行主程序：

        ```bash
        python -m main
        ```

    - **观察终端输出:** 如果一切正常，您应该会看到类似以下的日志信息，表示插件工具已成功加载并连接到 Dify：

        ```json
        {"event": "log", "data": {"level": "INFO", "message": "Installed tool: telegraph_publisher", "timestamp": 1678886400.123456}}
        {"event": "log", "data": {"level": "INFO", "message": "Plugin daemon started, waiting for requests...", "timestamp": 1678886400.123457}}
        ```

3. **在 Dify 中查看并测试:**

    - **刷新 Dify 页面:** 回到您的 Dify 环境（浏览器中），刷新插件管理页面 (通常是 `https://your-dify-host.com/plugins`)。
    - **查找插件:** 您应该能在列表中看到名为 "Telegraph" (或您在 Provider YAML 中定义的 `label`) 的插件，并且可能带有一个“调试中”的标记。
    - **添加凭证:** 点击该插件，系统会提示您输入之前在 `provider/telegraph.yaml` 中定义的 "Telegraph Access Token"。输入有效的 token 并保存。如果您的验证逻辑 (`_validate_credentials`) 实现正确，这里会进行验证。 _(请参考您本地对应的截图 ，它展示了插件出现在列表并请求授权的界面)_
    - **在应用中使用:** 现在，您可以在 Dify 的应用（如 Chatbot 或 Workflow）中添加这个工具节点，并尝试调用它了！当您在应用中运行并触发该工具时，请求会被转发到您本地运行的 `python -m main` 进程进行处理。您可以在本地终端看到相关的日志输出，并进行调试。

4. **停止本地服务:** 在终端中按下 `Ctrl + C` 可以停止本地插件服务。

这个运行 -> 测试 -> 停止 -> 修改代码 -> 重新运行 的循环是插件开发的主要流程。

## 6. 完善插件元信息

为了让插件更专业、更易于被发现和理解，我们需要完善一些展示性的信息。

1. **图标 (Icon):**
    - 在 `telegraph/_assets` 目录下放置一个代表您插件的图标文件（例如 `icon.png`, `icon.svg`）。推荐使用正方形、清晰的图片。
2. **Provider 信息 (`provider/telegraph.yaml`):**

    - 确保 `identity` 部分的 `label` (显示名称), `description` (功能描述), 和 `icon` (填写图标文件名，如 `icon.png`) 已填写并支持多语言。这部分信息主要在 Dify 应用编排界面中展示给_使用_插件的用户。

    ```yaml
    identity:
        author: your-name
        name: telegraph # 内部名称，保持不变
        label:
            en_US: Telegraph
            zh_Hans: Telegraph 发布文章
        description:
            en_US: A Telegraph plugin that allow you publish your content easily
            zh_Hans: 一个让您轻松发布内容的Telegraph插件
        icon: icon.png # 引用 _assets 目录下的图标文件名
    ```

3. **插件清单 (`manifest.yaml`):**

    - 编辑项目根目录下的 `telegraph/manifest.yaml` 文件。这是整个插件的“身份证”，其信息将展示在 Dify 的**插件管理页面**和**插件市场 (Marketplace)** 中。
    - 务必更新或确认以下字段：
        - `label`: 插件的**主要显示名称** (支持多语言)。
        - `description`: 对插件功能的**整体简介** (支持多语言)，应清晰概括其核心价值。注意市场展示可能有长度限制。
        - `icon`: 插件的**主图标** (直接填写 `_assets` 目录下的图标文件名，如 `icon.png`)。
        - `tags`: 为插件添加分类标签，有助于用户在市场中筛选。可选值请参考 Dify 提供的枚举或文档说明 (例如 `media`, `tools`, `data-processing` 等)。可参考 [ToolLabelEnum 定义](https://github.com/langgenius/dify-plugin-sdks/blob/main/python/dify_plugin/entities/tool.py)。

    ```yaml
    label:
        en_US: Telegraph Publisher
        zh_Hans: Telegraph 发布助手
    description:
        en_US: Easily publish content to Telegraph pages directly from your Dify applications. Supports Markdown formatting.
        zh_Hans: 从 Dify 应用中轻松将内容发布为 Telegraph 页面，支持 Markdown 格式。
    icon: icon.png
    tags: ['media', 'content-creation'] # 示例标签
    # ... (author, name 等其他字段保持不变)
    ```

4. **README 和隐私政策:**
    - `README.md`: 编辑项目根目录下的 `README.md` 文件。它将作为插件在 **Marketplace** 上的详细介绍页面，应包含更丰富的信息，如功能详述、使用示例、配置指南、常见问题等。可参考 [AWS 插件市场页面](https://marketplace.dify.ai/plugins/langgenius/aws_tools) 的样式。
    - `PRIVACY.md`: 如果您计划将插件发布到官方 Marketplace，需要提供隐私政策说明文件 `PRIVACY.md`，描述插件如何处理数据。

## 7. 打包插件

当插件开发完成并通过本地测试后，您可以将其打包成一个 `.difypkg` 文件，用于分发或安装。关于插件打包和发布的详细信息，请参考[发布概览](./plugin-dev-zh/0321-release-overview)。

1. **返回上级目录:** 确保您的终端当前路径在 `telegraph` 文件夹的**上一级**。

    ```bash
    cd ..
    ```

2. **执行打包命令:**

    ```bash
    ./dify plugin package ./telegraph
    ```

    (请将 `./telegraph` 替换为您插件项目的实际路径)

3. **获取打包文件:** 命令执行成功后，将在当前目录下生成一个名为 `telegraph.difypkg` (或 `您的插件名.difypkg`) 的文件。

这个 `.difypkg` 文件就是一个完整的插件包。您可以：

- 在 Dify 的插件管理页面手动**上传并安装**它。
- 将其**分享**给其他人安装。
- 按照 Dify 的规范和流程，将其**发布到官方的插件市场 (Marketplace)**，让所有 Dify 用户都能发现和使用您的插件。具体发布流程请参考[发布到 Dify 市场](./plugin-dev-zh/0322-release-to-dify-marketplace)。

恭喜！您已经完成了第一个 Dify 插件的开发、调试、完善和打包的全过程。现在您可以基于这个基础，探索更复杂、更强大的插件功能了。

## 下一步学习

- [远程调试插件](./plugin-dev-zh/0411-remote-debug-a-plugin) - 了解更高级的插件调试技巧
- [持久化存储](./plugin-dev-zh/0411-persistent-storage-kv) - 学习如何在插件中使用数据存储
- [Slack 机器人插件开发示例](./plugin-dev-zh/0432-develop-a-slack-bot-plugin) - 查看更复杂的插件开发案例
- [工具插件](./plugin-dev-zh/0222-tool-plugin) - 探索工具插件的高级功能

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0211-getting-started-dify-tool.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 快速接入一个新模型
> 来源：`plugin-dev-zh/0211-getting-started-new-model.mdx`
> 摘要：本文档指导非专业开发者如何为Dify添加新模型，重点在于通过修改配置文件为现有模型供应商添加新型号模型。包括Fork仓库、复制与修改模型配置、更新供应商版本、本地测试以及提交贡献的完整流程。

欢迎来到 Dify 的插件开发世界！Dify 的强大功能离不开社区贡献者的共同努力。我们相信，即使你不是专业的程序员，只要你对 AI 技术充满热情并愿意查阅资料，也能为 Dify 贡献自己的一份力量，例如帮助 Dify 支持更多、更新的 AI 模型。

本文将以最简明的方式，带你完成最常见也最简单的贡献：为一个 Dify **已经支持**的模型供应商，添加一个**新型号**的模型。这种方式通常**只需要修改配置文件**，无需编写代码，非常适合作为你的第一个贡献！

> **相关概念**：在开始前，建议你阅读[模型插件](./plugin-dev-zh/0131-model-plugin-introduction)文档，了解模型插件的基本概念和结构。

**这种快速接入方式适用于：**

- 新模型属于 Dify 已有插件支持的供应商（如 OpenAI, Google Gemini, Anthropic Claude 等）。
- 新模型与同系列其他模型使用相同的 API 认证和基础调用逻辑。
- 主要区别在于模型 ID、上下文长度、最大 Token 数、定价等配置参数。

_(如果你需要添加的模型需要新的 API 逻辑或支持特殊功能，那将涉及到 Python 代码编写，请参考 [创建新模型提供者](./plugin-dev-zh/0222-creating-new-model-provider) 获取更详细的指南。)_

**准备工作:**

- 熟悉基本的 Git 操作 (Fork, Clone, Pull Request)。
- 一个 GitHub 账号。
- 安装并配置好 Dify 插件开发工具包 (参考 [初始化开发工具](./plugin-dev-zh/0221-initialize-development-tools))。

**操作步骤:**

1. **Fork & Clone 官方插件仓库:**

    - 访问 Dify 官方插件仓库 `https://github.com/langgenius/dify-official-plugins`。
    - 点击 "Fork" 按钮，将仓库复刻到你自己的 GitHub 账号下。
    - 使用 Git 将你 Fork 的仓库 Clone 到你的本地电脑。

2. **找到并复制模型配置文件:**

    - 在本地仓库中，导航到 `models/` 目录下，找到你想要添加模型的供应商文件夹，例如 `vertex_ai`。
    - 进入该供应商对应的模型类型子目录，通常是 `models/llm/` (如果是文本生成模型)。
    - 在该目录下，找到一个与你要添加的新型号最相似的现有模型的 YAML 配置文件（例如 `gemini-1.0-pro-001.yaml`）。
    - 复制这个 YAML 文件，并将其重命名为能清晰标识新型号的名称（例如 `gemini-1.5-pro-latest.yaml`）。

3. **修改模型配置 (YAML):**

    - 打开你刚刚重命名的 YAML 文件 (例如 `gemini-1.5-pro-latest.yaml`)。
    - **核心步骤：** 参考**模型供应商的官方文档**，仔细核对并修改文件中的以下关键信息：
        - `model`: **必须**更新为新型号的官方 API 标识符。
        - `label`: **必须**更新为在 Dify 界面中展示给用户的模型名称 (建议提供 `en_US` 和 `zh_Hans` 两种语言)。
        - `model_properties`: 更新 `context_size` (上下文窗口大小)。
        - `parameter_rules`: 检查并更新模型参数的限制，特别是 `max_tokens` (最大输出 Token 数) 的 `default`, `min`, `max` 值。
        - `pricing`: 更新模型的输入 (`input`) 和输出 (`output`) 定价，以及单位 (`unit`, 通常是 `0.000001` 表示百万 Token) 和货币 (`currency`)。
    - _(参考)_ 关于模型 YAML 文件各字段的详细规范，请查阅 [模型设计规则](./plugin-dev-zh/0411-model-designing-rules) 和 [模型 Schema 定义](./plugin-dev-zh/0412-model-schema)。

    **示例 (添加 Gemini 1.5 Pro):**

    | 参数              | 可能的旧模型 (示例)  | 新 Gemini 1.5 Pro (示例) | 说明                                |
    | :---------------- | :------------------- | :----------------------- | :---------------------------------- |
    | `model`           | `gemini-1.0-pro-001` | `gemini-1.5-pro-latest`  | **必须**修改为官方模型 ID           |
    | `label: en_US`    | Gemini 1.0 Pro       | Gemini 1.5 Pro           | **必须**修改为用户可见标签          |
    | `context_size`    | 30720                | 1048576                  | **必须**根据官方文档修改            |
    | `max_tokens` (下) | 2048                 | 8192                     | **必须**根据官方文档修改默认/最大值 |

4. **更新供应商 Manifest 版本:**

    - 回到该模型供应商的根目录 (例如 `models/vertex_ai/`)。
    - 找到并打开 `manifest.yaml` 文件。
    - 将其中的 `version` 字段递增一个小版本号 (例如 `version: 0.0.8` -> `version: 0.0.9`)。这告诉 Dify 这是一个更新。

5. **打包与本地测试:**

    - 打开你的终端 (命令行工具)。
    - **确保你的当前目录是 `dify-official-plugins` 仓库的根目录** (即包含 `models`, `tools` 等文件夹的那个目录)。
    - 运行打包命令：

    ```bash
    # 将 <provider_name> 替换为实际的供应商目录名，例如 cohere 或 vertex_ai
    dify plugin package models/<provider_name>
    ```

    - _成功后，你会看到类似 `plugin packaged successfully, output path: <provider_name>.difypkg` 的提示，并在当前项目根目录下生成一个名为 `<provider_name>.difypkg` 的插件包文件。_
    - 登录你的 Dify 实例 (本地部署或云版本均可)。
    - 点击 Dify 页面最顶部导航栏右侧的 **"插件"** 菜单项。
    - 在插件页面，点击 **"安装插件"** 按钮。
    - 选择 **"本地插件"** 选项卡。
    - 点击上传区域，选择或拖拽你刚刚在本地生成的 `<provider_name>.difypkg` 文件进行上传。
    - 等待插件安装或更新完成。
    - 安装成功后，通常需要前往 "设置" -> "模型供应商" 找到对应的供应商，并配置你的 API 凭证（如果你之前没有配置过的话）。
    - 创建一个新的 Dify 应用或编辑现有应用，在 "提示词编排" -> "模型" 设置中，尝试选择你新添加的模型。进行一些简单的对话或调用测试，确保它能正常工作并返回预期结果。

6. **提交你的贡献:**
    - 本地测试无误后，将你的修改（新的模型 YAML 文件和更新后的 `manifest.yaml`）通过 Git 提交 (commit) 并推送 (push) 到你 Fork 的 GitHub 仓库。
    - 在 GitHub 上，向 `langgenius/dify-official-plugins` 主仓库发起一个 Pull Request (PR)。在 PR 描述中，可以简要说明你添加了哪个模型，并附上该模型官方文档的链接，方便审核者确认参数。

---

**然后呢？**

一旦你的 PR 被审核通过并合并，你的贡献就会成为 Dify 官方插件的一部分，所有 Dify 用户都能方便地使用这个新模型了！

这种快速接入方法是让 Dify 支持新模型的最快途径。当然，如果未来这个模型需要支持更复杂的功能（例如图片输入、函数调用等），那么可能就需要有经验的开发者对插件进行代码层面的更新了。但你现在完成的这一步，已经是非常有价值的贡献！

**探索更多:**

- [模型 Schema 定义](./plugin-dev-zh/0412-model-schema) (了解模型 YAML 文件的详细规则)
- [模型设计规则](./plugin-dev-zh/0411-model-designing-rules) (了解模型参数设计的规范)
- [一般规范定义](./plugin-dev-zh/0411-general-specifications) (了解 `manifest.yaml` 的作用)
- [创建新模型提供者](./plugin-dev-zh/0222-creating-new-model-provider) (了解如何添加新的模型提供商)
- [发布至 Dify 市场](./plugin-dev-zh/0322-release-to-dify-marketplace) (学习如何发布你的插件)
- [Dify 官方插件仓库](https://github.com/langgenius/dify-official-plugins) (查看其他插件的例子)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0211-getting-started-new-model.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 初始化开发工具
> 来源：`plugin-dev-zh/0221-initialize-development-tools.mdx`
> 摘要：本文档详细介绍了Dify插件开发前的必要准备工作，包括安装Dify插件CLI工具（dify-plugin-daemon）和配置Python环境（版本要求≥3.12）的完整步骤。文档还提供了各类型插件开发的参考链接。

开发 Dify 插件需要进行以下准备。本文档是开始[插件开发](./plugin-dev-zh/0111-getting-started-dify-plugin)的第一步。

* Dify 插件 CLI 工具
* Python 环境，版本号 ≥ 3.12

> Dify 插件 CLI 工具又称为 `dify-plugin-daemon`，可以被视作**插件开发 SDK**。

### **1. 安装 Dify 插件 CLI 工具**

Dify 插件 CLI 工具可以通过 Homebrew（在 Linux 和 macOS 上）或独立的二进制可执行文件（在 Windows、Linux 和 macOS 上）进行安装。

#### 通过 Homebrew 安装

对于 macOS 和 Linux 用户，建议使用 [Homebrew](https://brew.sh/) 安装 Dify 插件 CLI 工具。

首先添加 [Dify 插件 CLI 工具的 Homebrew 配方](https://github.com/langgenius/homebrew-dify)，然后使用 `brew install` 命令进行安装。

```bash
brew tap langgenius/dify
brew install dify
```

要检查安装是否成功，请运行 `dify version`，应该会显示版本代码。
```bash
dify version
```

要升级 Dify 插件 CLI 工具，请运行以下命令：

```bash
brew upgrade dify
```

#### 通过二进制可执行文件安装

**下载二进制可执行文件：**

访问 [Dify Plugin CLI](https://github.com/langgenius/dify-plugin-daemon/releases) 项目地址，在发布页面的资产列表中，选择并下载适合操作系统（Linux / macOS / Windows）和芯片架构（`amd64` 为 x86 芯片 / `arm64` 为 ARM 或 Apple 的 M 芯片）的二进制可执行文件。

本文**以装载 M 系列芯片的 macOS** 为例。下载 `dify-plugin-darwin-arm64` 文件后，赋予其执行权限。

```bash
chmod +x ./dify-plugin-darwin-arm64
mv ./dify-plugin-darwin-arm64 ./dify
```

要检查安装是否成功，请运行 `./dify version`，应该会显示版本代码。
```bash
./dify version
```

> 若提示 “Apple 无法验证” 错误，请前往 **“设置 → 隐私与安全性 → 安全性”**，轻点 “仍要打开” 按钮。

运行命令后，终端若返回类似 `v0.0.1-beta.15` 的版本号信息，则说明安装成功。

> **💡 提示：**
>
> 如果想要在系统全局使用 `dify` 命令运行 CLI 工具，建议将该二进制文件重命名为 `dify` 并拷贝至 `/usr/local/bin` 系统路径内。
> 
> 配置完成后，在终端输入 `dify version` 命令后将输出版本号信息。
> 
> ![](https://assets-docs.dify.ai/2025/02/74e57a57c1ae1cc70f4a45084cbbb37e.png)

### **2. 初始化 Python 环境**

详细说明请参考 [Python 安装教程](https://pythontest.com/python/installing-python-3-11/)，或询问 LLM 安装版本号 ≥ 3.12 的 Python 环境。

### 3. 开发插件

请参考以下内容查看不同类型的插件开发示例：

- [工具插件开发指南](./plugin-dev-zh/0211-getting-started-dify-tool) - Hello World 入门教程
- [模型插件开发指南](./plugin-dev-zh/0211-getting-started-new-model) - 快速接入一个新模型
- [Agent策略插件开发指南](./plugin-dev-zh/9433-agent-strategy-plugin) - 创建自定义推理策略
- [扩展插件开发指南](./plugin-dev-zh/9231-extension-plugin) - 通过 Webhook 实现外部服务集成
- [插件打包和发布](./plugin-dev-zh/0321-release-overview) - 发布您的插件

## 下一步学习

- [Dify 插件开发：Hello World 指南](./plugin-dev-zh/0211-getting-started-dify-tool) - 开始您的第一个插件开发
- [插件开发速查表](./plugin-dev-zh/0131-cheatsheet) - 了解常用命令和概念
- [一般规范定义](./plugin-dev-zh/0411-general-specifications) - 学习插件元数据配置

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0221-initialize-development-tools.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 实现标准的模型集成
> 来源：`plugin-dev-zh/0222-creating-new-model-provider-extra.mdx`
> 摘要：本文档面向需要编写Python代码以添加或增强Dify模型支持的开发者，详细指导如何创建目录结构、编写模型配置、实现模型调用逻辑、调试和发布插件的完整流程，包含了核心方法实现和错误处理的细节。

本文档是为需要通过编写 Python 代码来为 Dify 添加或增强模型支持的开发者准备的标准指南。当你需要添加的模型涉及新的 API 调用逻辑、特殊参数处理或 Dify 需要显式支持的新功能（如 Vision, Tool Calling）时，就需要遵循本指南的步骤。

**阅读本文前，建议你：**

* 具备 Python 编程基础和面向对象编程的基本理解。
* 熟悉你想要集成的模型供应商提供的 API 文档和认证方式。
* 已安装并配置好 Dify 插件开发工具包 (参考 [初始化开发工具](../initialize-development-tools.md))。
* （可选）阅读 [模型插件介绍](link-to-conceptual-intro) 文档，了解模型插件的基本概念和架构。

本指南将引导你完成创建目录结构、编写模型配置 (YAML)、实现模型调用逻辑 (Python) 以及调试和发布插件的全过程。

---

## 第 1 步: 创建目录结构

一个组织良好的目录结构是开发可维护插件的基础。你需要为你的模型供应商插件创建特定的目录和文件。

1. **定位或创建供应商目录:** 在你的插件项目（通常是 `dify-official-plugins` 的本地克隆）的 `models/` 目录下，找到或创建以模型供应商命名的文件夹（例如 `models/my_new_provider`）。
2. **创建 `models` 子目录:** 在供应商目录下，创建 `models` 子目录。
3. **按模型类型创建子目录:** 在 `models/models/` 目录下，为你需要支持的**每种模型类型**创建一个子目录。常见的类型包括：
    * `llm`: 文本生成模型
    * `text_embedding`: 文本 Embedding 模型
    * `rerank`: Rerank 模型
    * `speech2text`: 语音转文字模型
    * `tts`: 文字转语音模型
    * `moderation`: 内容审查模型
4. **准备实现文件:**
    * 在每个模型类型目录下（例如 `models/models/llm/`），你需要创建一个 Python 文件来实现该类型模型的调用逻辑（例如 `llm.py`）。
    * 同样在该目录下，你需要为该类型下的每个具体模型创建一个 YAML 配置文件（例如 `my-model-v1.yaml`）。
    * （可选）可以创建一个 `_position.yaml` 文件来控制该类型下模型在 Dify UI 中的显示顺序。

**示例结构 (假设供应商 `my_provider` 支持 LLM 和 Embedding):**

```bash
models/my_provider/
├── models                # 模型实现和配置目录
│   ├── llm               # LLM 类型
│   │   ├── _position.yaml  (可选, 控制排序)
│   │   ├── my-llm-model-v1.yaml
│   │   ├── my-llm-model-v2.yaml
│   │   └── llm.py          # LLM 实现逻辑
│   └── text_embedding    # Embedding 类型
│       ├── _position.yaml  (可选, 控制排序)
│       ├── my-embedding-model.yaml
│       └── text_embedding.py # Embedding 实现逻辑
├── provider              # 供应商级别代码目录
│   └── my_provider.py    (用于凭证验证等, 参考“创建模型供应商”文档)
└── manifest.yaml         # 插件清单文件
```

---

## 第 2 步: 定义模型配置 (YAML)

对于每个具体模型，你需要创建一个 YAML 文件来描述其属性、参数和功能，以便 Dify 能够正确地理解和使用它。

1. **创建 YAML 文件:** 在对应的模型类型目录下（例如 `models/models/llm/`），为你要添加的模型创建一个 YAML 文件，文件名通常与模型 ID 保持一致或具有描述性（例如 `my-llm-model-v1.yaml`）。
2. **编写配置内容:** 遵循 [AIModelEntity Schema Definition](../../../schema-definition/model/model-designing-rules.md#aimodelentity) 规范编写内容。关键字段包括：
    * `model`: (必需) 模型的官方 API 标识符。
    * `label`: (必需) 在 Dify UI 中显示的名称 (支持多语言)。
    * `model_type`: (必需) 必须与所在目录类型一致 (如 `llm`)。
    * `features`: (可选) 声明模型支持的特殊功能 (如 `vision`, `tool-call`, `stream-tool-call` 等)。
    * `model_properties`: (必需) 定义模型固有属性，如 `mode` (`chat` 或 `completion`), `context_size`。
    * `parameter_rules`: (必需) 定义用户可调参数及其规则 (名称 `name`, 类型 `type`, 是否必须 `required`, 默认值 `default`, 范围 `min`/`max`, 选项 `options` 等)。可以使用 `use_template` 引用预定义模板简化常见参数（如 `temperature`, `max_tokens`）的配置。
    * `pricing`: (可选) 定义模型的计费信息。

**示例 (`claude-3-5-sonnet-20240620.yaml`):**

```yaml
model: claude-3-5-sonnet-20240620
label:
  en_US: claude-3-5-sonnet-20240620
model_type: llm
features:
  - agent-thought
  - vision
  - tool-call
  - stream-tool-call
  - document
model_properties:
  mode: chat
  context_size: 200000
parameter_rules:
  - name: temperature
    use_template: temperature
  - name: top_p
    use_template: top_p
  - name: max_tokens
    use_template: max_tokens
    required: true
    default: 8192
    min: 1
    max: 8192 # 注意 Dify 层面可能有限制
pricing:
  input: '3.00'
  output: '15.00'
  unit: '0.000001' # 每百万 token
  currency: USD
```

---

## 第 3 步: 编写模型调用代码 (Python)

这是实现模型功能的和核心步骤。你需要在对应模型类型的 Python 文件中（例如 `llm.py`）编写代码来处理 API 调用、参数转换和结果返回。

1. **创建/编辑 Python 文件:** 在模型类型目录下（例如 `models/models/llm/`）创建或打开相应的 Python 文件（例如 `llm.py`）。
2. **定义实现类:**
    * 定义一个类，例如 `MyProviderLargeLanguageModel`。
    * 该类必须继承自 Dify 插件 SDK 中对应的**模型类型基类**。例如，对于 LLM，需要继承 `dify_plugin.provider_kits.llm.LargeLanguageModel`。

    ```python

    from typing import Union, Generator, Optional, List
    from dify_plugin.provider_kits.llm import LargeLanguageModel # 导入基类
    from dify_plugin.provider_kits.llm import LLMResult, LLMResultChunk, LLMUsage # 导入结果和用量类
    from dify_plugin.provider_kits.llm import PromptMessage, PromptMessageTool # 导入消息和工具类
    from dify_plugin.errors.provider_error import InvokeError, InvokeAuthorizationError # 导入错误类
    # 假设你有一个 vendor_sdk 用于调用 API
    # import vendor_sdk

    logger = logging.getLogger(__name__)

    class MyProviderLargeLanguageModel(LargeLanguageModel):
        # ... 实现方法 ...
    ```

3. **实现关键方法:** (具体需要实现的方法取决于继承的基类，以下以 LLM 为例)
    * `_invoke(...)`: **核心调用方法**。
        * **签名:** `def _invoke(self, model: str, credentials: dict, prompt_messages: List[PromptMessage], model_parameters: dict, tools: Optional[List[PromptMessageTool]] = None, stop: Optional[List[str]] = None, stream: bool = True, user: Optional[str] = None) -> Union[LLMResult, Generator[LLMResultChunk, None, None]]:`
        * **职责:**
            * 使用 `credentials` 和 `model_parameters` 准备 API 请求。
            * 将 Dify 的 `prompt_messages` 格式转换为供应商 API 所需的格式。
            * 处理 `tools` 参数以支持 Function Calling / Tool Use (如果模型支持)。
            * 根据 `stream` 参数决定是进行流式调用还是同步调用。
            * **流式返回:** 如果 `stream=True`，此方法必须返回一个生成器 (`Generator`)，通过 `yield` 逐块返回 `LLMResultChunk` 对象。每个 chunk 包含部分结果（文本、工具调用块等）和可选的用量信息。
            * **同步返回:** 如果 `stream=False`，此方法必须返回一个完整的 `LLMResult` 对象，包含最终的文本结果、完整的工具调用列表以及总的用量信息 (`LLMUsage`)。
        * **实现模式:** 强烈建议将同步和流式逻辑拆分到内部帮助方法中。

        ```python
        def _invoke(self, ..., stream: bool = True, ...) -> Union[LLMResult, Generator[LLMResultChunk, None, None]]:
            # 准备 API 请求参数 (认证、模型参数转换、消息格式转换等)
            api_params = self._prepare_api_params(credentials, model_parameters, prompt_messages, tools, stop)

            try:
                if stream:
                    return self._invoke_stream(model, api_params, user)
                else:
                    return self._invoke_sync(model, api_params, user)
            except vendor_sdk.APIError as e:
                # 处理 API 错误, 映射到 Dify 错误 (参考 _invoke_error_mapping)
                # ... raise mapped_error ...
                pass # Replace with actual error handling
            except Exception as e:
                logger.exception("Unknown error during model invocation")
                raise e # Or raise a generic InvokeError

        def _invoke_stream(self, model: str, api_params: dict, user: Optional[str]) -> Generator[LLMResultChunk, None, None]:
            # 调用 vendor_sdk 的流式接口
            # for api_chunk in vendor_sdk.create_stream(...):
            #     # 将 api_chunk 转换为 LLMResultChunk
            #     dify_chunk = self._convert_api_chunk_to_llm_result_chunk(api_chunk)
            #     yield dify_chunk
            pass # Replace with actual implementation

        def _invoke_sync(self, model: str, api_params: dict, user: Optional[str]) -> LLMResult:
            # 调用 vendor_sdk 的同步接口
            # api_response = vendor_sdk.create_sync(...)
            # 将 api_response 转换为 LLMResult (包括 message.content, tools, usage)
            # dify_result = self._convert_api_response_to_llm_result(api_response)
            # return dify_result
            pass # Replace with actual implementation
        ```

    * `validate_credentials(self, model: str, credentials: dict) -> None`: (必需) 用于在用户添加或修改凭证时验证其有效性。通常通过调用一个简单的、低成本的 API 端点（如列出可用模型、检查余额等）来实现。如果验证失败，应抛出 `CredentialsValidateFailedError` 或其子类。
    * `get_num_tokens(self, model: str, credentials: dict, prompt_messages: List[PromptMessage], tools: Optional[List[PromptMessageTool]] = None) -> int`: (可选但推荐) 用于预估给定输入的 Token 数量。如果无法准确计算或 API 不支持，可以返回 0。
    * `@property _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]`: (必需) 定义一个**错误映射**字典。键是 Dify 的标准 `InvokeError` 子类，值是供应商 SDK 可能抛出的需要被映射到该标准错误的异常类型列表。这对于 Dify 统一处理不同供应商的错误至关重要。

        ```python
        @property
        def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
            # 示例映射
            mapping = 
                InvokeAuthorizationError: [
                    vendor_sdk.AuthenticationError,
                    vendor_sdk.PermissionDeniedError,
                ],
                InvokeRateLimitError: [
                    vendor_sdk.RateLimitError,
                ],
                # ... 其他映射 ...

            # 可以在这里加入基类的默认映射 (如果基类提供的话)
            # base_mapping = super()._invoke_error_mapping
            # mapping.update(base_mapping) # 注意合并策略
            return mapping
        ```

---

## 第 4 步: 调试插件

在将插件贡献给社区之前，充分的测试和调试是必不可少的。Dify 提供了远程调试功能，让你可以在本地修改代码并实时在 Dify 实例中测试效果。

1. **获取调试信息:**
    * 在你的 Dify 实例中，进入 "插件管理" 页面 (可能需要管理员权限)。
    * 点击页面右上角的 "调试插件"，获取你的 `调试 Key` 和 `远程服务器地址` (例如 `http://<your-dify-domain>:5003`)。
2. **配置本地环境:**
    * 在你的本地插件项目**根目录**下，找到或创建 `.env` 文件 (可从 `.env.example` 复制)。
    * 编辑 `.env` 文件，填入调试信息：

      ```dotenv
      INSTALL_METHOD=remote
      REMOTE_INSTALL_HOST=<your-dify-domain-or-ip> # Dify 服务器地址
      REMOTE_INSTALL_PORT=5003                     # 调试端口
      REMOTE_INSTALL_KEY=****-****-****-****-**** # 你的调试 Key
      ```

3. **启动本地插件服务:**
    * 在插件项目根目录下，确保你的 Python 环境已激活（如果使用虚拟环境）。
    * 运行主程序：

      ```bash
      python -m main
      ```

    * 观察终端输出，如果连接成功，通常会有相应的日志提示。
4. **在 Dify 中测试:**
    * 刷新 Dify 的 "插件" 或 "模型供应商" 页面，你应该能看到你的本地插件实例，可能带有 "调试中" 标识。
    * 前往 "设置" -> "模型供应商"，找到你的插件，配置有效的 API 凭证。
    * 在 Dify 应用中选择并使用你的模型进行测试。你在本地对 Python 代码的修改（保存后通常会自动重新加载服务）会直接影响 Dify 中的调用行为。使用 Dify 的调试预览功能可以帮助你检查输入输出和错误信息。

---

## 第 5 步: 打包与发布

当你完成了开发和调试，并对插件的功能满意后，就可以将其打包并贡献给 Dify 社区了。

1. **打包插件:**
    * 停止本地调试服务 (`Ctrl+C`)。
    * 在插件项目**根目录**下运行打包命令：

      ```bash
      # 将 <provider_name> 替换为你的供应商目录名
      dify plugin package models/<provider_name>
      ```

    * 这将在项目根目录下生成一个 `<provider_name>.difypkg` 文件。
2. **提交 Pull Request:**
    * 确保你的代码风格良好，并遵循 Dify 的[插件发布规范](https://docs.dify.ai/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace)。
    * 将你的本地 Git 提交推送到你 Fork 的 `dify-official-plugins` 仓库。
    * 在 GitHub 上向 `langgenius/dify-official-plugins` 主仓库发起 Pull Request。在 PR 描述中清晰说明你所做的更改、添加的模型或功能，以及任何必要的测试说明。
    * 等待 Dify 团队审核。审核通过并合并后，你的贡献将包含在官方插件中，并在 [Dify Marketplace](https://marketplace.dify.ai/) 上可用。

---

## 探索更多

* [模型 Schema 定义](./plugin-dev-zh/0412-model-schema) (模型 YAML 规范)
* [插件 Manifest 结构](./plugin-dev-zh/0411-general-specifications) (`manifest.yaml` 规范)
* [Dify Plugin SDK 参考](https://github.com/langgenius/dify-plugin-sdks) (查找基类、数据结构和错误类型)
* [Dify 官方插件仓库](https://github.com/langgenius/dify-official-plugins) (查看现有插件的实现)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0222-creating-new-model-provider-extra.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 创建模型供应商
> 来源：`plugin-dev-zh/0222-creating-new-model-provider.mdx`
> 摘要：本文档详细指导如何创建模型供应商插件，包括项目初始化、模型配置方式（预定义模型和自定义模型）的选择、创建供应商配置YAML文件以及编写供应商代码的完整流程。

创建 Model 类型插件的第一步是初始化插件项目并创建模型供应商文件，随后编写具体的预定义 / 自定义模型代码。如果您只是想为已有的模型供应商添加新模型，请参考[快速接入一个新模型](./plugin-dev-zh/0211-getting-started-new-model)。

### 前置准备

* Dify 插件脚手架工具
* Python 环境，版本号 ≥ 3.12

关于如何准备插件开发的脚手架工具，详细说明请参考[初始化开发工具](./plugin-dev-zh/0221-initialize-development-tools)。在开始之前，建议您先了解[模型插件](./plugin-dev-zh/0131-model-plugin-introduction)的基本概念和结构。

### 创建新项目

在脚手架命令行工具的路径下，创建一个新的 dify 插件项目。

```
./dify-plugin-darwin-arm64 plugin init
```

如果你已将该二进制文件重命名为了 `dify` 并拷贝到了 `/usr/local/bin` 路径下，可以运行以下命令创建新的插件项目：

```bash
dify plugin init
```

### 选择模型插件模板

脚手架工具内的所有模板均已提供完整的代码项目，选择 `LLM` 类型插件模板。

![Plugin type: llm](https://assets-docs.dify.ai/2024/12/8efe646e9174164b9edbf658b5934b86.png)

#### 配置插件权限

为该 LLM 插件配置以下权限：

* Models
* LLM
* Storage

![模型插件权限](https://assets-docs.dify.ai/2024/12/10f3b3ee6c03a1215309f13d712455d4.png)

#### 模型类型配置说明

模型供应商支持以下两种模型的配置方式：

*   `predefined-model` **预定义模型**

    常见的大模型类型，只需要配置统一的供应商凭据即可使用模型供应商下的预定义模型。例如，`OpenAI` 模型供应商下提供 `gpt-3.5-turbo-0125` 和 `gpt-4o-2024-05-13` 等一系列预定义模型。详细开发说明请参考接入预定义模型。
*   `customizable-model` **自定义模型**

    需要手动新增每个模型的凭据配置，例如 `Xinference`，它同时支持 LLM 和 Text Embedding，但是每个模型都有唯一的 **model\_uid**，如果想要将两者同时接入，需要为每个模型配置一个 **model\_uid**。详细开发说明请参考接入自定义模型。

两种配置方式**支持共存**，即存在供应商支持 `predefined-model` + `customizable-model` 或 `predefined-model` 等，即配置了供应商统一凭据可以使用预定义模型和从远程获取的模型，若新增了模型，则可以在此基础上额外使用自定义的模型。

### 新增模型供应商

新增一个模型供应商主要包含以下几个步骤：

1.  **创建模型供应商配置 YAML** **文件**

    在供应商目录下新增一个 YAML 文件，用于描述供应商的基本信息和参数配置。按照 ProviderSchema 的要求编写内容，确保与系统的规范保持一致。
2.  **编写模型供应商代码**

    创建供应商 class 代码，实现一个符合系统接口要求的 Python class 用于对接供应商的 API，完成核心功能实现。

***

以下是每个步骤的完整操作详情。

#### 1. **创建模型供应商配置文件**

Manifest 是 YAML 格式文件，声明了模型供应商基础信息、所支持的模型类型、配置方式、凭据规则。插件项目模板将在 `/providers` 路径下自动生成配置文件。

以下是 `Anthropic` 模型配置文件 `anthropic.yaml` 的示例代码：

```yaml
provider: anthropic
label:
  en_US: Anthropic
description:
  en_US: Anthropic's powerful models, such as Claude 3.
  zh_Hans: Anthropic 的强大模型，例如 Claude 3。
icon_small:
  en_US: icon_s_en.svg
icon_large:
  en_US: icon_l_en.svg
background: "#F0F0EB"
help:
  title:
    en_US: Get your API Key from Anthropic
    zh_Hans: 从 Anthropic 获取 API Key
  url:
    en_US: https://console.anthropic.com/account/keys
supported_model_types:
  - llm
configurate_methods:
  - predefined-model
provider_credential_schema:
  credential_form_schemas:
    - variable: anthropic_api_key
      label:
        en_US: API Key
      type: secret-input
      required: true
      placeholder:
        zh_Hans: 在此输入您的 API Key
        en_US: Enter your API Key
    - variable: anthropic_api_url
      label:
        en_US: API URL
      type: text-input
      required: false
      placeholder:
        zh_Hans: 在此输入您的 API URL
        en_US: Enter your API URL
models:
  llm:
    predefined:
      - "models/llm/*.yaml"
    position: "models/llm/_position.yaml"
extra:
  python:
    provider_source: provider/anthropic.py
    model_sources:
      - "models/llm/llm.py"
```

如果接入的供应商提供自定义模型，比如`OpenAI`提供微调模型，需要添加`model_credential_schema` 字段。

以下是 `OpenAI` 家族模型的示例代码：

```yaml
model_credential_schema:
  model: # 微调模型名称
    label:
      en_US: Model Name
      zh_Hans: 模型名称
    placeholder:
      en_US: Enter your model name
      zh_Hans: 输入模型名称
  credential_form_schemas:
  - variable: openai_api_key
    label:
      en_US: API Key
    type: secret-input
    required: true
    placeholder:
      zh_Hans: 在此输入您的 API Key
      en_US: Enter your API Key
  - variable: openai_organization
    label:
        zh_Hans: 组织 ID
        en_US: Organization
    type: text-input
    required: false
    placeholder:
      zh_Hans: 在此输入您的组织 ID
      en_US: Enter your Organization ID
  - variable: openai_api_base
    label:
      zh_Hans: API Base
      en_US: API Base
    type: text-input
    required: false
    placeholder:
      zh_Hans: 在此输入您的 API Base
      en_US: Enter your API Base
```

如需查看更多完整的模型供应商 YAML 规范，详情请参考[模型架构](./plugin-dev-zh/0412-model-schema)文档。

#### 2. **编写模型供应商代码**

在 `/providers` 文件夹下创建一个同名的 python 文件，例如 `anthropic.py` 并实现一个 `class` ，继承 `__base.provider.Provider` 基类，例如 `AnthropicProvider`。

以下是 `Anthropic` 示例代码：

```python

from dify_plugin.entities.model import ModelType
from dify_plugin.errors.model import CredentialsValidateFailedError
from dify_plugin import ModelProvider

logger = logging.getLogger(__name__)

class AnthropicProvider(ModelProvider):
    def validate_provider_credentials(self, credentials: dict) -> None:
        """
        Validate provider credentials

        if validate failed, raise exception

        :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
        """
        try:
            model_instance = self.get_model_instance(ModelType.LLM)
            model_instance.validate_credentials(model="claude-3-opus-20240229", credentials=credentials)
        except CredentialsValidateFailedError as ex:
            raise ex
        except Exception as ex:
            logger.exception(f"self.get_provider_schema().provider credentials validate failed")
            raise ex
```

供应商需要继承 `__base.model_provider.ModelProvider` 基类，实现 `validate_provider_credentials` 供应商统一凭据校验方法即可。

```python
def validate_provider_credentials(self, credentials: dict) -> None:
    """
    Validate provider credentials
    You can choose any validate_credentials method of model type or implement validate method by yourself,
    such as: get model list api

    if validate failed, raise exception

    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
    """
```

当然也可以先预留 `validate_provider_credentials` 实现，在模型凭据校验方法实现后直接复用。

#### **自定义模型供应商**

对于其它类型模型供应商而言，请参考以下配置方法。

对于像 `Xinference` 这样的自定义模型供应商，可以跳过完整实现的步骤。只需创建一个名为 `XinferenceProvider` 的空类，并在其中实现一个空的 `validate_provider_credentials` 方法。

**具体说明：**

• `XinferenceProvider` 是一个占位类，用于标识自定义模型供应商。

• `validate_provider_credentials` 方法虽然不会被实际调用，但必须存在，这是因为其父类是抽象类，要求所有子类都实现这个方法。通过提供一个空实现，可以避免因未实现抽象方法而导致的实例化错误。

```python
class XinferenceProvider(Provider):
    def validate_provider_credentials(self, credentials: dict) -> None:
        pass
```

初始化模型供应商后，接下来需要接入供应商所提供的具体 llm 模型。详细说明请参考以下内容：

* [模型设计规则](./plugin-dev-zh/0411-model-designing-rules) - 了解接入预定义模型的规范
* [模型架构](./plugin-dev-zh/0412-model-schema) - 了解接入自定义模型的规范
* [发布概览](./plugin-dev-zh/0321-release-overview) - 学习插件发布流程

## 参考资源

- [快速接入一个新模型](./plugin-dev-zh/0211-getting-started-new-model) - 如何为现有供应商添加新模型
- [插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin) - 返回插件开发入门指南
- [创建新模型提供者补充](./plugin-dev-zh/0222-creating-new-model-provider-extra) - 了解更多高级配置
- [一般规范定义](./plugin-dev-zh/0411-general-specifications) - 了解插件清单文件的配置

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0222-creating-new-model-provider.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 输出开发和调试插件过程中的日志
> 来源：`plugin-dev-zh/0222-debugging-logs.mdx`
> 摘要：介绍如何在 Dify 插件开发中为你的工具添加日志输出功能，以便于开发和调试。

作为插件开发者，你可能希望在插件处理过程中，为了开发或调试目的，将任意字符串输出到日志中。

为此，插件 SDK 实现了一个适用于 Python 标准库 `logging` 的处理器。通过使用它，你可以将任意字符串输出到**远程调试时的标准输出**以及**插件守护进程的容器日志**（仅社区版）。

## 示例

导入 `plugin_logger_handler` 并将其添加到你的 logger 处理器中。以下是工具插件的示例代码。

```python
from collections.abc import Generator
from typing import Any
from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage

# 导入 logging 和自定义处理器

from dify_plugin.config.logger_format import plugin_logger_handler

# 使用自定义处理器设置日志
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.addHandler(plugin_logger_handler)

class LoggerDemoTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:

        # 以不同级别输出日志信息
        logger.info("This is a INFO log message.")
        logger.warning("This is a WARNING log message.")
        logger.error("This is a ERROR log message.")

        yield self.create_text_message("Hello, Dify!")
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0222-debugging-logs.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Tool 插件
> 来源：`plugin-dev-zh/0222-tool-plugin.mdx`
> 摘要：本文档详细介绍了如何开发Dify的工具插件，以Google Search为例实现了一个完整的工具插件开发流程。内容包括插件初始化、模板选择、模板选择、工具供应商配置文件定义、添加第三方服务凭证、工具功能代码实现、调试和打包发布等完整环节。

工具指的是能够被 Chatflow / Workflow / Agent 类型应用所调用的第三方服务，提供完整的 API 实现能力，用于增强 Dify 应用的能力。例如为应用添加在线搜索、图片生成等额外功能。

![Tool Plugin Example](https://assets-docs.dify.ai/2024/12/7e7bcf1f9e3acf72c6917ea9de4e4613.png)

在本文中，**"工具插件"** 指的是一个完整的项目，其中包含工具供应商文件、功能代码等结构。一个工具供应商内允许包含多个 Tools（可以理解为单个工具中提供的额外功能），结构如下：

```
- 工具供应商
    - Tool A
    - Tool B
```

![工具插件结构](https://assets-docs.dify.ai/2025/02/60c4c86a317d865133aa460592eac079.png)

本文将以 `Google Search` 为例，介绍如何快速开发一个工具插件。

### 前置准备

-   Dify 插件脚手架工具
-   Python 环境，版本号 ≥ 3.12

关于如何准备插件开发的脚手架工具，详细说明请参考[初始化开发工具](./plugin-dev-zh/0221-initialize-development-tools)。如果你是初次开发插件，建议先阅读[Dify 插件开发：Hello World 指南](./plugin-dev-zh/0211-getting-started-dify-tool)。

### 创建新项目

运行脚手架命令行工具，创建一个新的 dify 插件项目。

```bash
./dify-plugin-darwin-arm64 plugin init
```

如果你已将该二进制文件重命名为 `dify` 并拷贝至 `/usr/local/bin` 路径下，可以运行以下命令创建新的插件项目：

```bash
dify plugin init
```

> 下文将使用 `dify` 作为命令行示例。如遇到问题，请将 `dify` 命令替换为命令行工具的所在路径。

### 选择插件类型和模板

脚手架工具内的所有模板均已提供完整的代码项目。在本文实例中，选择 `Tool` 插件。

> 如果你已熟悉插件开发，无需借助模板，可参考[通用规范](./plugin-dev-zh/0411-general-specifications)指引完成不同类型的插件开发。

![插件类型：工具](https://assets-docs.dify.ai/2024/12/dd3c0f9a66454e15868eabced7b74fd6.png)

#### 配置插件权限

插件还需读取 Dify 平台的权限，为该示例插件授予以下权限：

-   Tools
-   Apps
-   启用持久化存储 Storage，分配默认大小存储
-   允许注册 Endpoint

> 在终端内使用方向键选择权限，使用 "Tab" 按钮授予权限。

勾选所有权限项后，轻点回车完成插件的创建。系统将自动生成插件项目代码。

![插件权限](https://assets-docs.dify.ai/2024/12/9cf92c2e74dce55e6e9e331d031e5a9f.png)

### 开发工具插件

#### 1. 创建工具供应商文件

工具供应商文件为 yaml 格式文件，可以理解为工具插件的基础配置入口，用于向工具提供必要的授权信息。

前往插件模板项目中的 `/provider` 路径，将其中的 yaml 文件重命名为 `google.yaml`。该 `yaml` 文件将包含工具供应商的信息，包括供应商名称、图标、作者等详情。这部分信息将在安装插件时进行展示。

**示例代码**

```yaml
identity: # 工具供应商的基本信息
    author: Your-name # 作者
    name: google # 名称，唯一，不允许和其他供应商重名
    label: # 标签，用于前端展示
        en_US: Google # 英文标签
        zh_Hans: Google # 中文标签
    description: # 描述，用于前端展示
        en_US: Google # 英文描述
        zh_Hans: Google # 中文描述
    icon: icon.svg # 工具图标，需要放置在 _assets 文件夹下
    tags: # 标签，用于前端展示
        - search
```

确保该文件路径位于 `/tools` 目录，完整的路径如下：

```yaml
plugins:
    tools:
        - 'google.yaml'
```

其中 `google.yaml` 文件需要使用其在插件项目的绝对路径。在本例中，它位于项目根目录。YAML 文件中的 identity 字段解释如下：`identity` 包含了工具供应商的基本信息，包括作者、名称、标签、描述、图标等。

-   图标需要属于附件资源，需要将其放置在项目根目录的 `_assets` 文件夹下。
-   标签可以帮助用户通过分类快速找到插件，以下是目前所支持的所有标签。

```python
class ToolLabelEnum(Enum):
  SEARCH = 'search'
  IMAGE = 'image'
  VIDEOS = 'videos'
  WEATHER = 'weather'
  FINANCE = 'finance'
  DESIGN = 'design'
  TRAVEL = 'travel'
  SOCIAL = 'social'
  NEWS = 'news'
  MEDICAL = 'medical'
  PRODUCTIVITY = 'productivity'
  EDUCATION = 'education'
  BUSINESS = 'business'
  ENTERTAINMENT = 'entertainment'
  UTILITIES = 'utilities'
  OTHER = 'other'
```

#### **2. 补全第三方服务凭据**

为了便于开发，选择采用第三方服务 `SerpApi` 所提供的 Google Search API 。 `SerpApi` 要求填写 API Key 进行使用，因此需要在 `yaml` 文件内添加 `credentials_for_provider` 字段。

完整代码如下：

```yaml
identity:
    author: Dify
    name: google
    label:
        en_US: Google
        zh_Hans: Google
        pt_BR: Google
    description:
        en_US: Google
        zh_Hans: GoogleSearch
        pt_BR: Google
    icon: icon.svg
    tags:
        - search
credentials_for_provider: #添加 credentials_for_provider 字段
    serpapi_api_key:
        type: secret-input
        required: true
        label:
            en_US: SerpApi API key
            zh_Hans: SerpApi API key
        placeholder:
            en_US: Please input your SerpApi API key
            zh_Hans: 请输入你的 SerpApi API key
        help:
            en_US: Get your SerpApi API key from SerpApi
            zh_Hans: 从 SerpApi 获取您的 SerpApi API key
        url: https://serpapi.com/manage-api-key
tools:
    - tools/google_search.yaml
extra:
    python:
        source: google.py
```

-   其中 `credentials_for_provider` 的子级结构需要满足 [通用规范](./plugin-dev-zh/0411-general-specifications) 的要求。
-   需要指定该供应商包含了哪些工具。本示例仅包含了一个 `tools/google_search.yaml` 文件。
-   作为供应商，除了定义其基础信息外，还需要实现一些它的代码逻辑，因此需要指定其实现逻辑，在本例子中，将功能的代码文件放在了 `google.py` 中，但是暂时不实现它，而是先编写 `google_search` 的代码。

#### 3. 填写工具 yaml 文件

一个工具插件下可以有多个工具功能，每个工具功能需要一个 `yaml` 文件进行描述，包含工具功能的基本信息、参数、输出等。

仍以 `GoogleSearch` 工具为例，在 `/tools`文件夹内新建一个 `google_search.yaml` 文件。

```yaml
identity:
    name: google_search
    author: Dify
    label:
        en_US: GoogleSearch
        zh_Hans: 谷歌搜索
        pt_BR: GoogleSearch
description:
    human:
        en_US: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.
        zh_Hans: 一个用于执行 Google SERP 搜索并提取片段和网页的工具。输入应该是一个搜索查询。
        pt_BR: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.
    llm: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.
parameters:
    - name: query
      type: string
      required: true
      label:
          en_US: Query string
          zh_Hans: 查询语句
          pt_BR: Query string
      human_description:
          en_US: used for searching
          zh_Hans: 用于搜索网页内容
          pt_BR: used for searching
      llm_description: key words for searching
      form: llm
extra:
    python:
        source: tools/google_search.py
```

-   `identity` 包含了工具的基本信息，包括名称、作者、标签、描述等。
-   `parameters` 参数列表
    -   `name` （必填）参数名称，唯一，不允许和其他参数重名。
    -   `type` （必填）参数类型，目前支持`string`、`number`、`boolean`、`select`、`secret-input`、`file`、`files`、`model-selector`、`app-selector` 九种类型，分别对应字符串、数字、布尔值、下拉框、加密输入框、文件、文件集、模型选择、应用选择，对于敏感信息，请使用 `secret-input` 类型。
    -   `label`（必填）参数标签，用于前端展示。
    -   `form` （必填）表单类型，目前支持`llm`、`form`两种类型。
        -   在 Agent 应用中，`llm` 表示该参数 LLM 自行推理，`form` 表示要使用该工具可提前设定的参数。
        -   在 Workflow 应用中，`llm`和`form` 均需要前端填写，但 `llm` 的参数会做为工具节点的输入变量。
    -   `required` 是否必填
        -   在 `llm` 模式下，如果参数为必填，则会要求 Agent 必须要推理出这个参数。
        -   在 `form` 模式下，如果参数为必填，则会要求用户在对话开始前在前端填写这个参数。
    -   `options` 参数选项
        -   在 `llm` 模式下，Dify 会将所有选项传递给 LLM，LLM 可以根据这些选项进行推理。
        -   在 `form` 模式下，`type` 为 `select` 时，前端会展示这些选项。
    -   `default` 默认值。
    -   `min` 最小值，当参数类型为`number`时可以设定。
    -   `max` 最大值，当参数类型为`number`时可以设定。
    -   `human_description` 用于前端展示的介绍，支持多语言。
    -   `placeholder` 字段输入框的提示文字，在表单类型为`form`，参数类型为`string`、`number`、`secret-input`时，可以设定，支持多语言。
    -   `llm_description` 传递给 LLM 的介绍。为了使得 LLM 更好理解这个参数，请在这里写上关于这个参数尽可能详细的信息，以便 LLM 能够理解该参数。

#### 4. 准备工具代码

填写工具的配置信息以后，可以开始编写工具的功能代码，实现工具的逻辑目的。在`/tools`目录下创建`google_search.py`，内容如下：

```python
from collections.abc import Generator
from typing import Any

from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage

SERP_API_URL = "https://serpapi.com/search"

class GoogleSearchTool(Tool):
    def _parse_response(self, response: dict) -> dict:
        result = {}
        if "knowledge_graph" in response:
            result["title"] = response["knowledge_graph"].get("title", "")
            result["description"] = response["knowledge_graph"].get("description", "")
        if "organic_results" in response:
            result["organic_results"] = [

                    "title": item.get("title", ""),
                    "link": item.get("link", ""),
                    "snippet": item.get("snippet", ""),

                for item in response["organic_results"]
            ]
        return result

    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        params = 
            "api_key": self.runtime.credentials["serpapi_api_key"],
            "q": tool_parameters["query"],
            "engine": "google",
            "google_domain": "google.com",
            "gl": "us",
            "hl": "en",

        response = requests.get(url=SERP_API_URL, params=params, timeout=5)
        response.raise_for_status()
        valuable_res = self._parse_response(response.json())

        yield self.create_json_message(valuable_res)
```

该例子的含义为请求 `serpapi`，并使用 `self.create_json_message` 返回一串 `json` 的格式化数据，如果想了解更多的返回数据类型，可以参考[远程调试插件](./plugin-dev-zh/0411-remote-debug-a-plugin)和[持久化存储 KV](./plugin-dev-zh/0411-persistent-storage-kv)文档。

#### 5. 完成工具供应商代码

最后需要创建一个供应商的实现代码，用于实现凭据验证逻辑。如果凭据验证失败，将会抛出`ToolProviderCredentialValidationError`异常。验证成功后，将正确请求 `google_search` 工具服务。

在 `/provider` 目录下创建 `google.py` 文件，代码的内容如下：

```python
from typing import Any

from dify_plugin import ToolProvider
from dify_plugin.errors.tool import ToolProviderCredentialValidationError
from tools.google_search import GoogleSearchTool

class GoogleProvider(ToolProvider):
    def _validate_credentials(self, credentials: dict[str, Any]) -> None:
        try:
            for _ in GoogleSearchTool.from_credentials(credentials).invoke(
                tool_parameters="query": "test", "result_type": "link",
            ):
                pass
        except Exception as e:
            raise ToolProviderCredentialValidationError(str(e))
```

### 调试插件

插件开发完成后，接下来需要测试插件是否可以正常运行。Dify 提供便捷地远程调试方式，帮助你快速在测试环境中验证插件功能。

前往["插件管理"](https://cloud.dify.ai/plugins)页获取远程服务器地址和调试 Key。

![Remote Debug Key](https://assets-docs.dify.ai/2024/12/053415ef127f1f4d6dd85dd3ae79626a.png)

回到插件项目，拷贝 `.env.example` 文件并重命名为 `.env`，将获取的远程服务器地址和调试 Key 等信息填入其中。

`.env` 文件：

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_URL=debug.dify.ai:5003
REMOTE_INSTALL_KEY=********-****-****-****-************
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内，团队中的其他成员也可以访问该插件。

![](https://assets-docs.dify.ai/2024/11/0fe19a8386b1234755395018bc2e0e35.png)

### 打包插件（可选）

确认插件能够正常运行后，可以通过以下命令行工具打包并命名插件。运行以后你可以在当前文件夹发现 `google.difypkg` 文件，该文件为最终的插件包。

```bash
# 将 ./google 替换为插件项目的实际路径

dify plugin package ./google
```

恭喜，你已完成一个工具类型插件的完整开发、调试与打包过程！

### 发布插件（可选）

如果想要将插件发布至 Dify Marketplace，请确保你的插件遵循了[发布到 Dify 市场](./plugin-dev-zh/0322-release-to-dify-marketplace)中的规范。审核通过后，代码将合并至主分支并自动上线至 [Dify Marketplace](https://marketplace.dify.ai/)。

[发布概览](./plugin-dev-zh/0321-release-overview)

### 探索更多

#### **快速开始：**

-   [开发 Extension 插件](./plugin-dev-zh/9231-extension-plugin)
-   [开发 Model 插件](./plugin-dev-zh/0211-getting-started-new-model)
-   [Bundle 插件：将多个插件打包](./plugin-dev-zh/9241-bundle)

#### **插件接口文档：**

-   [一般规范定义](./plugin-dev-zh/0411-general-specifications) - Manifest 结构和工具规范
-   [端点](./plugin-dev-zh/0432-endpoint) - Endpoint 详细定义
-   [反向调用](./plugin-dev-zh/9241-reverse-invocation) - 反向调用 Dify 能力
-   [模型架构](./plugin-dev-zh/0412-model-schema) - 模型
-   [Agent 插件](./plugin-dev-zh/9232-agent) - 扩展 Agent 策略

## 下一步学习

- [远程调试插件](./plugin-dev-zh/0411-remote-debug-a-plugin) - 了解更高级的调试技巧
- [持久化存储](./plugin-dev-zh/0411-persistent-storage-kv) - 学习如何在插件中使用数据存储
- [Slack 机器人插件开发示例](./plugin-dev-zh/0432-develop-a-slack-bot-plugin) - 查看更复杂的插件开发案例
- [工具插件](./plugin-dev-zh/0411-tool) - 探索工具插件的高级功能

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0222-tool-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 插件开发准则
> 来源：`plugin-dev-zh/0312-contributor-covenant-code-of-conduct.mdx`
> 摘要：为保障 Dify Marketplace 中所有插件的质量，并确保 Dify Marketplace 用户获得一致且高质量的体验。在申请提交插件审核时，必须遵循此《插件开发准则》的所有要求。提交插件即表示**您已阅读、理解并同意遵守以下所有条款**，这将有助于您的插件快速顺利地通过审核。

## 1. 验证插件的提交价值

* 确保插件的核心功能聚焦于生成式 AI 领域，并为 Dify 平台用户在此领域提供独特、显著的价值。
  - 集成新的模型、工具或服务；
  - 提供独特的数据源或处理能力以增强 AI 应用；
  - 简化或自动化 Dify 平台上的 AI 相关工作流程；
  - 为 AI 应用开发提供创新的辅助功能。
* 提交的插件**不应**与 Marketplace 目录中已有的插件**功能重复或高度相似**。每个发布的插件应是独特的、独立的，以确保为商店用户提供最佳体验。
* 如涉及插件的更新，应**引入当前插件尚未提供的功能或服务**。
* 我们**建议**您在提交 PR 中附上简要说明，解释为什么需要提交新插件。

## 2. 插件功能性检查
- 确保插件**名称是唯一的**，搜索我们的插件目录以确保您的名称尚未使用。
- 插件名称与插件品牌相匹配。
- 提交审核前需验证插件功能是否正常运行，详细请参考[远程调试插件](./plugin-dev-zh/0411-remote-debug-a-plugin)，插件应准备好应用于生产。
- 提供全面的 README 文件，包括：
  - 设置说明和使用指南。
  - 插件用户需用的代码、API、凭据或其他信息，以便连接插件到服务。
  - 描述不应包含与该插件不相关的内容或链接。
  - 描述不应使用夸张、营销术语、或无法证明的声明内容。
  - 描述不应包含任何类型的广告（您自己的广告或来自展示广告服务的广告）。
  - 描述不应包含误导性、令人不适或恶意诋毁等内容。
  - 描述不应在截图中暴露真实用户的姓名或数据。
  - 描述不应包含指向不存在的页面 （404） 或产生错误消息的页面链接。
  - 描述不应出现过多的拼写和标点符号错误。
- 确保收集的用户信息仅用于连接服务和改进插件功能。
- 务必将必填字段标识，显示清晰的报错信息，确保用户可理解插件无法正常运行的原因。
- 如果您的插件需要身份验证设置，请不要省略身份验证设置。
- 根据插件[隐私政策准则](./plugin-dev-zh/0312-privacy-protection-guidelines)，准备隐私政策内容文件或在线文档 URL。
- 插件应具有良好的性能表现，避免导致 Dify 或用户环境响应迟缓或崩溃。
- 涉及 API 密钥或其他凭证的管理，开发者必须采取安全的存储和传输措施，避免硬编码在代码中或泄露给无关方。

## 3. 插件的语言要求
- Dify Marketplace 平台**面向全球用户**提供服务，插件主语言要求为**英语**。所有面向用户的文本（例如插件名称和描述、名称、字段名称、字段标签、帮助文本和错误消息）都**需至少提供英文语言的支持**。
- 鼓励提供支持丰富多语言版本的插件。

## 4. 禁止或受限发布的插件
- **禁止**具有误导性或恶意功能
  插件不得误导用户。请勿创建可用于向用户发送垃圾邮件、进行网络钓鱼或发送未经请求消息的插件。如果您试图欺骗系统（例如，试图欺骗审核流程、窃取用户数据或伪造真实用户），您的插件将被从 Dify Marketplace 移除，并且您未来可能被禁止提交任何插件。
- **禁止**包含令人不适的内容
  插件内容不得包含暴力、仇恨言论、歧视性内容或任何不尊重全球不同文化、宗教及用户群体的内容。
- **禁止**进行金融交易
  插件不得促进任何形式的金融交易、资产转移或支付处理。对于区块链或加密货币应用，这包括任何代币或资产所有权的转移。
- **限制**多次提交功能缺陷的插件
  在提交插件以供审核之前，请自行对插件进行完整的功能性测试，确保不会出现严重的报错或功能性漏洞。多次提交质量缺陷的插件可能会导致审核时间变慢或收到进一步的处罚。
- **限制**不必要的插件拆分
  请勿为共享相同身份验证方法并与相同 API 交互的功能创建单独的插件，除非每个插件是针对明确独立营销的单独产品或服务（而非功能）。相反应将功能整合到一个高级别的插件中。
- **限制**重复提交相同插件
  提交本质上相同的多个插件会延迟审核流程，并有可能拒绝所有提交。在审核过程中，请避免连续提交相同的插件。违反此政策可能会导致审核时间变慢或受到进一步的处罚。

## 5. 插件收费模式
- Dify Marketplace 当前阶段仅支持**免费**插件，关于 Dify Marketplace 的商业化和收费模式，未来将另行发布相关政策。

## 6. 插件商标与知识产权
- 提交插件时应确认你有权使用 Logo 和商标，**禁止**未经授权使用第三方商标等。
- 插件审核团队保留向开发者索取第三方 Logo 授权证明的权利，尤其当所用 Logo 明显属于他人品牌时，可能会在必要时要求提供授权证明。
- 如在上架后被发现违规，Dify 有权要求开发者更改 Logo 或直接将插件下架处理。若接到商标权利人投诉，也会按照政策移除相关内容。（依据平台服务条款可能会警告或撤销插件的发布资格）
- **禁止**使用任何 Dify 所有的 Logo。
- 请勿提供质量低下、扭曲拉伸或以截断元素的方式被裁剪的图像，审核团队保留向开发者要求更换图标的权力。
- 图标中不应包含误导性、令人不适或恶意的画面。

## 7. 插件更新和版本管理
- 开发者应负责任地管理插件的更新。对于可能引入不兼容变更（Breaking Changes）的更新，建议提前在插件描述或通过其他渠道（如 GitHub Release Notes）通知用户，并提供清晰的版本说明。
- 鼓励开发者定期更新插件以修复 Bug、适配 Dify 平台更新或依赖的第三方服务变更，特别是涉及安全性的更新。
- 如果插件所有者计划停止维护并最终弃用某个插件，应尽可能提前通知用户（例如，在插件描述中说明弃用计划和时间表），并建议提供替代方案（如果可行）。

## 8. 插件的维护与支持
- 插件所有者对插件行使技术支持和维护的直接责任。
- 插件所有者**需至少提供一个支持渠道：GitHub 仓库链接或邮箱**，方便在插件审核和上架期间，Dify 审核团队或者商店用于对插件的问题进行反馈。
- 若插件长期无人维护，且所有者在 Dify 合理通知后仍未能在指定期限内响应或修复，Dify 保留采取相应措施的权利，包括但不限于：在插件页面添加“缺乏维护”或“可能存在风险”的标识、限制新用户安装、或最终将其下架处理。

## 9. 符合隐私数据规范

* 要求开发者在提交应用/工具时，**必须**声明是否收集任何类型的用户个人数据。详细请参考[插件隐私数据保护指南](./plugin-dev-zh/0312-privacy-protection-guidelines)。
* 如果收集，需要**简单列出**收集的数据类型（例如：用户名、邮箱、设备ID、位置信息等），**无需过于详细**。
* 开发者**必须**提供隐私政策链接，隐私政策只需要陈述收集了什么信息、怎么使用这些信息、以及哪些信息会和第三方披露，以及第三方相关的隐私政策链接。

**审核重点：**

* **形式审核：** 检查是否按要求声明了数据收集情况。
* **高危数据排查：** 重点关注是否收集了敏感数据（例如：健康信息、财务信息、儿童个人信息等），如果收集了敏感数据，则需要**额外审核**其使用目的和安全性措施。
* **恶意行为排查：** 检查是否存在明显恶意行为，例如未经用户同意私自收集数据、上传用户数据到未知服务器等。

## 10. 插件审核与裁量权
- 如果我们认为这些要求、隐私政策准则等未得到满足，我们保留拒绝发布请求或从 Dify Marketplace 删除已发布插件的权利。这包括试图利用审核流程、非法获取用户数据等情况。
- Marketplace 审核团队会尽力在合理的时间内完成插件审核，具体时间可能因提交量和插件复杂度而异。审核过程中，我们可能会通过您提供的支持渠道与您联系沟通反馈，请确保您的联系方式有效。

## 相关资源

- [插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin) - 了解插件开发基础
- [发布插件](./plugin-dev-zh/0321-release-overview) - 插件发布流程概览
- [插件隐私数据保护指南](./plugin-dev-zh/0312-privacy-protection-guidelines) - 编写隐私政策指南
- [发布至 Dify Marketplace](./plugin-dev-zh/0322-release-to-dify-marketplace) - 在官方市场发布插件
- [远程调试插件](./plugin-dev-zh/0411-remote-debug-a-plugin) - 插件调试指南

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0312-contributor-covenant-code-of-conduct.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 插件隐私政策准则
> 来源：`plugin-dev-zh/0312-privacy-protection-guidelines.mdx`
> 摘要：本文档描述了开发者向Dify Marketplace提交插件时如何撰写隐私政策的准则。内容包括如何确认和列出所收集的个人数据类型（直接识别信息、间接识别信息、组合信息）、如何填写插件隐私政策、如何在Manifest文件中引入隐私政策声明，以及相关常见问题的解答。

向 Dify Marketplace 提交插件上架申请时，您需要公开说明如何处理用户数据。以下是关于填写插件相关隐私问题和用户数据处理的指南。如果你还没有开发插件，可以参考[插件开发入门指南](./plugin-dev-zh/0211-getting-started-dify-tool)。

插件隐私政策声明内容围绕以下问题展开：

**您的插件是否收集和使用用户个人数据？** 如有，请整理并列出具体类型。

> 个人数据指可识别特定个人的任何信息，包括单独或与其他信息结合后可用于识别、联系或定位个人的信息。

#### **1. 列出所收集的数据类型**

**类型一：直接识别信息**

* 姓名（全名、名、姓）
* 邮箱
* 手机号
* 住址
* 身份证件号（身份证、护照、驾照等）

**类型二：间接识别信息**

* 设备识别码（IMEI、MAC 地址、设备 ID）
* IP 地址
* 位置信息（GPS 坐标、城市、地区）
* 在线标识（cookies、广告 ID）
* 用户名
* 头像
* 生物特征（指纹、人脸识别）
* 浏览记录
* 购物记录
* 健康数据
* 财务信息

**类型三：被用于识别个人的组合信息**

* 年龄
* 性别
* 职业
* 兴趣爱好

即使您的插件本身不收集个人信息，也请确认插件使用的第三方服务是否涉及数据收集或处理。作为开发者，您需要公开所有数据收集活动，包括第三方服务的数据处理。请务必阅读第三方服务的隐私政策，确保在提交时声明插件涉及的所有数据收集情况。

例如，当你正在开发的插件涉及 Slack 服务时，请在插件的隐私政策声明文件中引用 [Slack 的隐私政策](https://slack.com/trust/privacy/privacy-policy)并声明数据收集情况。

#### 2. 填写最新版本的插件隐私政策

**插件隐私政策**必须包含：

* 收集的数据类型
* 数据用途
* 是否与第三方共享数据（如有，请列出第三方服务的名称及其隐私政策链接）
* 如果不熟悉隐私政策写法，可以参考由 Dify 官方维护插件内的隐私政策

#### **3. 在插件 Manifest 文件内引入隐私政策声明**

详细字段的填写说明请参考[通过清单文件定义插件信息](./plugin-dev-zh/0411-plugin-info-by-manifest)。

### **常见问题**

1. **什么是"收集和使用"用户个人数据？有哪些常见案例？**

"收集和使用"指对用户数据进行收集、传输、使用或共享。常见情况包括：

* 通过表单收集个人信息；
* 使用登录功能（含第三方认证）；
* 收集可能包含个人信息的输入或资源；
* 分析用户行为、互动和使用情况；
* 存储通讯内容，如消息、聊天记录、邮件；
* 访问关联社交媒体的用户资料；
* 收集健康数据，如运动、心率、医疗信息；
* 保存搜索记录或浏览行为；
* 处理财务信息，如银行资料、信用分、交易记录。

## 相关资源

- [发布插件](./plugin-dev-zh/0321-release-overview) - 了解插件发布流程
- [发布至 Dify Marketplace](./plugin-dev-zh/0322-release-to-dify-marketplace) - 学习如何往官方市场提交插件
- [插件开发者准则](./plugin-dev-zh/0312-contributor-covenant-code-of-conduct) - 了解插件提交规范
- [通过清单文件定义插件信息](./plugin-dev-zh/0411-plugin-info-by-manifest) - 插件元数据配置

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0312-privacy-protection-guidelines.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 第三方签名验证
> 来源：`plugin-dev-zh/0312-third-party-signature-verification.mdx`
> 摘要：本文档介绍了如何在Dify社区版中启用和使用第三方签名验证功能，包括密钥对生成、插件签名与验证、以及环境配置步骤，使管理员能够安全地安装未在Dify市场上提供的插件。

> **警告：**

此功能仅在 Dify 社区版中可用，Dify 云端版目前不支持第三方签名验证。

第三方签名验证允许 Dify 管理员安全地安装尚未在 Dify 市场上提供的插件，而无需修改 `.env` 文件绕开签名验证安全限制。

**使用场景：**

* 一经同意，Dify 管理员可以为插件添加由开发者发送的签名。
* 插件开发者可以为他们的插件添加签名，并将其与公钥一起发布给无法禁用签名验证的 Dify 管理员。

Dify 管理员和插件开发者都可以使用预先生成的密钥对为插件添加签名。此外，管理员可以配置 Dify 在插件安装过程中使用特定公钥强制执行签名验证。

## 生成用于签名和验证的密钥对

使用以下命令生成新的密钥对，用于添加和验证插件签名：

```bash
dify signature generate -f your_key_pair
```

运行此命令后，将在当前目录中生成两个文件：

* **私钥**：`your_key_pair.private.pem`
* **公钥**：`your_key_pair.public.pem`

私钥用于签名插件，公钥用于验证插件的签名。

> **警告：**
请妥善保管私钥。如果私钥被泄露，攻击者可以为任何插件添加有效签名，这将危及 Dify 社区版的安全性。

## 为插件添加签名并验证

运行以下命令为插件添加签名。请注意，你需要指定**待签名的插件文件**和**私钥**：

```bash
dify signature sign your_plugin_project.difypkg -p your_key_pair.private.pem
```

执行命令后，将在同一目录中生成一个新的插件文件，文件名中添加了 `signed`：`your_plugin_project.signed.difypkg`

你可以使用以下命令验证插件是否已正确签名。运行命令时需要指定**已签名的插件文件**和**公钥**：

```bash
dify signature verify your_plugin_project.signed.difypkg -p your_key_pair.public.pem
```

> **信息提示：**
如果省略公钥参数，验证将使用 Dify 市场公钥。在这种情况下，对于任何未从 Dify 市场下载的插件文件，签名验证将失败。

## 启用第三方签名验证

Dify 管理员可以在安装插件前强制使用预先批准的公钥进行签名验证。

### 放置公钥

将用于签名的私钥对应的**公钥**放在插件守护程序可以访问的位置。

例如，在 `docker/volumes/plugin_daemon` 下创建 `public_keys` 目录，并将公钥文件复制到对应路径：

```bash
mkdir docker/volumes/plugin_daemon/public_keys
cp your_key_pair.public.pem docker/volumes/plugin_daemon/public_keys
```

### 环境变量配置

在 `plugin_daemon` 容器中，配置以下环境变量：

* `THIRD_PARTY_SIGNATURE_VERIFICATION_ENABLED`
  * 启用第三方签名验证。
  * 将此项设置为 `true` 以启用此功能。
* `THIRD_PARTY_SIGNATURE_VERIFICATION_PUBLIC_KEYS`
  * 指定用于签名验证的公钥文件路径。
  * 你可以列出多个公钥文件，用逗号分隔。

以下是配置这些变量的 Docker Compose 覆盖文件 (`docker-compose.override.yaml`) 示例：

```yaml
services:
  plugin_daemon:
    environment:
      FORCE_VERIFYING_SIGNATURE: true
      THIRD_PARTY_SIGNATURE_VERIFICATION_ENABLED: true
      THIRD_PARTY_SIGNATURE_VERIFICATION_PUBLIC_KEYS: /app/storage/public_keys/your_key_pair.public.pem
```

> **信息提示：**
请注意，`docker/volumes/plugin_daemon` 在 `plugin_daemon` 容器中被挂载到 `/app/storage`。确保在 `THIRD_PARTY_SIGNATURE_VERIFICATION_PUBLIC_KEYS` 中指定的路径对应于容器内的路径。

要应用这些更改，请重启 Dify 服务：

```bash
cd docker
docker compose down
docker compose up -d
```

重启服务后，第三方签名验证功能将在当前社区版环境中启用。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0312-third-party-signature-verification.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 自动发布插件
> 来源：`plugin-dev-zh/0321-plugin-auto-publish-pr.mdx`
> 摘要：本文档介绍了如何使用GitHub Actions自动化Dify插件的发布流程，包括配置步骤、参数说明及使用方法，帮助插件开发者简化发布更新流程，无需手动

### 背景

当插件贡献者需要严肃更新 **已被其他用户使用的 Dify 插件** 时，流程通常非常繁琐：贡献者需要先修改插件源码并更新版本号，将更改推送到插件源码仓库，并在 fork 的 dify-plugin 仓库中创建新分支。随后，贡献者需要手动打包插件并上传打包文件，再创建 PR 合并到原始 dify-plugin 仓库。这个过程必须在每次插件代码变更时重复，非常耗时低效。

为了简化这一流程，我们构建了基于 GitHub Actions 的自动化工作流 **Plugin Auto-PR**。借助这个工具，插件贡献者可以一键完成插件打包、分支推送以及 PR 创建。

### 概念简介

#### GitHub Actions

GitHub Actions 是 GitHub 提供的内置 CI/CD 服务，可以自动化各种构建、测试和部署任务。

**运行原理**：当触发条件（如 push 代码）满足时，GitHub 会自动分配虚拟机运行你的工作流。所有操作都在 GitHub 云端完成。

![Workflow](https://assets-docs.dify.ai/2025/04/60534de8e220f860947b32a8329a8349.png)

**免费额度**：

* 公共仓库：无限制
* 私有仓库：每月 2000 分钟

#### Plugin Auto-PR

**运行原理**：

1. 当你推送代码到插件源码仓库的 main 分支时，触发工作流
2. 工作流从 `manifest.yaml` 文件中读取插件信息
3. 自动打包插件为 `.difypkg` 文件
4. 将打包文件推送到你 fork 的 `dify-plugins` 仓库中
5. 创建新分支并提交更改
6. 自动创建 PR 请求合并到上游仓库

### 环境准备

#### 仓库要求

* 你已拥有自己的插件源码仓库（例如：`your-name/plugin-source`）
* 你已拥有自己的 fork 插件仓库（例如：`your-name/dify-plugins`）
* 你的 fork 仓库中已有插件目录结构：

```
dify-plugins/
└── your-author-name
    └── plugin-name
```

#### 权限要求

此工作流需要适当的权限才能正常运行：

* 你需要创建一个有足够权限的 GitHub Personal Access Token (PAT)
* 该 PAT 必须有权向你的 fork 仓库推送代码
* 该 PAT 必须有权向上游仓库创建 PR

### 参数与配置项说明

#### 必要参数

插件自动发布工作流需要你正确配置以下关键元素：

**manifest.yaml 文件**：这是整个自动化流程的核心配置源。你需要确保以下字段正确无误：

* `name`：插件名称（将用于生成包名和分支名）
* `version`：版本号（每次更新时需要递增）
* `author`：GitHub 用户名（用于确定目标仓库路径）

**PLUGIN_ACTION Secret**：你需要在插件源码仓库中正确设置此密钥。

* 值要求：必须是具有足够权限的个人访问令牌（PAT）
* 权限要求：能够推送分支到你的 fork 仓库，能够创建 PR 到上游仓库

#### 自动生成的参数

工作流会**自动处理以下内容**，无需手动干预：

* GitHub 用户名：从 `manifest.yaml` 的 `author` 字段读取
* 作者文件夹名称：与 `author` 字段保持一致
* 插件名称：从 `manifest.yaml` 的 `name` 字段读取
* 分支名称：`bump-插件名-plugin-版本号`
* 打包文件名：`插件名-版本号.difypkg`
* PR 标题和内容：基于插件名称和版本自动生成

### 安装配置步骤

> **步骤：**

    确保你已经 fork 了官方的 `dify-plugins` 仓库，并且有自己的插件源码仓库。

    导航到你的插件源码仓库，点击 **Settings > Secrets and variables > Actions > New repository secret**，创建 GitHub Secret：

    * 名称填写： `PLUGIN_ACTION`
    * 值填写： 拥有目标仓库（`your-name/dify-plugins`）写入权限的 GitHub Personal Access Token (PAT)

    ![Create Secrets](https://assets-docs.dify.ai/2025/04/8abd72b677dd24752910c304c76f1c26.png)

    在仓库中创建 `.github/workflows/`目录，并在此目录中创建名为 `plugin-publish.yml` 的文件，再将以下内容复制到该文件中：

    ```yaml
    # .github/workflows/auto-pr.yml
    name: Auto Create PR on Main Push

    on:
      push:
        branches: [ main ]  # Trigger on push to main

    jobs:
      create_pr: # Renamed job for clarity
        runs-on: ubuntu-latest
        steps:
          - name: Checkout code
            uses: actions/checkout@v3

          - name: Print working directory # Kept for debugging
            run: |
              pwd
              ls -la

          - name: Download CLI tool
            run: |
              # Create bin directory in runner temp
              mkdir -p $RUNNER_TEMP/bin
              cd $RUNNER_TEMP/bin

              # Download CLI tool
              wget https://github.com/langgenius/dify-plugin-daemon/releases/download/0.0.6/dify-plugin-linux-amd64
              chmod +x dify-plugin-linux-amd64

              # Show download location and file
              echo "CLI tool location:"
              pwd
              ls -la dify-plugin-linux-amd64

          - name: Get basic info from manifest # Changed step name and content
            id: get_basic_info
            run: |
              PLUGIN_NAME=$(grep "^name:" manifest.yaml | cut -d' ' -f2)
              echo "Plugin name: $PLUGIN_NAME"
              echo "plugin_name=$PLUGIN_NAME" >> $GITHUB_OUTPUT

              VERSION=$(grep "^version:" manifest.yaml | cut -d' ' -f2)
              echo "Plugin version: $VERSION"
              echo "version=$VERSION" >> $GITHUB_OUTPUT

              # If the author's name is not your github username, you can change the author here
              AUTHOR=$(grep "^author:" manifest.yaml | cut -d' ' -f2)
              echo "Plugin author: $AUTHOR"
              echo "author=$AUTHOR" >> $GITHUB_OUTPUT

          - name: Package Plugin
            id: package
            run: |
              # Use the downloaded CLI tool to package
              cd $GITHUB_WORKSPACE
              # Use variables for package name
              PACKAGE_NAME="${{ steps.get_basic_info.outputs.plugin_name }}-${{ steps.get_basic_info.outputs.version }}.difypkg"
              # Use CLI from runner temp
              $RUNNER_TEMP/bin/dify-plugin-linux-amd64 plugin package . -o "$PACKAGE_NAME"

              # Show packaging result
              echo "Package result:"
              ls -la "$PACKAGE_NAME"
              echo "package_name=$PACKAGE_NAME" >> $GITHUB_OUTPUT

              # Show full file path and directory structure (kept for debugging)
              echo "\\nFull file path:"
              pwd
              echo "\\nDirectory structure:"
              tree || ls -R

          - name: Checkout target repo
            uses: actions/checkout@v3
            with:
              # Use author variable for repository
              repository: ${{steps.get_basic_info.outputs.author}}/dify-plugins
              path: dify-plugins
              token: ${{ secrets.PLUGIN_ACTION }}
              fetch-depth: 1 # Fetch only the last commit to speed up checkout
              persist-credentials: true # Persist credentials for subsequent git operations

          - name: Prepare and create PR
            run: |
              # Debug info (kept)
              echo "Debug: Current directory $(pwd)"
              # Use variable for package name
              PACKAGE_NAME="${{ steps.get_basic_info.outputs.plugin_name }}-${{ steps.get_basic_info.outputs.version }}.difypkg"
              echo "Debug: Package name: $PACKAGE_NAME"
              ls -la

              # Move the packaged file to the target directory using variables
              mkdir -p dify-plugins/${{ steps.get_basic_info.outputs.author }}/${{ steps.get_basic_info.outputs.plugin_name }}
              mv "$PACKAGE_NAME" dify-plugins/${{ steps.get_basic_info.outputs.author }}/${{ steps.get_basic_info.outputs.plugin_name }}/

              # Enter the target repository directory
              cd dify-plugins

              # Configure git
              git config user.name "GitHub Actions"
              git config user.email "actions@github.com"

              # Ensure we are on the latest main branch
              git fetch origin main
              git checkout main
              git pull origin main

              # Create and switch to a new branch using variables and new naming convention
              BRANCH_NAME="bump-${{ steps.get_basic_info.outputs.plugin_name }}-plugin-${{ steps.get_basic_info.outputs.version }}"
              git checkout -b "$BRANCH_NAME"

              # Add and commit changes (using git add .)
              git add .
              git status # for debugging
              # Use variables in commit message
              git commit -m "bump ${{ steps.get_basic_info.outputs.plugin_name }} plugin to version ${{ steps.get_basic_info.outputs.version }}"

              # Push to remote (use force just in case the branch existed before from a failed run)
              git push -u origin "$BRANCH_NAME" --force

              # Confirm branch has been pushed and wait for sync (GitHub API might need a moment)
              git branch -a
              echo "Waiting for branch to sync..."
              sleep 10  # Wait 10 seconds for branch sync

          - name: Create PR via GitHub API
            env:
              GH_TOKEN: ${{ secrets.PLUGIN_ACTION }} # Use the provided token for authentication
            run: |
              gh pr create \
                --repo langgenius/dify-plugins \
                --head "${{ steps.get_basic_info.outputs.author }}:${{ steps.get_basic_info.outputs.plugin_name }}-${{ steps.get_basic_info.outputs.version }}" \
                --base main \
                --title "bump ${{ steps.get_basic_info.outputs.plugin_name }} plugin to version ${{ steps.get_basic_info.outputs.version }}" \
                --body "bump ${{ steps.get_basic_info.outputs.plugin_name }} plugin package to version ${{ steps.get_basic_info.outputs.version }}

                Changes:
                - Updated plugin package file" || echo "PR already exists or creation skipped." # Handle cases where PR already exists

          - name: Print environment info # Kept for debugging
            run: |
              echo "GITHUB_WORKSPACE: $GITHUB_WORKSPACE"
              echo "Current directory contents:"
              ls -R
    ```

    确保 `manifest.yaml` 文件正确设置以下字段：

    ```yaml
    version: 0.0.x  # Version number
    author: your-github-username  # GitHub username/Author name
    name: your-plugin-name  # Plugin name
    ```

### 使用指南

#### 初次使用流程

首次设置自动发布工作流时，需要完成以下步骤：

1. 确保你已经 fork 了官方的 `dify-plugins` 仓库
2. 确保你的插件源码仓库结构正确
3. 在插件源码仓库中设置 `PLUGIN_ACTION Secret`
4. 创建工作流文件 `.github/workflows/plugin-publish.yml`
5. 确保 `manifest.yaml` 文件中的 `name` 和 `author` 字段正确配置

#### 后续更新流程

设置完成后，每次需要发布新版本时，只需：

1. 修改插件代码
2. 更新 `manifest.yaml` 中的 `version` 字段

![Release](https://assets-docs.dify.ai/2025/04/9eed2b9110e91e18008b399e58198f03.png)

3. 将所有更改推送到 main 分支
4. 等待 GitHub Actions 自动完成打包、分支创建和 PR 提交

### 执行效果展示

当你推送代码到插件源码仓库的 main 分支时，GitHub Actions 将自动执行发布流程：

* 自动打包插件为 `plugin-name-version.difypkg` 格式
* 自动将打包文件推送到目标仓库
* 自动创建 PR 合并到 fork 仓库

![Outcome](https://assets-docs.dify.ai/2025/04/60d5de910c6ce2482c67ddec3320311f.png)

### 示例仓库

你可以参考[示例仓库](https://github.com/Yevanchen/exa-in-dify)，了解完整的配置细节和最佳实践。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0321-plugin-auto-publish-pr.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 发布插件
> 来源：`plugin-dev-zh/0321-release-overview.mdx`
> 摘要：本文档介绍了Dify插件的三种发布方式：官方Marketplace、开源GitHub仓库和本地插件文件包。详细说明了每种发布方式的特点、发布流程以及适用场景，并提供了具体的发布建议以满足不同开发者的需求。

### 发布方式

为了满足不同开发者的发布需求，Dify 提供了以下三种插件发布方式。在发布前，请确保您已完成插件的开发和测试，并阅读[插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin)和[插件开发者准则](./plugin-dev-zh/0312-contributor-covenant-code-of-conduct)。

#### **1. Marketplace**

**简介**：Dify 官方提供的插件市场，用户可以在此浏览、搜索并一键安装各类插件。

**特点**：

* 插件经审核后上线，**安全可靠**。
* 可直接安装至个人或团队的 **Workspace** 中。

**发布流程**：

* 将插件项目提交至 **Dify Marketplace** [代码仓库](https://github.com/langgenius/dify-plugins)。
* 经过官方审核后，插件将在市场内公开发布，供其他用户安装使用。

详细说明请参考：

[发布至 Dify Marketplace](./plugin-dev-zh/0322-release-to-dify-marketplace)

#### 2. **GitHub 仓库**

**简介**：将插件开源或托管在 **GitHub** 上，方便他人查看、下载和安装。

**特点**：

* 便于**版本管理**和**开源共享**。
* 用户可通过插件链接直接安装，无需平台审核。

**发布流程**：

* 将插件代码推送至 GitHub 仓库。
* 分享仓库链接，用户可通过链接将插件集成至 **Dify Workspace**。

详细说明请参考：

[发布至个人 GitHub 仓库](./plugin-dev-zh/0322-release-to-individual-github-repo)

#### 3. 插件文件包（本地安装）

**简介**：将插件打包成本地文件（如 `.difypkg` 格式），通过文件分享的方式供他人安装。

**特点**：

* 不依赖在线平台，**快速灵活**地分享插件。
* 适用于**私有插件**或**内部测试**。

**发布流程**：

* 将插件项目打包为本地文件。
* 在 Dify 插件页面点击**上传插件**，选择本地文件安装插件。

你可以将插件项目打包为一个本地文件并分享给他人，在插件页上传文件后即可将插件安装至 Dify Workspace 内。

详细说明请参考：

[打包为本地文件与分享](./plugin-dev-zh/0322-release-by-file)

### **发布建议**

* **想要推广插件** → **推荐使用 Marketplace**，通过官方审核保障插件质量，提升曝光度。
* **开源共享项目** → **推荐使用 GitHub**，方便版本管理与社区协作。
* **快速分发或内部测试** → **推荐使用插件文件**，简单高效地安装和分享。

### 第三方验证

安装非 Dify 市场内的插件时，有可能遇到第三方签名验证问题。解决办法请参考[第三方签名验证](./plugin-dev-zh/0312-third-party-signature-verification)。

## 相关资源

- [插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin) - 全面了解Dify插件开发
- [插件开发者准则](./plugin-dev-zh/0312-contributor-covenant-code-of-conduct) - 了解插件提交的规范
- [插件隐私数据保护指南](./plugin-dev-zh/0312-privacy-protection-guidelines) - 了解隐私政策编写要求
- [一般规范定义](./plugin-dev-zh/0411-general-specifications) - 了解插件清单文件的配置

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0321-release-overview.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 打包为本地文件与分享
> 来源：`plugin-dev-zh/0322-release-by-file.mdx`
> 摘要：本文档介绍了如何将Dify插件项目打包为本地文件并分享给他人的详细步骤。内容包括插件打包前的准备工作、使用Dify插件开发工具执行打包命令、生成的.difypkg文件的安装方式以及如何分享插件文件给其他用户。

完成插件开发后，你可以将插件项目打包为一个本地文件并分享给他人，通过插件文件即可安装至 Dify Workspace 内。如果您还没有开发插件，可以参考[插件开发入门指南](./plugin-dev-zh/0211-getting-started-dify-tool)。

* **特点**：
  * 不依赖在线平台，**快速灵活**地分享插件。
  * 适用于**私有插件**或**内部测试**。
* **发布流程**：
  * 将插件项目打包为本地文件。
  * 在 Dify 插件页面上传文件安装插件。

本文将介绍如何将插件项目打包为本地文件，以及如何使用本地文件安装插件。

### 前置准备

* **Dify 插件开发工具**，详细说明请参考[初始化开发工具](./plugin-dev-zh/0221-initialize-development-tools)。

配置完成后，在终端输入 `dify version` 命令，检查是否输出版本号信息以确认已安装必要的开发工具。

### 打包插件

> 打包插件前，请确保插件的 `manifest.yaml` 文件和 `/provider` 路径下的 `.yaml` 文件中的 `author` 字段与 GitHub ID 保持一致。关于清单文件的详细信息，请参考[一般规范定义](./plugin-dev-zh/0411-general-specifications)。

插件项目开发完成后，请确保已完成[远程调试测试](./plugin-dev-zh/0411-remote-debug-a-plugin)。需前往插件项目的上一级目录，运行以下插件打包命令：

```bash
dify plugin package ./your_plugin_project
```

运行命令后将在当前路径下生成以 `.difypkg` 后缀结尾的文件。

![生成插件文件](https://assets-docs.dify.ai/2024/12/98e09c04273eace8fe6e5ac976443cca.png)

### 安装插件

访问 Dify 插件管理页，轻点右上角的**安装插件** → **通过本地文件**安装，或将插件文件拖拽至页面空白处安装插件。

![安装插件文件](https://assets-docs.dify.ai/2024/12/8c31c4025a070f23455799f942b91a57.png)

### 发布插件

你可以将插件文件分享给他人，或上传至互联网供他人下载。如果你希望更广泛地分享你的插件，可以考虑：

1. [发布至个人GitHub仓库](./plugin-dev-zh/0322-release-to-individual-github-repo) - 通过GitHub分享插件
2. [发布至Dify Marketplace](./plugin-dev-zh/0322-release-to-dify-marketplace) - 在官方市场发布插件

## 相关资源

- [发布插件](./plugin-dev-zh/0321-release-overview) - 了解各种发布方式
- [初始化开发工具](./plugin-dev-zh/0221-initialize-development-tools) - 配置插件开发环境
- [远程调试插件](./plugin-dev-zh/0411-remote-debug-a-plugin) - 学习插件调试方法
- [一般规范定义](./plugin-dev-zh/0411-general-specifications) - 定义插件元数据
- [插件开发入门指南](./plugin-dev-zh/0211-getting-started-dify-tool) - 从零开始开发插件

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0322-release-by-file.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 发布至 Dify Marketplace
> 来源：`plugin-dev-zh/0322-release-to-dify-marketplace.mdx`
> 摘要：本指引详细介绍了如何将插件发布到Dify Marketplace的完整流程，包括提交PR、审核流程、发布后维护等关键步骤和注意事项。

Dify Marketplace 欢迎来自合作伙伴和社区开发者的插件上架申请，您的贡献将进一步丰富 Dify 插件的可能性。本指引将提供清晰的发布流程和最佳实践建议，让您的插件能够顺利发布，并为社区带来价值。如果您还没有开发插件，可以参考[插件开发入门指南](./plugin-dev-zh/0211-getting-started-dify-tool)。

请按照以下步骤，在 [GitHub 代码仓库](https://github.com/langgenius/dify-plugins)提交您的插件 Pull Request（PR）并接受审核，通过后插件将正式上线至 Dify Marketplace。

### 插件的发布流程

将插件发布至 Dify Marketplace 包含以下步骤：

1. 根据[插件开发者准则](./plugin-dev-zh/0312-contributor-covenant-code-of-conduct)完成插件的开发和测试；
2. 根据[插件隐私数据保护指南](./plugin-dev-zh/0312-privacy-protection-guidelines)撰写该插件隐私政策，并将该隐私政策的文件路径或 URL 写入插件[一般规范定义](./plugin-dev-zh/0411-general-specifications)；
3. 完成插件打包；
4. Fork [Dify Plugins](https://github.com/langgenius/dify-plugins) 代码仓库；
5. 在代码仓库中创建您的个人或组织文件夹，并将打包好的 `.difypkg` 文件上传至该文件夹下；
6. 遵循 GitHub 中的 PR Template 内容格式提交 Pull Request (PR)，等待审核；
7. 审核通过后，插件代码将合并至 Main 分支，插件自动上架至 [Dify Marketplace](https://marketplace.dify.ai/)。

插件提交、审核和上架流程图：

![The process of uploading plugins](https://assets-docs.dify.ai/2025/01/05df333acfaf662e99316432db23ba9f.png)

> **Note**: 上图中的 Contributor Agreement 指的是[插件开发者准则](./plugin-dev-zh/0312-contributor-covenant-code-of-conduct)。

***

### Pull Request (PR) 审核期间

积极回应审查人员的提问和反馈：

* **14 天内**未解决的 PR 评论将被标记为过时（可重新开启）。
* **30 天内**未解决的 PR 评论将被关闭（不可重新开启，需要创建新 PR）。

***

### **Pull Request (PR) 审核通过后**

**1. 持续维护**

* 处理用户报告的问题和功能请求。
* 在发生重大 API 变更时迁移插件：
  * Dify 将提前发布变更通知和迁移说明。
  * Dify 工程师可提供迁移支持。

**2. Marketplace 公开 Beta 测试阶段的限制**

* 避免对现有插件引入破坏性更改。

***

### 审核流程

**1. 审核顺序**

* 按照 **先到先审** 的顺序处理 PR。审核将在 1 周内开始。如有延迟，审查人员将通过评论通知 PR 作者。

**2. 审核重点**

* 检查插件名称、描述和设置说明是否清晰且具有指导性。
* 检查插件的 [一般规范定义](./plugin-dev-zh/0411-general-specifications)是否符合格式规范，并包含有效的作者联系信息。

3. **插件的功能性和相关性**

* 根据[插件开发指南](./plugin-dev-zh/0111-getting-started-dify-plugin)测试插件。
* 确保插件在 Dify 生态系统中的用途合理。

[Dify.AI](https://dify.ai/) 保留接受或拒绝插件提交的权利。

***

### 常见问题

1. **如何判断插件是否独特？**

示例：一个 Google 搜索插件仅增加了多语言版本，应被视为现有插件的优化。但如果插件实现了显著的功能改进（如优化批量处理或错误处理），则可以作为新插件提交。

2. **如果我的 PR 被标记为过时或关闭怎么办？**

被标记为过时的 PR 可以在解决反馈后重新开启。被关闭的 PR（超过 30 天）需要重新创建一个新 PR。

3. **Beta 测试阶段可以更新插件吗？**

可以，但应避免引入破坏性更改。

## 相关资源

- [发布插件](./plugin-dev-zh/0321-release-overview) - 了解各种发布方式
- [插件开发者准则](./plugin-dev-zh/0312-contributor-covenant-code-of-conduct) - 插件提交规范
- [插件隐私数据保护指南](./plugin-dev-zh/0312-privacy-protection-guidelines) - 隐私政策编写要求
- [打包为本地文件与分享](./plugin-dev-zh/0322-release-by-file) - 插件打包方法
- [一般规范定义](./plugin-dev-zh/0411-general-specifications) - 插件元数据定义

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0322-release-to-dify-marketplace.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 发布至个人 GitHub 仓库
> 来源：`plugin-dev-zh/0322-release-to-individual-github-repo.mdx`
> 摘要：本文档详细介绍了如何将Dify插件发布到个人的GitHub仓库中，包括准备工作、初始化本地插件仓库、连接远程仓库、上传插件文件、打包插件代码以及如何通过GitHub安装插件的完整流程。该方式允许开发者完全管理自己的插件代码和更新。

支持通过 GitHub 仓库链接安装插件。插件开发完成后，你可以选择将插件发布至公开 GitHub 仓库供其他人下载和使用。如果您还没有开发插件，可以参考[插件开发入门指南](./plugin-dev-zh/0211-getting-started-dify-tool)。

该方式具备以下优势：

• **个人管理**：你可以完全控制插件的代码和更新

• **快速分享**：通过 GitHub 链接即可轻松分享给其他用户或团队成员，便于测试和使用

• **协作与反馈**：将插件开源后，有可能会吸引 GitHub 上潜在的协作者，帮助您快速改进插件

本文将指导你如何将插件发布到 GitHub 仓库。

### 准备工作

首先要确认您已开发并测试了插件，并阅读了[插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin)和[插件开发者准则](./plugin-dev-zh/0312-contributor-covenant-code-of-conduct)。在发布插件前，请确保您本地已安装以下工具：

* GitHub 账号
* 创建一个新的公开 GitHub 仓库
* 本地已安装 Git 工具

关于 GitHub 的基础知识，请参考 [GitHub 文档](https://docs.github.com/en/repositories/creating-and-managing-repositories/creating-a-new-repository)。

### 1. 完善插件项目

将上传至公开的 GitHub 意味着你将公开插件。请确保你已完成插件的调试和验证，并已完善插件的 `README.md` 文件说明。

建议说明文件包含以下内容：

* 插件的简介和功能描述
* 安装和配置步骤
* 使用示例
* 联系方式或贡献指南

### 2. 初始化本地插件仓库

将插件公开上传至 GitHub 之前，请确保已完成插件的调试和验证工作，详细请参考[远程调试插件](./plugin-dev-zh/0411-remote-debug-a-plugin)。在终端中导航到插件项目文件夹，并运行以下命令：

```bash
git init
git add .
git commit -m "Initial commit: Add plugin files"
```

如果你是第一次使用 Git，可能还需要配置 Git 用户名和邮箱：

```bash
git config --global user.name "Your Name"
git config --global user.email "your.email@example.com"
```

### 3. 连接远程仓库

使用以下命令，将本地仓库连接到 GitHub 仓库：

```bash
git remote add origin https://github.com/<your-username>/<repository-name>.git
```

### 4. 上传插件文件

> 打包插件前，请确保插件的 `manifest.yaml` 文件和 `/provider` 路径下的 `.yaml` 文件中的 author 字段与 GitHub ID 保持一致。关于清单文件的详细规范，请参考[通过清单文件定义插件信息](./plugin-dev-zh/0411-plugin-info-by-manifest)。

将插件项目推送到 GitHub 仓库：

```bash
git branch -M main
git push -u origin main
```

上传代码时建议附上标签，以便后续打包代码。

```bash
git tag -a v0.0.1 -m "Release version 0.0.1"

git push origin v0.0.1
```

### 5. 打包插件代码

前往 GitHub 代码仓库的 Releases 页，创建一个新的版本发布。发布版本时需上传插件文件。关于如何打包插件文件，详细说明请阅读[打包为本地文件与分享](./plugin-dev-zh/0322-release-by-file)。

![打包插件](https://assets-docs.dify.ai/2024/12/5cb4696348cc6903e380287fce8f529d.png)

### 通过 GitHub 安装插件

其他人可以通过 GitHub 仓库地址安装该插件。访问 Dify 平台的插件管理页，选择通过 GitHub 安装插件，输入仓库地址后，选择版本号和包文件完成安装。

![](https://assets-docs.dify.ai/2024/12/3c2612349c67e6898a1f33a7cc320468.png)

## 相关资源

- [发布插件](./plugin-dev-zh/0321-release-overview) - 了解各种发布方式
- [打包为本地文件与分享](./plugin-dev-zh/0322-release-by-file) - 插件打包方法
- [通过清单文件定义插件信息](./plugin-dev-zh/0411-plugin-info-by-manifest) - 定义插件元数据
- [插件开发者准则](./plugin-dev-zh/0312-contributor-covenant-code-of-conduct) - 了解插件开发规范
- [远程调试插件](./plugin-dev-zh/0411-remote-debug-a-plugin) - 学习插件调试方法

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0322-release-to-individual-github-repo.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 常见问题
> 来源：`plugin-dev-zh/0331-faq.mdx`
> 摘要：Author Allen 本文档回答了Dify插件开发和安装过程中的常见问题，包括插件上传失败的解决方法（修改author字段）以及如何处理插件安装过程中的验证异常（设置FORCE_VERIFYING_SIGNATURE环境变量）。

## 安装插件时提示上传失败如何处理？

**错误详情**：出现 `PluginDaemonBadRequestError: plugin_unique_identifier is not valid` 报错提示。

**解决办法**：将插件项目下的 `manifest.yaml` 文件和 `/provider` 路径下的 `.yaml` 文件中的 `author` 字段修改为 GitHub ID。

重新运行插件打包命令并安装新的插件包。

## 安装插件时遇到异常应如何处理？

**问题描述**：安装插件时遇到异常信息：`plugin verification has been enabled, and the plugin you want to install has a bad signature`，应该如何处理？

**解决办法**：在 `/docker/.env` 配置文件的末尾添加 `FORCE_VERIFYING_SIGNATURE=false` 字段，运行以下命令重启 Dify 服务：

```bash
cd docker
docker compose down
docker compose up -d
```

添加该字段后，Dify 平台将允许安装所有未在 Dify Marketplace 上架（审核）的插件，可能存在安全隐患。

建议在测试 / 沙箱环境内安装插件，确认安全后再安装至生产环境。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0331-faq.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 贡献指南
> 来源：`plugin-dev-zh/0411-doc-contribution-guide.mdx`

欢迎参与 Dify 文档的协同构建！本指南旨在阐述 Dify 开发者文档的贡献流程与规范，鼓励并协助社区成员共同提升文档质量。

## 更新现有文档

    在您希望修改的文档页面末尾，点击  **编辑此页面** 按钮。这将直接链接到 GitHub 上对应的源文件。

    Dify 文档的 URL 与其在 GitHub 仓库中的相对路径存在明确的对应关系，可供熟悉结构的贡献者参考：

    | 网址 (示例) | GitHub 仓库相对路径 (示例) |
    | :--- | :--- |
    | `https://docs.dify.ai/plugin-dev-zh/0111-getting-started-dify-plugin` | `plugin-dev-zh/0111-getting-started-dify-plugin.mdx` |

---

  编辑时，请专注于正文内容的准确性和清晰度。文件头部的 Frontmatter 元数据及末尾的特定脚本或包含内容，通常由核心贡献者或通过自动化流程进行管理和维护。

  如发现文档问题，您也可以通过页面上的 **提交问题** 按钮向我们报告。准确的问题反馈对社区和项目而言都是重要的贡献。

## 创建新文档

> **步骤：**

    在相应的语言目录下 (例如 `plugin-dev-zh`) 创建一个新的 `.mdx` 文件。

    点击此卡片，直接在 GitHub 上创建文档。

    初始文件名可自行定义 (例如 `qwertyuiop12345678.mdx`)，文件名必须足够长。

      请遵循标准的 **Markdown** 语法。在 MDX 文件中，注释请使用 JSX 风格：``，而非 HTML 风格的 ``。

      可适当运用 Mintlify 提供的组件优化内容结构与呈现：

      ```jsx

        这是一个重要提示。

> **警告：**

        这是一个警告信息。

        更多内容请参考相关资源...

      ```

      更多组件请参考 [Mintlify 组件文档](https://mintlify.com/docs)。

    每篇文档都需要定义 Frontmatter 元数据：

    * 正确配置的 Frontmatter 是确保文档能够被系统准确索引、排序并在文档网站上正确显示和导航的关键。
    * **您的首要任务是贡献高质量、准确的文档内容。**
    * 如果您熟悉 Dify 的 [文档 Frontmatter 元数据指南](./plugin-dev-zh/0412-doc-writing-dimensions-guide)，我们非常欢迎您在提交时包含 Frontmatter。
    * **如果您不确定如何填写 Frontmatter，或者希望专注于内容创作，完全没有问题。** 您可以提交不包含 Frontmatter 或仅包含部分元数据的 Pull Request。社区和项目核心贡献者会协助您进行后续的添加、审核与优化。

  **您的内容贡献至关重要。** 即使您未提供完整的 Frontmatter，您的 Pull Request 依然受欢迎。确保文档最终拥有规范的元数据并成功集成，是社区与核心团队协作完成的工作。

## 提交您的贡献

完成编辑或创建新文档后，请通过 GitHub 向主仓库提交 Pull Request。社区成员和项目维护者将对您的贡献进行审阅。

## 常见问题解答

    当然可以！文档贡献不需要编程技能。如果您对 Dify 有所了解，您可以帮助改进现有文档的清晰度、准确性，或添加更多用户友好的说明和示例。

    确保您的内容清晰、准确，并遵循我们的格式指南。在提交前检查拼写和语法。如果不确定，可以在提交前在社区中讨论您的想法。

    可以！我们欢迎多语言文档贡献。请确保您的文件放在对应语言的目录中，并在 Frontmatter 中正确标注语言代码。

---

感谢您为 Dify 社区和文档建设贡献力量！

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0411-doc-contribution-guide.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 通用规范定义
> 来源：`plugin-dev-zh/0411-general-specifications.mdx`
> 摘要：本文档详细介绍了Dify插件开发中的通用结构和规范，包括路径规范、国际化对象(I18nObject)、供应商表单结构(ProviderConfig)、模型配置(ModelConfig)、节点响应(NodeResponse)和工具选择器(ToolSelector)等重要数据结构的定义和用途。

本文将简要介绍插件开发中常见的结构。在开发过程中，强烈建议配合[插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin)和[开发者速查表](./plugin-dev-zh/0131-cheatsheet)一起阅读，以便更好地理解整体架构。

### 路径规范

在 Manifest 或任意 yaml 文件中填写文件路径时，根据不同的类型的文件，遵循下面两条规范：

* 如果目标文件是一个图片或视频等多媒体文件时，例如填写插件的 `icon` ，你应该将这些文件放置于插件根目录下的 `_assets` 文件夹中。
* 如果目标文件是一个普通文本文件，如 `.py` `.yaml` 等代码文件，你应该填写该文件在插件项目内的绝对路径。

### 通用结构

在定义插件时，有一些数据结构是可以在工具、模型、Endpoint 之间共用的，这里定义了这些共用结构。

#### I18nObject

`I18nObject` 是一个符合 [IETF BCP 47](https://tools.ietf.org/html/bcp47) 标准的国际化结构，目前支持的四种语言为

* en\_US
* zh\_Hans
* ja\_Jp
* pt\_BR

#### ProviderConfig

`ProviderConfig` 为一个通用的供应商表单结构，适用于 `Tool`与`Endpoint`

* `name`(string)：表单项名称
* `label`([I18nObject](#i18nobject), required)：遵循 [IETF BCP 47](https://tools.ietf.org/html/bcp47)
* `type`([provider\_config\_type](#providerconfigtype-string), required)：表单类型
* `scope`([provider\_config\_scope](#providerconfigscope-string))：可选项范围，根据`type`变动
* `required`(bool)：不能为空
* `default`(any)：默认值，仅支持基础类型 `float` `int` `string`
* `options`(list\[[provider\_config\_option](#providerconfigoption-object)])：可选项，仅当 type 为 `select` 时使用
* `helper`(object)：帮助文档链接的 label，遵循 [IETF BCP 47](https://tools.ietf.org/html/bcp47)
* `url` (string)：帮助文档链接
* `placeholder`(object)：遵循 [IETF BCP 47](https://tools.ietf.org/html/bcp47)

#### ProviderConfigOption(object)

* `value`(string, required)：值
* `label`(object, required)：遵循 [IETF BCP 47](https://tools.ietf.org/html/bcp47)

#### ProviderConfigType(string)

* `secret-input` (string)：配置信息将被加密
* `text-input`(string)：普通文本
* `select`(string)：下拉框
* `boolean`(bool)：开关
* `model-selector`(object)：模型配置信息，包含供应商名称、模型名称、模型参数等
* `app-selector`(object)：app id
* `tool-selector`(object)：工具配置信息，包含工具供应商、名称、参数等
* `dataset-selector`(string)：TBD

#### ProviderConfigScope(string)

* 当 `type` 为 `model-selector` 时
  * `all`
  * `llm`
  * `text-embedding`
  * `rerank`
  * `tts`
  * `speech2text`
  * `moderation`
  * `vision`
* 当 `type` 为 `app-selector` 时
  * `all`
  * `chat`
  * `workflow`
  * `completion`
* 当`type` 为 `tool-selector` 时
  * `all`
  * `plugin`
  * `api`
  * `workflow`

#### ModelConfig

* `provider` (string): 包含 plugin\_id 的模型供应商名称，形如 `langgenius/openai/openai`。
* `model` (string): 具体的模型名称。
* `model_type` (enum): 模型类型的枚举，可以参考[模型设计规则](./plugin-dev-zh/0411-model-designing-rules#modeltype)文档。

#### NodeResponse

* `inputs` (dict): 最终输入到节点中的变量。
* `outputs` (dict): 节点的输出结果。
* `process_data` (dict): 节点运行过程中产生的数据。

#### ToolSelector

* `provider_id` (string): 工具供应商名称
* `tool_name` (string): 工具名称
* `tool_description` (string): 工具描述
* `tool_configuration` (dict\[str, Any]): 工具的配置信息
* `tool_parameters` (dict\[str, dict]): 需要 LLM 推理的参数
  * `name` (string): 参数名称
  * `type` (string): 参数类型
  * `required` (bool): 是否必填
  * `description` (string): 参数描述
  * `default` (any): 默认
  * `options`(list\[string]): 可选项

## 相关资源

- [插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin) - 全面了解Dify插件开发
- [开发者速查表](./plugin-dev-zh/0131-cheatsheet) - 插件开发常用命令和概念速查

- [工具插件开发详情](./plugin-dev-zh/0222-tool-plugin) - 详细了解工具插件开发流程
- [模型设计规则](./plugin-dev-zh/0411-model-designing-rules) - 了解模型配置的规范

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0411-general-specifications.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 模型设计规则
> 来源：`plugin-dev-zh/0411-model-designing-rules.mdx`
> 摘要：本文档详细定义了Dify模型插件开发的核心概念和结构，包括模型供应商(Provider)、AI模型实体(AIModelEntity)、模型类型(ModelType)、配置方法(ConfigurateMethod)、模型特性(ModelFeature)、参数规则(ParameterRule)、价格配置(PriceConfig)及各种凭证模式的详细数据结构规范。

* 模型供应商规则基于 [Provider](#provider) 实体。
* 模型规则基于 [AIModelEntity](#aimodelentity) 实体。

> 以下所有实体均基于 `Pydantic BaseModel`，可在 `entities` 模块中找到对应实体。

### Provider

* `provider` (string) 供应商标识，如：`openai`
* `label` (object) 供应商展示名称，i18n，可设置 `en_US` 英文、`zh_Hans` 中文两种语言
  * `zh_Hans` (string) \[optional] 中文标签名，`zh_Hans` 不设置将默认使用 `en_US`。
  * `en_US` (string) 英文标签名
* `description` (object) \[optional] 供应商描述，i18n
  * `zh_Hans` (string) \[optional] 中文描述
  * `en_US` (string) 英文描述
* `icon_small` (string) \[optional] 供应商小 ICON，存储在对应供应商实现目录下的 `_assets` 目录，中英文策略同 `label`
  * `zh_Hans` (string) \[optional] 中文 ICON
  * `en_US` (string) 英文 ICON
* `icon_large` (string) \[optional] 供应商大 ICON，存储在对应供应商实现目录下的 \_assets 目录，中英文策略同 label
  * `zh_Hans` (string) \[optional] 中文 ICON
  * `en_US` (string) 英文 ICON
* `background` (string) \[optional] 背景颜色色值，例：#FFFFFF，为空则展示前端默认色值。
* `help` (object) \[optional] 帮助信息
  * `title` (object) 帮助标题，i18n
    * `zh_Hans` (string) \[optional] 中文标题
    * `en_US` (string) 英文标题
  * `url` (object) 帮助链接，i18n
    * `zh_Hans` (string) \[optional] 中文链接
    * `en_US` (string) 英文链接
* `supported_model_types` (array\[[ModelType](#modeltype)]) 支持的模型类型
* `configurate_methods` (array\[[ConfigurateMethod](#configuratemethod)]) 配置方式
* `provider_credential_schema` (\[[ProviderCredentialSchema](#providercredentialschema)]) 供应商凭据规格
* `model_credential_schema` (\[[ModelCredentialSchema](#modelcredentialschema)]) 模型凭据规格

### AIModelEntity

* `model` (string) 模型标识，如：`gpt-3.5-turbo`
* `label` (object) \[optional] 模型展示名称，i18n，可设置 `en_US` 英文、`zh_Hans` 中文两种语言
  * `zh_Hans` (string) \[optional] 中文标签名
  * `en_US` (string) 英文标签名
* `model_type` ([ModelType](#modeltype)) 模型类型
* `features` (array\[[ModelFeature](#modelfeature)]) \[optional] 支持功能列表
* `model_properties` (object) 模型属性
  * `mode` ([LLMMode](#llmmode)) 模式 (模型类型 `llm` 可用)
  * `context_size` (int) 上下文大小 (模型类型 `llm` `text-embedding` 可用)
  * `max_chunks` (int) 最大分块数量 (模型类型 `text-embedding moderation` 可用)
  * `file_upload_limit` (int) 文件最大上传限制，单位：MB。（模型类型 `speech2text` 可用）
  * `supported_file_extensions` (string) 支持文件扩展格式，如：mp3,mp4（模型类型 `speech2text` 可用）
  * `default_voice` (string) 缺省音色，必选：alloy,echo,fable,onyx,nova,shimmer（模型类型 `tts` 可用）
  * `voices` (list) 可选音色列表。
    * `mode` (string) 音色模型。（模型类型 `tts` 可用）
    * `name` (string) 音色模型显示名称。（模型类型 `tts` 可用）
    * `language` (string) 音色模型支持语言。（模型类型 `tts` 可用）
  * `word_limit` (int) 单次转换字数限制，默认按段落分段（模型类型 `tts` 可用）
  * `audio_type` (string) 支持音频文件扩展格式，如：mp3,wav（模型类型 `tts` 可用）
  * `max_workers` (int) 支持文字音频转换并发任务数（模型类型 `tts` 可用）
  * `max_characters_per_chunk` (int) 每块最大字符数 (模型类型 `moderation` 可用)
* `parameter_rules` (array\[[ParameterRule](#parameterrule)]) \[optional] 模型调用参数规则
* `pricing` (\[[PriceConfig](#priceconfig)]) \[optional] 价格信息
* `deprecated` (bool) 是否废弃。若废弃，模型列表将不再展示，但已经配置的可以继续使用，默认 False。

### ModelType

* `llm` 文本生成模型
* `text-embedding` 文本 Embedding 模型
* `rerank` Rerank 模型
* `speech2text` 语音转文字
* `tts` 文字转语音
* `moderation` 审查

### ConfigurateMethod

* `predefined-model` 预定义模型

表示用户只需要配置统一的供应商凭据即可使用供应商下的预定义模型。

* `customizable-model` 自定义模型

用户需要新增每个模型的凭据配置。

* `fetch-from-remote` 从远程获取

与 `predefined-model` 配置方式一致，只需要配置统一的供应商凭据即可，模型通过凭据信息从供应商获取。

### ModelFeature

* `agent-thought` Agent 推理，一般超过 70B 有思维链能力。
* `vision` 视觉，即：图像理解。
* `tool-call` 工具调用
* `multi-tool-call` 多工具调用
* `stream-tool-call` 流式工具调用

### FetchFrom

* `predefined-model` 预定义模型
* `fetch-from-remote` 远程模型

### LLMMode

* `completion` 文本补全
* `chat` 对话

### ParameterRule

* `name` (string) 调用模型实际参数名
* `use_template` (string) \[optional] 使用模板 

> 关于模板的具体使用，可以参考[创建新模型提供者](./plugin-dev-zh/0222-creating-new-model-provider)中的示例。

默认预置了 5 种变量内容配置模板：

* `temperature`
* `top_p`
* `frequency_penalty`
* `presence_penalty`
* `max_tokens`

可在 use\_template 中直接设置模板变量名，将会使用 entities.defaults.PARAMETER\_RULE\_TEMPLATE 中的默认配置不用设置除 `name` 和 `use_template` 之外的所有参数，若设置了额外的配置参数，将覆盖默认配置。可参考 `openai/llm/gpt-3.5-turbo.yaml`。

* `label` (object) \[optional] 标签，i18n
  * `zh_Hans`(string) \[optional] 中文标签名
  * `en_US` (string) 英文标签名
* `type`(string) \[optional] 参数类型
  * `int` 整数
  * `float` 浮点数
  * `string` 字符串
  * `boolean` 布尔型
* `help` (object) \[optional] 帮助信息
  * `zh_Hans` (string) \[optional] 中文帮助信息
  * `en_US` (string) 英文帮助信息
* `required` (bool) 是否必填，默认 False。
* `default`(int/float/string/bool) \[optional] 默认值
* `min`(int/float) \[optional] 最小值，仅数字类型适用
* `max`(int/float) \[optional] 最大值，仅数字类型适用
* `precision`(int) \[optional] 精度，保留小数位数，仅数字类型适用
* `options` (array\[string]) \[optional] 下拉选项值，仅当 `type` 为 `string` 时适用，若不设置或为 null 则不限制选项值

### PriceConfig

* `input` (float) 输入单价，即 Prompt 单价
* `output` (float) 输出单价，即返回内容单价
* `unit` (float) 价格单位，如以 1M tokens 计价，则单价对应的单位 token 数为 `0.000001`
* `currency` (string) 货币单位

### ProviderCredentialSchema

* `credential_form_schemas` (array\[[CredentialFormSchema](#credentialformschema)]) 凭据表单规范

### ModelCredentialSchema

* `model` (object) 模型标识，变量名默认 `model`
  * `label` (object) 模型表单项展示名称
    * `en_US` (string) 英文
    * `zh_Hans`(string) \[optional] 中文
  * `placeholder` (object) 模型提示内容
    * `en_US`(string) 英文
    * `zh_Hans`(string) \[optional] 中文
* `credential_form_schemas` (array\[[CredentialFormSchema](#credentialformschema)]) 凭据表单规范

### CredentialFormSchema

* `variable` (string) 表单项变量名
* `label` (object) 表单项标签名
  * `en_US`(string) 英文
  * `zh_Hans` (string) \[optional] 中文
* `type` ([FormType](#formtype)) 表单项类型
* `required` (bool) 是否必填
* `default`(string) 默认值
* `options` (array\[[FormOption](#formoption)]) 表单项为 `select` 或 `radio` 专有属性，定义下拉内容
* `placeholder`(object) 表单项为 `text-input` 专有属性，表单项 PlaceHolder
  * `en_US`(string) 英文
  * `zh_Hans` (string) \[optional] 中文
* `max_length` (int) 表单项为`text-input`专有属性，定义输入最大长度，0 为不限制。
* `show_on` (array\[[FormShowOnObject](#formshowonobject)]) 当其他表单项值符合条件时显示，为空则始终显示。

#### FormType

* `text-input` 文本输入组件
* `secret-input` 密码输入组件
* `select` 单选下拉
* `radio` Radio 组件
* `switch` 开关组件，仅支持 `true` 和 `false`

#### FormOption

* `label` (object) 标签
  * `en_US`(string) 英文
  * `zh_Hans`(string) \[optional] 中文
* `value` (string) 下拉选项值
* `show_on` (array\[[FormShowOnObject](#formshowonobject)]) 当其他表单项值符合条件时显示，为空则始终显示。

#### FormShowOnObject

* `variable` (string) 其他表单项变量名
* `value` (string) 其他表单项变量值

## 相关资源

- [模型架构详解](./plugin-dev-zh/0412-model-schema) - 深入了解模型插件的架构规范
- [快速接入一个新模型](./plugin-dev-zh/0211-getting-started-new-model) - 学习如何应用这些规则添加新模型
- [一般规范定义](./plugin-dev-zh/0411-general-specifications) - 了解插件清单文件的配置
- [创建新模型提供者](./plugin-dev-zh/0222-creating-new-model-provider) - 开发全新的模型提供商插件

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0411-model-designing-rules.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Model 插件
> 来源：`plugin-dev-zh/0411-model-plugin-introduction.mdx`
> 摘要：介绍模型插件的基本概念和结构。模型插件让Dify能够调用不同供应商（如OpenAI、Anthropic、Google等）的各类模型，包括大语言模型（LLM）、文本嵌入、语音转文字等不同类型。

Model 模型插件使 Dify 平台能够调用该模型供应商下的所有 LLM。例如，安装 OpenAI 模型插件后，Dify 平台即可调用 OpenAI 提供的 `GPT-4`、`GPT-4o-2024-05-13` 等模型。

## 模型插件结构

为了便于理解在开发模型插件过程中可能涉及的概念，以下是模型插件内的结构简介：

* **模型供应商**：大模型的开发公司，例如 **OpenAI、Anthropic、Google** 等；
* **模型分类**：根据模型供应商的不同，存在大语言模型（LLM）、文本嵌入模型（Text embedding）、语音转文字（Speech2text）等分类；
* **具体模型**：`claude-3-5-sonnet`、`gpt-4-turbo` 等。

插件项目中的代码层级结构：

```bash
- 模型供应商
    - 模型分类
        - 具体模型
```

以 **Anthropic** 为例，模型插件的示例结构如下：

```bash
- Anthropic
    - llm
        claude-3-5-sonnet-20240620 
        claude-3-haiku-20240307
        claude-3-opus-20240229 
        claude-3-sonnet-20240229 
        claude-instant-1.2 
        claude-instant-1
```

以 OpenAI 为例，因为它支持多种模型类型，所以存在多层模型分类，结构如下：

```bash
├── models
│   ├── llm
│   │   ├── chatgpt-4o-latest
│   │   ├── gpt-3.5-turbo
│   │   ├── gpt-4-0125-preview
│   │   ├── gpt-4-turbo
│   │   ├── gpt-4o
│   │   ├── llm
│   │   ├── o1-preview
│   │   └── text-davinci-003
│   ├── moderation
│   │   ├── moderation
│   │   └── text-moderation-stable
│   ├── speech2text
│   │   ├── speech2text
│   │   └── whisper-1
│   ├── text_embedding
│   │   ├── text-embedding-3-large
│   │   └── text_embedding
│   └── tts
│       ├── tts-1-hd
│       ├── tts-1
│       └── tts
```

## 模型配置

模型插件通过配置文件定义模型的行为和属性。详细的模型设计规则和配置格式请参考[模型设计规则](./plugin-dev-zh/0411-model-designing-rules)文档和[模型架构](./plugin-dev-zh/0412-model-schema)规范。

## 进一步阅读

- [快速接入一个新模型](./plugin-dev-zh/0211-getting-started-new-model) - 学习如何为已支持的供应商添加新模型
- [模型设计规则](./plugin-dev-zh/0411-model-designing-rules) - 详细了解模型配置的规范
- [模型架构](./plugin-dev-zh/0412-model-schema) - 深入理解模型插件的架构
- [通用规范定义](./plugin-dev-zh/0411-general-specifications) - 了解插件元数据定义方式
- [插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin) - 返回插件开发入门指南

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0411-model-plugin-introduction.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 持久化存储
> 来源：`plugin-dev-zh/0411-persistent-storage-kv.mdx`
> 摘要：本文档介绍了Dify插件中的持久化存储功能，详细说明了如何在插件中使用KV数据库来储存、获取和删除数据。这一功能使插件能够在相同Workspace内持久化存储数据，满足跨会话数据保存的需求。

如果单独审视插件中的 Tool 及 Endpoint，不难发现大多数情况下其只能完成单轮交互，请求后返回数据，任务结束。

如果有需要长期储存的数据，如实现持久化的记忆，需要插件具备持久化存储能力。**持久化存储机制能够让插件具备在相同 Workspace 持久存储数据的能力**，目前通过提供 KV 数据库满足存储需求，未来可能会根据实际的使用情况推出更灵活更强大的储存接口。

### 储存 Key

#### **入口**

```python
    self.session.storage
```

#### **接口**

```python
    def set(self, key: str, val: bytes) -> None:
        pass
```

可以注意到传入的是一个 bytes，因此实际上你可以在其中储存文件。

### 获取 Key

#### **入口**

```python
    self.session.storage
```

#### **接口**

```python
    def get(self, key: str) -> bytes:
        pass
```

### 删除 Key

#### **入口**

```python
    self.session.storage
```

#### **接口**

```python
    def delete(self, key: str) -> None:
        pass
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0411-persistent-storage-kv.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Manifest
> 来源：`plugin-dev-zh/0411-plugin-info-by-manifest.mdx`
> 摘要：Author Yeuoly，Allen 本文档详细介绍了Dify插件中的Manifest文件，它是定义插件基本信息的YAML文件。文档包含完整的代码示例和详细的结构说明，涵盖插件版本、类型、作者、名称、资源使用、权限申请、功能定义、运行时等各方面的配置信息。

Manifest 是一个符合 yaml 规范的文件，它定义了**插件**最基础的信息，包括但不限于插件名称、作者、包含的工具、模型等信息。关于插件的整体架构，请参考[插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin)和[开发者速查表](./plugin-dev-zh/0131-cheatsheet)。

若该文件的格式错误，插件的解析和打包过程都将会失败。

### 版本管理

插件的版本由 `manifest` 文件中的 `version` 字段管理。版本号必须符合 `大版本.小版本.补丁版本` 格式，否则自动更新可能无法正常工作。

### 代码示例

下面是一个 Manifest 文件的简单示例，将在下文解释各个数据的含义和作用。

如需参考其它插件的代码，请参考 [GitHub 代码仓库](https://github.com/langgenius/dify-official-plugins/blob/main/tools/google/manifest.yaml)。

```yaml
version: 0.0.1
type: "plugin"
author: "Yeuoly"
name: "neko"
label:
  en_US: "Neko"
created_at: "2024-07-12T08:03:44.658609186Z"
icon: "icon.svg"
resource:
  memory: 1048576
  permission:
    tool:
      enabled: true
    model:
      enabled: true
      llm: true
    endpoint:
      enabled: true
    app:
      enabled: true
    storage: 
      enabled: true
      size: 1048576
plugins:
  endpoints:
    - "provider/neko.yaml"
meta:
  version: 0.0.1
  arch:
    - "amd64"
    - "arm64"
  runner:
    language: "python"
    version: "3.11"
    entrypoint: "main"
privacy: "./privacy.md"
```

### 结构

* `version`(version, required)：插件的版本
* `type`(type, required)：插件类型，目前仅支持 `plugin`，未来支持 `bundle`
* `author`(string, required)：作者，在 Marketplace 中定义为组织名
* `label`(label, required)：多语言名称
* `created_at`(RFC3339, required)：创建时间，Marketplace 上要求创建时间不得大于当前时间
* `icon`(asset, required)：图标路径
* `resource` (object)：需要申请的资源
  * `memory` (int64)：最大内存占用，主要与 SaaS 上的 AWS Lambda 资源申请相关，单位字节
  * `permission`(object)：权限申请
    * `tool`(object)：反向调用工具的权限
      * `enabled` (bool)
    * `model`(object)：反向调用模型的权限
      * `enabled`(bool)
      * `llm`(bool)
      * `text_embedding`(bool)
      * `rerank`(bool)
      * `tts`(bool)
      * `speech2text`(bool)
      * `moderation`(bool)
    * `node`(object)：反向调用节点的权限
      * `enabled`(bool)
    * `endpoint`(object)：允许注册 `endpoint` 的权限
      * `enabled`(bool)
    * `app`(object)：反向调用`app`的权限
      * `enabled`(bool)
    * `storage`(object)：申请持久化存储的权限
      * `enabled`(bool)
      * `size`(int64)：最大允许多大的持久化内存，单位字节
* `plugins`(object, required)：插件扩展的具体能力的`yaml`文件列表，插件包内的绝对路径，如需要扩展模型，则需要定义一个类似于 `openai.yaml`的文件，并将该文件路径填写在此处，且该路径上的文件必须真实存在，否则打包将失败。
  * 格式
    * `tools`(list\[string])：插件扩展的[工具](./plugin-dev-zh/0222-tool-plugin)供应商
    * `models`(list\[string])：插件扩展的[模型](./plugin-dev-zh/0131-model-plugin-introduction)供应商
    * `endpoints`(list\[string])：插件扩展的 [Endpoints](./plugin-dev-zh/0432-endpoint) 供应商
    * `agent_strategies` (list\[string])：插件扩展的 [Agent 策略](./plugin-dev-zh/9433-agent-strategy-plugin)供应商
  * 限制
    * 不允许同时扩展工具与模型
    * 不允许没有任意扩展
    * 不允许同时扩展模型与 Endpoint
    * 目前仅支持各类型扩展最多一个供应商
* `meta`(object)
  * `version`(version, required)：`manifest` 格式版本，初始版本 `0.0.1`
  * `arch`(list\[string], required)：支持的架构，目前仅支持 `amd64` `arm64`
  * `runner`(object, required)：运行时配置
    * `language`(string)：目前仅支持 python
    * `version`(string)：语言的版本，目前仅支持 `3.12`
    * `entrypoint`(string)：程序入口，在 python 下应为 `main`
* `privacy` (string, optional)：可选项，指定插件隐私政策文件的相对路径或 URL，例如 `"./privacy.md"` 或 `"https://your-web/privacy"`。如果计划将插件上架至 Dify Marketplace，**该字段为必填项**，用于提供明确的用户数据使用和隐私声明。详细填写指引请参考[插件隐私数据保护指南](./plugin-dev-zh/0312-privacy-protection-guidelines)。

## 相关资源

- [插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin) - 全面了解Dify插件开发
- [快速接入一个新模型](./plugin-dev-zh/0211-getting-started-new-model) - 学习为已有的供应商添加新模型
- [通用规范定义](./plugin-dev-zh/0411-general-specifications) - 了解插件开发中的通用结构
- [发布概览](./plugin-dev-zh/0321-release-overview) - 学习插件发布流程

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0411-plugin-info-by-manifest.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 插件调试
> 来源：`plugin-dev-zh/0411-remote-debug-a-plugin.mdx`
> 摘要：本文档介绍了如何使用Dify的远程调试功能来测试插件。详细说明了获取调试信息、配置环境变量文件、启动插件远程调试以及验证插件安装状态的完整流程。通过这种方式，开发者可以在本地开发的同时在Dify环境中实时测试插件。

插件开发完成后，接下来需要测试插件是否可以正常运行。Dify 提供便捷的远程调试方式，帮助你快速在测试环境中验证插件功能。

前往[“插件管理”](https://cloud.dify.ai/plugins)页获取远程服务器地址和调试 Key。

![远程调试插件](https://assets-docs.dify.ai/2025/04/2779338a43687f3e00155baccdd6d06c.png)

回到插件项目，拷贝 `.env.example` 文件并重命名为 `.env`，将获取的远程服务器地址和调试 Key 等信息填入其中。

`.env` 文件：

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_URL=debug.dify.ai:5003
REMOTE_INSTALL_KEY=********-****-****-****-************
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内，团队中的其他成员也可以访问该插件。

![插件安装到 Workspace](https://assets-docs.dify.ai/2024/12/ec26e5afc57bbfeb807719638f603807.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0411-remote-debug-a-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Tool Return
> 来源：`plugin-dev-zh/0411-tool.mdx`
> 摘要：本文档详细介绍了Dify插件中Tool的数据结构和使用方法。内容包括如何返回不同类型的消息（图片URL、链接、文本、文件、JSON）、如何创建变量和流式变量消息以及如何定义工具的输出变量模式以便于在workflow中引用。

在阅读详细的接口文档之前，请确保你对 Dify 插件的工具接入流程已有大致了解。

### 数据结构

#### 消息返回

Dify 支持`文本` `链接` `图片` `文件BLOB` `JSON` 等多种消息类型，你可以通过以下不同的接口返回不同类型的消息。

在默认情况下，一个工具在 `workflow` 中的输出会包含 `files` `text` `json` 三个固定变量，且你可以通过下面的方法来返回这三个变量的数据。

例如使用 `create_image_message` 来返回图片，但是同时工具也支持自定义的输出变量，从而可以更方便地在 `workflow` 中引用这些变量。

#### **图片 URL**

只需要传递图片的 URL，Dify 将通过链接自动下载图片并返回给用户。

```python
    def create_image_message(self, image: str) -> ToolInvokeMessage:
        pass
```

#### **链接**

如果你需要返回一个链接，使用以下接口。

```python
    def create_link_message(self, link: str) -> ToolInvokeMessage:
        pass
```

#### **文本**

如果你需要返回一个文本消息，使用以下接口。

```python
    def create_text_message(self, text: str) -> ToolInvokeMessage:
        pass
```

**文件**

如果你需要返回文件的原始数据，如图片、音频、视频、PPT、Word、Excel 等，可以使用以下接口。

* `blob` 文件的原始数据，bytes 类型。
* `meta` 文件的元数据。如果开发者需要明确的文件类型，请指定`mime_type`，否则 Dify 将使用`octet/stream`作为默认类型。

```python
    def create_blob_message(self, blob: bytes, meta: dict = None) -> ToolInvokeMessage:
        pass
```

#### **JSON**

如果你需要返回一个格式化的 JSON，可以使用以下接口。这通常用于 workflow 中的节点间的数据传递。在 agent 模式中，大部分大模型也都能够阅读和理解 JSON。

* `object` 一个 Python 的字典对象，会被自动序列化为 JSON。

```python
    def create_json_message(self, json: dict) -> ToolInvokeMessage:
        pass
```

#### **变量**

对于非流式输出的变量，你可以使用以下接口返回，如创建多份，后者将覆盖前者。

```python
    def create_variable_message(self, variable_name: str, variable_value: Any) -> ToolInvokeMessage:
        pass
```

#### **流式变量**

如果你想以“打字机”效果输出一段文字，可以使用流式变量输出文本。如果你在 `chatflow` 应用中使用 `answer` 节点并引用了该变量，那么文本将以“打字机”的效果输出。但目前该方法仅支持字符串类型的数据。

```python
    def create_stream_variable_message(
        self, variable_name: str, variable_value: str
    ) -> ToolInvokeMessage:
```

#### 返回自定义变量

如果想要在 `workflow` 应用中引用 `tool` 的输出变量，则有必要提前定义有哪些变量可能被输出。Dify 插件支持使用 [`json_schema`](https://json-schema.org/)格式的输出变量定义，以下是一个简单的示例：

```yaml
identity:
  author: author
  name: tool
  label:
    en_US: label
    zh_Hans: 标签
    ja_JP: ラベル
    pt_BR: etiqueta
description:
  human:
    en_US: description
    zh_Hans: 描述
    ja_JP: 説明
    pt_BR: descrição
  llm: description
output_schema:
  type: object
  properties:
    name:
      type: string
```

上述示例代码定义了一个简单的工具，并为它指定了 `output_schema`，其中包含一个 `name` 字段，此时可以在 `workflow` 中引用该字段。但是请注意，还需要在工具的实现代码中返回一个变量才可以真正使用，否则将得到一个 `None` 返回结果。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0411-tool.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 结构化与排序规范详解
> 来源：`plugin-dev-zh/0412-doc-understanding-the-dimensions.mdx`

> <b><i><u>dimensions</u></i></b>

## 背景与动机：应对开发者生态的演进

Dify 最初的成功很大程度上源于其产品的直观易用性。对于核心用户（User/Buyer），产品本身的体验往往足以引导他们；对于少数需要深度定制的早期开发者而言，他们通常具备直接阅读源代码的能力。因此，初期的文档建设并非最高优先级。

然而，随着 **Dify Plugin 插件生态的上线和蓬勃发展**，情况发生了显著变化：

1. 受众扩大化： 我们的开发者社区不再局限于能够深入源码的核心贡献者。大量拥有一定技术背景但可能不熟悉 Dify 底层或特定编程范式的 **“半专业开发者” (Citizen Developers)** 或集成开发者涌现，他们需要清晰、循序渐进的指导来构建和贡献插件。
2. 内容交织与目标模糊： 现有的文档往往将面向最终用户的**帮助内容**（如何使用插件）与面向开发者的**技术内容**（如何开发插件）混合在一起，导致两类受众都感到困惑，增加了信息查找成本。
3. 结构缺失与导航困难： 文档缺乏统一的组织结构和逻辑顺序，使得开发者（尤其是新加入者）难以找到所需信息，也无法形成对插件开发生命周期的完整认知。现有导航难以承载日益增长的内容。
4. 构建开发者关系 (DevRel) 的基石： 一个清晰、有效、结构优异的开发者文档体系，是构建成功开发者关系、繁荣插件生态不可或缺的一环。它直接影响开发者的体验、贡献意愿和成功率。

基于以上挑战，以及对业界优秀范例（如 Zapier Developer Platform, Cloudflare Docs）的分析——它们都展现了清晰的受众分离、结构化的内容组织和面向不同技能水平的路径设计——我们认识到对 Dify 的开发者文档进行**系统性重构**的迫切性。

dimensions**系统**应运而生。它并非一套僵化的格式要求，而是我们为了解决上述问题，将**结构化思维、受众细分、渐进式学习**等理念，通过一套**基于元数据的自动化流程**沉淀下来的解决方案。它旨在为 Dify 插件开发者提供一个清晰、一致且易于导航的技术知识库。

## 核心原则：元数据作为规范性数据源

本系统的基石在于以下核心原则：

-   元数据驱动 (Metadata-Driven): 每篇 Markdown 文档的 Front Matter 中定义的元数据（特别是 dimensions, standard_title, language）是描述该文档内容属性、目标受众和预期用途的**规范性数据源 (Normative Data Source)**。
-   内容与表现分离 (Decoupling Content from Presentation): 文档的最终呈现形式——包括文件名、在文档网站上的排序、导航菜单结构——都**必须由自动化工具根据这些元数据动态生成**。作者应专注于内容本身及其元数据描述的准确性。
-   自动化保障一致性与可维护性 (Automation for Consistency & Maintainability): 自动化流程确保了整个文档库在结构、命名和排序上的一致性。对分类体系或排序逻辑的调整，只需修改中央配置和生成脚本即可全局应用，极大地提高了可维护性。

这种方法论让内容创作者（作者）和技术实现者（文档系统维护者/DevOps）能够有效协作，共同服务于最终开发者读者的需求。

## 元数据规范

每篇开发者文档（Markdown 文件）必须包含一个 YAML Front Matter 块，定义如下关键字段：

```yaml
---
# --- 核心元数据 ---

# 'dimensions' 用于内容分类和自动排序
dimensions:
    type: # 主要类别 (Conceptual, Implementation, Operational, Reference) - 决定宏观顺序 (W)
        primary: <primary_type_value> # 次要类别/细节 (Introduction, Basic, Core, Examples...) - 决定章节内顺序 (X)
        detail: <detail_type_value>
    # 目标读者级别/内容复杂度 (Beginner, Intermediate, Advanced) - 决定微观顺序 (Y) 及优先级 (P)
    level: <level_value>

# 'standard_title' 用于生成可读的文件名，并供概览页面使用
standard_title: '文档的标准、描述性标题'

# 'language' (ISO 639-1 代码如 'en', 'zh') 用于国际化(i18n)和文件名后缀
language: <language_code>

# --- 其他可选元数据 ---

# 'summary': 文档内容的简短摘要 (可选, 可能用于列表页或 SEO)
# 'tags': [关键词列表] (可选, 用于过滤或关联内容)
# ... 其他未来可能需要的字段
---
```

```markdown
Type Dimension (Primary)

-   conceptual: Theoretical or explanatory content
-   implementation: Code and development content
-   operational: Content related to running and maintaining the system
-   reference: Reference materials

Type Detail Dimension

-   For conceptual: introduction, principles, architecture
-   For implementation: basic, standard, high, advanced
-   For operational: setup, deployment, maintenance
-   For reference: core, configuration, examples

Level Dimension

-   beginner: For newcomers to the topic
-   intermediate: For users with basic understanding
-   advanced: For advanced users
```

## dimensions 深度解析：为内容赋予意义

dimensions 元数据是本系统的核心，它要求我们为每一篇文档回答三个基本问题，从而赋予其明确的**语境、范围和受众定位**。这种分类是后续所有自动化结构和排序的基础。

-   dimensions.type.primary：定义内容的“性质”

    -   核心问题: 这篇文档从根本上属于哪一类知识？它是关于“是什么/为什么”（理论），“如何做”（实践），“如何运行/维护”（运维），还是“精确查找”（参考）？
    -   作用: 这个维度确立了文档在整个知识体系中的**宏观类别**。我们采用 conceptual, implementation, operational, reference 这几个业界通用的分类，来划分开发者关注的主要领域。这个分类决定了文档所属的**顶层章节**或主题区域，是构建文档信息架构的第一步。

-   dimensions.type.detail：明确内容的“主题焦点”

    -   核心问题: 在上述宏观类别下，这篇文档具体是关于该类别的哪个**特定方面或子主题**？例如，是某个概念的“入门介绍”，还是某个实现的“标准用法”，或是某个参考信息的“核心 API”？
    -   作用: 它在主类别内部提供了**更精细的主题划分**。这使得相关的文档能够聚集在一起，形成逻辑连贯的**子章节**或段落。选择恰当的 detail 有助于用户在浏览特定章节时快速定位到具体内容点。

-   dimensions.level：标定内容的“复杂度与受众”
    -   核心问题: 这篇特定主题的文档，主要是为哪个**经验水平的读者**准备的？或者说，其内容的**复杂度**如何？是入门 (beginner)，通用 (intermediate)，还是深入/专门 (advanced)？
    -   作用: 这个维度具有**双重关键作用**：
        1. 细粒度排序: 在同一具体主题下，它允许内容按从易到难的顺序排列，优化学习曲线。
        2. 优先级判定: 它（尤其是 advanced 级别）是系统区分“核心内容”与“进阶/深水区内容”的关键输入，直接影响内容是否被后置（见第 5 节）。

为内容精准地打上这三个维度的标签，是确保文档库结构合理、易于导航、满足不同用户需求的前提。

## 排序机制：**PWXY** 前缀与优先级规则

为实现一致且逻辑清晰的文档呈现顺序，系统将根据 dimensions 元数据为每篇文档自动生成一个 4 位、零填充的数字前缀 (PWXY)，并以此作为文件名的一部分来实现排序。

-   P **优先级 (Priority)**: 第 1 位。区分常规 (P=0) 与后置/深水区 (P=9) 内容。
-   W **主类编号 (Primary Type)**: 第 2 位。体现 primary 类型的宏观顺序。
-   X **子类编号 (Detail Type)**: 第 3 位。体现 detail 类型在主类内的顺序。
-   Y **难度级别编号 (Level)**: 第 4 位。体现 level 在子类内的顺序。

优先级 (**P=9**) 规则详解:

将内容标记为 P=9 的目的是，将对入门和常规使用非必需的、复杂度较高的内容**自动后置**，从而为主流用户群体提供更平滑的学习曲线和更聚焦的核心内容流。触发 P=9 的条件是：

1. 内容本身定义为高级: level: advanced。
2. 实现类目下的特定复杂细节: primary: implementation 且 detail 为 high 或 advanced。

P=9 的内容可被视为文档库的“附录”、“深度探讨”或“高级参考”。

## 文件名生成策略

最终部署的文件名由自动化脚本基于元数据生成，其概念格式为：
`PWXY-[sanitized_standard_title].language.md`

此文件名主要用于**机器排序**和内部标识。文档的**人类可读标题**以 `standard_title` 元数据和文档内的 H1 标题为准。自动化脚本负责处理元数据提取、PWXY 计算、标题清理、语言后缀、基于 GitHub 的[编辑与反馈按钮的自动实现](./tools/contributing_in_page.py)等所有细节。

## 面向受众的设计原则：渐进式披露与路径优化

本系统的设计贯穿着“渐进式信息披露” (Progressive Disclosure) 的核心原则，旨在优化不同背景开发者的信息获取路径。

1. 优先级机制 (P 值区分): 这是实现渐进式披露的主要手段。系统性地将基础、核心、高频使用的内容 (P=0) 与高级、复杂、特定场景的内容 (P=9) 分离开来。这保证了用户默认首先接触到的是一个相对精简、聚焦核心的知识体系。
2. 结构化分类 (基于 type.primary 和 type.detail): 即便在同一优先级内，内容也被清晰地组织成不同类别和主题，为所有用户（尤其是经验丰富的用户）提供了一个可预测的“信息地图”。

基于以上原则，系统致力于为不同目标受众提供优化的体验：

-   学习者与初探者 (Learners & Newcomers, incl. Citizen Developers): 通过默认阅览 P=0 的内容序列，获得一条从概念到基础实践的、结构化的学习路径，从而循序渐进，降低初期认知负荷。
-   经验丰富的开发者与贡献者 (Experienced Developers & Contributors): 利用清晰的结构进行高效的**随机访问**，快速定位特定参考信息或实现细节，或根据需要直接深入 P=9 的高级内容。文档库对其而言更像一本可快速查阅的技术手册。
-   自动化工具与服务 (e.g., LLMs): 承认其与人类不同的信息消费模式。结构化的元数据**使我们能够**为其生成专门优化的、可能更扁平化的数据输入流（如 `llms-full.txt`），提升其理解效率。

总而言之，dimensions 系统并非试图用一种方式满足所有人，而是通过**结构化分类、优先级排序和元数据驱动的自动化**，为不同需求的用户群体提供各自相对最优的信息访问和学习路径。

## 系统收益

-   结构清晰 & 导航改善: 基于可靠的分类和可预测的排序。
-   一致性体验: 自动化确保所有文档遵循相同模式。
-   受众适配: 通过优先级区分，提供差异化的阅读路径。
-   高可维护性: 调整分类或排序逻辑只需修改中心配置和脚本。
-   可扩展性: 易于添加新的内容类型或难度级别。
-   促进协作: 为作者、审阅者和系统维护者提供了共同的理解基础和协作标准。

## 创作流程、角色与治理：应对现实挑战

建立高质量文档库是一个涉及多方协作的过程，并面临现实挑战。dimensions 系统旨在成为这个过程中的一个结构化框架和协作工具。

### 协作模型中的关键角色

-   创作者 (Creator / Author):

    -   核心职责: 创作准确、清晰、有价值的文档内容。
    -   协作要点: 学习并尝试理解 dimensions 分类体系，在提交时为文档**尝试**打上最合适的元数据标签（dimensions, standard_title, language）。准确的初始分类有助于后续流程。

-   审阅者 (Owner / Reviewer):

    -   核心职责: 对文档内容的**准确性、清晰度、范围**以及**元数据的恰当性**进行最终把关。这是确保文档库质量和结构一致性的关键环节。
    -   能力要求: 需要具备对相关技术领域的深刻理解，**同时**要能理解 dimensions 系统背后的**整体信息架构和受众细分逻辑**（这往往需要一定的系统性思维，类似于架构师视角）。
    -   协作要点: 利用 dimensions 作为客观“标尺”来评审内容定位。如果元数据不准确或内容边界模糊，应指导创作者修改或直接修正元数据。**最终合并到主分支的元数据决定了文档的呈现**。

-   运营者 (Operator / DevOps):

    -   核心职责: 维护和优化文档自动化构建、测试、部署的流程与工具。
    -   协作要点: 确保自动化脚本正确、高效地解析元数据并生成最终产物（排序的文件、导航数据等）。他们关注的是**流程的健壮性**，而非单篇文档的内容细节。

### 应对文档协作的现实挑战

这种角色划分有助于我们正视并尝试缓解一些常见的文档困境：

-   “程序员不爱写文档” vs. “写文档的不懂技术”：

    -   dimensions 系统**降低了对创作者（程序员）的要求**：首要任务是写准技术内容，元数据分类可以“尽力而为”，因为有审阅者把关。
    -   同时，它**提升了对审阅者的要求**，承认了高质量文档需要深刻的技术理解和架构性思维，并将这种高阶能力引导到对文档结构和元数据的把控上。
    -   对于可能存在的“专职文档工程师”，他们可以作为创作者，或者辅助审阅者进行元数据校验和内容润色，角色更加灵活。

-   高质量审阅者稀缺且“性价比”疑虑：

    -   确实，具备所需技术深度和架构思维的审阅者是宝贵的。他们可能会觉得审阅文档相比核心功能开发“价值较低”。
    -   关键在于提升认知： 必须强调，**高质量、结构化的文档对于开发者生态的成功、降低支持成本、提升产品采用率具有极高的战略价值**。dimensions 系统正是将审阅者的高阶思维**显性化、规范化**，并**直接转化为可衡量的文档体验提升**的工具。审阅文档不再是“杂活”，而是塑造开发者体验、构建知识体系的关键一环。

-   流程保障: dimensions 系统提供了一个**协作框架**。它鼓励创作者思考内容定位，赋予审阅者清晰的评估标准和修正权限，并让运营者可以独立地维护自动化流程。通过将元数据检查纳入 PR 流程（类似 Code Review），可以制度化地保障最终产出的质量。

## 扩展性与代码的角色

-   系统扩展: dimensions 的分类体系并非静态。随着 Dify 功能的演进，可以（也应该）适时增加新的 primary 类型、detail 类型或 level。这主要通过更新中央映射配置和（如有必要）调整生成脚本来实现，体现了系统的灵活性。
-   文档与代码的关系: 开发者文档（特别是 Reference 和高级 Implementation 部分）的核心目标之一是作为理解和使用**源代码**的**有效向导**。它应解释代码层面的设计、用法、约束，并通过链接等方式促进开发者在需要时**无缝地深入到源代码**这一最终的、最精确的内容中。文档不是代码的替代品，而是其**高质量的另一面和解释器**。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0412-doc-understanding-the-dimensions.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Frontmatter 元数据指南
> 来源：`plugin-dev-zh/0412-doc-writing-dimensions-guide.mdx`

本文档帮助您快速为 Dify 开发者文档定义核心元数据。正确填写这些字段是实现文档自动化结构和排序的关键。

## 快速开始

> **步骤：**

        完成您的文档内容撰写。

        将您的文档和 [**dimensions** 系统详解](./plugin-dev-zh/0412-doc-understanding-the-dimensions) 的内容交给您偏好的大模型，请求生成适合的 Frontmatter。

        根据实际情况和下面的详细说明，对生成的元数据进行必要的调整和优化。

    阅读下方的详细说明，根据您的文档内容特点，自行定义适合的元数据字段。

## 必要 Frontmatter 字段

请在每篇 Markdown 文档的开头添加以下 YAML Frontmatter：

```yaml
---
# --- 系统核心元数据 (影响结构和排序) ---
dimensions:
  type:
    primary: <见下方选项>
    detail: <见下方选项>
  level: <见下方选项>
standard_title: '英文描述性标题，用于生成文件名' # e.g., 'Getting Started Dify Plugin'
language: 'zh' # 或 'en', 'ja', etc. (ISO 639-2 代码)

# --- 页面内容元数据 (可选，但推荐) ---
title: '文档的 H1 标题或页面标题'
description: '文档内容的简短 SEO 描述'
# summary: '更详细的摘要 (可选)'
# tags: ['关键词'] (可选)
---
```

## `dimensions` 字段详解

        **概念、理论** (是什么/为什么)

重点解释概念和基础理论

        **开发实践、代码** (如何做)

重点提供实现步骤和代码示例

        **运维、部署** (如何运行)

重点关注系统运行和维护

        **API、配置参考** (精确查找)

重点提供技术规格和参考信息

    在 `primary` 类别下的细分：

        <ul>
          <li><code>introduction</code>: 入门介绍</li>
          <li><code>principles</code>: 设计原则</li>
          <li><code>architecture</code>: 架构说明</li>
        </ul>

        <ul>
          <li><code>basic</code>: 基础实现</li>
          <li><code>standard</code>: 标准实现</li>
          <li><code>high</code>: 高级实现 (可能后置)</li>
          <li><code>advanced</code>: 深度实现 (可能后置)</li>
        </ul>

        <ul>
          <li><code>setup</code>: 环境设置</li>
          <li><code>deployment</code>: 部署操作</li>
          <li><code>maintenance</code>: 维护管理</li>
        </ul>

        <ul>
          <li><code>core</code>: 核心参考</li>
          <li><code>configuration</code>: 配置参考</li>
          <li><code>examples</code>: 示例参考</li>
        </ul>

      更多选项请参考 [dimensions 系统详解](./plugin-dev-zh/0412-doc-understanding-the-dimensions) 文档

        **新手入门**

适合初学者的入门内容

        **常规用户**

适合有一定基础的用户

        **高级用户**

适合专业用户的深入内容 (通常会被后置排序)

## 其他重要字段

  使用**英文**，清晰描述文档核心内容。系统将用它生成部分文件名 (例如 `Getting Started Dify Plugin`)。

  ISO 639-2 双字母语言代码 (如 `en`, `zh`, `ja`)。

  文档在页面上显示的主标题，通常是本地化语言。

  简短的SEO描述，用于搜索引擎和预览。

## 完整示例

  ```yaml 入门文档示例
  ---
  dimensions:
    type:
      primary: conceptual
      detail: introduction
    level: beginner
  standard_title: 'Getting Started Dify Plugin'
  language: zh
  title: '欢迎开始 Dify 插件开发'
  description: '介绍Dify插件的概念、功能和开发价值，包括插件类型的简要说明，以及开发者文档的内容概览。'
  ---
  ```

  ```yaml 工具开发文档示例
  ---
  dimensions:
    type:
      primary: implementation
      detail: standard
    level: intermediate
  standard_title: 'Developing Tool Plugin'
  language: zh
  title: '开发工具插件'
  description: '详细指导如何创建和配置Dify工具插件，包括API调用、数据处理和用户界面集成方面的实践指南。'
  ---
  ```

  ```yaml 参考文档示例
  ---
  dimensions:
    type:
      primary: reference
      detail: configuration
    level: intermediate
  standard_title: 'Plugin Manifest Configuration'
  language: zh
  title: '插件配置清单参考'
  description: '全面说明插件配置文件(manifest.json)的各项参数设置、格式要求和应用场景。'
  ---
  ```

> **提示：**

  **解读示例:** 第一个例子是一篇面向初学者的、关于 Dify 插件概念的入门介绍文档，语言为中文。系统会根据元数据自动将其正确放置在文档结构中。

## 文档自动化处理

    运行 `tools/main_docs_bundle.py`，文档将被自动根据 Frontmatter 完成以下操作：

> **步骤：**

        系统将根据 dimensions 和 standard_title 自动生成标准化文件名。

        文档将被自动注入到 docs.json 导航配置中。

        自动刷新贡献和反馈按钮等交互组件。

> **信息提示：**

      在本地环境开发文档时，建议运行该脚本确保文档配置正确生效。

    如果您在 GitHub 上直接进行编辑，**无需担心**自动化步骤。我们已经配置了 GitHub Action 等自动化工具，会在以下情况自动执行 `tools/main_docs_bundle.py`：

    - 当您提交 Pull Request 时
    - 当您的更改被合并到主分支时

      您可以专注于内容创作，GitHub 工作流会处理文件重命名、导航更新和交互组件生成等技术细节。

  如果您对 Dimensions 系统的设计理念、排序机制的完整细节或角色与治理感兴趣，请阅读完整的 Dimensions 系统详解文档。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0412-doc-writing-dimensions-guide.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 模型接口
> 来源：`plugin-dev-zh/0412-model-schema.mdx`
> 摘要：本文档详细介绍了Dify模型插件开发所需的接口规范，包括模型供应商实现、五种模型类型（LLM、TextEmbedding、Rerank、Speech2text、Text2speech）的接口定义以及相关数据结构如PromptMessage、LLMResult等的完整规范。文档适用于开发者实现各种模型集成的开发参考。

这里介绍供应商和各模型类型需要实现的接口方法和参数说明。在开发模型插件前，您可能需要首先阅读[模型设计规则](./plugin-dev-zh/0411-model-designing-rules)和[模型插件介绍](./plugin-dev-zh/0131-model-plugin-introduction)。

### 模型供应商

继承 `__base.model_provider.ModelProvider` 基类，实现以下接口：

```python
def validate_provider_credentials(self, credentials: dict) -> None:
    """
    Validate provider credentials
    You can choose any validate_credentials method of model type or implement validate method by yourself,
    such as: get model list api

    if validate failed, raise exception

    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
    """
```

* `credentials` (object) 凭据信息

凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 定义，传入如：`api_key` 等。验证失败请抛出 `errors.validate.CredentialsValidateFailedError` 错误。**注：预定义模型需完整实现该接口，自定义模型供应商只需要如下简单实现即可：**

```python
class XinferenceProvider(Provider):
    def validate_provider_credentials(self, credentials: dict) -> None:
        pass
```

### 模型

模型分为 5 种不同的模型类型，不同模型类型继承的基类不同，需要实现的方法也不同。

#### 通用接口

所有模型均需要统一实现下面 2 个方法：

* 模型凭据校验

与供应商凭据校验类似，这里针对单个模型进行校验。

```python
def validate_credentials(self, model: str, credentials: dict) -> None:
    """
    Validate model credentials

    :param model: model name
    :param credentials: model credentials
    :return:
    """
```

参数：

* `model` (string) 模型名称
* `credentials` (object) 凭据信息

凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。验证失败请抛出 `errors.validate.CredentialsValidateFailedError` 错误。

* 调用异常错误映射表

当模型调用异常时需要映射到 Runtime 指定的 `InvokeError` 类型，方便 Dify 针对不同错误做不同后续处理。Runtime Errors:

* `InvokeConnectionError` 调用连接错误
* `InvokeServerUnavailableError` 调用服务方不可用
* `InvokeRateLimitError` 调用达到限额
* `InvokeAuthorizationError` 调用鉴权失败
* `InvokeBadRequestError` 调用传参有误

```python
@property
def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
    """
    Map model invoke error to unified error
    The key is the error type thrown to the caller
    The value is the error type thrown by the model,
    which needs to be converted into a unified error type for the caller.

    :return: Invoke error mapping
    """
```

也可以直接抛出对应 Erros，并做如下定义，这样在之后的调用中可以直接抛出`InvokeConnectionError`等异常。

#### LLM

继承 `__base.large_language_model.LargeLanguageModel` 基类，实现以下接口：

* LLM 调用

实现 LLM 调用的核心方法，可同时支持流式和同步返回。

```python
def _invoke(self, model: str, credentials: dict,
            prompt_messages: list[PromptMessage], model_parameters: dict,
            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,
            stream: bool = True, user: Optional[str] = None) \
        -> Union[LLMResult, Generator]:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param model_parameters: model parameters
    :param tools: tools for tool calling
    :param stop: stop sequences
    :param stream: is stream response
    :param user: unique user id
    :return: full response or stream response chunk generator result
    """
```

* 参数：
  * `model` (string) 模型名称
  * `credentials` (object) 凭据信息

凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

* `prompt_messages` (array\[[PromptMessage](#promptmessage)]) Prompt 列表

若模型为 `Completion` 类型，则列表只需要传入一个 [UserPromptMessage](#userpromptmessage) 元素即可；若模型为 `Chat` 类型，需要根据消息不同传入 [SystemPromptMessage](#systempromptmessage), [UserPromptMessage](#userpromptmessage), [AssistantPromptMessage](#assistantpromptmessage), [ToolPromptMessage](#toolpromptmessage) 元素列表

* `model_parameters` (object) 模型参数模型参数由模型 YAML 配置的 `parameter_rules` 定义。

* `tools` (array\[[PromptMessageTool](#promptmessagetool)]) \[optional] 工具列表，等同于 `function calling` 中的 `function`。即传入 tool calling 的工具列表。

* `stop` (array\[string]) \[optional] 停止序列模型返回将在停止序列定义的字符串之前停止输出。

* `stream` (bool) 是否流式输出，默认 True
流式输出返回 Generator\[[LLMResultChunk](#llmresultchunk)]，非流式输出返回 [LLMResult](#llmresult)。

* `user` (string) \[optional] 用户的唯一标识符可以帮助供应商监控和检测滥用行为。

* 返回

流式输出返回 Generator\[[LLMResultChunk](#llmresultchunk)]，非流式输出返回 [LLMResult](#llmresult)。

* 预计算输入 tokens

若模型未提供预计算 tokens 接口，可直接返回 0。

```python
def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                   tools: Optional[list[PromptMessageTool]] = None) -> int:
    """
    Get number of tokens for given prompt messages

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param tools: tools for tool calling
    :return:
    """
```

参数说明见上述 `LLM 调用`。该接口需要根据对应`model`选择合适的`tokenizer`进行计算，如果对应模型没有提供`tokenizer`，可以使用`AIModel`基类中的`_get_num_tokens_by_gpt2(text: str)`方法进行计算。

* 获取自定义模型规则 \[可选]

```python
def get_customizable_model_schema(self, model: str, credentials: dict) -> Optional[AIModelEntity]:
    """
    Get customizable model schema

    :param model: model name
    :param credentials: model credentials
    :return: model schema
    """
```

当供应商支持增加自定义 LLM 时，可实现此方法让自定义模型可获取模型规则，默认返回 None。

对于 `OpenAI` 供应商下的大部分微调模型，可以通过其微调模型名称获取到其基类模型，如`gpt-3.5-turbo-1106`，然后返回基类模型的预定义参数规则，参考 [OpenAI](https://github.com/langgenius/dify-official-plugins/tree/main/models/openai) 的具体实现。

#### TextEmbedding

继承 `__base.text_embedding_model.TextEmbeddingModel` 基类，实现以下接口：

* Embedding 调用

```python
def _invoke(self, model: str, credentials: dict,
            texts: list[str], user: Optional[str] = None) \
        -> TextEmbeddingResult:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param texts: texts to embed
    :param user: unique user id
    :return: embeddings result
    """
```

* 参数：

* `model` (string) 模型名称

* `credentials` (object) 凭据信息

凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

* `texts` (array\[string]) 文本列表，可批量处理

* `user` (string) \[optional] 用户的唯一标识符
可以帮助供应商监控和检测滥用行为。

* 返回：

[TextEmbeddingResult](#textembeddingresult) 实体。

* 预计算 tokens

```python
def get_num_tokens(self, model: str, credentials: dict, texts: list[str]) -> int:
    """
    Get number of tokens for given prompt messages

    :param model: model name
    :param credentials: model credentials
    :param texts: texts to embed
    :return:
    """
```

参数说明见上述 `Embedding 调用`。

同上述 `LargeLanguageModel`，该接口需要根据对应 `model` 选择合适的 `tokenizer` 进行计算，如果对应模型没有提供 `tokenizer`，可以使用`AIModel`基类中的`_get_num_tokens_by_gpt2(text: str)`方法进行计算。

#### Rerank

继承 `__base.rerank_model.RerankModel` 基类，实现以下接口：

* rerank 调用

```python
def _invoke(self, model: str, credentials: dict,
            query: str, docs: list[str], score_threshold: Optional[float] = None, top_n: Optional[int] = None,
            user: Optional[str] = None) \
        -> RerankResult:
    """
    Invoke rerank model

    :param model: model name
    :param credentials: model credentials
    :param query: search query
    :param docs: docs for reranking
    :param score_threshold: score threshold
    :param top_n: top n
    :param user: unique user id
    :return: rerank result
    """
```

* 参数：

* `model` (string) 模型名称
* `credentials` (object) 凭据信息
凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。
* `query` (string) 查询请求内容
* `docs` (array\[string]) 需要重排的分段列表
* `score_threshold` (float) \[optional] Score 阈值
* `top_n` (int) \[optional] 取前 n 个分段
* `user` (string) \[optional] 用户的唯一标识符
可以帮助供应商监控和检测滥用行为。

* 返回：

[RerankResult](#rerankresult) 实体。

#### Speech2text

继承 `__base.speech2text_model.Speech2TextModel` 基类，实现以下接口：

* Invoke 调用

```python
def _invoke(self, model: str, credentials: dict,
            file: IO[bytes], user: Optional[str] = None) \
        -> str:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param file: audio file
    :param user: unique user id
    :return: text for given audio file
    """        
```

* 参数：

* `model` (string) 模型名称
* `credentials` (object) 凭据信息
凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。
* `file` (File) 文件流
* `user` (string) \[optional] 用户的唯一标识符
可以帮助供应商监控和检测滥用行为。

* 返回：

语音转换后的字符串。

#### Text2speech

继承 `__base.text2speech_model.Text2SpeechModel` 基类，实现以下接口：

* Invoke 调用

```python
def _invoke(self, model: str, credentials: dict, content_text: str, streaming: bool, user: Optional[str] = None):
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param content_text: text content to be translated
    :param streaming: output is streaming
    :param user: unique user id
    :return: translated audio file
    """        
```

* 参数：

* `model` (string) 模型名称
* `credentials` (object) 凭据信息
凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。
* `content_text` (string) 需要转换的文本内容
* `streaming` (bool) 是否进行流式输出
* `user` (string) \[optional] 用户的唯一标识符
可以帮助供应商监控和检测滥用行为。

* 返回：

文本转换后的语音流。

#### Moderation

继承 `__base.moderation_model.ModerationModel` 基类，实现以下接口：

* Invoke 调用

```python
def _invoke(self, model: str, credentials: dict,
            text: str, user: Optional[str] = None) \
        -> bool:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param text: text to moderate
    :param user: unique user id
    :return: false if text is safe, true otherwise
    """
```

* 参数：

* `model` (string) 模型名称
* `credentials` (object) 凭据信息
凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。
* `text` (string) 文本内容
* `user` (string) \[optional] 用户的唯一标识符
可以帮助供应商监控和检测滥用行为。

* 返回：

False 代表传入的文本安全，True 则反之。

### 实体

#### PromptMessageRole

消息角色

```python
class PromptMessageRole(Enum):
    """
    Enum class for prompt message.
    """
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"
    TOOL = "tool"
```

#### PromptMessageContentType

消息内容类型，分为纯文本和图片。

```python
class PromptMessageContentType(Enum):
    """
    Enum class for prompt message content type.
    """
    TEXT = 'text'
    IMAGE = 'image'
```

#### PromptMessageContent

消息内容基类，仅作为参数声明用，不可初始化。

```python
class PromptMessageContent(BaseModel):
    """
    Model class for prompt message content.
    """
    type: PromptMessageContentType
    data: str  # 内容数据
```

当前支持文本和图片两种类型，可支持同时传入文本和多图。
需要分别初始化 `TextPromptMessageContent` 和 `ImagePromptMessageContent` 传入。

#### TextPromptMessageContent

```python
class TextPromptMessageContent(PromptMessageContent):
    """
    Model class for text prompt message content.
    """
    type: PromptMessageContentType = PromptMessageContentType.TEXT
```

若传入图文，其中文字需要构造此实体作为 `content` 列表中的一部分。

#### ImagePromptMessageContent

```python
class ImagePromptMessageContent(PromptMessageContent):
    """
    Model class for image prompt message content.
    """
    class DETAIL(Enum):
        LOW = 'low'
        HIGH = 'high'

    type: PromptMessageContentType = PromptMessageContentType.IMAGE
    detail: DETAIL = DETAIL.LOW  # 分辨率
```

若传入图文，其中图片需要构造此实体作为 `content` 列表中的一部分
`data` 可以为 `url` 或者图片 `base64` 加密后的字符串。

#### PromptMessage

所有 Role 消息体的基类，仅作为参数声明用，不可初始化。

```python
class PromptMessage(ABC, BaseModel):
    """
    Model class for prompt message.
    """
    role: PromptMessageRole  # 消息角色
    content: Optional[str | list[PromptMessageContent]] = None  # 支持两种类型，字符串和内容列表，内容列表是为了满足多模态的需要，可详见 PromptMessageContent 说明。
    name: Optional[str] = None  # 名称，可选。
```

#### UserPromptMessage

UserMessage 消息体，代表用户消息。

```python
class UserPromptMessage(PromptMessage):
    """
    Model class for user prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.USER
```

#### AssistantPromptMessage

代表模型返回消息，通常用于 `few-shots` 或聊天历史传入。

```python
class AssistantPromptMessage(PromptMessage):
    """
    Model class for assistant prompt message.
    """
    class ToolCall(BaseModel):
        """
        Model class for assistant prompt message tool call.
        """
        class ToolCallFunction(BaseModel):
            """
            Model class for assistant prompt message tool call function.
            """
            name: str  # 工具名称
            arguments: str  # 工具参数

        id: str  # 工具 ID，仅在 OpenAI tool call 生效，为工具调用的唯一 ID，同一个工具可以调用多次
        type: str  # 默认 function
        function: ToolCallFunction  # 工具调用信息

    role: PromptMessageRole = PromptMessageRole.ASSISTANT
    tool_calls: list[ToolCall] = []  # 模型回复的工具调用结果（仅当传入 tools，并且模型认为需要调用工具时返回）
```

其中 `tool_calls` 为调用模型传入 `tools` 后，由模型返回的 `tool call` 列表。

#### SystemPromptMessage

代表系统消息，通常用于设定给模型的系统指令。

```python
class SystemPromptMessage(PromptMessage):
    """
    Model class for system prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.SYSTEM
```

#### ToolPromptMessage

代表工具消息，用于工具执行后将结果交给模型进行下一步计划。

```python
class ToolPromptMessage(PromptMessage):
    """
    Model class for tool prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.TOOL
    tool_call_id: str  # 工具调用 ID，若不支持 OpenAI tool call，也可传入工具名称
```

基类的 `content` 传入工具执行结果。

#### PromptMessageTool

```python
class PromptMessageTool(BaseModel):
    """
    Model class for prompt message tool.
    """
    name: str  # 工具名称
    description: str  # 工具描述
    parameters: dict  # 工具参数 dict

```

***

#### LLMResult

```python
class LLMResult(BaseModel):
    """
    Model class for llm result.
    """
    model: str  # 实际使用模型
    prompt_messages: list[PromptMessage]  # prompt 消息列表
    message: AssistantPromptMessage  # 回复消息
    usage: LLMUsage  # 使用的 tokens 及费用信息
    system_fingerprint: Optional[str] = None  # 请求指纹，可参考 OpenAI 该参数定义
```

#### LLMResultChunkDelta

流式返回中每个迭代内部 `delta` 实体

```python
class LLMResultChunkDelta(BaseModel):
    """
    Model class for llm result chunk delta.
    """
    index: int  # 序号
    message: AssistantPromptMessage  # 回复消息
    usage: Optional[LLMUsage] = None  # 使用的 tokens 及费用信息，仅最后一条返回
    finish_reason: Optional[str] = None  # 结束原因，仅最后一条返回
```

#### LLMResultChunk

流式返回中每个迭代实体

```python
class LLMResultChunk(BaseModel):
    """
    Model class for llm result chunk.
    """
    model: str  # 实际使用模型
    prompt_messages: list[PromptMessage]  # prompt 消息列表
    system_fingerprint: Optional[str] = None  # 请求指纹，可参考 OpenAI 该参数定义
    delta: LLMResultChunkDelta  # 每个迭代存在变化的内容
```

#### LLMUsage

```python
class LLMUsage(ModelUsage):
    """
    Model class for llm usage.
    """
    prompt_tokens: int  # prompt 使用 tokens
    prompt_unit_price: Decimal  # prompt 单价
    prompt_price_unit: Decimal  # prompt 价格单位，即单价基于多少 tokens 
    prompt_price: Decimal  # prompt 费用
    completion_tokens: int  # 回复使用 tokens
    completion_unit_price: Decimal  # 回复单价
    completion_price_unit: Decimal  # 回复价格单位，即单价基于多少 tokens 
    completion_price: Decimal  # 回复费用
    total_tokens: int  # 总使用 token 数
    total_price: Decimal  # 总费用
    currency: str  # 货币单位
    latency: float  # 请求耗时(s)
```

***

#### TextEmbeddingResult

```python
class TextEmbeddingResult(BaseModel):
    """
    Model class for text embedding result.
    """
    model: str  # 实际使用模型
    embeddings: list[list[float]]  # embedding 向量列表，对应传入的 texts 列表
    usage: EmbeddingUsage  # 使用信息
```

#### EmbeddingUsage

```python
class EmbeddingUsage(ModelUsage):
    """
    Model class for embedding usage.
    """
    tokens: int  # 使用 token 数
    total_tokens: int  # 总使用 token 数
    unit_price: Decimal  # 单价
    price_unit: Decimal  # 价格单位，即单价基于多少 tokens
    total_price: Decimal  # 总费用
    currency: str  # 货币单位
    latency: float  # 请求耗时(s)
```

***

#### RerankResult

```python
class RerankResult(BaseModel):
    """
    Model class for rerank result.
    """
    model: str  # 实际使用模型
    docs: list[RerankDocument]  # 重排后的分段列表        
```

#### RerankDocument

```python
class RerankDocument(BaseModel):
    """
    Model class for rerank document.
    """
    index: int  # 原序号
    text: str  # 分段文本内容
    score: float  # 分数
```

## 相关资源

- [模型设计规则](./plugin-dev-zh/0411-model-designing-rules) - 了解模型配置的规范
- [模型插件介绍](./plugin-dev-zh/0131-model-plugin-introduction) - 快速了解模型插件的基本概念
- [快速接入一个新模型](./plugin-dev-zh/0211-getting-started-new-model) - 学习为已有的供应商添加新模型
- [创建新模型提供者](./plugin-dev-zh/0222-creating-new-model-provider) - 学习如何开发全新的模型供应商

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0412-model-schema.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 开发示例目录
> 来源：`plugin-dev-zh/0431-example-overview-and-index.mdx`

tool-plugin

        extension-plugin

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0431-example-overview-and-index.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 开发 Slack Bot 插件
> 来源：`plugin-dev-zh/0432-develop-a-slack-bot-plugin.mdx`
> 摘要：本文档提供了完整的Slack Bot插件开发指南，包括遍历项目初始化、编辑配置表单、实现功能代码、插件调试、设置Endpoint、效果验证到打包发布的完整流程。需要使用Dify插件脚手架工具和已创建的Slack

**本文将帮助你：**

深入掌握 Slack Bot 的搭建方法，创建由 AI 驱动的 Slack 聊天机器人，在 Slack 平台上智能回答用户的问题。如果你还没有开发插件的经验，建议先阅读[插件开发入门指南](./plugin-dev-zh/0211-getting-started-dify-tool)。

### 项目背景

Dify 插件生态致力于支持更简单、更易用的接入方式。本文将以 Slack 为例，详细介绍如何开发一个 Slack Bot 插件，便于团队中的成员直接在 Slack 平台内与 LLM 对话，提升 AI 服务的使用效率。

Dify 插件生态旨在提供更简单、更便捷的接入方式。本文将以 Slack 为例，详细讲解如何开发一个 Slack Bot 插件，帮助团队成员直接在 Slack 平台使用 AI 应用，提升办公效率。

Slack 是一个自由开放的实时办公通信平台，拥有丰富的 API。其中，基于事件机制的 Webhook 功能易于上手开发。我们将利用该机制创建 Slack Bot 插件，其原理如下图所示：

![Slack Bot 原理图](https://assets-docs.dify.ai/2025/01/a0865d18f1ca4051601ca53fa6f92db2.png)

> 为了避免混乱，现对以下概念作出解释：
>
> * **Slack Bot** 是在 Slack 平台上的一个聊天机器人，可以被视为虚拟角色，你可以与它进行聊天互动
> * **Slack Bot 插件**指的是 Dify Marketplace上的一款插件，用于连接 Dify 应用与 Slack 平台。本文将主要围绕该插件开发展开。

**原理简介：**

1.  **向 Slack Bot 发送消息**

    当用户在 Slack 中向 Bot 机器人发出一条消息的时候，Slack Bot 会发出一个 Webhook 请求到 Dify 平台。
2.  **消息转发至 Slack Bot 插件**

    用户在与 Slack bot 对话时，需要将消息转发至 Dify 应用。好比邮件系统需要一位收件人的邮箱，此时可以通过 Slack 的 API 配置一个 Slack Webhook 的地址，并将其填入至 Slack Bot 插件并建立连接。
3.  **插件在接受到消息后，返回至某个 Dify 应用**

    Slack Bot 插件将处理 Slack 请求，发送至 Dify 中的应用。由 LLM 分析用户输入的内容并给出回应。
4.  **Dify 应用回应后，将消息返回至 Slack Bot 并回答用户**

    Slack Bot 获取 Dify 应用的回复后，通过插件将消息原路返回至 Slack Bot，使得用户能够在使用 Slack 时直接与 Dify 应用互动

### 前置准备

* Dify 插件脚手架工具，详细说明请参考[初始化开发工具](./plugin-dev-zh/0221-initialize-development-tools)。
* Python 环境，版本号 ≥ 3.12，详细说明请参考 [Python 安装教程](https://pythontest.com/python/installing-python-3-11/)，或询问 LLM 获取完整的安装教程。
* 创建 Slack App 并获取 OAuth Token

前往 [Slack API](https://api.slack.com/apps) 平台， 选择以 scratch 方式创建 Slack APP，并选择需部署应用的 Slack 空间。

![Slack API Token](https://assets-docs.dify.ai/2025/01/8217c23ee16c47c586a1387a442ea6f0.png)

开启 Webhooks 功能。

![开启 Webhooks 功能](https://assets-docs.dify.ai/2025/01/fc9d7797608422219a01248f7151fc81.png)

将 App 安装至 Slack 工作区内。

![安装到工作区内](https://assets-docs.dify.ai/2025/01/6ab7226078f88853fc7f4d3520245d63.png)

获取 OAuth Token，用于后续的插件开发。

![获取 OAuth Token](https://assets-docs.dify.ai/2025/01/f08052044c8c17eebbffacdc9b2558e6.png)

### 1. 开发插件

现在开始实际的插件编码工作。在开始之前，请确保你已经阅读过[开发 Extension 插件](./plugin-dev-zh/9231-extension-plugin)，或已动手开发过一次 Dify 插件。

#### 初始化项目

运行以下命令初始化插件开发项目：

```bash
dify plugin init
```

按照提示填写项目的基础信息，选择 `extension` 模板，并且授予 `Apps` 和 `Endpoints` 两个权限。

如需了解更多关于插件反向调用 Dify 平台能力，请参考[反向调用](./plugin-dev-zh/9241-reverse-invocation)。

![Plugins permission](https://assets-docs.dify.ai/2024/12/d89a6282c5584fc43a9cadeddf09c0de.png)

#### 1. 编辑配置表单

在这个插件中，需要指定使用哪个 Dify 的 App 进行回复，并且在回复的时候需要使用到 Slack 的 App token，因此需要在插件表单中加上这两个字段。

修改 group 路径下的 yaml 文件，例如 `group/slack.yaml。`表单配置文件的名称由创建插件时填写的基础信息决定，你可以修改对应的 yaml 文件。

**示例代码：**

`slack.yaml`

```yaml
settings:
  - name: bot_token
    type: secret-input
    required: true
    label:
      en_US: Bot Token
      zh_Hans: Bot Token
      pt_BR: Token do Bot
      ja_JP: Bot Token
    placeholder:
      en_US: Please input your Bot Token
      zh_Hans: 请输入你的 Bot Token
      pt_BR: Por favor, insira seu Token do Bot
      ja_JP: ボットトークンを入力してください
  - name: allow_retry
    type: boolean
    required: false
    label:
      en_US: Allow Retry
      zh_Hans: 允许重试
      pt_BR: Permitir Retentativas
      ja_JP: 再試行を許可
    default: false
  - name: app
    type: app-selector
    required: true
    label:
      en_US: App
      zh_Hans: 应用
      pt_BR: App
      ja_JP: アプリ
    placeholder:
      en_US: the app you want to use to answer Slack messages
      zh_Hans: 你想要用来回答 Slack 消息的应用
      pt_BR: o app que você deseja usar para responder mensagens do Slack
      ja_JP: あなたが Slack メッセージに回答するために使用するアプリ
endpoints:
  - endpoints/slack.yaml
```

代码数据结构说明：

```
  - name: app
    type: app-selector
    scope: chat
```

*   type 字段指定为 app-selector 字段

    用户在使用插件时可以访问某个 Dify 应用并进行消息转发。
*   scope 字段指定为 chat 字段

    只能使用 `agent` 、`chatbot` 、`chatflow` 等类型的 app。

最后修改 `endpoints/slack.yaml` 文件中的请求路径和请求方式，需要将 method 修改为 POST 方式。

**示例代码：**

`endpoints/slack.yaml`

```yaml
path: "/"
method: "POST"
extra:
  python:
    source: "endpoints/slack.py"
```

#### 2. 编辑功能代码

修改 `endpoints/slack.py`文件，并在其中添加下面的代码：

````python

from typing import Mapping
from werkzeug import Request, Response
from dify_plugin import Endpoint
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError

class SlackEndpoint(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        """
        Invokes the endpoint with the given request.
        """
        retry_num = r.headers.get("X-Slack-Retry-Num")
        if (not settings.get("allow_retry") and (r.headers.get("X-Slack-Retry-Reason") == "http_timeout" or ((retry_num is not None and int(retry_num) > 0)))):
            return Response(status=200, response="ok")
        data = r.get_json()

        # Handle Slack URL verification challenge
        if data.get("type") == "url_verification":
            return Response(
                response=json.dumps("challenge": data.get("challenge")),
                status=200,
                content_type="application/json"
            )

        if (data.get("type") == "event_callback"):
            event = data.get("event")
            if (event.get("type") == "app_mention"):
                message = event.get("text", "")
                if message.startswith("<@"):
                    message = message.split("> ", 1)[1] if "> " in message else message
                    channel = event.get("channel", "")
                    blocks = event.get("blocks", [])
                    blocks[0]["elements"][0]["elements"] = blocks[0].get("elements")[0].get("elements")[1:]
                    token = settings.get("bot_token")
                    client = WebClient(token=token)
                    try: 
                        response = self.session.app.chat.invoke(
                            app_id=settings["app"]["app_id"],
                            query=message,
                            inputs={},
                            response_mode="blocking",
                        )
                        try:
                            blocks[0]["elements"][0]["elements"][0]["text"] = response.get("answer")
                            result = client.chat_postMessage(
                                channel=channel,
                                text=response.get("answer"),
                                blocks=blocks
                            )
                            return Response(
                                status=200,
                                response=json.dumps(result),
                                content_type="application/json"
                            )
                        except SlackApiError as e:
                            raise e
                    except Exception as e:
                        err = traceback.format_exc()
                        return Response(
                            status=200,
                            response="Sorry, I'm having trouble processing your request. Please try again later." + str(err),
                            content_type="text/plain",
                        )
                else:
                    return Response(status=200, response="ok")
            else:
                return Response(status=200, response="ok")
        else:
            return Response(status=200, response="ok")

```
````

为了便于测试，插件功能目前仅能重复用户输入的内容，暂不调用 Dify app。

### 2. 调试插件

前往 Dify 平台，获取 Dify 插件远程调试的连接地址和密钥。

![测试插件](https://assets-docs.dify.ai/2025/01/8d24006f0cabf5bf61640a9023c45db8.png)

回到插件项目，复制 `.env.example` 文件并重命名为 `.env`。

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_HOST=remote-url
REMOTE_INSTALL_PORT=5003
REMOTE_INSTALL_KEY=****-****-****-****-****
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内。其他团队成员也可以访问该插件。

```bash
python -m main
```

#### 设置插件 Endpoint

在 Dify 的插件管理页中找到自动安装的测试插件，新建一个 Endpoint，填写名称、Bot token、选择需要连接的 app。

![测试插件](https://assets-docs.dify.ai/2025/01/07f87e8a2786d6f5f05195961c5630c3.png)

保存后将生成一个 POST 请求地址。

![生成 POST 请求地址](https://assets-docs.dify.ai/2025/01/e6952a5798a7ae793b3fe7df6f76ea73.png)

接下来还需要完成 Slack App 的设置。

1. 启用 Event 订阅

![启用 Event 订阅](https://assets-docs.dify.ai/2025/01/1d33bb9cde78a1b5656ad6a0b8350195.png)

在其中粘贴上文中生成的插件 POST 请求地址。

![粘贴生成的插件 POST 请求地址](https://assets-docs.dify.ai/2025/01/65aa41f37c3800af49e944f9ff28e121.png)

勾选 Slack App 所需具备的权限。

![选择 Slack App 所需权限](https://assets-docs.dify.ai/2025/01/25c38a2cf10ec6c55ae54970d790f37e.png)

### 3. 验证插件效果

代码使用了 `self.session.app.chat.invoke` 调用 Dify 平台内的 App，并传递了 `app_id` 和 `query` 等信息，最后将 response 的内容返回至 Slack Bot。运行 `python -m main` 命令重启插件进行调试，确认 Slack Bot 是否能够正确输出 Dify App 的答复消息。

![验证插件效果](https://assets-docs.dify.ai/2025/01/6fc872d1343ce8503d63c5222f7f26f9.png)

### 4. 打包插件（可选）

确认插件能够正常运行后，可以通过以下命令行工具打包并命名插件。运行以后你可以在当前文件夹发现 `slack_bot.difypkg` 文件，该文件为最终的插件包。关于打包的详细步骤，请参考[打包为本地文件与分享](./plugin-dev-zh/0322-release-by-file)。

```bash
# Replace ./slack_bot with your actual plugin project path.

dify plugin package ./slack_bot
```

恭喜，你已完成一个插件的完整开发、测试打包过程！

### 5. 发布插件（可选）

现在可以将它上传至 [Dify Marketplace 仓库](https://github.com/langgenius/dify-plugins) 来发布你的插件了！不过在发布前，请确保你的插件遵循了[发布至 Dify Marketplace](./plugin-dev-zh/0322-release-to-dify-marketplace)中的规范。

## 相关资源

- [插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin) - 全面了解Dify插件开发
- [插件开发入门指南](./plugin-dev-zh/0211-getting-started-dify-tool) - 从零开始开发插件
- [开发 Extension 插件](./plugin-dev-zh/9231-extension-plugin) - 了解扩展插件开发
- [反向调用 Dify 服务](./plugin-dev-zh/9241-reverse-invocation) - 了解如何调用 Dify 平台能力
- [反向调用 App](./plugin-dev-zh/9242-reverse-invocation-app) - 了解如何调用平台内的 App
- [发布插件](./plugin-dev-zh/0321-release-overview) - 学习发布流程
- [发布至 Dify Marketplace](./plugin-dev-zh/0322-release-to-dify-marketplace) - 市场发布指南
- [端点详细定义](./plugin-dev-zh/0432-endpoint) - Endpoint 详细定义

### 参考阅读

如果你想要查看完整 Dify 插件的项目代码，请前往 [GitHub 代码仓库](https://github.com/langgenius/dify-plugins)。除此之外，你可以看到其它插件的完整代码与具体细节。

如果想要了解更多插件，请参考以下内容。

**快速开始：**

* [开发 Extension 插件](./plugin-dev-zh/9231-extension-plugin)
* [开发 Model 插件](./plugin-dev-zh/0211-getting-started-new-model)
* [Bundle 类型插件：将多个插件打包](./plugin-dev-zh/9241-bundle)

**插件接口文档：**

* [通过清单文件定义插件信息](./plugin-dev-zh/0411-plugin-info-by-manifest) - Manifest 结构
* [端点](./plugin-dev-zh/0432-endpoint) - Endpoint 详细定义
* [反向调用](./plugin-dev-zh/9241-reverse-invocation) - 反向调用 Dify 能力
* [通用规范](./plugin-dev-zh/0411-general-specifications) - 工具规范
* [模型架构](./plugin-dev-zh/0412-model-schema) - 模型

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0432-develop-a-slack-bot-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 彩虹猫 Endpoint
> 来源：`plugin-dev-zh/0432-endpoint.mdx`
> 摘要：Author Yeuoly，Allen 本文档详细介绍了Dify插件中Endpoint的结构和实现方式，以彩虹猫项目为例。内容包括如何定义Endpoint组、配置接口、实现_invoke方法以及处理请求和响应。文档详细解释了各种YAML配置字段的含义和使用方法。

本文将以[彩虹猫](./plugin-dev-zh/9231-extension-plugin)项目为例，说明插件内的 Endpoint 的结构。Endpoint是插件对外暴露的HTTP接口，可用于与外部系统集成。完整的插件代码请参考 [GitHub 仓库](https://github.com/langgenius/dify-plugin-sdks/tree/main/python/examples/neko)。

### 组定义

一个 `Endpoint` 组是多个 `Endpoint` 的集合，在 `Dify` 插件内新建 `Endpoint` 时可能需要填写如下配置。

![](https://assets-docs.dify.ai/2024/11/763dbf86e4319591415dc5a1b6948ccb.png)

除了 `Endpoint Name` 外，你可以通过编写组的配置信息来添加新的表单项，点击保存后，你可以看到其中包含的多个接口，它们将使用相同的配置信息。

![](https://assets-docs.dify.ai/2024/11/b778b7093b7df0dc80a476c65ddcbe58.png)

#### **结构**

* `settings`(map\[string] [ProviderConfig](./plugin-dev-zh/0411-general-specifications#providerconfig) )：Endpoint 配置定义
* `endpoints`(list\[string], required)：指向具体的 `endpoint` 接口定义

```yaml
settings:
  api_key:
    type: secret-input
    required: true
    label:
      en_US: API key
      zh_Hans: API key
      ja_Jp: API key
      pt_BR: API key
    placeholder:
      en_US: Please input your API key
      zh_Hans: 请输入你的 API key
      ja_Jp: あなたの API key を入れてください
      pt_BR: Por favor, insira sua chave API
endpoints:
  - endpoints/duck.yaml
  - endpoints/neko.yaml
```

### 接口定义

* `path`(string)：遵循 werkzeug 接口标准
* `method`(string)：接口方法，仅支持`HEAD` `GET` `POST` `PUT` `DELETE` `OPTIONS`
* `extra`(object)：除基础信息外的配置信息
  * `python`(object)
    * `source`(string)：实现该接口的源代码

```yaml
path: "/duck/<app_id>"
method: "GET"
extra:
  python:
    source: "endpoints/duck.py"
```

### 接口实现

需要实现一个继承自 `dify_plugin.Endpoint` 子类，并实现 `_invoke` 方法。

* **输入参数**
  * `r`(Request)：`werkzeug` 中的 `Request` 对象
  * `values`(Mapping)：从 path 中解析到的路径参数
  * `settings`(Mapping)：该 `Endpoint` 的配置信息
* **返回**
  * `werkzeug` 中的 `Response` 对象，支持流式返回
  * 不支持直接返回字符串

示例代码：

```python

from typing import Mapping
from werkzeug import Request, Response
from dify_plugin import Endpoint

class Duck(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        """
        Invokes the endpoint with the given request.
        """
        app_id = values["app_id"]

        def generator():
            yield f"app_id   
"

        return Response(generator(), status=200, content_type="text/html")
```

## 注意事项

* Endpoint 只在插件被调用时才会实例化，并不是长期运行的服务
* 请在开发 Endpoint 时注意安全性，避免执行危险操作
* Endpoint 可以用于处理 Webhook 回调或提供接口给其他系统连接

如果您正在学习插件开发，建议先阅读[插件开发入门指南](./plugin-dev-zh/0211-getting-started-dify-tool)和[开发者速查表](./plugin-dev-zh/0131-cheatsheet)。

## 相关资源

- [插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin) - 了解插件开发的整体架构
- [彩虹猫实例](./plugin-dev-zh/9231-extension-plugin) - 扩展插件开发示例
- [通用规范定义](./plugin-dev-zh/0411-general-specifications) - 了解 ProviderConfig 等通用结构
- [Slack 机器人插件开发示例](./plugin-dev-zh/0432-develop-a-slack-bot-plugin) - 另一个插件开发示例
- [插件开发入门指南](./plugin-dev-zh/0211-getting-started-dify-tool) - 从零开始开发插件
- [反向调用 Dify 服务](./plugin-dev-zh/9241-reverse-invocation) - 了解如何使用反向调用功能

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/0432-endpoint.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Extension 插件
> 来源：`plugin-dev-zh/9231-extension-plugin.mdx`
> 摘要：本文档提供了开发Extension类型插件的完整教程，详细介绍了环境准备、创建项目、定义插件请求入口、编写功能代码、调试、打包发布等全过程。示例项目是一个彩虹猫插件，展示了如何通过Extension插件处理HTTP请求并提供网页服务。

本文将引导你快速开发一个 Extension 类型的插件，以帮助你了解插件开发的基础流程。

### 前置准备

* Dify 插件脚手架工具
* Python 环境，版本号 ≥ 3.12

关于如何准备插件开发的脚手架工具，详细说明请参考[初始化开发工具](initialize-development-tools.md)。

### 创建新项目

在当前路径下，运行脚手架命令行工具，创建一个新的 dify 插件项目。

```
./dify-plugin-darwin-arm64 plugin init
```

如果你已将该二进制文件重命名为了 `dify` 并拷贝到了 `/usr/local/bin` 路径下，可以运行以下命令创建新的插件项目：

```bash
dify plugin init
```

#### 1. 填写插件信息

按照提示配置插件名称、作者信息与插件描述。如果你是团队协作，也可以将作者填写为组织名。

> 插件名称长度必须为 1-128 个字符，并且只能包含字母、数字、破折号和下划线。

![Plugins details](https://assets-docs.dify.ai/2024/12/75cfccb11fe31c56c16429b3998f2eb0.png)

填写完成后，在插件开发语言环节中选择 Python。

![Plugins development: Python](https://assets-docs.dify.ai/2024/11/1129101623ac4c091a3f6f75f4103848.png)

#### 2. 选择插件类型并初始化项目模板

脚手架工具内的所有模板均已提供完整的代码项目。出于演示说明，本文将以 `Extension` 类型插件模板作为示例。对于已熟悉插件的开发者而言，无需借助模板，可参考[接口文档](../../schema-definition/)指引完成不同类型的插件开发。

![Extension](https://assets-docs.dify.ai/2024/11/ff08f77b928494e10197b456fc4e2d5b.png)

#### 3. 配置插件权限

插件还需要读取 Dify 主平台的权限才能正常连接。需要为该示例插件授予以下权限：

* Tools
* LLMs
* Apps
* 启用持久化存储 Storage，分配默认大小存储
* 允许注册 Endpoint

> 在终端内使用方向键选择权限，使用 “Tab” 按钮授予权限。

勾选所有权限项后，轻点回车完成插件的创建。系统将自动生成插件项目代码。

![Plugins 权限](https://assets-docs.dify.ai/2024/11/5518ca1e425a7135f18f499e55d16bdd.png)

插件的基础文件结构包含以下内容：

```
.
├── GUIDE.md
├── README.md
├── _assets
│   └── icon.svg
├── endpoints
│   ├── your-project.py
│   └── your-project.yaml
├── group
│   └── your-project.yaml
├── main.py
├── manifest.yaml
└── requirements.txt
```

* `GUIDE.md` 一个简短的引导教程，带领你完成插件的编写流程。
* `README.md` 关于当前插件的简介信息，你需要把有关该插件的介绍和使用方法填写至该文件内。
* `_assets` 存储所有与当前插件相关的多媒体文件。
* `endpoints` 按照 cli 中的引导创建的一个 `Extension` 类型插件模板，该目录存放所有 Endpoint 的功能实现代码。
* `group` 指定密钥类型、多语言设置以及 API 定义的文件路径。
* `main.py` 整个项目的入口文件。
* `manifest.yaml` 整个插件的基础配置文件，包含该插件需要什么权限、是什么类型的扩展等配置信息。
* `requirements.txt` 存放 Python 环境的依赖项。

### 开发插件

#### 1. 定义插件的请求入口 Endpoint

编辑 `endpoints/test_plugin.yaml` ，参考以下代码进行修改：

```yaml
path: "/neko"
method: "GET"
extra:
  python:
    source: "endpoints/test_plugin.py"
```

该代码的意图是定义该插件的入口路径为 `/neko`，请求方法为 GET 类型。插件的功能实现代码为 `endpoints/test_plugin.py` 文件。

#### 2. 编写插件功能

插件功能：请求服务，输出一只彩虹猫。

编写插件的功能实现代码 `endpoints/test_plugin.py` 文件，参考以下示例代码：

```python
from typing import Mapping
from werkzeug import Request, Response
from flask import Flask, render_template_string
from dify_plugin import Endpoint

app = Flask(__name__)

class NekoEndpoint(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        ascii_art = '''
⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛⬛️⬜️⬜️⬜️⬜️⬜⬜️⬜️️
🟥🟥⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️🟥🟥🟥🟥🟥🟥🟥🟥⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬛🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧⬛️⬜️⬜️⬜️⬜️⬜⬜️️
🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥⬛️🥧🥧🥧💟💟💟💟💟💟💟💟💟💟💟💟💟🥧🥧🥧⬛️⬜️⬜️⬜️⬜⬜️️
🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥⬛️🥧🥧💟💟💟💟💟💟🍓💟💟🍓💟💟💟💟💟🥧🥧⬛️⬜️⬜️⬜️⬜️⬜️️
🟧🟧🟥🟥🟥🟥🟥🟥🟥🟥🟧🟧🟧🟧🟧🟧🟧🟧🟥🟥🟥🟥🟥🟥🟥⬛🥧💟💟🍓💟💟💟💟💟💟💟💟💟💟💟💟💟💟🥧⬛️⬜️⬜️⬜️⬜⬜️️
🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧⬛️🥧💟💟💟💟💟💟💟💟💟💟⬛️⬛️💟💟🍓💟💟🥧⬛️⬜️⬛️️⬛️️⬜⬜️️
🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧⬛️🥧💟💟💟💟💟💟💟💟💟⬛️🌫🌫⬛💟💟💟💟🥧⬛️⬛️🌫🌫⬛⬜️️
🟨🟨🟧🟧🟧🟧🟧🟧🟧🟧🟨🟨🟨🟨🟨🟨🟨🟨🟧⬛️⬛️⬛️⬛️🟧🟧⬛️🥧💟💟💟💟💟💟🍓💟💟⬛️🌫🌫🌫⬛💟💟💟🥧⬛️🌫🌫🌫⬛⬜️️
🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨⬛️🌫🌫⬛️⬛️🟧⬛️🥧💟💟💟💟💟💟💟💟💟⬛️🌫🌫🌫🌫⬛️⬛️⬛️⬛️🌫🌫🌫🌫⬛⬜️️
🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨⬛️⬛️🌫🌫⬛️⬛️⬛️🥧💟💟💟🍓💟💟💟💟💟⬛️🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫⬛⬜️️
🟩🟩🟨🟨🟨🟨🟨🟨🟨🟨🟩🟩🟩🟩🟩🟩🟩🟩🟨🟨⬛⬛️🌫🌫⬛️⬛️🥧💟💟💟💟💟💟💟🍓⬛️🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫⬛️
🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩⬛️⬛️🌫🌫⬛️🥧💟🍓💟💟💟💟💟💟⬛️🌫🌫🌫⬜️⬛️🌫🌫🌫🌫🌫⬜️⬛️🌫🌫⬛️
️🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩⬛️⬛️⬛️⬛️🥧💟💟💟💟💟💟💟💟⬛️🌫🌫🌫⬛️⬛️🌫🌫🌫⬛️🌫⬛️⬛️🌫🌫⬛️
🟦🟦🟩🟩🟩🟩🟩🟩🟩🟩🟦🟦🟦🟦🟦🟦🟦🟦🟩🟩🟩🟩🟩🟩⬛️⬛️🥧💟💟💟💟💟🍓💟💟⬛🌫🟥🟥🌫🌫🌫🌫🌫🌫🌫🌫🌫🟥🟥⬛️
🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦⬛️🥧🥧💟🍓💟💟💟💟💟⬛️🌫🟥🟥🌫⬛️🌫🌫⬛️🌫🌫⬛️🌫🟥🟥⬛️
🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦⬛️🥧🥧🥧💟💟💟💟💟💟💟⬛️🌫🌫🌫⬛️⬛️⬛️⬛️⬛️⬛️⬛️🌫🌫⬛️⬜️
🟪🟪🟦🟦🟦🟦🟦🟦🟦🟦🟪🟪🟪🟪🟪🟪🟪🟪🟦🟦🟦🟦🟦🟦⬛️⬛️⬛️🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧⬛️🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫⬛️⬜️⬜️
🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪⬛️🌫🌫🌫⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬜️⬜️⬜️
🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪⬛️🌫🌫⬛️⬛️⬜️⬛️🌫🌫⬛️⬜️⬜️⬜️⬜️⬜️⬛️🌫🌫⬛️⬜️⬛️🌫🌫⬛️⬜️⬜️⬜️⬜️
⬜️⬜️🟪🟪🟪🟪🟪🟪🟪🟪⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️🟪🟪🟪🟪🟪⬛️⬛️⬛️⬛⬜️⬜️⬛️⬛️⬛️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬛️⬛️⬛️⬜️⬜️⬛️⬛️⬜️⬜️⬜️⬜️⬜️️
        '''
        ascii_art_lines = ascii_art.strip().split('\n')
        with app.app_context():
            return Response(render_template_string('''
    <!DOCTYPE html>
    <html>
    <head>
        <style>
            body 
                background-color: black;
                color: white;
                overflow: hidden;
                margin: 0;
                padding: 0;

            #ascii-art 
                font-family: monospace;
                white-space: pre;
                position: absolute;
                top: 50%;
                transform: translateY(-50%);
                display: inline-block;
                font-size: 16px;
                line-height: 1;

        </style>
    </head>
    <body>
        <div id="ascii-art"></div>
        <script>
            var asciiArtLines = {{ ascii_art_lines | tojson }};
            var asciiArtDiv = document.getElementById("ascii-art");
            var index = 0;
            function displayNextLine() {
                if (index < asciiArtLines.length) {
                    var line = asciiArtLines[index];
                    var lineElement = document.createElement("div");
                    lineElement.innerHTML = line;
                    asciiArtDiv.appendChild(lineElement);
                    index++;
                    setTimeout(displayNextLine, 100);
                } else 
                    animateCat();

            }
            function animateCat() {
                var pos = 0;
                var screenWidth = window.innerWidth;
                var catWidth = asciiArtDiv.offsetWidth;
                function move() {
                    asciiArtDiv.style.left = pos + "px";
                    pos += 2;
                    if (pos > screenWidth) {
                        pos = -catWidth;
                    }
                    requestAnimationFrame(move);
                }
                move();
            }
            displayNextLine();
        </script>
    </body>
    </html>
        ''', ascii_art_lines=ascii_art_lines), status=200, content_type="text/html")
```

运行此代码需要先安装以下 Python 依赖包：

```python
pip install werkzeug
pip install flask
pip install dify-plugin
```

### 调试插件

接下来需测试插件是否可以正常运行。Dify 提供远程调试方式，前往“插件管理”页获取调试 Key 和远程服务器地址。

![](https://assets-docs.dify.ai/2024/11/1cf15bc59ea10eb67513c8bdca557111.png)

回到插件项目，拷贝 `.env.example` 文件并重命名为 `.env`，将获取的远程服务器地址和调试 Key 等信息填入其中。

`.env` 文件

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_HOST=remote-url
REMOTE_INSTALL_PORT=5003
REMOTE_INSTALL_KEY=****-****-****-****-****
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内。其他团队成员也可以访问该插件。

![](https://assets-docs.dify.ai/2024/11/0fe19a8386b1234755395018bc2e0e35.png)

在插件内新增 Endpoint，随意填写名称和 `api_key` 等信息。访问自动生成的 URL，即可看到由插件提供的网页服务。

![](https://assets-docs.dify.ai/2024/11/c76375b8df2449d0d8c31a7c2a337579.png)

### 打包插件

确认插件能够正常运行后，可以通过以下命令行工具打包并命名插件。运行以后你可以在当前文件夹发现 `neko.difypkg` 文件，该文件为最终的插件包。

```bash
dify plugin package ./neko
```

恭喜，你已完成一个插件的完整开发、测试打包过程！

### 发布插件

现在可以将它上传至 [Dify Plugins 代码仓库](https://github.com/langgenius/dify-plugins) 来发布你的插件了！上传前，请确保你的插件遵循了[插件发布规范](https://docs.dify.ai/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace)。审核通过后，代码将合并至主分支并自动上线至 [Dify Marketplace](https://marketplace.dify.ai/)。

### 探索更多

**快速开始：**

* [Tool 插件：Google Search](tool-plugin.md)
* [Model 插件](model-plugin/)
* [Bundle 插件：将多个插件打包](bundle.md)

**插件接口文档：**

* [Manifest](../../schema-definition/manifest.md) 结构
* [Endpoint](../../schema-definition/endpoint.md) 详细定义
* [反向调用 Dify 能力](../../schema-definition/reverse-invocation-of-the-dify-service/)
* [工具](../../schema-definition/tool.md)
* [模型](../../schema-definition/model/)
* [扩展 Agent 策略](../../schema-definition/agent.md)

**最佳实践：**

[开发 Slack Bot 插件](../../best-practice/develop-a-slack-bot-plugin.md)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/9231-extension-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Agent
> 来源：`plugin-dev-zh/9232-agent.mdx`
> 摘要：本文档详细介绍了Dify的Agent策略插件开发流程，包括在Manifest文件中添加Agent策略字段、定义Agent供应商以及实现Agent策略的核心步骤。文档详细介绍了如何获取参数、调用模型、调用工具以及生成和管理日志的完整示例代码。

Agent 策略是一个定义了标准输入内容与输出格式的可扩展模板。通过开发具体 Agent 策略接口的功能代码，你可以实现众多不同的 Agent 策略如 CoT（思维链）/ ToT（思维树）/ GoT（思维图）/ BoT（思维骨架），实现一些诸如 [Sementic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/)  的复杂策略。

### 在 Manifest 内添加字段

在插件中添加 Agent 策略需要在 `manifest.yaml` 文件内新增 `plugins.agent_strategies` 字段，并且也需要定义 Agent 供应商，示例代码如下

```yaml
version: 0.0.2
type: plugin
author: "langgenius"
name: "agent"
plugins:
  agent_strategies:
    - "provider/agent.yaml"
```

此处已省去 `manifest` 文件内部分无关的字段。如需了解 Manifest 的详细格式，请参考 [通过清单文件定义插件信息](./plugin-dev-zh/0411-plugin-info-by-manifest) 文档。

### 定义 Agent 供应商

随后，你需要新建 `agent.yaml` 文件并填写基础的 Agent 供应商信息。

```yaml
identity:
  author: langgenius
  name: agent
  label:
    en_US: Agent
    zh_Hans: Agent
    pt_BR: Agent
  description:
    en_US: Agent
    zh_Hans: Agent
    pt_BR: Agent
  icon: icon.svg
strategies:
  - strategies/function_calling.yaml
```

其主要包含一些描述性质的基础内容，并且指明当前供应商包含哪些策略。在上述示例代码中仅指定了一个最基础的 `function_calling.yaml` 策略文件。

### 定义并实现 Agent 策略

#### 定义

接下来需要定义能够实现 Agent 策略的代码。新建一个 `function_calling.yaml` 文件：

```yaml
identity:
  name: function_calling
  author: Dify
  label:
    en_US: FunctionCalling
    zh_Hans: FunctionCalling
    pt_BR: FunctionCalling
description:
  en_US: Function Calling is a basic strategy for agent, model will use the tools provided to perform the task.
  zh_Hans: Function Calling 是一个基本的 Agent 策略，模型将使用提供的工具来执行任务。
  pt_BR: Function Calling is a basic strategy for agent, model will use the tools provided to perform the task.
parameters:
  - name: model
    type: model-selector
    scope: tool-call&llm
    required: true
    label:
      en_US: Model
      zh_Hans: 模型
      pt_BR: Model
  - name: tools
    type: array[tools]
    required: true
    label:
      en_US: Tools list
      zh_Hans: 工具列表
      pt_BR: Tools list
  - name: query
    type: string
    required: true
    label:
      en_US: Query
      zh_Hans: 用户提问
      pt_BR: Query
  - name: max_iterations
    type: number
    required: false
    default: 5
    label:
      en_US: Max Iterations
      zh_Hans: 最大迭代次数
      pt_BR: Max Iterations
    max: 50
    min: 1
extra:
  python:
    source: strategies/function_calling.py
```

代码格式类似 [`Tool` 标准格式](./plugin-dev-zh/0411-tool)，定义了 `model` `tools` `query` `max_iterations` 等一共四个参数，以便于实现最基础的 Agent 策略。该代码的含义是可以允许用户选择模型和需要使用的工具，配置最大迭代次数并最终传入一个 query 后开始执行 Agent。

#### 编写功能实现代码

**获取参数**

根据上文定义的四个参数，其中 model 类型参数为`model-selector`，tool 类型参数为特殊的 `array[tools]。`在参数中获取到的形式可以通过 SDK 中内置的 `AgentModelConfig` 和 `list[ToolEntity]`进行转换。

```python
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity

class FunctionCallingParams(BaseModel):
    query: str
    model: AgentModelConfig
    tools: list[ToolEntity] | None
    maximum_iterations: int = 3

 class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        """
        Run FunctionCall agent application
        """
        fc_params = FunctionCallingParams(**parameters)
```

**调用模型**

调用指定模型是 Agent 插件中必不可少的能力。通过 SDK 中的 `session.model.invoke()` 函数调用模型。可以从 model 中获取所需的传入参数。

invoke model 的方法签名示例代码：

```python
def invoke(
        self,
        model_config: LLMModelConfig,
        prompt_messages: list[PromptMessage],
        tools: list[PromptMessageTool] | None = None,
        stop: list[str] | None = None,
        stream: bool = True,
    ) -> Generator[LLMResultChunk, None, None] | LLMResult:
```

需要传入模型信息 `model_config`，prompt 信息 `prompt_messages` 和工具信息 `tools`。

其中`prompt_messages`参数可以参考以下示例代码调用；而`tool_messages`则需要进行一定的转换。

请参考 invoke model 使用方法的示例代码：

```python
from collections.abc import Generator
from typing import Any

from pydantic import BaseModel

from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.model.message import (
    PromptMessageTool,
    SystemPromptMessage,
    UserPromptMessage,
)
from dify_plugin.entities.tool import ToolParameter
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity

class FunctionCallingParams(BaseModel):
    query: str
    instruction: str | None
    model: AgentModelConfig
    tools: list[ToolEntity] | None
    maximum_iterations: int = 3

class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        """
        Run FunctionCall agent application
        """
        # init params
        fc_params = FunctionCallingParams(**parameters)
        query = fc_params.query
        model = fc_params.model
        stop = fc_params.model.completion_params.get("stop", []) if fc_params.model.completion_params else []
        prompt_messages = [
            SystemPromptMessage(content="your system prompt message"),
            UserPromptMessage(content=query),
        ]
        tools = fc_params.tools
        prompt_messages_tools = self._init_prompt_tools(tools)

        # invoke llm
        chunks = self.session.model.llm.invoke(
            model_config=LLMModelConfig(**model.model_dump(mode="json")),
            prompt_messages=prompt_messages,
            stream=True,
            stop=stop,
            tools=prompt_messages_tools,
        )

    def _init_prompt_tools(self, tools: list[ToolEntity] | None) -> list[PromptMessageTool]:
        """
        Init tools
        """

        prompt_messages_tools = []
        for tool in tools or []:
            try:
                prompt_tool = self._convert_tool_to_prompt_message_tool(tool)
            except Exception:
                # api tool may be deleted
                continue

            # save prompt tool
            prompt_messages_tools.append(prompt_tool)

        return prompt_messages_tools

    def _convert_tool_to_prompt_message_tool(self, tool: ToolEntity) -> PromptMessageTool:
        """
        convert tool to prompt message tool
        """
        message_tool = PromptMessageTool(
            name=tool.identity.name,
            description=tool.description.llm if tool.description else "",
            parameters={
                "type": "object",
                "properties": {},
                "required": [],
            },
        )

        parameters = tool.parameters
        for parameter in parameters:
            if parameter.form != ToolParameter.ToolParameterForm.LLM:
                continue

            parameter_type = parameter.type
            if parameter.type in 
                ToolParameter.ToolParameterType.FILE,
                ToolParameter.ToolParameterType.FILES,
            :
                continue
            enum = []
            if parameter.type == ToolParameter.ToolParameterType.SELECT:
                enum = [option.value for option in parameter.options] if parameter.options else []

            message_tool.parameters["properties"][parameter.name] = 
                "type": parameter_type,
                "description": parameter.llm_description or "",

            if len(enum) > 0:
                message_tool.parameters["properties"][parameter.name]["enum"] = enum

            if parameter.required:
                message_tool.parameters["required"].append(parameter.name)

        return message_tool

```

**调用工具**

调用工具同样是 Agent 插件必不可少的能力。可以通过`self.session.tool.invoke()`进行调用。invoke tool 的方法签名示例代码：

```python
def invoke(
        self,
        provider_type: ToolProviderType,
        provider: str,
        tool_name: str,
        parameters: dict[str, Any],
    ) -> Generator[ToolInvokeMessage, None, None]
```

必须的参数有 `provider_type`, `provider`, `tool_name`, `parameters`。其中 `tool_name` 和`parameters`在 Function Calling 中往往都由 LLM 生成。使用 invoke tool 的示例代码：

```python
from dify_plugin.entities.tool import ToolProviderType

class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        """
        Run FunctionCall agent application
        """
        fc_params = FunctionCallingParams(**parameters)

        # tool_call_name and tool_call_args parameter is obtained from the output of LLM
        tool_instances = tool.identity.name: tool for tool in fc_params.tools if fc_params.tools else {}
        tool_instance = tool_instances[tool_call_name]
        tool_invoke_responses = self.session.tool.invoke(
            provider_type=ToolProviderType.BUILT_IN,
            provider=tool_instance.identity.provider,
            tool_name=tool_instance.identity.name,
            # add the default value
            parameters=**tool_instance.runtime_parameters, **tool_call_args,
        )
```

`self.session.tool.invoke()`函数的输出是一个 Generator，代表着同样需要进行流式解析。

解析方法请参考以下函数：

```python

from collections.abc import Generator
from typing import cast

from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.tool import ToolInvokeMessage

def parse_invoke_response(tool_invoke_responses: Generator[AgentInvokeMessage]) -> str:
    result = ""
    for response in tool_invoke_responses:
        if response.type == ToolInvokeMessage.MessageType.TEXT:
            result += cast(ToolInvokeMessage.TextMessage, response.message).text
        elif response.type == ToolInvokeMessage.MessageType.LINK:
            result += (
                f"result link: cast(ToolInvokeMessage.TextMessage, response.message).text."
                + " please tell user to check it."
            )
        elif response.type in 
            ToolInvokeMessage.MessageType.IMAGE_LINK,
            ToolInvokeMessage.MessageType.IMAGE,
        :
            result += (
                "image has been created and sent to user already, "
                + "you do not need to create it, just tell the user to check it now."
            )
        elif response.type == ToolInvokeMessage.MessageType.JSON:
            text = json.dumps(cast(ToolInvokeMessage.JsonMessage, response.message).json_object, ensure_ascii=False)
            result += f"tool response: text."
        else:
            result += f"tool response: response.message!r."
    return result
```

#### Log

如果你希望看到 Agent 思考的过程，除了通过查看正常返回的消息以外，还可以使用专门的接口实现以树状结构展示整个 Agent 的思考过程。

**创建日志**

* 该接口创建并返回一个 `AgentLogMessage`，该 Message 表示日志中树的一个节点。
* 如果有传入 parent 则表示该节点具备父节点。
* 状态默认为"Success"（成功）。但如果你想要更好地展示任务执行过程，可以先设置状态为"start"来显示"正在执行"的日志，等任务完成后再将该日志的状态更新为"Success"。这样用户就能清楚地看到任务从开始到完成的整个过程。
* label 将用于最终给用户展示日志标题。

```python
    def create_log_message(
        self,
        label: str,
        data: Mapping[str, Any],
        status: AgentInvokeMessage.LogMessage.LogStatus = AgentInvokeMessage.LogMessage.LogStatus.SUCCESS,
        parent: AgentInvokeMessage | None = None,
    ) -> AgentInvokeMessage
```

**完成日志**

如果在前一个步骤选择了 start 状态作为初始状态，可以使用完成日志的接口来更改状态。

```python
    def finish_log_message(
        self,
        log: AgentInvokeMessage,
        status: AgentInvokeMessage.LogMessage.LogStatus = AgentInvokeMessage.LogMessage.LogStatus.SUCCESS,
        error: Optional[str] = None,
    ) -> AgentInvokeMessage
```

**实例**

这个示例展示了一个简单的两步执行过程：首先输出一条"正在思考"的状态日志，然后完成实际的任务处理。

```python
class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        thinking_log = self.create_log_message(
            data=
                "Query": parameters.get("query"),
            ,
            label="Thinking",
            status=AgentInvokeMessage.LogMessage.LogStatus.START,
        )

        yield thinking_log

        llm_response = self.session.model.llm.invoke(
            model_config=LLMModelConfig(
                provider="openai",
                model="gpt-4o-mini",
                mode="chat",
                completion_params={},
            ),
            prompt_messages=[
                SystemPromptMessage(content="you are a helpful assistant"),
                UserPromptMessage(content=parameters.get("query")),
            ],
            stream=False,
            tools=[],
        )

        thinking_log = self.finish_log_message(
            log=thinking_log,
        )

        yield thinking_log

        yield self.create_text_message(text=llm_response.message.content)
```

## 相关资源

- [插件开发基本概念](./plugin-dev-zh/0111-getting-started-dify-plugin) - 了解插件开发的整体架构
- [Agent 策略插件开发示例](./plugin-dev-zh/9433-agent-strategy-plugin) - 实际的 Agent 策略插件开发示例
- [通过清单文件定义插件信息](./plugin-dev-zh/0411-plugin-info-by-manifest) - 了解 Manifest 文件的详细格式
- [反向调用 Model](./plugin-dev-zh/9242-reverse-invocation-model) - 了解如何调用平台内的模型能力
- [反向调用 Tool](./plugin-dev-zh/9242-reverse-invocation-tool) - 了解如何调用其它插件

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/9232-agent.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Bundle 插件包
> 来源：`plugin-dev-zh/9241-bundle.mdx`
> 摘要：本文档介绍了Bundle插件包的概念和开发方法。Bundle插件包可以将多个插件集合到一起，支持三种类型（Marketplace类型、GitHub类型和Package类型）。文档详细说明了创建Bundle项目、添加不同类型依赖以及打包Bundle项目的全过程。

Bundle 插件包是多个插件的集合。它可以将多个插件打包在一个插件内，以达到批量安装插件的效果，同时提供更强大的服务。

你可以通过 Dify cli 工具将多个插件打包为 Bundle。Bundle 插件包提供三种类型，分别为：

* `Marketplace` 类型。储存了插件的 id 与版本信息。导入时会通过 Dify Marketplace 下载具体的插件包。
* `GitHub` 类型。储存了 GitHub 的仓库地址、 release 版本号和 asset 文件名。导入时 Dify 会访问对应的 GitHub 仓库下载插件包。
* `Package` 类型。插件包会直接被储存在 Bundle 中。它不储存引用源，但可能会造成 Bundle 包体积较大的问题。

### 前置准备

* Dify 插件脚手架工具
* Python 环境，版本号 ≥ 3.10

关于如何准备插件开发的脚手架工具，详细说明请参考[初始化开发工具](initialize-development-tools.mdx)。

### 创建 Bundle 项目

在当前路径下，运行脚手架命令行工具，创建一个新的插件包项目。

```bash
./dify-plugin-darwin-arm64 bundle init
```

如果你已将该二进制文件重命名为了 `dify` 并拷贝到了 `/usr/local/bin` 路径下，可以运行以下命令创建新的插件项目：

```bash
dify bundle init
```

#### 1. 填写插件信息

按照提示配置插件名称、作者信息与插件描述。如果你是团队协作，也可以将作者填写为组织名。

> 名称长度必须为 1-128 个字符，并且只能包含字母、数字、破折号和下划线。

![Bundle basic information](https://assets-docs.dify.ai/2024/12/03a1c4cdc72213f09523eb1b40832279.png)

填写信息后敲击回车，将自动创建 Bundle 插件项目目录。

![](https://assets-docs.dify.ai/2024/12/356d1a8201fac3759bf01ee64e79a52b.png)

#### 2. 添加依赖

* **Marketplace**

执行以下命令：

```bash
dify-plugin bundle append marketplace . --marketplace_pattern=langgenius/openai:0.0.1
```

其中 marketplace\_pattern 为插件在 marketplace 中的引用，格式为 `组织名/插件名:版本号`。

* **Github**

执行以下命令：

```bash
dify-plugin bundle append github . --repo_pattern=langgenius/openai:0.0.1/openai.difypkg
```

其中 repo\_pattern 为插件在 github 中的引用，格式为 `组织名/仓库名:release/附件名`。

* **Package**

执行以下命令：

```bash
dify-plugin bundle append package . --package_path=./openai.difypkg
```

其中 package\_path 为插件包的目录。

### 打包 Bundle 项目

运行以下命令打包 Bundle 插件：

```bash
dify-plugin bundle package ./bundle
```

执行命令后，当前目录下将自动创建 `bundle.difybndl` 文件，该文件即为最后的打包结果。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/9241-bundle.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 反向调用 Dify 服务
> 来源：`plugin-dev-zh/9241-reverse-invocation.mdx`
> 摘要：本文档简要介绍了Dify插件的反向调用能力，即插件可以调用Dify主平台内的指定服务。文档列出了四类可被调用的模块：App（访问App数据）、Model（调用平台内的模型能力）、Tool（调用平台内的其他工具插件）和Node（调用Chatflow/Workflow应用内的节点）。

插件可以自由调用 Dify 主平台内的部分服务，用以提升插件的能力。

### 可被调用的 Dify 模块

*   [App](./plugin-dev-zh/9242-reverse-invocation-app)

    插件能够访问 Dify 平台内 App 的数据。
*   [Model](./plugin-dev-zh/9242-reverse-invocation-model)

    插件能够反向调用 Dify 平台内的 LLM 能力，包括平台内的所有模型类型与功能，例如 TTS、Rerank 等。
*   [Tool](./plugin-dev-zh/9242-reverse-invocation-tool)

    插件能够调用 Dify 平台内的其它工具类型插件。
*   [Node](./plugin-dev-zh/9243-reverse-invocation-node)

    插件能够调用 Dify 平台内某个 Chatflow/Workflow 应用内的节点。

## 相关资源

- [开发 Extension 插件](./plugin-dev-zh/9231-extension-plugin) - 学习如何开发与外部系统集成的插件
- [开发 Slack Bot 插件](./plugin-dev-zh/0432-develop-a-slack-bot-plugin) - 使用反向调用实现与 Slack 平台集成的实例
- [Bundle 类型插件](./plugin-dev-zh/9241-bundle) - 了解如何打包多个使用反向调用的插件
- [使用持久化存储](./plugin-dev-zh/0411-persistent-storage-kv) - 通过 KV 存储提升插件能力

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/9241-reverse-invocation.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## App
> 来源：`plugin-dev-zh/9242-reverse-invocation-app.mdx`
> 摘要：本文档详细介绍了插件如何反向调用Dify平台中的App服务。内容包括三种不同类型的接口：聊天接口（适用于Chatbot/Agent/Chatflow类型应用）、Workflow接口和Completion接口，并提供了每种接口的入口方式、调用规范以及实际的调用示例代码。

反向调用 App 指的是插件能够访问 Dify 中的 App 数据。该模块同时支持流式与非流式的 App 调用。如果你对反向调用的基本概念还不熟悉，请先阅读[反向调用 Dify 服务](./plugin-dev-zh/9241-reverse-invocation)。

**接口类型：**

* 对于 `Chatbot/Agent/Chatflow`  类型应用而言，它们都属于聊天类型的应用，因此拥有相同类型的输入参数和输出参数，因此可被统一视为**聊天接口。**
* 对于 Workflow 应用而言，它单独占据一个 **Workflow 接口。**
* 对于 Completion（文本生成应用）应用而言，它单独占据一个 **Completion 接口**。

请注意，插件仅允许访问插件所在的 Workspace 中的 App。

### 调用聊天接口

#### **入口**

```python
    self.session.app.chat
```

#### **接口规范**

```python
    def invoke(
        self,
        app_id: str,
        inputs: dict,
        response_mode: Literal["streaming", "blocking"],
        conversation_id: str,
        files: list,
    ) -> Generator[dict, None, None] | dict:
        pass
```

当 `response_mode` 为 `streaming` 时，该接口将直接返回 `Generator[dict]`，否则直接返回 `dict`，具体的接口字段请参考 `ServiceApi` 的返回结果。

#### **用例**

我们可以在一个 `Endpoint` 中调用 Chat 类型的 App，并将结果直接返回。

```python

from typing import Mapping
from werkzeug import Request, Response
from dify_plugin import Endpoint

class Duck(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        """
        Invokes the endpoint with the given request.
        """
        app_id = values["app_id"]

        def generator():
            response = self.session.app.chat.invoke(
                app_id=app_id, 
                inputs={}, 
                response_mode="streaming", 
                conversation_id="",  # 可选，留空则创建新对话
                files=[]
            )

            for data in response:
                yield f"json.dumps(data)   
"

        return Response(generator(), status=200, content_type="text/html")
```

### 调用 Workflow 接口

#### **入口**

```python
    self.session.app.workflow
```

#### **接口规范**

```python
    def invoke(
        self,
        app_id: str,
        inputs: dict,
        response_mode: Literal["streaming", "blocking"],
        files: list,
    ) -> Generator[dict, None, None] | dict:
        pass
```

### 调用 Completion 接口

#### **入口**

```python
    self.session.app.completion
```

**接口规范**

```python
    def invoke(
        self,
        app_id: str,
        inputs: dict,
        response_mode: Literal["streaming", "blocking"],
        files: list,
    ) -> Generator[dict, None, None] | dict:
        pass
```

## 相关资源

- [反向调用 Dify 服务](./plugin-dev-zh/9241-reverse-invocation) - 了解反向调用的根本概念
- [反向调用 Model](./plugin-dev-zh/9242-reverse-invocation-model) - 了解如何调用平台内的模型能力
- [反向调用 Tool](./plugin-dev-zh/9242-reverse-invocation-tool) - 了解如何调用其它插件
- [开发 Slack Bot 插件](./plugin-dev-zh/0432-develop-a-slack-bot-plugin) - 使用反向调用的实际应用案例
- [开发 Extension 插件](./plugin-dev-zh/9231-extension-plugin) - 学习如何开发扩展插件

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/9242-reverse-invocation-app.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Model
> 来源：`plugin-dev-zh/9242-reverse-invocation-model.mdx`
> 摘要：本文档详细介绍了插件如何反向调用Dify平台中的模型服务。内容包括反向调用LLM、Summary、TextEmbedding、Rerank、TTS、Speech2Text和Moderation等模型的具体方法，每种模型调用都配有对应的入口、接口参数说明以及实际的使用示例代码，并提供了调用模型的最佳实践建议。

反向调用 Model 指的是插件能够反向调用 Dify 内 LLM 的能力，包括平台内的所有模型类型与功能，例如 TTS、Rerank 等。如果你对反向调用的基本概念还不熟悉，请先阅读[反向调用 Dify 服务](./plugin-dev-zh/9241-reverse-invocation)。

不过请注意，调用模型需要传入一个 `ModelConfig` 类型的参数，它的结构可以参考 [通用规范定义](./plugin-dev-zh/0411-general-specifications)，并且对于不同类型的模型，该结构会存在细微的差别。

例如对于 `LLM` 类型的模型，还需要包含 `completion_params` 与 `mode` 参数，你可以手动构建该结构，或者使用 `model-selector` 类型的参数或配置。

### 调用 LLM

#### **入口**

```python
    self.session.model.llm
```

#### **端点**

```python
    def invoke(
        self,
        model_config: LLMModelConfig,
        prompt_messages: list[PromptMessage],
        tools: list[PromptMessageTool] | None = None,
        stop: list[str] | None = None,
        stream: bool = True,
    ) -> Generator[LLMResultChunk, None, None] | LLMResult:
        pass
```

请注意，如果你调用的模型不具备 `tool_call` 的能力，那么此处传入的 `tools` 将不会生效。

#### **用例**

如果想在 `Tool` 中调用 `OpenAI` 的 `gpt-4o-mini` 模型，请参考以下示例代码：

```python
from collections.abc import Generator
from typing import Any

from dify_plugin import Tool
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin.entities.model.message import SystemPromptMessage, UserPromptMessage

class LLMTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        response = self.session.model.llm.invoke(
            model_config=LLMModelConfig(
                provider='openai',
                model='gpt-4o-mini',
                mode='chat',
                completion_params={}
            ),
            prompt_messages=[
                SystemPromptMessage(
                    content='you are a helpful assistant'
                ),
                UserPromptMessage(
                    content=tool_parameters.get('query')
                )
            ],
            stream=True
        )

        for chunk in response:
            if chunk.delta.message:
                assert isinstance(chunk.delta.message.content, str)
                yield self.create_text_message(text=chunk.delta.message.content)
```

可以留意到代码中传入了 `tool_parameters` 中的 `query` 参数。

### **最佳实践**

并不建议手动来构建 `LLMModelConfig`，而是允许用户可以在 UI 上选择自己想使用的模型，在这种情况下可以修改一下工具的参数列表，按照如下配置，添加一个 `model` 参数：

```yaml
identity:
  name: llm
  author: Dify
  label:
    en_US: LLM
    zh_Hans: LLM
    pt_BR: LLM
description:
  human:
    en_US: A tool for invoking a large language model
    zh_Hans: 用于调用大型语言模型的工具
    pt_BR: A tool for invoking a large language model
  llm: A tool for invoking a large language model
parameters:
  - name: prompt
    type: string
    required: true
    label:
      en_US: Prompt string
      zh_Hans: 提示字符串
      pt_BR: Prompt string
    human_description:
      en_US: used for searching
      zh_Hans: 用于搜索网页内容
      pt_BR: used for searching
    llm_description: key words for searching
    form: llm
  - name: model
    type: model-selector
    scope: llm
    required: true
    label:
      en_US: Model
      zh_Hans: 使用的模型
      pt_BR: Model
    human_description:
      en_US: Model
      zh_Hans: 使用的模型
      pt_BR: Model
    llm_description: which Model to invoke
    form: form
extra:
  python:
    source: tools/llm.py
```

请注意在该例子中指定了 `model` 的 `scope` 为 `llm`，那么此时用户就只能选择 `llm` 类型的参数，从而可以将上述用例的代码改成以下代码：

```python
from collections.abc import Generator
from typing import Any

from dify_plugin import Tool
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin.entities.model.message import SystemPromptMessage, UserPromptMessage

class LLMTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        response = self.session.model.llm.invoke(
            model_config=tool_parameters.get('model'),
            prompt_messages=[
                SystemPromptMessage(
                    content='you are a helpful assistant'
                ),
                UserPromptMessage(
                    content=tool_parameters.get('query')
                )
            ],
            stream=True
        )

        for chunk in response:
            if chunk.delta.message:
                assert isinstance(chunk.delta.message.content, str)
                yield self.create_text_message(text=chunk.delta.message.content)
```

### 调用 Summary

你可以请求该端点来总结一段文本，它会使用你当前 workspace 内的系统模型来总结文本。

**入口**

```python
    self.session.model.summary
```

**端点**

* `text` 为需要被总结的文本。
* `instruction` 为你想要额外添加的指令，它可以让你风格化地总结文本。

```python
    def invoke(
        self, text: str, instruction: str,
    ) -> str:
```

### 调用 TextEmbedding

**入口**

```python
    self.session.model.text_embedding
```

**端点**

```python
    def invoke(
        self, model_config: TextEmbeddingResult, texts: list[str]
    ) -> TextEmbeddingResult:
        pass
```

### 调用 Rerank

**入口**

```python
    self.session.model.rerank
```

**端点**

```python
    def invoke(
        self, model_config: RerankModelConfig, docs: list[str], query: str
    ) -> RerankResult:
        pass
```

### 调用 TTS

**入口**

```python
    self.session.model.tts
```

**端点**

```python
    def invoke(
        self, model_config: TTSModelConfig, content_text: str
    ) -> Generator[bytes, None, None]:
        pass
```

请注意 `tts` 端点返回的 `bytes` 流是一个 `mp3` 音频字节流，每一轮迭代返回的都是一个完整的音频。如果你想做更深入的处理任务，请选择合适的库进行。

### 调用 Speech2Text

**入口**

```python
    self.session.model.speech2text
```

**端点**

```python
    def invoke(
        self, model_config: Speech2TextModelConfig, file: IO[bytes]
    ) -> str:
        pass
```

其中 `file` 是一个 `mp3` 格式编码的音频文件。

### 调用 Moderation

**入口**

```python
    self.session.model.moderation
```

**端点**

```python
    def invoke(self, model_config: ModerationModelConfig, text: str) -> bool:
        pass
```

若该端点返回 `true` 则表示 `text` 中包含敏感内容。

## 相关资源

- [反向调用 Dify 服务](./plugin-dev-zh/9241-reverse-invocation) - 了解反向调用的根本概念
- [反向调用 App](./plugin-dev-zh/9242-reverse-invocation-app) - 了解如何调用平台内的 App
- [反向调用 Tool](./plugin-dev-zh/9242-reverse-invocation-tool) - 了解如何调用其它插件
- [模型插件开发指南](./plugin-dev-zh/0211-getting-started-new-model) - 学习如何开发自定义模型插件
- [模型设计规则](./plugin-dev-zh/0411-model-designing-rules) - 了解模型插件的设计原则

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/9242-reverse-invocation-model.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Tool
> 来源：`plugin-dev-zh/9242-reverse-invocation-tool.mdx`
> 摘要：本文档详细介绍了插件如何反向调用Dify平台中的工具服务。内容涉及三种不同类型的工具调用方法：调用已安装的工具（Built-in Tool）、调用Workflow

反向调用 Tool 指的是插件能够调用 Dify 平台内的其它工具类型插件。如果你对反向调用的基本概念还不熟悉，请先阅读[反向调用 Dify 服务](./plugin-dev-zh/9241-reverse-invocation)。

当遇到以下需求时：

* 某个工具类型插件已经实现好了一个功能，但效果未达预期，需要对数据进行二次加工。
* 某个任务需要使用到爬虫，希望能够自由选择爬虫服务。
* 需要集合多个工具的返回结果，但是通过 Workflow 应用不好处理。

此时需要在插件中调用其他已经实现好的工具，该工具可能是市场中的某个工具插件，可能是自主构建的 Workflow as a Tool，亦或是自定义工具。

上述需求可以通过调用插件的 `self.session.tool` 字段来实现。

### 调用已安装的工具

允许插件调用已安装在当前 Workspace 内的各个工具，其中也包含其它工具类型的插件。

**入口**

```python
    self.session.tool
```

**接口**

```python
    def invoke_builtin_tool(
        self, provider: str, tool_name: str, parameters: dict[str, Any]
    ) -> Generator[ToolInvokeMessage, None, None]:
        pass
```

其中 provider 为 plugin 的 ID 加上工具供应商名称，格式形如 `langgenius/google/google`，tool\_name 为具体的工具名称，`parameters` 为最后传递给该工具的参数。

### 调用 Workflow as Tool

如需了解关于 Workflow as Tool 的更多说明，请参考[工具插件文档](./plugin-dev-zh/9223-tool)。

**入口**

```python
    self.session.tool
```

**接口**

```python
    def invoke_workflow_tool(
        self, provider: str, tool_name: str, parameters: dict[str, Any]
    ) -> Generator[ToolInvokeMessage, None, None]:
        pass
```

此时的 provider 为该 tool 的 ID，tool\_name 在创建该 tool 的时候会要求填写。

### 调用 Custom Tool

**入口**

```python
    self.session.tool
```

**接口**

```python
    def invoke_api_tool(
        self, provider: str, tool_name: str, parameters: dict[str, Any]
    ) -> Generator[ToolInvokeMessage, None, None]:
        pass
```

此时的 `provider` 为该 tool 的 ID，`tool_name` 为 OpenAPI 中的 `operation_id`，若不存在，即为 Dify 自动生成的 `tool_name`，可以在工具管理页中看到具体的名称。

## 相关资源

- [反向调用 Dify 服务](./plugin-dev-zh/9241-reverse-invocation) - 了解反向调用的根本概念
- [反向调用 App](./plugin-dev-zh/9242-reverse-invocation-app) - 了解如何调用平台内的 App
- [反向调用 Model](./plugin-dev-zh/9242-reverse-invocation-model) - 了解如何调用平台内的模型能力
- [工具插件开发指南](./plugin-dev-zh/0211-getting-started-dify-tool) - 学习如何开发工具插件
- [高级工具插件](./plugin-dev-zh/9223-tool) - 了解 Workflow as Tool 等高级功能

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/9242-reverse-invocation-tool.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入自定义模型
> 来源：`plugin-dev-zh/9243-customizable-model.mdx`
> 摘要：本文档详细介绍了如何在Dify中接入自定义模型，以Xinference模型为例。文档涉及创建模型供应商文件、根据模型类型编写对应代码、实现模型调用逻辑和异常处理及调试发布等完整流程。特别详细地说明了LLM调用、Token计算、凭证校验和参数生成等核心方法的实现。

自定义模型指的是需要自行部署或配置的 LLM。本文将以 [Xinference 模型](https://inference.readthedocs.io/en/latest/)为例，演示如何在模型插件内接入自定义模型。

自定义模型默认包含模型类型和模型名称两个参数，无需在供应商 yaml 文件定义。

供应商配置文件无需实现 `validate_provider_credential`。Runtime 会根据用户选择的模型类型或模型名称，自动调用对应模型层的 `validate_credentials` 方法进行验证。

### 接入自定义模型插件

接入自定义模型分为以下步骤：

1.  **创建模型供应商文件**

    明确自定义模型中所包含的模型类型。
2.  **根据模型类型创建代码文件**

    根据模型的类型（如 `llm` 或 `text_embedding`）创建代码文件。确保每种模型类型有独立的逻辑分层，便于维护和扩展。
3.  **根据不同的模型模块，编写模型调用代码**

    在对应的模型类型模块下，创建一个与模型类型同名的 Python 文件（例如 llm.py）。在文件中定义实现具体模型逻辑的类，该类应符合系统的模型接口规范。
4.  **调试插件**

    为新增的供应商功能编写单元测试和集成测试，确保所有功能模块符合预期，并能够正常运行。

***

### 1. **创建模型供应商文件**

在插件项目的 `/provider` 路径下，新建 `xinference.yaml` 文件。

`Xinference` 家族模型支持 `LLM``，Text Embedding` 和 `Rerank` 模型类型，因此需要在 `xinference.yaml` 文件中包含上述模型类型。

示例代码：

```yaml 14-17
provider: xinference # 确定供应商标识
label: # 供应商展示名称，可设置 en_US 英文、zh_Hans 中文两种语言，zh_Hans 不设置将默认使用 en_US。
  en_US: Xorbits Inference
icon_small: # 小图标，可以参考其他供应商的图标，存储在对应供应商实现目录下的 _assets 目录，中英文策略同 label
  en_US: icon_s_en.svg
icon_large: # 大图标
  en_US: icon_l_en.svg
help: # 帮助
  title:
    en_US: How to deploy Xinference
    zh_Hans: 如何部署 Xinference
  url:
    en_US: https://github.com/xorbitsai/inference
supported_model_types: # 支持的模型类型，Xinference 同时支持 LLM/Text Embedding/Rerank
- llm
- text-embedding
- rerank
configurate_methods: # Xinference 为本地部署的供应商，并且没有预定义模型，需要用什么模型需要根据 Xinference 的文档进行部署，因此此处的方法为自定义模型。
- customizable-model
provider_credential_schema:
  credential_form_schemas:
```

接着需要定义 `provider_credential_schema` 字段。`Xinference 支持` text-generation，embeddings 和 reranking 模型，示例代码如下：

```yaml 10,14,17
provider_credential_schema:
  credential_form_schemas:
  - variable: model_type
    type: select
    label:
      en_US: Model type
      zh_Hans: 模型类型
    required: true
    options:
    - value: text-generation
      label:
        en_US: Language Model
        zh_Hans: 语言模型
    - value: embeddings
      label:
        en_US: Text Embedding
    - value: reranking
      label:
        en_US: Rerank
```

Xinference 中的每个模型都需要定义名称 `model_name`。

```yaml
  - variable: model_name
    type: text-input
    label:
      en_US: Model name
      zh_Hans: 模型名称
    required: true
    placeholder:
      zh_Hans: 填写模型名称
      en_US: Input model name
```

Xinference 模型需要使用者输入模型的本地部署地址，插件内需要提供允许填写 Xinference 模型的本地部署地址（server\_url）和模型 UID 的位置，示例代码如下：

```yaml 1,10
  - variable: server_url
    label:
      zh_Hans: 服务器 URL
      en_US: Server url
    type: text-input
    required: true
    placeholder:
      zh_Hans: 在此输入 Xinference 的服务器地址，如 https://example.com/xxx
      en_US: Enter the url of your Xinference, for example https://example.com/xxx
  - variable: model_uid
    label:
      zh_Hans: 模型 UID
      en_US: Model uid
    type: text-input
    required: true
    placeholder:
      zh_Hans: 在此输入您的 Model UID
      en_US: Enter the model uid
```

填写所有参数后即可完成自定义模型供应商 yaml 配置文件的创建。接下来需为配置文件内定义的模型添加具体的功能代码文件。

### 2. 编写模型代码

Xinference 模型供应商的模型类型包含 llm、rerank、speech2text、tts 类型，因此需要在 /models 路径下为每个模型类型创建独立的分组，并创建对应的功能代码文件。

下文将以 llm 类型为例，说明如何创建 `llm.py` 代码文件。创建代码时需创建一个 Xinference LLM 类，可以取名为 `XinferenceAILargeLanguageModel`，继承 `__base.large_language_model.LargeLanguageModel` 基类，实现以下几个方法：

* **LLM 调用**

LLM 调用的核心方法，同时支持流式和同步返回。

```python
def _invoke(self, model: str, credentials: dict,
            prompt_messages: list[PromptMessage], model_parameters: dict,
            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,
            stream: bool = True, user: Optional[str] = None) \
        -> Union[LLMResult, Generator]:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param model_parameters: model parameters
    :param tools: tools for tool calling
    :param stop: stop words
    :param stream: is stream response
    :param user: unique user id
    :return: full response or stream response chunk generator result
    """
```

实现代码时，需要注意使用两个函数来返回数据，分别用于处理同步返回和流式返回。

Python 会将函数中包含 `yield` 的关键字函数识别为生成器函数，返回的数据类型固定为 `Generator`，因此需要分别实现同步和流式返回，例如以下示例代码：

> 该示例使用了简化参数，实际编写代码时需参考上文中的参数列表。

```python
def _invoke(self, stream: bool, **kwargs) \
        -> Union[LLMResult, Generator]:
    if stream:
          return self._handle_stream_response(**kwargs)
    return self._handle_sync_response(**kwargs)

def _handle_stream_response(self, **kwargs) -> Generator:
    for chunk in response:
          yield chunk
def _handle_sync_response(self, **kwargs) -> LLMResult:
    return LLMResult(**response)
```

* **预计算输入 Tokens**

如果模型未提供预计算 tokens 的接口，可以直接返回 0。

```python
def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                 tools: Optional[list[PromptMessageTool]] = None) -> int:
  """
  Get number of tokens for given prompt messages

  :param model: model name
  :param credentials: model credentials
  :param prompt_messages: prompt messages
  :param tools: tools for tool calling
  :return:
  """
```

在某些情况下，如果不想直接返回 0，可以使用 `self._get_num_tokens_by_gpt2(text: str)` 方法计算 tokens。该方法位于 `AIModel` 基类中，使用 GPT-2 的 Tokenizer 进行计算。但请注意，这是一个替代方案，计算结果可能存在一定误差。

* **模型凭据校验**

与供应商凭据校验类似，这里针对单个模型进行校验。

```python
def validate_credentials(self, model: str, credentials: dict) -> None:
    """
    Validate model credentials

    :param model: model name
    :param credentials: model credentials
    :return:
    """
```

* **模型参数 Schema**

与[预定义模型类型](integrate-the-predefined-model.md)不同，由于未在 YAML 文件中预设模型所支持的参数，因此需要动态生成模型参数的 Schema。

例如，Xinference 支持 `max_tokens`、`temperature` 和 `top_p` 三种模型参数。然而一些供应商（例如 OpenLLM）会根据具体模型支持不同的参数。

举例来说，供应商 `OpenLLM` 的 A 模型支持 `top_k` 参数，而 B 模型则不支持 `top_k`。在该情况下，需要动态生成每个模型对应的参数 Schema，示例代码如下：

```python
  def get_customizable_model_schema(self, model: str, credentials: dict) -> AIModelEntity | None:
      """
          used to define customizable model schema
      """
      rules = [
          ParameterRule(
              name='temperature', type=ParameterType.FLOAT,
              use_template='temperature',
              label=I18nObject(
                  zh_Hans='温度', en_US='Temperature'
              )
          ),
          ParameterRule(
              name='top_p', type=ParameterType.FLOAT,
              use_template='top_p',
              label=I18nObject(
                  zh_Hans='Top P', en_US='Top P'
              )
          ),
          ParameterRule(
              name='max_tokens', type=ParameterType.INT,
              use_template='max_tokens',
              min=1,
              default=512,
              label=I18nObject(
                  zh_Hans='最大生成长度', en_US='Max Tokens'
              )
          )
      ]

      # if model is A, add top_k to rules
      if model == 'A':
          rules.append(
              ParameterRule(
                  name='top_k', type=ParameterType.INT,
                  use_template='top_k',
                  min=1,
                  default=50,
                  label=I18nObject(
                      zh_Hans='Top K', en_US='Top K'
                  )
              )
          )

      """
          some NOT IMPORTANT code here
      """

      entity = AIModelEntity(
          model=model,
          label=I18nObject(
              en_US=model
          ),
          fetch_from=FetchFrom.CUSTOMIZABLE_MODEL,
          model_type=model_type,
          model_properties=
              ModelPropertyKey.MODE:  ModelType.LLM,
          ,
          parameter_rules=rules
      )

      return entity
```

* **调用异常错误映射表**

当模型调用异常时需要映射到 Runtime 指定的 `InvokeError` 类型，方便 Dify 针对不同错误做不同后续处理。

Runtime Errors:

* `InvokeConnectionError` 调用连接错误
* `InvokeServerUnavailableError` 调用服务方不可用
* `InvokeRateLimitError` 调用达到限额
* `InvokeAuthorizationError` 调用鉴权失败
* `InvokeBadRequestError` 调用传参有误

```python
@property
def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
    """
    Map model invoke error to unified error
    The key is the error type thrown to the caller
    The value is the error type thrown by the model,
    which needs to be converted into a unified error type for the caller.

    :return: Invoke error mapping
    """
```

如需了解更多接口方法，请参考[接口文档：Model](../../../schema-definition/model/)。

如需获取本文所涉及的完整代码文件，请访问 [GitHub 代码仓库](https://github.com/langgenius/dify-official-plugins/tree/main/models/xinference)。

### 3. 调试插件

插件开发完成后，接下来需测试插件是否可以正常运行。详细说明请参考：

[debug-plugin.md](../../debug-plugin.md)

### 4. 发布插件

如果想要将插件发布至 Dify Marketplace，请参考以下内容：

[publish-to-dify-marketplace](../../../publish-plugins/publish-to-dify-marketplace/)

### **探索更多**

**快速开始：**

* [开发 Extension 插件](../extension-plugin.md)
* [开发 Tool 插件](../tool-plugin.md)
* [Bundle 插件：将多个插件打包](../bundle.md)

**插件接口文档：**

* [Manifest](../../../schema-definition/manifest.md) 结构
* [Endpoint](../../../schema-definition/endpoint.md) 详细定义
* [反向调用 Dify 能力](../../../schema-definition/reverse-invocation-of-the-dify-service/)
* [工具](../../../schema-definition/tool.md)
* [模型](../../../schema-definition/model/)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/9243-customizable-model.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Node
> 来源：`plugin-dev-zh/9243-reverse-invocation-node.mdx`
> 摘要：本文档介绍了插件如何反向调用Dify平台中的Chatflow/Workflow应用节点功能。内容主要涉及两种特殊节点的调用方法：参数提取器节点（ParameterExtractor）和问题分类节点（QuestionClassifier）。文档详细说明了这两种节点的调用入口、接口参数和用例代码。

反向调用 Node 指的是插件能够访问 Dify 中 Chatflow/Workflow 应用内部分节点的能力。

`Workflow` 中的 `ParameterExtractor（参数提取器）`与 `QuestionClassifier（问题分类）`节点封装了较为复杂的 Prompt 与代码逻辑，可以通过 LLM 来完成许多硬编码难以解决的任务。插件能够调用这两个节点。

### 调用参数提取器节点;

#### **入口**

```python
    self.session.workflow_node.parameter_extractor
```

#### **接口**

```python
    def invoke(
        self,
        parameters: list[ParameterConfig],
        model: ModelConfig,
        query: str,
        instruction: str = "",
    ) -> NodeResponse
        pass
```

其中 `parameters` 是需要提取出的参数的列表，`model` 符合 `LLMModelConfig` 规范，`query` 为提取参数的源文本，`instruction` 为一些可能额外需要给到 LLM 的指令，`NodeResponse` 的结构请参考该[文档](../general-specifications#noderesponse)。

#### **用例**

如果想要提取对话中的某个人名，可以参考以下代码：

```python
from collections.abc import Generator
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin import Tool
from dify_plugin.entities.workflow_node import ModelConfig, ParameterConfig

class ParameterExtractorTool(Tool):
    def _invoke(
        self, tool_parameters: dict
    ) -> Generator[ToolInvokeMessage, None, None]:
        response = self.session.workflow_node.parameter_extractor.invoke(
            parameters=[
                ParameterConfig(
                    name="name",
                    description="name of the person",
                    required=True,
                    type="string",
                )
            ],
            model=ModelConfig(
                provider="langgenius/openai/openai",
                name="gpt-4o-mini",
                completion_params={},
            ),
            query="My name is John Doe",
            instruction="Extract the name of the person",
        )

        yield self.create_text_message(response.outputs["name"])
```

### 调用问题分类节点

#### **入口**

```python
    self.session.workflow_node.question_classifier
```

#### **接口**

```python
    def invoke(
        self,
        classes: list[ClassConfig],
        model: ModelConfig,
        query: str,
        instruction: str = "",
    ) -> NodeResponse:
        pass
```

该接口参数与 `ParameterExtractor` 一致，最终的返回结果储存在 `NodeResponse.outputs['class_name']` 中。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/9243-reverse-invocation-node.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Agent 策略插件
> 来源：`plugin-dev-zh/9433-agent-strategy-plugin.mdx`
> 摘要：本文档详细介绍了如何开发Agent策略插件，从初始化插件模板到调用模型、调用工具、输出日志和打包发布的整个过程。文档提供了详尽的代码示例，包括如何实现帮助LLM执行推理或决策逻辑的自动化工具调用功能。

Agent 策略插件能够帮助 LLM 执行推理或决策逻辑，包括工具选择、调用和结果处理，以更加自动化的方式处理问题。

本文将演示如何创建一个具备工具调用（Function Calling）能力，自动获取当前准确时间的插件。

### 前置准备

* Dify 插件脚手架工具
* Python 环境，版本号 ≥ 3.12

关于如何准备插件开发的脚手架工具，详细说明请参考[初始化开发工具](./plugin-dev-zh/0221-initialize-development-tools)。

> **信息提示：**
**Tips**：在终端运行 `dify version` 命令，检查是否出现版本号以确认成功安装脚手架工具。

### 1. 初始化插件模板

运行以下命令，初始化 Agent 插件开发模板。

```bash
dify plugin init
```

按照页面提示，填写对应信息。参考以下代码中的备注信息，进行设置。

```
➜  Dify Plugins Developing dify plugin init
Edit profile of the plugin
Plugin name (press Enter to next step): # 填写插件的名称
Author (press Enter to next step): Author name # 填写插件作者
Description (press Enter to next step): Description # 填写插件的描述
---
Select the language you want to use for plugin development, and press Enter to con
BTW, you need Python 3.12+ to develop the Plugin if you choose Python.
-> python # 选择 Python 环境
  go (not supported yet)
---
Based on the ability you want to extend, we have divided the Plugin into four type

- Tool: It's a tool provider, but not only limited to tools, you can implement an 
- Model: Just a model provider, extending others is not allowed.
- Extension: Other times, you may only need a simple http service to extend the fu
- Agent Strategy: Implement your own logics here, just by focusing on Agent itself

What's more, we have provided the template for you, you can choose one of them b
  tool
-> agent-strategy # 选择 Agent 策略模板
  llm
  text-embedding
---
Configure the permissions of the plugin, use up and down to navigate, tab to sel
Backwards Invocation:
Tools:
    Enabled: [✔]  You can invoke tools inside Dify if it's enabled # 默认开启
Models:
    Enabled: [✔]  You can invoke models inside Dify if it's enabled # 默认开启
    LLM: [✔]  You can invoke LLM models inside Dify if it's enabled # 默认开启
    Text Embedding: [✘]  You can invoke text embedding models inside Dify if it'
    Rerank: [✘]  You can invoke rerank models inside Dify if it's enabled
...
```

初始化插件模板后将生成一个代码文件夹，包含插件开发过程中所需的完整资源。熟悉 Agent 策略插件的整体代码结构有助于插件的开发过程。

```text
├── GUIDE.md               # User guide and documentation
├── PRIVACY.md            # Privacy policy and data handling guidelines
├── README.md             # Project overview and setup instructions
├── _assets/             # Static assets directory
│   └── icon.svg         # Agent strategy provider icon/logo
├── main.py              # Main application entry point
├── manifest.yaml        # Basic plugin configuration
├── provider/           # Provider configurations directory
│   └── basic_agent.yaml # Your agent provider settings
├── requirements.txt    # Python dependencies list
└── strategies/         # Strategy implementation directory
    ├── basic_agent.py  # Basic agent strategy implementation
    └── basic_agent.yaml # Basic agent strategy configuration
```

插件的功能代码集中在 `strategies/` 目录内。

### 2. 开发插件功能

Agent 策略插件的开发主要围绕以下两个文件展开：

* 插件声明文件：`strategies/basic_agent.yaml`
* 插件功能代码：`strategies/basic_agent.py`

#### 2.1 定义参数

要创建一个 Agent 插件，首先需要在 `strategies/basic_agent.yaml` 文件中定义插件所需的参数。这些参数决定了插件的核心功能，例如调用 LLM 模型和使用工具的能力。

建议优先配置以下四个基础参数：

1. **model**：指定要调用的大语言模型（LLM），如 GPT-4、GPT-4o-mini 等。

2. **tools**：定义插件可以使用的工具列表，增强插件功能。

3. **query**：设置与模型交互的提示词或输入内容。

4. **maximum_iterations**：限制插件执行的最大迭代次数，避免过度计算。

示例代码：

```yaml
identity:
  name: basic_agent # the name of the agent_strategy
  author: novice # the author of the agent_strategy
  label:
    en_US: BasicAgent # the engilish label of the agent_strategy
description:
  en_US: BasicAgent # the english description of the agent_strategy
parameters:
  - name: model # the name of the model parameter
    type: model-selector # model-type
    scope: tool-call&llm # the scope of the parameter
    required: true
    label:
      en_US: Model
      zh_Hans: 模型
      pt_BR: Model
  - name: tools # the name of the tools parameter
    type: array[tools] # the type of tool parameter
    required: true
    label:
      en_US: Tools list
      zh_Hans: 工具列表
      pt_BR: Tools list
  - name: query # the name of the query parameter
    type: string # the type of query parameter
    required: true
    label:
      en_US: Query
      zh_Hans: 查询
      pt_BR: Query
  - name: maximum_iterations
    type: number
    required: false
    default: 5
    label:
      en_US: Maxium Iterations
      zh_Hans: 最大迭代次数
      pt_BR: Maxium Iterations
    max: 50 # if you set the max and min value, the display of the parameter will be a slider
    min: 1
extra:
  python:
    source: strategies/basic_agent.py

```

完成参数配置后，插件将在自动生成相应的设置的使用页面，方便你进行直观、便捷的调整和使用。

![Agent 策略插件的使用页面](https://assets-docs.dify.ai/2025/01/d011e2eba4c37f07a9564067ba787df8.png)

#### 2.2 获取参数并执行

当使用者在插件的使用页面完成基础的信息填写后，插件需要处理已填写的传入参数。因此需要先在 `strategies/basic_agent.py` 文件内定义 Agent 参数类供后续使用。

校验传入参数：

```python
from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity
from pydantic import BaseModel

class BasicParams(BaseModel):
    maximum_iterations: int
    model: AgentModelConfig
    tools: list[ToolEntity]
    query: str

```

获取参数后，执行具体的业务逻辑：

```python
class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)
```

#### 2.3 调用模型

在 Agent 策略插件中，**调用模型**是核心执行逻辑之一。可以通过 SDK 提供的 `session.model.llm.invoke()` 方法高效地调用 LLM 模型，实现文本生成、对话处理等功能。

如果希望模型具备**调用工具**的能力，首先需要确保模型能够输出符合工具调用格式的输入参数。也就是说，模型需要根据用户指令生成符合工具接口要求的参数。

构造以下参数：

* model：模型信息
* prompt\_messages：提示词
* tools：工具信息（Function Calling 相关）
* stop：停止符
* stream：是否支持流式输出

方法定义示例代码：

```python
def invoke(
        self,
        model_config: LLMModelConfig,
        prompt_messages: list[PromptMessage],
        tools: list[PromptMessageTool] | None = None,
        stop: list[str] | None = None,
        stream: bool = True,
    ) -> Generator[LLMResultChunk, None, None] | LLMResult:...
```

要查看完整的功能实现，请参考模型调用[示例代码](agent-strategy-plugin.md#diao-yong-gong-ju-1)。

该代码实现了以下功能：用户输入指令后，Agent 策略插件会自动调用 LLM，根据生成结果构建并传递工具调用所需的参数，使模型能够灵活调度已接入的工具，高效完成复杂任务。

![生成工具的请求参数](https://assets-docs.dify.ai/2025/01/01e32c2d77150213c7c929b3cceb4dae.png)

#### 2.4 为模型添加记忆

当使用 Agent 插件调用模型时，为模型添加记忆功能能够极大提升对话体验。通过记忆功能，模型可以理解完整的对话上下文，实现连贯的交互体验和精准的工具调用。

具体实现步骤：

1. 配置记忆功能

在 Agent 插件的 YAML 配置文件 `strategies/agent.yaml` 中添加 `history-messages` 特性：

```yaml
identity:
  name: basic_agent  # Agent策略名称
  author: novice     # 作者
  label:
    en_US: BasicAgent  # 英文标签
description:
  en_US: BasicAgent    # 英文描述
features:
  - history-messages   # 启用历史消息功能
...
```

2. 启用记忆设置

修改插件配置文件并重启后，你将在节点配置界面中看到 **记忆** 开关。点击右侧的开关按钮，启用记忆功能。

启用后，您可以通过 **窗口大小** 滑块调整记忆窗口，它决定了模型能够“记住”多少之前的对话内容。

3. 调试历史消息

添加以下代码，查看历史消息内容：

```python
class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)
        print(f"history_messages: params.model.history_prompt_messages")
        ...
```

![History messages](https://assets-docs.dify.ai/2025/04/cb11fae7981dae431966f83fa99f1dfb.png)

控制台将显示类似如下输出：

```
history_messages: []
history_messages: [UserPromptMessage(role=, content='hello, my name is novice', name=None), AssistantPromptMessage(role=, content='Hello, Novice! How can I assist you today?', name=None, tool_calls=[])]
```

4. 将历史消息集成到模型调用

最后，修改模型调用代码，将历史消息拼接到当前查询：

```python
class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)

        chunks: Generator[LLMResultChunk, None, None] | LLMResult = (
            self.session.model.llm.invoke(
                model_config=LLMModelConfig(**params.model.model_dump(mode="json")),
                # 添加历史消息
                prompt_messages=params.model.history_prompt_messages
                + [UserPromptMessage(content=params.query)],
                tools=[
                    self._convert_tool_to_prompt_message_tool(tool)
                    for tool in params.tools
                ],
                stop=params.model.completion_params.get("stop", [])
                if params.model.completion_params
                else [],
                stream=True,
            )
        )
        ...
```

5. 效果验证

添加加记忆功能后，模型能够基于历史对话进行回复。在下图示例中，模型成功地记住了之前对话中提及的用户名称，实现了对话的连贯性。

![Outcome](https://assets-docs.dify.ai/2025/04/6bdd3d2c6a455ae8e463bd6abab5c3a4.png)

#### 2.5 调用工具

填写工具参数后，需赋予 Agent 策略插件实际调用工具的能力。可以通过 SDK 中的`session.tool.invoke()` 函数进行工具调用。

构造以下参数：

* provider：工具提供商
* tool\_name：工具名称
* parameters：输入参数

方法定义示例代码：

```python
 def invoke(
        self,
        provider_type: ToolProviderType,
        provider: str,
        tool_name: str,
        parameters: dict[str, Any],
    ) -> Generator[ToolInvokeMessage, None, None]:...
```

若希望通过 LLM 直接生成参数完成工具调用，请参考以下工具调用的示例代码：

```python
tool_instances = (
    tool.identity.name: tool for tool in params.tools if params.tools else {}
)
for tool_call_id, tool_call_name, tool_call_args in tool_calls:
    tool_instance = tool_instances[tool_call_name]
    self.session.tool.invoke(
        provider_type=ToolProviderType.BUILT_IN,
        provider=tool_instance.identity.provider,
        tool_name=tool_instance.identity.name,
        parameters=**tool_instance.runtime_parameters, **tool_call_args,
    )
```

如需查看完整的功能代码，请阅读调用工具[示例代码](agent-strategy-plugin.md#diao-yong-gong-ju-1)。

实现这部分的功能代码后，Agent 策略插件将具备自动 Function Calling 的能力，例如自动获取当前时间：

![工具调用](https://assets-docs.dify.ai/2025/01/80e5de8acc2b0ed00524e490fd611ff5.png)

#### 2.6 日志创建

在 **Agent 策略插件**中，通常需要执行多轮操作才能完成复杂任务。记录每轮操作的执行结果对于开发者来说非常重要，有助于追踪 Agent 的执行过程、分析每一步的决策依据，从而更好地评估和优化策略效果。

为了实现这一功能，可以利用 SDK 中的 `create_log_message` 和 `finish_log_message` 方法记录日志。这种方式不仅可以在模型调用前后实时记录操作状态，还能帮助开发者快速定位问题。

场景示例：

* 在模型调用之前，记录一条“开始调用模型”的日志，帮助开发者明确任务执行进度。
* 在模型调用成功后，记录一条“调用成功”的日志，方便追踪模型响应的完整性。

```python
model_log = self.create_log_message(
            label=f"params.model.model Thought",
            data={},
            metadata="start_at": model_started_at, "provider": params.model.provider,
            status=ToolInvokeMessage.LogMessage.LogStatus.START,
        )
yield model_log
self.session.model.llm.invoke(...)
yield self.finish_log_message(
    log=model_log,
    data=
        "output": response,
        "tool_name": tool_call_names,
        "tool_input": tool_call_inputs,
    ,
    metadata=
        "started_at": model_started_at,
        "finished_at": time.perf_counter(),
        "elapsed_time": time.perf_counter() - model_started_at,
        "provider": params.model.provider,
    ,
)
```

设置完成后，工作流日志将输出执行结果：

![Agent 输出执行结果](https://assets-docs.dify.ai/2025/01/96516388a4fb1da9cea85fc1804ff377.png)

在 Agent 执行的过程中，有可能会产生多轮日志。若日志能具备层级结构将有助于开发者查看。通过在日志记录时传入 parent 参数，不同轮次的日志可以形成上下级关系，使日志展示更加清晰、易于追踪。

**引用方法：**

```python
function_call_round_log = self.create_log_message(
    label="Function Call Round1 ",
    data={},
    metadata={},
)
yield function_call_round_log

model_log = self.create_log_message(
    label=f"params.model.model Thought",
    data={},
    metadata="start_at": model_started_at, "provider": params.model.provider,
    status=ToolInvokeMessage.LogMessage.LogStatus.START,
    # add parent log
    parent=function_call_round_log,
)
yield model_log
```

### 插件功能示例代码

#### 调用模型

以下代码将演示如何赋予 Agent 策略插件调用模型的能力：

```python

from collections.abc import Generator
from typing import Any, cast

from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig, LLMResult, LLMResultChunk
from dify_plugin.entities.model.message import (
    PromptMessageTool,
    UserPromptMessage,
)
from dify_plugin.entities.tool import ToolInvokeMessage, ToolParameter, ToolProviderType
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity
from pydantic import BaseModel

class BasicParams(BaseModel):
    maximum_iterations: int
    model: AgentModelConfig
    tools: list[ToolEntity]
    query: str

class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)
        chunks: Generator[LLMResultChunk, None, None] | LLMResult = (
            self.session.model.llm.invoke(
                model_config=LLMModelConfig(**params.model.model_dump(mode="json")),
                prompt_messages=[UserPromptMessage(content=params.query)],
                tools=[
                    self._convert_tool_to_prompt_message_tool(tool)
                    for tool in params.tools
                ],
                stop=params.model.completion_params.get("stop", [])
                if params.model.completion_params
                else [],
                stream=True,
            )
        )
        response = ""
        tool_calls = []
        tool_instances = (
            tool.identity.name: tool for tool in params.tools if params.tools else {}
        )

        for chunk in chunks:
            # check if there is any tool call
            if self.check_tool_calls(chunk):
                tool_calls = self.extract_tool_calls(chunk)
                tool_call_names = ";".join([tool_call[1] for tool_call in tool_calls])
                try:
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls,
                        ensure_ascii=False,
                    )
                except json.JSONDecodeError:
                    # ensure ascii to avoid encoding error
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls
                    )
                print(tool_call_names, tool_call_inputs)
            if chunk.delta.message and chunk.delta.message.content:
                if isinstance(chunk.delta.message.content, list):
                    for content in chunk.delta.message.content:
                        response += content.data
                        print(content.data, end="", flush=True)
                else:
                    response += str(chunk.delta.message.content)
                    print(str(chunk.delta.message.content), end="", flush=True)

            if chunk.delta.usage:
                # usage of the model
                usage = chunk.delta.usage

        yield self.create_text_message(
            text=f"response or json.dumps(tool_calls, ensure_ascii=False)\n"
        )
        result = ""
        for tool_call_id, tool_call_name, tool_call_args in tool_calls:
            tool_instance = tool_instances[tool_call_name]
            tool_invoke_responses = self.session.tool.invoke(
                provider_type=ToolProviderType.BUILT_IN,
                provider=tool_instance.identity.provider,
                tool_name=tool_instance.identity.name,
                parameters=**tool_instance.runtime_parameters, **tool_call_args,
            )
            if not tool_instance:
                tool_invoke_responses = {
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": f"there is not a tool named {tool_call_name}",
                }
            else:
                # invoke tool
                tool_invoke_responses = self.session.tool.invoke(
                    provider_type=ToolProviderType.BUILT_IN,
                    provider=tool_instance.identity.provider,
                    tool_name=tool_instance.identity.name,
                    parameters=**tool_instance.runtime_parameters, **tool_call_args,
                )
                result = ""
                for tool_invoke_response in tool_invoke_responses:
                    if tool_invoke_response.type == ToolInvokeMessage.MessageType.TEXT:
                        result += cast(
                            ToolInvokeMessage.TextMessage, tool_invoke_response.message
                        ).text
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.LINK
                    ):
                        result += (
                            f"result link: cast(ToolInvokeMessage.TextMessage, tool_invoke_response.message).text."
                            + " please tell user to check it."
                        )
                    elif tool_invoke_response.type in 
                        ToolInvokeMessage.MessageType.IMAGE_LINK,
                        ToolInvokeMessage.MessageType.IMAGE,
                    :
                        result += (
                            "image has been created and sent to user already, "
                            + "you do not need to create it, just tell the user to check it now."
                        )
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.JSON
                    ):
                        text = json.dumps(
                            cast(
                                ToolInvokeMessage.JsonMessage,
                                tool_invoke_response.message,
                            ).json_object,
                            ensure_ascii=False,
                        )
                        result += f"tool response: text."
                    else:
                        result += f"tool response: tool_invoke_response.message!r."

                tool_response = 
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": result,

        yield self.create_text_message(result)

    def _convert_tool_to_prompt_message_tool(
        self, tool: ToolEntity
    ) -> PromptMessageTool:
        """
        convert tool to prompt message tool
        """
        message_tool = PromptMessageTool(
            name=tool.identity.name,
            description=tool.description.llm if tool.description else "",
            parameters={
                "type": "object",
                "properties": {},
                "required": [],
            },
        )

        parameters = tool.parameters
        for parameter in parameters:
            if parameter.form != ToolParameter.ToolParameterForm.LLM:
                continue

            parameter_type = parameter.type
            if parameter.type in 
                ToolParameter.ToolParameterType.FILE,
                ToolParameter.ToolParameterType.FILES,
            :
                continue
            enum = []
            if parameter.type == ToolParameter.ToolParameterType.SELECT:
                enum = (
                    [option.value for option in parameter.options]
                    if parameter.options
                    else []
                )

            message_tool.parameters["properties"][parameter.name] = 
                "type": parameter_type,
                "description": parameter.llm_description or "",

            if len(enum) > 0:
                message_tool.parameters["properties"][parameter.name]["enum"] = enum

            if parameter.required:
                message_tool.parameters["required"].append(parameter.name)

        return message_tool

    def check_tool_calls(self, llm_result_chunk: LLMResultChunk) -> bool:
        """
        Check if there is any tool call in llm result chunk
        """
        return bool(llm_result_chunk.delta.message.tool_calls)

    def extract_tool_calls(
        self, llm_result_chunk: LLMResultChunk
    ) -> list[tuple[str, str, dict[str, Any]]]:
        """
        Extract tool calls from llm result chunk

        Returns:
            List[Tuple[str, str, Dict[str, Any]]]: [(tool_call_id, tool_call_name, tool_call_args)]
        """
        tool_calls = []
        for prompt_message in llm_result_chunk.delta.message.tool_calls:
            args = {}
            if prompt_message.function.arguments != "":
                args = json.loads(prompt_message.function.arguments)

            tool_calls.append(
                (
                    prompt_message.id,
                    prompt_message.function.name,
                    args,
                )
            )

        return tool_calls
```

#### 调用工具

以下代码展示了如何为 Agent 策略插件实现模型调用并向工具发送规范化请求。

```python

from collections.abc import Generator
from typing import Any, cast

from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig, LLMResult, LLMResultChunk
from dify_plugin.entities.model.message import (
    PromptMessageTool,
    UserPromptMessage,
)
from dify_plugin.entities.tool import ToolInvokeMessage, ToolParameter, ToolProviderType
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity
from pydantic import BaseModel

class BasicParams(BaseModel):
    maximum_iterations: int
    model: AgentModelConfig
    tools: list[ToolEntity]
    query: str

class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)
        chunks: Generator[LLMResultChunk, None, None] | LLMResult = (
            self.session.model.llm.invoke(
                model_config=LLMModelConfig(**params.model.model_dump(mode="json")),
                prompt_messages=[UserPromptMessage(content=params.query)],
                tools=[
                    self._convert_tool_to_prompt_message_tool(tool)
                    for tool in params.tools
                ],
                stop=params.model.completion_params.get("stop", [])
                if params.model.completion_params
                else [],
                stream=True,
            )
        )
        response = ""
        tool_calls = []
        tool_instances = (
            tool.identity.name: tool for tool in params.tools if params.tools else {}
        )

        for chunk in chunks:
            # check if there is any tool call
            if self.check_tool_calls(chunk):
                tool_calls = self.extract_tool_calls(chunk)
                tool_call_names = ";".join([tool_call[1] for tool_call in tool_calls])
                try:
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls,
                        ensure_ascii=False,
                    )
                except json.JSONDecodeError:
                    # ensure ascii to avoid encoding error
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls
                    )
                print(tool_call_names, tool_call_inputs)
            if chunk.delta.message and chunk.delta.message.content:
                if isinstance(chunk.delta.message.content, list):
                    for content in chunk.delta.message.content:
                        response += content.data
                        print(content.data, end="", flush=True)
                else:
                    response += str(chunk.delta.message.content)
                    print(str(chunk.delta.message.content), end="", flush=True)

            if chunk.delta.usage:
                # usage of the model
                usage = chunk.delta.usage

        yield self.create_text_message(
            text=f"response or json.dumps(tool_calls, ensure_ascii=False)\n"
        )
        result = ""
        for tool_call_id, tool_call_name, tool_call_args in tool_calls:
            tool_instance = tool_instances[tool_call_name]
            tool_invoke_responses = self.session.tool.invoke(
                provider_type=ToolProviderType.BUILT_IN,
                provider=tool_instance.identity.provider,
                tool_name=tool_instance.identity.name,
                parameters=**tool_instance.runtime_parameters, **tool_call_args,
            )
            if not tool_instance:
                tool_invoke_responses = {
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": f"there is not a tool named {tool_call_name}",
                }
            else:
                # invoke tool
                tool_invoke_responses = self.session.tool.invoke(
                    provider_type=ToolProviderType.BUILT_IN,
                    provider=tool_instance.identity.provider,
                    tool_name=tool_instance.identity.name,
                    parameters=**tool_instance.runtime_parameters, **tool_call_args,
                )
                result = ""
                for tool_invoke_response in tool_invoke_responses:
                    if tool_invoke_response.type == ToolInvokeMessage.MessageType.TEXT:
                        result += cast(
                            ToolInvokeMessage.TextMessage, tool_invoke_response.message
                        ).text
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.LINK
                    ):
                        result += (
                            f"result link: cast(ToolInvokeMessage.TextMessage, tool_invoke_response.message).text."
                            + " please tell user to check it."
                        )
                    elif tool_invoke_response.type in 
                        ToolInvokeMessage.MessageType.IMAGE_LINK,
                        ToolInvokeMessage.MessageType.IMAGE,
                    :
                        result += (
                            "image has been created and sent to user already, "
                            + "you do not need to create it, just tell the user to check it now."
                        )
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.JSON
                    ):
                        text = json.dumps(
                            cast(
                                ToolInvokeMessage.JsonMessage,
                                tool_invoke_response.message,
                            ).json_object,
                            ensure_ascii=False,
                        )
                        result += f"tool response: text."
                    else:
                        result += f"tool response: tool_invoke_response.message!r."

                tool_response = 
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": result,

        yield self.create_text_message(result)

    def _convert_tool_to_prompt_message_tool(
        self, tool: ToolEntity
    ) -> PromptMessageTool:
        """
        convert tool to prompt message tool
        """
        message_tool = PromptMessageTool(
            name=tool.identity.name,
            description=tool.description.llm if tool.description else "",
            parameters={
                "type": "object",
                "properties": {},
                "required": [],
            },
        )

        parameters = tool.parameters
        for parameter in parameters:
            if parameter.form != ToolParameter.ToolParameterForm.LLM:
                continue

            parameter_type = parameter.type
            if parameter.type in 
                ToolParameter.ToolParameterType.FILE,
                ToolParameter.ToolParameterType.FILES,
            :
                continue
            enum = []
            if parameter.type == ToolParameter.ToolParameterType.SELECT:
                enum = (
                    [option.value for option in parameter.options]
                    if parameter.options
                    else []
                )

            message_tool.parameters["properties"][parameter.name] = 
                "type": parameter_type,
                "description": parameter.llm_description or "",

            if len(enum) > 0:
                message_tool.parameters["properties"][parameter.name]["enum"] = enum

            if parameter.required:
                message_tool.parameters["required"].append(parameter.name)

        return message_tool

    def check_tool_calls(self, llm_result_chunk: LLMResultChunk) -> bool:
        """
        Check if there is any tool call in llm result chunk
        """
        return bool(llm_result_chunk.delta.message.tool_calls)

    def extract_tool_calls(
        self, llm_result_chunk: LLMResultChunk
    ) -> list[tuple[str, str, dict[str, Any]]]:
        """
        Extract tool calls from llm result chunk

        Returns:
            List[Tuple[str, str, Dict[str, Any]]]: [(tool_call_id, tool_call_name, tool_call_args)]
        """
        tool_calls = []
        for prompt_message in llm_result_chunk.delta.message.tool_calls:
            args = {}
            if prompt_message.function.arguments != "":
                args = json.loads(prompt_message.function.arguments)

            tool_calls.append(
                (
                    prompt_message.id,
                    prompt_message.function.name,
                    args,
                )
            )

        return tool_calls
```

#### 完整功能代码示例

包含**调用模型、调用工具**以及**输出多轮日志功能**的完整插件代码示例：

```python

from collections.abc import Generator
from typing import Any, cast

from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig, LLMResult, LLMResultChunk
from dify_plugin.entities.model.message import (
    PromptMessageTool,
    UserPromptMessage,
)
from dify_plugin.entities.tool import ToolInvokeMessage, ToolParameter, ToolProviderType
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity
from pydantic import BaseModel

class BasicParams(BaseModel):
    maximum_iterations: int
    model: AgentModelConfig
    tools: list[ToolEntity]
    query: str

class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)
        function_call_round_log = self.create_log_message(
            label="Function Call Round1 ",
            data={},
            metadata={},
        )
        yield function_call_round_log
        model_started_at = time.perf_counter()
        model_log = self.create_log_message(
            label=f"params.model.model Thought",
            data={},
            metadata="start_at": model_started_at, "provider": params.model.provider,
            status=ToolInvokeMessage.LogMessage.LogStatus.START,
            parent=function_call_round_log,
        )
        yield model_log
        chunks: Generator[LLMResultChunk, None, None] | LLMResult = (
            self.session.model.llm.invoke(
                model_config=LLMModelConfig(**params.model.model_dump(mode="json")),
                prompt_messages=[UserPromptMessage(content=params.query)],
                tools=[
                    self._convert_tool_to_prompt_message_tool(tool)
                    for tool in params.tools
                ],
                stop=params.model.completion_params.get("stop", [])
                if params.model.completion_params
                else [],
                stream=True,
            )
        )
        response = ""
        tool_calls = []
        tool_instances = (
            tool.identity.name: tool for tool in params.tools if params.tools else {}
        )
        tool_call_names = ""
        tool_call_inputs = ""
        for chunk in chunks:
            # check if there is any tool call
            if self.check_tool_calls(chunk):
                tool_calls = self.extract_tool_calls(chunk)
                tool_call_names = ";".join([tool_call[1] for tool_call in tool_calls])
                try:
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls,
                        ensure_ascii=False,
                    )
                except json.JSONDecodeError:
                    # ensure ascii to avoid encoding error
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls
                    )
                print(tool_call_names, tool_call_inputs)
            if chunk.delta.message and chunk.delta.message.content:
                if isinstance(chunk.delta.message.content, list):
                    for content in chunk.delta.message.content:
                        response += content.data
                        print(content.data, end="", flush=True)
                else:
                    response += str(chunk.delta.message.content)
                    print(str(chunk.delta.message.content), end="", flush=True)

            if chunk.delta.usage:
                # usage of the model
                usage = chunk.delta.usage

        yield self.finish_log_message(
            log=model_log,
            data=
                "output": response,
                "tool_name": tool_call_names,
                "tool_input": tool_call_inputs,
            ,
            metadata=
                "started_at": model_started_at,
                "finished_at": time.perf_counter(),
                "elapsed_time": time.perf_counter() - model_started_at,
                "provider": params.model.provider,
            ,
        )
        yield self.create_text_message(
            text=f"response or json.dumps(tool_calls, ensure_ascii=False)\n"
        )
        result = ""
        for tool_call_id, tool_call_name, tool_call_args in tool_calls:
            tool_instance = tool_instances[tool_call_name]
            tool_invoke_responses = self.session.tool.invoke(
                provider_type=ToolProviderType.BUILT_IN,
                provider=tool_instance.identity.provider,
                tool_name=tool_instance.identity.name,
                parameters=**tool_instance.runtime_parameters, **tool_call_args,
            )
            if not tool_instance:
                tool_invoke_responses = {
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": f"there is not a tool named {tool_call_name}",
                }
            else:
                # invoke tool
                tool_invoke_responses = self.session.tool.invoke(
                    provider_type=ToolProviderType.BUILT_IN,
                    provider=tool_instance.identity.provider,
                    tool_name=tool_instance.identity.name,
                    parameters=**tool_instance.runtime_parameters, **tool_call_args,
                )
                result = ""
                for tool_invoke_response in tool_invoke_responses:
                    if tool_invoke_response.type == ToolInvokeMessage.MessageType.TEXT:
                        result += cast(
                            ToolInvokeMessage.TextMessage, tool_invoke_response.message
                        ).text
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.LINK
                    ):
                        result += (
                            f"result link: cast(ToolInvokeMessage.TextMessage, tool_invoke_response.message).text."
                            + " please tell user to check it."
                        )
                    elif tool_invoke_response.type in 
                        ToolInvokeMessage.MessageType.IMAGE_LINK,
                        ToolInvokeMessage.MessageType.IMAGE,
                    :
                        result += (
                            "image has been created and sent to user already, "
                            + "you do not need to create it, just tell the user to check it now."
                        )
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.JSON
                    ):
                        text = json.dumps(
                            cast(
                                ToolInvokeMessage.JsonMessage,
                                tool_invoke_response.message,
                            ).json_object,
                            ensure_ascii=False,
                        )
                        result += f"tool response: text."
                    else:
                        result += f"tool response: tool_invoke_response.message!r."

                tool_response = 
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": result,

        yield self.create_text_message(result)

    def _convert_tool_to_prompt_message_tool(
        self, tool: ToolEntity
    ) -> PromptMessageTool:
        """
        convert tool to prompt message tool
        """
        message_tool = PromptMessageTool(
            name=tool.identity.name,
            description=tool.description.llm if tool.description else "",
            parameters={
                "type": "object",
                "properties": {},
                "required": [],
            },
        )

        parameters = tool.parameters
        for parameter in parameters:
            if parameter.form != ToolParameter.ToolParameterForm.LLM:
                continue

            parameter_type = parameter.type
            if parameter.type in 
                ToolParameter.ToolParameterType.FILE,
                ToolParameter.ToolParameterType.FILES,
            :
                continue
            enum = []
            if parameter.type == ToolParameter.ToolParameterType.SELECT:
                enum = (
                    [option.value for option in parameter.options]
                    if parameter.options
                    else []
                )

            message_tool.parameters["properties"][parameter.name] = 
                "type": parameter_type,
                "description": parameter.llm_description or "",

            if len(enum) > 0:
                message_tool.parameters["properties"][parameter.name]["enum"] = enum

            if parameter.required:
                message_tool.parameters["required"].append(parameter.name)

        return message_tool

    def check_tool_calls(self, llm_result_chunk: LLMResultChunk) -> bool:
        """
        Check if there is any tool call in llm result chunk
        """
        return bool(llm_result_chunk.delta.message.tool_calls)

    def extract_tool_calls(
        self, llm_result_chunk: LLMResultChunk
    ) -> list[tuple[str, str, dict[str, Any]]]:
        """
        Extract tool calls from llm result chunk

        Returns:
            List[Tuple[str, str, Dict[str, Any]]]: [(tool_call_id, tool_call_name, tool_call_args)]
        """
        tool_calls = []
        for prompt_message in llm_result_chunk.delta.message.tool_calls:
            args = {}
            if prompt_message.function.arguments != "":
                args = json.loads(prompt_message.function.arguments)

            tool_calls.append(
                (
                    prompt_message.id,
                    prompt_message.function.name,
                    args,
                )
            )

        return tool_calls
```

### 3. 调试插件

配置插件的声明文件与功能代码后，在插件的目录内运行 `python -m main` 命令重启插件。接下来需测试插件是否可以正常运行。Dify 提供远程调试方式，前往[“插件管理”](https://cloud.dify.ai/plugins)获取调试 Key 和远程服务器地址。

![Image](https://assets-docs.dify.ai/2024/12/053415ef127f1f4d6dd85dd3ae79626a.png)

回到插件项目，拷贝 `.env.example` 文件并重命名为 `.env`，将获取的远程服务器地址和调试 Key 等信息填入至 `REMOTE_INSTALL_HOST` 与 `REMOTE_INSTALL_KEY` 参数内。

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_URL=debug.dify.ai:5003
REMOTE_INSTALL_KEY=********-****-****-****-************
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内。其他团队成员也可以访问该插件。

![访问插件](https://assets-docs.dify.ai/2025/01/c82ec0202e5bf914b36e06c796398dd6.png)

### 打包插件（可选）

确认插件能够正常运行后，可以通过以下命令行工具打包并命名插件。运行以后你可以在当前文件夹发现 `google.difypkg` 文件，该文件为最终的插件包。

```bash
# 将 ./basic_agent 替换为插件项目的实际路径
dify plugin package ./basic_agent/
```

恭喜，你已完成一个工具类型插件的完整开发、调试与打包过程！

### 发布插件（可选）

现在可以将它上传至 [Dify Plugins 代码仓库](https://github.com/langgenius/dify-plugins)来发布你的插件了！上传前，请确保插件已遵循[插件发布规范](https://docs.dify.ai/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace)。审核通过后，代码将合并至主分支并自动上线至 [Dify Marketplace](https://marketplace.dify.ai/)。

### 探索更多

复杂任务往往需要多轮思考和多次工具调用。为了实现更智能的任务处理，通常采用循环执行的策略：**模型调用 → 工具调用**，直到任务完成或达到设定的最大迭代次数。

在这个过程中，提示词（Prompt）管理变得尤为重要。为了高效地组织和动态调整模型输入，建议参考插件内 Function Calling 功能的[完整实现代码](https://github.com/langgenius/dify-official-plugins/blob/main/agent-strategies/cot_agent/strategies/function_calling.py)，了解如何通过标准化的方式来让模型调用外部工具并处理返回结果。

## 相关资源

- [Agent 插件开发基础](./plugin-dev-zh/9232-agent) - 了解 Agent 策略插件的基本概念
- [插件开发基础概念](./plugin-dev-zh/0111-getting-started-dify-plugin) - 了解插件开发的整体架构
- [初始化开发工具](./plugin-dev-zh/0221-initialize-development-tools) - 学习如何搭建开发环境
- [反向调用 Model](./plugin-dev-zh/9242-reverse-invocation-model) - 了解如何调用平台内的模型能力
- [反向调用 Tool](./plugin-dev-zh/9242-reverse-invocation-tool) - 了解如何调用其它插件
- [发布插件概述](./plugin-dev-zh/0321-release-overview) - 学习插件发布流程

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/plugin-dev-zh/9433-agent-strategy-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## README
> 来源：`plugin-dev-zh/README.md`

# Dify 插件开发者文档

本指南旨在帮助开发者快速上手 Dify 插件开发，提供必要的文档和资源链接。

贡献指南: [Dify Docs](https://docs.dify.ai/plugin-dev-zh/0411-doc-contribution-guide)


## 成为贡献者
> 来源：`zh-hans/community/contribution.mdx`

所以你想为 Dify 做贡献 - 这太棒了，我们迫不及待地想看到你的贡献。作为一家人员和资金有限的初创公司，我们有着雄心勃勃的目标，希望设计出最直观的工作流程来构建和管理 LLM 应用程序。社区的任何帮助都是宝贵的。

考虑到我们的现状，我们需要灵活快速地交付，但我们也希望确保像你这样的贡献者在贡献过程中获得尽可能顺畅的体验。我们为此编写了这份贡献指南，旨在让你熟悉代码库和我们与贡献者的合作方式，以便你能快速进入有趣的部分。

这份指南，就像 Dify 本身一样，是一个不断改进的工作。如果有时它落后于实际项目，我们非常感谢你的理解，并欢迎任何反馈以供我们改进。

在许可方面，请花一分钟阅读我们简短的 [许可证和贡献者协议](https://github.com/langgenius/dify/blob/main/LICENSE)。社区还遵守 [行为准则](https://github.com/langgenius/dify/blob/ecade13455d7cb93cc1a9c39358aeff7f419c423/.github/CODE_OF_CONDUCT.md?plain=1#L4)。

## 在开始之前

[查找](https://github.com/langgenius/dify/issues?q=is:issue+is:closed) 现有问题，或 [创建](https://github.com/langgenius/dify/issues/new/choose) 一个新问题。我们将问题分为两类：

### 功能请求：

* 如果你要提出新的功能请求，请解释所提议的功能的目标，并尽可能提供详细的上下文。[@perzeusss](https://github.com/perzeuss) 制作了一个很好的 [功能请求助手](https://udify.app/chat/MK2kVSnw1gakVwMX)，可以帮助你起草需求。随时尝试一下。

* 如果你想从现有问题中选择一个，请在其下方留下评论表示你的意愿。

相关方向的团队成员将参与其中。如果一切顺利，他们将批准你开始编码。在此之前，请不要开始工作，以免我们提出更改导致你的工作付诸东流。

根据所提议的功能所属的领域不同，你可能需要与不同的团队成员交流。以下是我们团队成员目前正在从事的各个领域的概述：

  | Member                                                       | Scope                                                |
  | ------------------------------------------------------------ | ---------------------------------------------------- |
  | [@yeuoly](https://github.com/Yeuoly)                         | Architecting Agents                                  |
  | [@jyong](https://github.com/JohnJyong)                       | RAG pipeline design                                  |
  | [@GarfieldDai](https://github.com/GarfieldDai)               | Building workflow orchestrations                     |
  | [@iamjoel](https://github.com/iamjoel) & [@zxhlyh](https://github.com/zxhlyh) | Making our frontend a breeze to use                  |
  | [@guchenhe](https://github.com/guchenhe) & [@crazywoola](https://github.com/crazywoola) | Developer experience, points of contact for anything |
  | [@takatost](https://github.com/takatost)                     | Overall product direction and architecture           |

  优先级的评判标准:

<table>
  <thead>
    <tr>
      <th>Feature Type</th>
      <th>Priority</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>High-Priority Features as being labeled by a team member</td>
      <td>High Priority</td>
    </tr>
    <tr>
      <td>Popular feature requests from our <a href="https://github.com/langgenius/dify/discussions/categories/ideas">community feedback board</a></td>
      <td>Medium Priority</td>
    </tr>
    <tr>
      <td>Non-core features and minor enhancements</td>
      <td>Low Priority</td>
    </tr>
    <tr>
      <td>Valuable but not immediate</td>
      <td>Future-Feature</td>
    </tr>
  </tbody>
</table>

### 其他任何事情（例如 bug 报告、性能优化、拼写错误更正）：
* 立即开始编码。

  优先级的评判标准:

  | Issue Type                                                   | Priority        |
  | ------------------------------------------------------------ | --------------- |
  | Bugs in core functions (cannot login, applications not working, security loopholes) | Critical        |
  | Non-critical bugs, performance boosts                        | Medium Priority |
  | Minor fixes (typos, confusing but working UI)                | Low Priority    |

## 安装

以下是设置 Dify 进行开发的步骤：

### 1. Fork 该仓库

### 2. 克隆仓库

从终端克隆 fork 的仓库：

```
git clone git@github.com:<github_username>/dify.git
```

### 3. 验证依赖项

Dify 依赖以下工具和库：

- [Docker](https://www.docker.com/)
- [Docker Compose](https://docs.docker.com/compose/install/)
- [Node.js v18.x (LTS)](http://nodejs.org)
- [npm](https://www.npmjs.com/) version 8.x.x or [Yarn](https://yarnpkg.com/)
- [Python](https://www.python.org/) version 3.11.x

### 4. 安装

Dify 由后端和前端组成。通过 `cd api/` 导航到后端目录，然后按照 [后端 README](https://github.com/langgenius/dify/blob/main/api/README.md) 进行安装。在另一个终端中，通过 `cd web/` 导航到前端目录，然后按照 [前端 README](https://github.com/langgenius/dify/blob/main/web/README.md) 进行安装。

查看 [安装常见问题解答](./zh-hans/learn-more/faq/install-faq) 以获取常见问题列表和故障排除步骤。

### 5. 在浏览器中访问 Dify

为了验证你的设置，打开浏览器并访问 [http://localhost:3000](http://localhost:3000)（默认或你自定义的 URL 和端口）。现在你应该看到 Dify 正在运行。

## 开发

如果你要添加模型提供程序，请参考 [模型开发](https://docs.dify.ai/plugins/quick-start/develop-plugins/model-plugin)。

如果你要向 Agent 或 Workflow 添加工具提供程序，请参考 [工具开发](https://docs.dify.ai/plugins/quick-start/develop-plugins/tool-plugin)。

> **警告：**

**注意**：如果你想要贡献新的工具，请确保已在工具的 `YAML` 文件内留下了你的联系方式，并且在 [Dify-docs](https://github.com/langgenius/dify-docs-mintlify) 帮助文档代码仓库中提交了对应的文档 PR。

为了帮助你快速了解你的贡献在哪个部分，以下是 Dify 后端和前端的简要注释大纲：

### 后端

Dify 的后端使用 Python 编写，使用 [Flask](https://flask.palletsprojects.com/en/3.0.x/) 框架。它使用 [SQLAlchemy](https://www.sqlalchemy.org/) 作为 ORM，使用 [Celery](https://docs.celeryq.dev/en/stable/getting-started/introduction.html) 作为任务队列。授权逻辑通过 Flask-login 进行处理。

```
[api/]
├── constants             // 整个代码库中使用的常量设置
├── controllers           // API 路由定义和请求处理逻辑           
├── core                  // 核心应用程序编排、模型集成和工具
├── docker                // Docker 和容器化相关配置
├── events                // 事件处理和处理逻辑
├── extensions            // 与第三方框架/平台的扩展集成
├── fields                // 序列化/编组的字段定义
├── libs                  // 可重用的库和辅助函数
├── migrations            // 数据库迁移脚本
├── models                // 数据库模型和架构定义
├── services              // 业务逻辑规范
├── storage               // 私钥存储      
├── tasks                 // 异步任务和后台作业处理
└── tests
```

### 前端

该网站使用基于 Typescript 的 [Next.js](https://nextjs.org/) 模板进行引导，并使用 [Tailwind CSS](https://tailwindcss.com/) 进行样式设计。[React-i18next](https://react.i18next.com/) 用于国际化。

```
[web/]
├── app                   // 布局、页面和组件
│   ├── (commonLayout)    // 整个应用程序中使用的通用布局
│   ├── (shareLayout)     // 跨令牌特定会话共享的布局 
│   ├── activate          // 激活页面
│   ├── components        // 页面和布局共享的组件
│   ├── install           // 安装页面
│   ├── signin            // 登录页面
│   └── styles            // 全局共享样式
├── assets                // 静态资源
├── bin                   // 构建步骤运行的脚本
├── config                // 可调整的设置和选项 
├── context               // 应用程序不同部分使用的共享上下文
├── hooks                 // 可重用的钩子
├── i18n                  // 国际化翻译文件
├── i18n-config           // 国际化配置和逻辑
├── models                // 描述数据模型和 API 响应的形状
├── public                // 如 favicon 等元资源
├── service               // 指定 API 操作的形状
├── test                  // 测试文件
├── themes                // 主题配置
├── types                 // 函数参数和返回值的描述
└── utils                 // 共享实用工具函数
```

## 提交你的 PR

最后，是时候向我们的仓库提交一个拉取请求（PR）了。对于重要的功能，我们首先将它们合并到 `deploy/dev` 分支进行测试，然后再合并到 `main` 分支。如果你遇到合并冲突或者不知道如何提交拉取请求的问题，请查看 [GitHub 的拉取请求教程](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests)。

就是这样！一旦你的 PR 被合并，你将成为我们 [README](https://github.com/langgenius/dify/blob/main/README_CN.md) 中的贡献者。

## 获取帮助

如果你在贡献过程中遇到困难或者有任何问题，可以通过相关的 GitHub 问题提出你的疑问，或者加入我们的 [Discord](https://discord.com/invite/8Tpq4AcN9c) 进行快速交流。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/community/contribution.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 为 Dify 文档做出贡献
> 来源：`zh-hans/community/docs-contribution.mdx`

Dify 帮助文档是一个[开源项目](https://github.com/langgenius/dify-docs)，我们欢迎任何形式的贡献。如果你在阅读文档时发现任何问题，亦或是想要动手写作，贡献自己的一份力量，欢迎你在 Github 上提交 issue 或者直接发起 pull request，我们将尽快处理你的请求。

## 如何提交贡献

我们将文档问题分为以下几类：

* 内容勘误（错别字 / 内容不正确）
* 内容缺失（需要补充新的内容）

### 内容勘误

如果你在阅读某篇文档的时候发现存在内容错误，或者想要修改部分内容，请点击文档页面右侧目录栏内的 **“在 Github 上编辑”** 按钮，使用 Github 内置的在线编辑器修改文件，然后提交 pull request 并简单描述本次修改行为。标题格式请使用 `Fix: Update xxx`，我们将在收到请求后进行 review，无误后将合并你的修改。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/community/5558460f6bd4aa9153439595e9603dc7.png)

当然，你也可以在 [Issues 页](https://github.com/langgenius/dify-docs/issues)贴上文档链接，并简单描述需要修改的内容。收到反馈后将尽快处理。

### 内容缺失

如果你想要提交新的文档至代码仓库中，请遵循以下步骤：

1. Fork 代码仓库

首先将代码仓库 Fork 至你的 Github 账号内，然后使用 Git 拉取代码仓库至本地：

```bash
git clone https://github.com/<your-github-account>/dify-docs.git
```

> 你也可以使用 Github 在线代码编辑器，在合适的目录内提交新的 md 文件。

2. 找到对应的文档目录并提交文件

例如，你想要提交第三方工具的使用文档，请在 `/guides/tools/tool-configuration/` 目录内提交新的 md 文件（建议提供中英双语内容）。

3. 提交 pull request

提交 pull request 时，请使用 `Docs: add xxx` 的格式，并在描述栏内简单说明文档的大致内容，我们在收到请求后进行 review，无误后将合并你的修改。

### 最佳实践

我们非常欢迎你分享使用 Dify 搭建的创新应用案例！为了帮助社区成员更好地理解和复现你的实践经验，建议按照以下框架来组织内容：

```text
1. 项目简介
   - 应用场景和解决的问题
   - 核心功能和特点介绍
   - 最终效果展示

2. 项目原理/流程介绍

3. 前置准备（如有）
   - 所需资源清单
   - 工具依赖要求

4. Dify 平台实践步骤（参考）
   - 应用创建和基础配置
   - 应用流程搭建详解
   - 关键节点配置说明

5. 常见问题
```

> 为了便于用户理解，建议为文章添加必要说明截图。请以在线图床链接的形式提交图片内容。

我们期待你的精彩分享，一起助力 Dify 社区的知识积累！

## 获取帮助

如果你在贡献过程中遇到困难或者有任何问题，可以通过相关的 GitHub 问题提出你的疑问。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/community/docs-contribution.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 寻求支持
> 来源：`zh-hans/community/support.mdx`

如果你阅读这套文档时，仍然对产品使用存在疑问和建议，可尝试以下方式寻求支持。我们的团队与社区会竭尽所能的为你提供帮助。

### 社区支持

> **信息提示：**

请不要将涉及你的 Dify 账户信息与其它密钥信息发至社区，我们的支持人员也不会索要你的账户信息。

* 在 [GitHub](https://github.com/langgenius/dify) 上提交 Issue
* 加入 [Discord ](https://discord.gg/8Tpq4AcN9c)社群

### 联系我们

适用于除了寻求产品支持以外的其他事宜。

* 发邮件至 [hello@dify.ai](mailto:hello@dify.ai)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/community/support.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## DifySandbox
> 来源：`zh-hans/development/backend/sandbox/README.mdx`

### 介绍

`DifySandbox` 是一个轻量、快速、安全的代码运行环境，支持多种编程语言，包括 `Python`、`Nodejs` 等，用户在 `Dify Workflow` 中使用到的如 `Code` 节点、`Template Transform` 节点、`LLM` 节点的 Jinja2 语法、`Tool` 节点的 `Code Interpreter` 等都基于 DifySandbox 运行，它确保了 `Dify` 可以运行用户代码的前提下整个系统的安全性。

### 特性
- **多语言支持**：`DifySandbox` 基于 `Seccomp`，这是一个系统层级的解决方案，从而确保了可以支持多种编程语言，目前支持了 `Python` 与 `Nodejs`。
- **系统安全**：使用白名单策略，只允许运行特定的系统调用，从而确保不会出现意外的绕过。
- **文件系统隔离**：用户代码将运行在一个独立的隔离的文件系统中。
- **网络隔离**:
    - **DockerCompose**：独立网络 Sandbox 网络，并使用代理容器进行网络访问，确保内网系统的安全，同时提供了灵活的代理配置方案。
    - **K8s**：直接使用 `Egress` 配置网络隔离策略即可。

### 安装依赖

在安装和部署 DifySandbox 项目前，请确保你的系统满足以下依赖要求：

1. **系统依赖**

根据 Linux 发行版，执行相应的命令安装必要的系统组件：

- Ubuntu/Debian

```bash
sudo apt-get update
sudo apt-get install pkg-config gcc libseccomp-dev git wget
```

- CentOS

```bash
sudo yum install pkgconfig gcc libseccomp-devel git wget
```

2. **Go 语言环境**

需要安装 Go 开发环境（建议 Go 1.20.6 或更高版本）：

```bash
# 安装 Go 1.21
sudo apt-get install -y golang-1.20.6
```

验证安装：

```bash
go version  # 显示安装的 Go 版本
```

3. **Python 环境配置**

**Sandbox 环境准备**

建议安装 Python 3.10 或以上版本。

**预装依赖管理**

DifySandbox 已预先配置了以下 Python 依赖：

- `http` - 基础网络请求库
- `jinja2` - 模板引擎，用于 LLM 提示词处理
- `requests` - HTTP 客户端库

**添加自定义依赖**

若需要额外的 Python 依赖，请遵循以下步骤

1. 找到项目根目录下的 `dependencies/python-requirements.txt` 文件。
2. 在文件中添加所需的依赖包名及版本。若涉及权限变更，请参考[常见问题](https://github.com/langgenius/dify-sandbox/blob/main/FAQ.md)。
3. 重新构建 DifySandbox。

> **警告：**

    添加新依赖可能引入额外权限需求，请谨慎评估安全影响。若未能完全掌控潜在安全风险，不建议更改权限配置。

### 贡献

你可以参考 [贡献指南](contribution) 来参与到 `DifySandbox` 的开发中。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/backend/sandbox/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 贡献
> 来源：`zh-hans/development/backend/sandbox/contribution.mdx`

### 代码结构
参考如下代码文件结构可以帮助你更好地理解代码的组织方式。
```
[cmd/]
├── server                // Enterpoint for starting the server.
├── lib                   // Enterpoint for Shared libraries.
└── test                  // Common test scripts.
[build/]                  // build scripts for different architectures and platforms.
[internal/]               // Internal packages.
├── controller            // HTTP request handlers.
├── middleware            // Middleware for request processing.
├── server                // Server setup and configuration.
├── service               // Provides service for controller.
├── static                // Configuration files.
│   ├── nodejs_syscall    // Whitelist for nodejs syscall.
│   └── python_syscall    // Whitelist for python syscall.
├── types                 // Entities
├── core                  // Core logic for isolation and execution.
│   ├── lib               // Shared libraries.
│   ├── runner            // Code execution.
│   │   ├── nodejs        // Nodejs runner.
|   |   └── python        // Python runner.
└── tests                 // Tests for CI/CD.
```

### 原理
目前来说，核心逻辑的入口部分有两个，一个是`DifySandbox`的`HTTP`服务入口，另一个是`动态链接库`的入口，在Sandbox尝试运行代码时，它会首先生产一个临时代码文件，在这个文件的最开始，会调用`动态链接库`来初始化运行环境，也就是`Sandbox`，随后才是用户代码的执行，最终执行代码时并不会直接执行用户提交的代码，而是执行这个临时文件，从而确保不会被用户提交的代码破坏系统。

其中，动态链接库中就是使用了`Seccomp`来限制系统调用，其中运行的系统调用位于`static`目录下的`nodejs_syscall`和`python_syscall`文件中，并分别提供了`ARM64`和`AMD64`两种架构的系统调用白名单，一共四份文件，在没有特殊需求的情况下，请不要随意修改这些文件。

### 如何贡献
首先，对于`Typo`、`Bug`等问题，欢迎直接提交`PR`，如果是较大的改动或`Feature`级别的提交，请先提交`Issue`，以便我们更好地讨论。

#### 待办事项
这里是一些我们目前正在考虑的待办事项，如果你有兴趣，可以选择其中一个来贡献。
- [ ] 新编程语言的支持：
    - 我们目前支持`Python`和`Nodejs`，如果你有兴趣，可以尝试添加新的编程语言支持。
    - 请注意，每新增一个语言，都要同时考虑`ARM64`和`AMD64`两种架构，并提供`CI`测试，以便我们能确保新增语言的安全性。
- [ ] Nodejs的依赖问题：
    - 目前我们仅完成了`Python`的依赖支持，可以在`Sandbox`初始化时自动安装`Python`依赖，但对于`Nodejs`，由于其`node_modules`的复杂性，我们目前还没有找到一个很好的解决方案，如果你有兴趣，可以尝试解决这个问题。
- [ ] 图片处理:
    - 在未来、多模态是一个必然的趋势，因此在`Sandbox`支持处理图片也是一个很有意义的事情。
    - 你可以尝试添加对图片处理的支持，比如`Pillow`等库的支持，并支持在`Dify`中传入图片到`Sandbox`中进行处理。
- [ ] 完善的`CI`测试：
    - 目前我们的`CI`测试还不够完善，只有一些简单的用例。
- [ ] 生成多模态数据:
    - 尝试使用`Sandbox`生成多模态数据，比如文本和图片的组合数据。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/backend/sandbox/contribution.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 迁移
> 来源：`zh-hans/development/migration/README.mdx`

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/migration/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 将社区版升级至 v1.0.0+
> 来源：`zh-hans/development/migration/migrate-to-v1.mdx`

> 本文主要介绍如何将旧社区版本升级为 [v1.0.0](https://github.com/langgenius/dify/releases/tag/1.0.0)。如果你未曾安装过 Dify 社区版，可以直接克隆 [Dify 项目](https://github.com/langgenius/dify)，并切换至 `1.0.0` 分支。参考[文档](https://docs.dify.ai/zh-hans/getting-started/install-self-hosted/docker-compose)执行安装命令。

如需在社区版中体验插件功能，需要将版本号升级为 `v1.0.0`。本文将为你介绍如何从旧版本升级至 `v1.0.0` 以体验插件生态功能。

## 开始升级

升级分为以下步骤：

1. 备份数据
2. 插件迁移
3. 主项目升级

### 1. 备份数据

1.1 运行 `cd` 命令至你的 Dify 项目路径，新建备份分支。

1.2 运行以下命令，备份你的 docker-compose YAML 文件（可选）。

```bash
cd docker
cp docker-compose.yaml docker-compose.yaml.$(date +%s).bak
```

1.3 运行命令停止服务，在 Docker 目录中执行备份数据命令。

```bash
docker compose down
tar -cvf volumes-$(date +%s).tgz volumes
```

### 2. 升级版本

`v1.0.0` 支持通过 Docker Compose 部署。运行 `cd` 命令至你的 Dify 项目路径，运行以下命令升级 Dify 版本：

```bash
git fetch origin
git checkout 1.0.0 # 切换至 1.0.0 分支
cd docker
nano .env # 修改环境配置文件同步 .env.example 文件
docker compose -f docker-compose.yaml up -d
```

### 3. 工具迁移为插件

> **重要提示：关于命令执行和包管理**
> *   **默认容器名称：** `docker exec` 命令示例使用了 `docker-api-1`。如果您的 API 容器有不同的名称或 ID（您可以使用 `docker ps` 查找），请相应调整命令。
> *   **Python 包管理器 (`uv` 与 `poetry`)：**
    *   从版本 [v1.3.0](https://github.com/langgenius/dify/releases/tag/1.3.0) 开始，Dify 已将 Python 包管理器从 `poetry` 切换到 `uv` 以提升性能。对于 Dify v1.3.0 或更新版本中的常规操作，标准命令是 `uv run flask ...`。
    *   **本指南专注于升级到 Dify v1.0.0。** 在 Dify v1.0.0 到 v1.3.0 (不含v1.3.0) 期间，`poetry` 是其包管理器。因此，下方示例中的 `flask` 命令正确地使用了 `poetry run ...`。代码示例首先在注释中强调了当前 `uv` 的标准用法，然后显示了与本指南特定的 v1.0.0 迁移范围相关的 `poetry` 命令。

该步骤的目的：将此前社区版本所使用的工具及模型供应商，自动进行数据迁移并安装至新版本的插件环境中。

1. 运行 `docker ps` 命令，查看 API 容器的名称或 ID。默认名称通常是 `docker-api-1`。

示例：

```bash
docker ps
CONTAINER ID   IMAGE                                       COMMAND                  CREATED       STATUS                 PORTS                                                                                                                             NAMES
417241cd****   nginx:latest                                "sh -c 'cp /docker-e…"   3 hours ago   Up 3 hours             0.0.0.0:80->80/tcp, :::80->80/tcp, 0.0.0.0:443->443/tcp, :::443->443/tcp                                                          docker-nginx-1
f84aa773****   langgenius/dify-api:1.0.0                   "/bin/bash /entrypoi…"   3 hours ago   Up 3 hours             5001/tcp                                                                                                                          docker-worker-1
a3cb19c2****   langgenius/dify-api:1.0.0                   "/bin/bash /entrypoi…"   3 hours ago   Up 3 hours             5001/tcp                                                                                                                          docker-api-1
```

运行命令 `docker exec -it docker-api-1 bash` 进入容器终端（如果您的容器名称不同，请使用对应的名称），在容器内运行：

```bash
# 对于 Dify v1.3.0+ 的环境，标准命令是 'uv run ...'。
uv run flask extract-plugins --workers=20
#
# 如果您的目标迁移版本是 Dify v1.0.0 至 v1.3.0 (不含v1.3.0) 之间，请使用 'poetry':
# poetry run flask extract-plugins --workers=20
```

> 如果在按照本指南为 v1.0.0 版本迁移执行命令时发生错误（例如，找不到 `uv` 或 `poetry`），请确保按照该版本最初的先决条件，在服务器上正确设置了 `poetry` 环境。如果在运行 `poetry` 命令后终端提示输入，请按 **"回车"** 跳过。

此命令将提取当前环境中使用的所有模型和工具。workers 参数将决定提取过程中的所使用的并行进程数，可根据需要进行调整。命令运行完成后将生成 `plugins.jsonl` 文件保存结果，该文件包含了当前 Dify 实例中所有工作区的插件信息。

确保你的网络正常访问公网，并支持访问：`https://marketplace.dify.ai`。在 `docker-api-1` 容器内继续运行以下命令：

```bash
# 对于 Dify v1.3.0+ 的环境，标准命令是 'uv run ...'。
uv run flask install-plugins --workers=2
#
# 如果您的目标迁移版本是 Dify v1.0.0 至 v1.3.0 (不含v1.3.0) 之间，请使用 'poetry':
# poetry run flask install-plugins --workers=2
```

此命令将下载并安装所有必要的插件到最新的社区版本中。

最后迁移插件数据。运行以下命令更新 `provider name`，并在其后附加 `langgenius/provider_name/provider_name`。

```bash
# 对于 Dify v1.3.0+ 的环境，标准命令是 'uv run ...'。
uv run flask migrate-data-for-plugin
#
# 如果您的目标迁移版本是 Dify v1.0.0 至 v1.3.0 (不含v1.3.0) 之间，请使用 'poetry':
# poetry run flask migrate-data-for-plugin
``` 

当终端出现以下标识时，迁移完成。

```bash
Migrate [tool_builtin_providers] data for plugin completed, total: 6
Migrate data for plugin completed.
```

## 验证结果

访问 Dify 平台，轻点右上角 **"插件"** 查看此前所使用的工具是否被正确安装。随机使用某个插件，验证是否能够正常运行。如果无误，说明你已完成版本升级和数据迁移。

![](https://assets-docs.dify.ai/2025/02/6467b3578d3d3e96510f50a09442d5a5.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/migration/migrate-to-v1.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 模型接入
> 来源：`zh-hans/development/models-integration/README.mdx`

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/models-integration/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入 AWS Bedrock 上的模型
> 来源：`zh-hans/development/models-integration/aws-bedrock-deepseek.mdx`

## 功能介绍

[AWS Bedrock Marketplace](https://aws.amazon.com/bedrock/marketplace/) 是一个综合的 LLM 部署平台，开发人员可以在该平台发现、测试和使用 100 多种常用的新兴专业基础模型（FM）并轻松部署与访问。

本文将以部署 DeepSeek 模型为例，演示如何在 Bedrock Marketplace 平台部署模型并集成至 Dify 平台，帮助你快速搭建基于 DeepSeek 模型的 AI 应用。

## 前置准备

* 拥有 [Bedrock](https://aws.amazon.com/bedrock/) 访问权限的 AWS 账号
* [Dify.AI 账号](https://cloud.dify.ai/)

## 开始部署

### 1. 部署 DeepSeek 模型

1.1 在 **Bedrock Marketplace** 中搜索 **DeepSeek**，选择任意一个 **DeepSeek R1** 及其蒸馏版本的模型。

![](https://assets-docs.dify.ai/2025/02/9c6e17fc0cf262b2005013bf122251d1.png)

1.2 进入模型详情页，点击 **"Deploy"** 并按照页面提示填写相关信息，完成一键部署。

> 请注意，不同版本的模型可能要求不同的计算实例配置，费用有所差异。

![](https://assets-docs.dify.ai/2025/02/613497e3473d9b6eaa7cb5611decee0c.png)

1.3 部署完成后，你可以在 **Marketplace Deployments** 页查看自动生成的 **Endpoint**，该参数与 **SageMaker Endpoint** 参数相同，将用于后续 Dify 平台的连接。

![Endpoint 查看](https://assets-docs.dify.ai/2025/02/82a1d6406662b83386b86ec511ab20be.png)

### 2. 建立 DeepSeek 模型与 Dify 平台的连接

2.1 进入 **Dify** 管理面板，打开 **Settings** 页面。

2.2 在 **Model Provider** 选项中找到 **SageMaker**，并点击 **SageMaker** 卡片右下角的 **"Add Model"** 进入配置页面。

![添加模型](https://assets-docs.dify.ai/2025/02/864fc8476c47b460b67f14152cbbf360.png)

2.3 进入 SageMaker 配置页面，参考以下内容进行填写。

- **Model Type**: 模型类型，选择 LLM 类型
- **Model Name**：模型名称，可自定义填写
- **sagemaker endpoint**：填写在上文中提及的 **Endpoint** 参数。该参数可以在 AWS Bedrock Marketplace 中的 **Endpoint** 页获取。
- **Marketplace Deployments** 页查看自动生成的 **Endpoint**，

![](https://assets-docs.dify.ai/2025/02/1feaa8d5054933f42da25a8f655b5a9e.png)

### 3. 运行模型

配置完成后，你可以在 Dify 平台内测试 DeepSeek 模型是否能够正常运行。轻点 Dify 平台首页左侧的"创建空白应用"，选择 「Chatflow 或 Workflow」类型应用并添加 LLM 节点。

参考以下截图，在应用预览页测试模型是否能够正常给出答复。

![模型运行](https://assets-docs.dify.ai/2025/02/e7fb06888101662ecb970401fdba63b5.png)

除了使用 Chatflow / Workflow 应用类型进行测试以外，你还可以创建 Chatbot 类型应用进行测试。

## 常见问题

### 1. **部署后没有看到 Endpoint 参数？**

确保已正确配置实例，并检查 AWS 权限设置是否正确。如果仍有问题，尝试重新部署或咨询 AWS 客户支持人员。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/models-integration/aws-bedrock-deepseek.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


##  gpt-oss + Ollama 本地化部署指南 
> 来源：`zh-hans/development/models-integration/gpt-oss-local-deployment.md`

# 一、引言

*   gpt-oss 系列是 OpenAI 于 2025 年 8 月首次发布的开源模型。

> gpt-oss:20b（适用于约 16GB 的内存）
> 
> gpt-oss:120b（适用于≥ 60GB 的内存）

*   使用 Ollama 在本地部署，无需向云端发送 API 请求。数据始终在本地运行，适用于对隐私和响应速度有要求的场景。

*   Dify 是一个开源的 LLM 应用平台，支持集成本地模型、快速构建 AI 应用程序和 RAG 流程。

**目标：** 展示如何使用 Ollama 在本地部署 gpt-oss 并将其集成到 Dify 中，以构建一个私有且安全的 LLM 服务。

* * *

# **二、环境准备**

## **第一步：使用 Ollama 本地部署 gpt-oss 模型**

1.  安装 Ollama

访问 [Ollama 官网](https://ollama.com)下载安装，根据操作系统选择 macOS、Windows 或 Linux 版本。

2.  拉取 gpt-oss 模型

*   gpt-oss:20b（推荐日常开发机器，需 ≥ 16 GB 显存或统一内存） `ollama pull gpt-oss:20b`

*   gpt-oss:120b（需 ≥ 60 GB 显存或多 GPU 支持） `ollama pull gpt-oss:120b`

这两个模型均默认已量化为 MXFP4 格式，适合大多数本地部署场景

3.  启动 Ollama 服务

服务默认监听在： http://localhost:11434。

## **第二步：本地部署 Dify 并准备接入**

详细内容参考Dify[官方文档](https://docs.dify.ai/zh-hans/getting-started/install-self-hosted/readme)，也可以参考如下简易教程。

### 前置条件

下载安装[Docker](https://www.docker.com/products/docker-desktop/) 环境，安装完毕后确认 Docker Engine 能正常运行。

![1](https://raw.githubusercontent.com/NanSike/image-host/main/images/1.png)

### 本地部署Dify

1.  使用Git克隆

`git clone` `https://github.com/langgenius/Dify.git`

2.  进入 Dify 源代码的 docker 目录，执行一键启动命令：

`cd Dify/docker` `cp .env.example .env` `d`ouyin

![2](https://raw.githubusercontent.com/NanSike/image-host/main/images/2.png)

3.  进入本地 Dify，填写相关信息

![3](https://raw.githubusercontent.com/NanSike/image-host/main/images/3.png)

* * *

# **三、添加模型并测试聊天接口**

1.  点击页面右上角的设置，进入后选择模型提供商，点击添加 Ollama 模型类型： **Settings > Model Providers > Ollama**

![4](https://raw.githubusercontent.com/NanSike/image-host/main/images/4.png)  

2.  请填写 ollama 的相关信息。将 **“gpt-oss:20b”** 选作模型名称。如有任何不清楚的地方，您可以参考官方详细的[部署文档](https://docs.dify.ai/en/development/models-integration/ollama#integrate-local-models-deployed-by-ollama)来操作 ollama。

![5](https://raw.githubusercontent.com/NanSike/image-host/main/images/5.png)

3.  新建空白模板

![6](https://raw.githubusercontent.com/NanSike/image-host/main/images/6.png)

4.  选择您想创建的类型

![7](https://raw.githubusercontent.com/NanSike/image-host/main/images/7.png)

* * *

# **四、验证与使用**

*   在 Dify 的模型测试页面中，输入适当的提示语，并确认模型的响应符合您的预期。

*   在您的应用流程中添加一个简单的 LLM 节点，选择 gpt-oss:20b 作为模型，并确保整个工作流程连接无误。

![8](https://raw.githubusercontent.com/NanSike/image-host/main/images/8.png)

![9](https://raw.githubusercontent.com/NanSike/image-host/main/images/9.png)

* * *

# **五、附录**

**常见问题及建议**

*   **模型下载速度慢**

提示：配置 Docker 代理或使用图像加速服务以加快下载速度。

*   **GPU 内存不足**

提示：对于 GPU 内存有限的设备，请使用 gpt-oss：20b。您还可以启用 CPU 转发功能，但这样会导致响应速度变慢。

*   **端口访问问题**

提示：检查防火墙规则、端口绑定和 Docker 网络设置，以确保连接正常。


## 整合通过 GPUStack 部署的本地模型
> 来源：`zh-hans/development/models-integration/gpustack.mdx`

[GPUStack](https://github.com/gpustack/gpustack) 是一个用于运行 AI 模型的开源 GPU 集群管理器。

Dify 支持与 GPUStack 集成，用于本地部署大语言模型推理、嵌入和重排序能力。

## 部署 GPUStack

你可以参考官方[文档](https://docs.gpustack.ai)进行部署，或按照以下步骤快速集成：

### Linux 或 MacOS

GPUStack 提供了一个脚本，可以将其作为服务安装在基于 systemd 或 launchd 的系统上。要使用此方法安装 GPUStack，只需运行：

```bash
curl -sfL https://get.gpustack.ai | sh -s -
```

### Windows

以管理员身份运行 PowerShell（**避免**使用 PowerShell ISE），然后运行以下命令安装 GPUStack：

```powershell
Invoke-Expression (Invoke-WebRequest -Uri "https://get.gpustack.ai" -UseBasicParsing).Content
```

然后你可以按照终端的输出说明访问 GPUStack 界面。

## 部署模型

以某个托管在 GPUStack 的大语言模型为例：

1. 在 GPUStack 界面中，进入"模型"页面并点击"部署模型"，从下拉菜单中选择 `Hugging Face`。

2. 使用左上角的搜索栏搜索模型名称 `Qwen/Qwen2.5-0.5B-Instruct-GGUF`。

3. 点击`保存`以部署模型。

![gpustack-deploy-llm](https://assets-docs.dify.ai/2025/04/d19b69596b95ae94071f9430a1b983e6.png)

## 创建 API 密钥

1. 进入"API 密钥"页面并点击"新建 API 密钥"。

2. 填写名称，然后点击`保存`。

3. 复制 API 密钥并保存以供后续使用。

## 将 GPUStack 集成到 Dify

5. 进入`设置 > 模型供应商 > GPUStack`并填写：

   - 模型类型：`LLM`

   - 模型名称：`qwen2.5-0.5b-instruct`

   - 服务器 URL：`http://your-gpustack-server-ip`

   - API 密钥：`输入你从前面步骤复制的 API 密钥`

   点击"保存"以在应用中使用该模型。

![add-gpustack-llm](https://assets-docs.dify.ai/2025/04/8178418f93ccea1668564d8bd9777303.png)

更多关于 GPUStack 的信息，请参考 [GitHub 仓库](https://github.com/gpustack/gpustack)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/models-integration/gpustack.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入 Hugging Face 上的开源模型
> 来源：`zh-hans/development/models-integration/hugging-face.mdx`

Dify 支持 Text-Generation 和 Embeddings，以下是与之对应的 Hugging Face 模型类型：

* Text-Generation：[text-generation](https://huggingface.co/models?pipeline\_tag=text-generation\&sort=trending)，[text2text-generation](https://huggingface.co/models?pipeline\_tag=text2text-generation\&sort=trending)
* Embeddings：[feature-extraction](https://huggingface.co/models?pipeline\_tag=feature-extraction\&sort=trending)

具体步骤如下：

1. 你需要有 Hugging Face 账号([注册地址](https://huggingface.co/join))。
2. 设置 Hugging Face 的 API key([获取地址](https://huggingface.co/settings/tokens))。
3. 进入 [Hugging Face 模型列表页](https://huggingface.co/models)，选择对应的模型类型。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/af8a771b1e71152837e0f25b87a4471e.png)

Dify 支持用两种方式接入 Hugging Face 上的模型：

1. Hosted Inference API。这种方式是用的 Hugging Face 官方部署的模型。不需要付费。但缺点是，只有少量模型支持这种方式。
2. Inference Endpoint。这种方式是用 Hugging Face 接入的 AWS 等资源来部署模型，需要付费。

### 接入 Hosted Inference API 的模型

#### 1 选择模型

模型详情页右侧有包含 Hosted inference API 的 区域才支持 Hosted inference API 。如下图所：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/dc5a5584cef16fe76595058d37043546.png)

在模型详情页，可以获得模型的名称。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/248a80fb0dac520e690cb122dbe91324.png)

#### 2 在 Dify 中使用接入模型

在 `设置 > 模型供应商 > Hugging Face > 模型类型` 的 Endpoint Type 选择 Hosted Inference API。如下图所示：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/0bb37fe604f12bf766a84538574e36a6.png)

API Token 为文章开头设置的 API Key。模型名字为上一步获得的模型名字。

### 方式 2: Inference Endpoint

#### 1 选择要部署模型

模型详情页右侧的 `Deploy` 按钮下有 Inference Endpoints 选项的模型才支持 Inference Endpoint。如下图所示：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/0821340197577ff126440b2558446890.png)

#### 2 部署模型

点击模型的部署按钮，选择 Inference Endpoint 选项。如果之前没绑过银行卡的，会需要绑卡。按流程走即可。绑过卡后，会出现下面的界面：按需求修改配置，点击左下角的 Create Endpoint 来创建 Inference Endpoint。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/f7582adc0937dc4f038e462b578d9c17.png)

模型部署好后，就可以看到 Endpoint URL。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/30c38995813c0d05c35c42dc0f1d467c.png)

#### 3 在 Dify 中使用接入模型

在 `设置 > 模型供应商 > Hugging Face > 模型类型` 的 Endpoint Type 选择 Inference Endpoints。如下图所示：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/ca2b2f7d98954ba92753d04440543caa.png)

API Token 为文章开头设置的 API Key。`Text-Generation 模型名字随便起，Embeddings 模型名字需要跟 Hugging Face 的保持一致。`Endpoint URL 为 上一步部署模型成功后获得的 Endpoint URL。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/6a8908cace5b287070577bf555d69b0c.png)

> 注意：Embeddings 的「用户名 / 组织名称」，需要根据你在 Hugging Face 的 [Inference Endpoints](https://huggingface.co/docs/inference-endpoints/guides/access) 部署方式，来填写「[用户名](https://huggingface.co/settings/account)」或者「[组织名称](https://ui.endpoints.huggingface.co/)」。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/models-integration/hugging-face.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入 LiteLLM 代理的模型
> 来源：`zh-hans/development/models-integration/litellm.mdx`

LiteLLM Proxy 是一个代理服务器，支持以下功能：

* 支持 OpenAI 格式调用 100 多种 LLMs ，包括 OpenAI、Azure、Vertex 和 Bedrock 等。
* 设置 API Key 、预算、速率限制并跟踪使用情况。

Dify 支持集成 LiteLLM Proxy 上的 LLM 和 Text Embedding 模型。

## **快速集成**

### **步骤 1. 启动 LiteLLM Proxy 服务器**

LiteLLM 需要一个包含所有定义模型的配置文件，命名为 `litellm_config.yaml`。

如何设置 LiteLLM 配置的详细文档 - [点击这里](https://example.com)

```yaml
model_list:
  - model_name: deepseek-chat #调用 LiteLLM 的模型名词
    litellm_params:
      model: openai/deepseek-chat #`openai/` 前缀表示该模型与 openai 格式兼容
      api_key: 
      api_base: https://api.deepseek.com/
  - model_name: gpt-4
    litellm_params:
      model: azure/chatgpt-v-2
      api_base: https://openai-gpt-4-test-v-1.openai.azure.com/
      api_version: "2023-05-15"
      api_key: 
  - model_name: gpt-4
    litellm_params:
      model: azure/gpt-4
      api_key: 
      api_base: https://openai-gpt-4-test-v-2.openai.azure.com/
```

### **步骤 2. 启动 LiteLLM 代理**

```bash
docker run \
    -v $(pwd)/litellm_config.yaml:/app/config.yaml \
    -p 4000:4000 \
    ghcr.io/berriai/litellm:main-latest \
    --config /app/config.yaml --detailed_debug
```

成功后，代理将在 `http://localhost:4000` 上运行。

### **步骤 3. 在 Dify 中集成 LiteLLM Proxy**

在`设置 > 模型供应商 > OpenAI-API-compatible` 中填写：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/77bffb41849491914f95b05e0f42cd29.png)

* **模型名称**: gpt-4
* **API endpoint URL**: `http://localhost:4000`
  * 输入 LiteLLM 服务可访问的基础 URL。
* **Completion mode**: 对话
* **模型上下文长度**: 4096
  * 模型的最大上下文长度。如果不确定，使用默认值 4096。
* **最大 Token 上限**: 4096
  * 模型返回的最大 Token 数量。如果没有特定要求，可以与模型上下文长度一致。
* **支持视觉**:
  * 如果模型支持图像理解（多模态），如 gpt4-o，请勾选此选项。

点击`保存`，在确认无误后即可在应用程序中使用该模型。

嵌入模型的集成方法与 LLM 类似，只需将模型类型更改为文本嵌入。

**更多信息**

有关 LiteLLM 的更多信息，请参阅：

* [LiteLLM](https://example.com)
* [LiteLLM Proxy Server](https://example.com)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/models-integration/litellm.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入 LocalAI 部署的本地模型
> 来源：`zh-hans/development/models-integration/localai.mdx`

[LocalAI](https://github.com/go-skynet/LocalAI) 是一个本地推理框架，提供了 RESTFul API，与 OpenAI API 规范兼容。它允许你在消费级硬件上本地或者在自有服务器上运行 LLM（和其他模型），支持与 ggml 格式兼容的多种模型家族。不需要 GPU。
Dify 支持以本地部署的方式接入 LocalAI 部署的大型语言模型推理和 embedding 能力。

## 部署 LocalAI

### 使用前注意事项

如果确实需要直接使用容器的 IP 地址，以上步骤将帮助你获取到这一信息。

### 开始部署

可参考官方 [Getting Started](https://localai.io/basics/getting_started/) 进行部署，也可参考下方步骤进行快速接入：

（以下步骤来自 [LocalAI Data query example](https://github.com/mudler/LocalAI-examples/tree/main/langchain-chroma/README.md)）

1. 首先拉取 LocalAI 代码仓库，并进入指定目录

    ```bash
    $ git clone https://github.com/go-skynet/LocalAI
    $ cd LocalAI/examples/langchain-chroma
    ```

2. 下载范例 LLM 和 Embedding 模型

    ```bash
    $ wget https://huggingface.co/skeskinen/ggml/resolve/main/all-MiniLM-L6-v2/ggml-model-q4_0.bin -O models/bert
    $ wget https://gpt4all.io/models/ggml-gpt4all-j.bin -O models/ggml-gpt4all-j
    ```

    这里选用了较小且全平台兼容的两个模型，`ggml-gpt4all-j` 作为默认 LLM 模型，`all-MiniLM-L6-v2` 作为默认 Embedding 模型，方便在本地快速部署使用。

3. 配置 .env 文件

   ```shell
   $ mv .env.example .env
   ```

   NOTE：请确保 `.env` 中的 THREADS 变量值不超过你本机的 CPU 核心数。

4. 启动 LocalAI

   ```shell
   # start with docker-compose
   $ docker-compose up -d --build

   # tail the logs & wait until the build completes
   $ docker logs -f langchain-chroma-api-1
   7:16AM INF Starting LocalAI using 4 threads, with models path: /models
   7:16AM INF LocalAI version: v1.24.1 (9cc8d9086580bd2a96f5c96a6b873242879c70bc)

    ┌───────────────────────────────────────────────────┐ 
    │                   Fiber v2.48.0                   │ 
    │               http://127.0.0.1:8080               │ 
    │       (bound on host 0.0.0.0 and port 8080)       │ 
    │                                                   │ 
    │ Handlers ............ 55  Processes ........... 1 │ 
    │ Prefork ....... Disabled  PID ................ 14 │ 
    └───────────────────────────────────────────────────┘ 
   ```

   开放了本机 `http://127.0.0.1:8080` 作为 LocalAI 请求 API 的端点。

   并提供了两个模型，分别为：

   - LLM 模型：`ggml-gpt4all-j`

     对外访问名称：`gpt-3.5-turbo`（该名称可自定义，在 `models/gpt-3.5-turbo.yaml` 中配置。

   - Embedding 模型：`all-MiniLM-L6-v2`

     对外访问名称：`text-embedding-ada-002`（该名称可自定义，在 `models/embeddings.yaml` 中配置。
    >  使用 Dify Docker 部署方式的需要注意网络配置，确保 Dify 容器可以访问到 Xinference 的端点，Dify 容器内部无法访问到 localhost，需要使用宿主机 IP 地址。

5. LocalAI API 服务部署完毕，在 Dify 中使用接入模型

   在 `设置 > 模型供应商 > LocalAI` 中填入：

   模型 1：`ggml-gpt4all-j`

   - 模型类型：文本生成

   - 模型名称：`gpt-3.5-turbo`

   - 服务器 URL：http://127.0.0.1:8080

     若 Dify 为 docker 部署，请填入 host 域名：`http://<your-LocalAI-endpoint-domain>:8080`，可填写局域网 IP 地址，如：`http://192.168.1.100:8080`

   "保存" 后即可在应用中使用该模型。

   模型 2：`all-MiniLM-L6-v2`

   - 模型类型：Embeddings

   - 模型名称：`text-embedding-ada-002`

   - 服务器 URL：http://127.0.0.1:8080

     > 若 Dify 为 docker 部署，请填入 host 域名：`http://<your-LocalAI-endpoint-domain>:8080`，可填写局域网 IP 地址，如：`http://192.168.1.100:8080`

   "保存" 后即可在应用中使用该模型。

如需获取 LocalAI 更多信息，请参考：https://github.com/go-skynet/LocalAI

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/models-integration/localai.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入 Ollama 部署的本地模型
> 来源：`zh-hans/development/models-integration/ollama.mdx`

[Ollama](https://github.com/jmorganca/ollama) 是一款跨平台推理框架客户端（MacOS、Windows、Linux），专为无缝部署大型语言模型（LLM）（如 Llama 2、Mistral、Llava 等）而设计。通过一键式设置，Ollama 可以在本地运行 LLM，将所有交互数据保存在自己的机器上，从而提高数据的私密性和安全性。

## 快速接入

### 下载并启动 Ollama

1. 下载 Ollama

   访问 [Ollama 下载页](https://ollama.com/download)，下载对应系统 Ollama 客户端。

2. 运行 Ollama 并与 Llama3.2 聊天

    ```bash
    ollama run llama3.2
    ```

    启动成功后，ollama 在本地 11434 端口启动了一个 API 服务，可通过 `http://localhost:11434` 访问。

    如需运行其它模型，访问 [Ollama Models](https://ollama.com/library) 了解详情。

3. 在 Dify 中接入 Ollama

   在 `设置 > 模型供应商 > Ollama` 中填入：

   ![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/981679ae2e56d49e5a983e37cc134172.png)

   - 模型名称：`llama3.2`

   - 基础 URL：`http://<your-ollama-endpoint-domain>:11434`

     此处需填写 Ollama 服务地址。如果填写公开 URL 后仍提示报错，请参考[常见问题](#如何在我的网络上暴露-ollama)，修改环境变量并使得 Ollama 服务可被所有 IP 访问。

     若 Dify 为 Docker 部署，建议填写局域网 IP 地址，例如：`http://192.168.1.100:11434` 或 Docker 容器的内部 IP 地址，例如：`http://host.docker.internal:11434`。

     若为本地源码部署，可填写 `http://localhost:11434`。

   - 模型类型：`对话`

   - 模型上下文长度：`4096`

     模型的最大上下文长度，若不清楚可填写默认值 4096。

   - 最大 token 上限：`4096`

     模型返回内容的最大 token 数量，若模型无特别说明，则可与模型上下文长度保持一致。

   - 是否支持 Vision：`是`

     当模型支持图片理解（多模态）勾选此项，如 `llava`。

   点击 "保存" 校验无误后即可在应用中使用该模型。

   Embedding 模型接入方式与 LLM 类似，只需将模型类型改为 Text Embedding 即可。

4. 使用 Ollama 模型

   ![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/0561ed1f5c265689b504ff539f5d3edd.png)

   进入需要配置的 App 提示词编排页面，选择 Ollama 供应商下的 `llava` 模型，配置模型参数后即可使用。

## FAQ

### ⚠️ 如果你使用 Docker 部署 Dify 和 Ollama，你可能会遇到以下错误:

```bash
httpconnectionpool (host=127.0.0.1, port=11434): max retries exceeded with url:/cpi/chat (Caused by NewConnectionError ('<urllib3.connection.HTTPConnection object at 0x7f8562812c20>: fail to establish a new connection:[Errno 111] Connection refused'))

httpconnectionpool (host=localhost, port=11434): max retries exceeded with url:/cpi/chat (Caused by NewConnectionError ('<urllib3.connection.HTTPConnection object at 0x7f8562812c20>: fail to establish a new connection:[Errno 111] Connection refused'))
```

这个错误是因为 Docker 容器无法访问 Ollama 服务。localhost 通常指的是容器本身，而不是主机或其他容器。要解决此问题，你需要将 Ollama 服务暴露给网络。

### 在 Mac 上设置环境变量

如果 `Ollama` 作为 `macOS` 应用程序运行，则应使用以下命令设置环境变量 `launchctl`：

1. 通过调用 `launchctl setenv` 设置环境变量：

    ```bash
    launchctl setenv OLLAMA_HOST "0.0.0.0"
    ```

2. 重启 Ollama 应用程序。

3. 如果以上步骤无效，可以使用以下方法：

    问题是在 docker 内部，你应该连接到 `host.docker.internal`，才能访问 docker 的主机，所以将 `localhost` 替换为 `host.docker.internal` 服务就可以生效了：

    ```bash
    http://host.docker.internal:11434
    ```

### 在 Linux 上设置环境变量

如果 Ollama 作为 systemd 服务运行，应该使用 `systemctl` 设置环境变量：

1. 通过调用 `systemctl edit ollama.service` 编辑 systemd 服务。这将打开一个编辑器。

2. 对于每个环境变量，在 `[Service]` 部分下添加一行 `Environment`：

    ```ini
    [Service]
    Environment="OLLAMA_HOST=0.0.0.0"
    ```

3. 保存并退出。

4. 重载 `systemd` 并重启 Ollama：

   ```bash
   systemctl daemon-reload
   systemctl restart ollama
   ```

### 在 Windows 上设置环境变量

在 Windows 上，Ollama 继承了你的用户和系统环境变量。

1. 首先通过任务栏点击 Ollama 退出程序

2. 从控制面板编辑系统环境变量

3. 为你的用户账户编辑或新建变量，比如 `OLLAMA_HOST`、`OLLAMA_MODELS` 等。

4. 点击 OK / 应用保存

5. 在一个新的终端窗口运行 `ollama`

### 如何在我的网络上暴露 Ollama？

Ollama 默认绑定 127.0.0.1 端口 11434。通过 `OLLAMA_HOST` 环境变量更改绑定地址。

如需获取 Ollama 更多信息，请参考

- [Ollama](https://github.com/jmorganca/ollama)
- [Ollama FAQ](https://github.com/ollama/ollama/blob/main/docs/faq.md)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/models-integration/ollama.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入 OpenLLM 部署的本地模型
> 来源：`zh-hans/development/models-integration/openllm.mdx`

使用 [OpenLLM](https://github.com/bentoml/OpenLLM), 你可以针对任何开源大型语言模型进行推理,部署到云端或本地,并构建强大的 AI 应用程序。
Dify 支持以本地部署的方式接入 OpenLLM 部署的大型语言模型的推理能力。

## 部署 OpenLLM 模型
### 开始部署

你可以通过以下方式部署：

```bash
docker run --rm -it -p 3333:3000 ghcr.io/bentoml/openllm start facebook/opt-1.3b --backend pt
```
> 注意：此处使用 facebook/opt-1.3b 模型仅作为示例，效果可能不佳，请根据实际情况选择合适的模型，更多模型请参考：[支持的模型列表](https://github.com/bentoml/OpenLLM#-supported-models)。

模型部署完毕，在 Dify 中使用接入模型

   在 `设置 > 模型供应商 > OpenLLM` 中填入：

   - 模型名称：`facebook/opt-1.3b`
   - 服务器 URL：`http://:3333` 替换成你的机器 IP 地址
   "保存" 后即可在应用中使用该模型。

本说明仅作为快速接入的示例，如需使用 OpenLLM 更多特性和信息，请参考：[OpenLLM](https://github.com/bentoml/OpenLLM)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/models-integration/openllm.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入 Replicate 上的开源模型
> 来源：`zh-hans/development/models-integration/replicate.mdx`

Dify 支持接入 Replicate 上的 [Language models](https://replicate.com/collections/language-models) 和 [Embedding models](https://replicate.com/collections/embedding-models)。Language models 对应 Dify 的推理模型，Embedding models 对应 Dify 的 Embedding 模型。

具体步骤如下：

1. 你需要有 Replicate 的账号([注册地址](https://replicate.com/signin?next=/docs))。
2. 获取 API Key([获取地址](https://replicate.com/account/api-tokens))。
3. 挑选模型。在 [Language models](https://replicate.com/collections/language-models) 和 [Embedding models](https://replicate.com/collections/embedding-models) 下挑选模型。
4. 在 Dify 的 `设置 > 模型供应商 > Replicate` 中添加模型。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/b11aa84eb58e4457b47696f077389e37.png)

API key 为第 2 步中设置的 API Key。Model Name 和 Model Version 可以在模型详情页中找到：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/95e2ad371c82ef7ef641192f2bf1a1f8.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/models-integration/replicate.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入 Xinference 部署的本地模型
> 来源：`zh-hans/development/models-integration/xinference.mdx`

[Xorbits inference](https://github.com/xorbitsai/inference) 是一个强大且通用的分布式推理框架，旨在为大型语言模型、语音识别模型和多模态模型提供服务，甚至可以在笔记本电脑上使用。它支持多种与GGML兼容的模型,如 chatglm, baichuan, whisper, vicuna, orca 等。 Dify 支持以本地部署的方式接入 Xinference 部署的大型语言模型推理和 embedding 能力。

## 部署 Xinference

### 开始部署

部署 Xinference 有两种方式，分别为[本地部署](https://github.com/xorbitsai/inference)和[分布式部署](https://github.com/xorbitsai/inference/blob/main/README\_zh\_CN.md#%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2)，以下以本地部署为例。

1.  首先通过 PyPI 安装 Xinference：

    ```bash
    $ pip install "xinference[all]"
    ```
2.  本地部署方式启动 Xinference：

    ```bash
    $ xinference-local
    2023-08-20 19:21:05,265 xinference   10148 INFO     Xinference successfully started. Endpoint: http://127.0.0.1:9997
    2023-08-20 19:21:05,266 xinference.core.supervisor 10148 INFO     Worker 127.0.0.1:37822 has been added successfully
    2023-08-20 19:21:05,267 xinference.deploy.worker 10148 INFO     Xinference worker successfully started.
    ```

    Xinference 默认会在本地启动一个 worker，端点为：`http://127.0.0.1:9997`，端口默认为 `9997`。 默认只可本机访问，可配置 `-H 0.0.0.0`，非本地客户端可任意访问。 如需进一步修改 host 或 port，可查看 xinference 的帮助信息：`xinference-local --help`。

    > 使用 Dify Docker 部署方式的需要注意网络配置，确保 Dify 容器可以访问到 Xinference 的端点，Dify 容器内部无法访问到 localhost，需要使用宿主机 IP 地址。
3.  创建并部署模型

    进入 `http://127.0.0.1:9997` 选择需要部署的模型和规格进行部署，如下图所示：

    ![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/6945f8e7a0ae88d1f67f988d53d420bd.png)

    由于不同模型在不同硬件平台兼容性不同，请查看 [Xinference 内置模型](https://inference.readthedocs.io/en/latest/models/builtin/index.html) 确定创建的模型是否支持当前硬件平台。
4.  获取模型 UID

    从上图所在页面获取对应模型的 ID，如：`2c886330-8849-11ee-9518-43b0b8f40bea`
5.  模型部署完毕，在 Dify 中使用接入模型

    在 `设置 > 模型供应商 > Xinference` 中填入：

    * 模型名称：`vicuna-v1.3`
    * 服务器 URL：`http://:9997` **替换成你的机器 IP 地址**
    * 模型 UID：`2c886330-8849-11ee-9518-43b0b8f40bea`

    "保存" 后即可在应用中使用该模型。

Dify 同时支持将 [Xinference embed 模型](https://github.com/xorbitsai/inference) 作为 Embedding 模型使用，只需在配置框中选择 `Embeddings` 类型即可。

如需获取 Xinference 更多信息，请参考：[Xorbits Inference](https://github.com/xorbitsai/inference)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/development/models-integration/xinference.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 云服务
> 来源：`zh-hans/getting-started/cloud.mdx`

> **信息提示：**

**提示:** Dify 目前正在 Beta 测试阶段，如文档与产品存在不一致，请以产品实际体验为准。

任何人都可以 [开箱即用](https://cloud.dify.ai/apps) Dify 的云服务。探索灵活的 [套餐和价格](https://dify.ai/pricing)，选择最适合你需求的计划。

立即开始使用 [Sandbox 计划](http://cloud.dify.ai)，其中包含 200 次 OpenAI 调用的免费试用，无需信用卡。要使用云版本的 Sandbox 计划，你需要拥有 GitHub 或 Google 账号，以及 OpenAI API 密钥。以下是开始使用的方法：

1. 注册 [Dify 云服务](https://cloud.dify.ai) 并创建一个新的工作区（Workspace），或加入已有的工作区。
2. 配置你的模型提供商或使用我们托管的模型提供商。
3. 现在你可以 [创建应用](../guides/application-orchestrate/creating-an-application) 了！

### 常见问题

**问：使用 Dify 云服务时，我的数据如何处理和存储？**

答：当你使用 Dify 云服务时，你的用户数据会被安全地存储在位于美国东部地区的 AWS 服务器上。这包括你主动输入的数据以及从你的应用生成的任何数据。我们优先考虑你数据的安全性和完整性，确保它按照云存储解决方案的最高标准进行管理。

**问：有哪些措施来保护我的 API 密钥和其他敏感信息？**

答：在 Dify，我们了解保护你的 API 密钥和其他机密信息的重要性。这些信息在静态时会被加密，这意味着 Dify 无法查看它们，只有合法所有者才能访问你的密钥。

**问：能解释一下 Dify 云服务中应用数据是如何匿名化的吗？**

答：在 Dify 云服务中，我们对应用数据进行匿名化处理，以确保隐私并减少加密和解密的开销。这意味着应用使用的数据不会直接与可识别的用户账户关联。通过匿名化数据，我们增强了隐私保护，同时维持了云服务的性能。

**问：从 Dify 云服务中删除我的账户和所有相关数据的流程是什么？**

答：如果你决定删除账户并从 Dify 云服务中移除所有相关数据，你可以访问 [账户设置](https://cloud.dify.ai/account) 或点击右上角的头像，然后点击 **账户**。你会看到一个 **删除账户** 按钮；请点击它并按照指示操作。

Dify 致力于尊重每位用户的隐私和数据权利。当你授权后，我们将遵守数据保护法规，从系统中删除你的所有数据。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/cloud.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Dify 教育版
> 来源：`zh-hans/getting-started/dify-for-education.mdx`

## 简介

Dify 教育版旨在为学生、教师及教育机构提供便捷、实惠的 AI 学习与开发工具，让 AI 教育更可及、更普及。

## 价值

-   **为学生**：让你以更优惠的价格使用 Dify 的 SaaS 订阅服务，获取更多计算资源，以支持课程作业、科研项目和 AI 应用开发。

-   **为教师**：帮助你在教学中使用 Dify 作为 AI 教具，引导学生深入学习 AI 应用开发。

-   **为教育机构 & 学校**：让你的团队更轻松地管理 AI 资源，提高教学效率，探索 AI 在教育领域的更多可能性。

## Dify 教育版权益

Dify 教育版目前提供**免费的 Dify 专业版订阅**，需每年续期一次。

> **信息提示：**

我们将持续推出更多教育版专属权益以支持你的学习或授课，敬请期待。

## 如何申请 Dify 教育版认证？

### 申请资格

如果你希望申请 Dify 教育版认证，需要**同时**满足以下申请条件：

1.  年满 18 周岁。
2.  目前是在校学生、教师或教育机构的员工。
3.  已经使用教育邮箱注册了 Dify 账号。

### 申请步骤

1.  **创建 Dify 账号**

在申请教育版认证前，请使用你的教育邮箱[注册 Dify 账号](https://cloud.dify.ai/signin)。

2.  **完成 Dify 教育版认证**

    1.  登录已使用教育邮箱注册的 Dify 账号后，点击右上角的用户头像，在下拉列表中点击 **设置**。

    2.  进入设置页后，点击 **账单 > 申请教育版认证**。

    ![Get Education Verified](https://assets-docs.dify.ai/2025/03/662ee0255a499ab4184fd617e0f5767d.png)

    3.  输入你的学校全称 *（请勿使用缩写）*。

    4.  选择你的身份。

    ![Get Education Verified Form](https://assets-docs.dify.ai/2025/05/fd3ea7c1846c17bd753d84bcc2fea72b.png)

    5.  勾选 **同意条款与协议**，点击 **提交**。

## 如何查看 Dify 教育版认证状态？

申请教育认证成功后，点击右上角的用户头像，在下拉列表中查看订阅状态。若订阅状态显示为 `Edu`，则说明教育版认证申请成功。

## 如何使用 Dify 教育优惠券？

### Dify 教育版订阅简介

完成 Dify 教育认证后，优惠券已自动添加到您的账户中。

> **信息提示：**

教育版订阅权益：**完全免费的专业版**

订阅有效期：**12 个月**

教育版订阅限制：
-   用户需要在有效期结束前续期，**过期后权益失效**。
-   每年需申请**一次**教育版认证续期。
-   教育版订阅只能用于申请人为 Workspace Owner 的空间。

### 激活教育版订阅

1.  完成教育版认证后，请在升级界面选择年付账单的 Professional 订阅，进入支付界面。

![Pricing](https://assets-docs.dify.ai/2025/05/574d95416f57fba457259c3db2ae947d.png)

2. 在支付过程中，优惠券会自动应用于你的账号中，无需手动输入优惠码。

![Payment](https://assets-docs.dify.ai/2025/05/c2c6afeb44b4bd0ce7f1eccc1292e08b.png)

3.  订阅激活后，你的订阅状态将更新为 `Pro(Edu)`。

## 如何更新我的教育信息？

### 更新邮箱信息

如果你的邮箱需要更改，目前只能由人工处理。请发送邮件至 [support@dify.ai](mailto:support@dify.ai) 寻求帮助。

### 更新学校信息

-   **首次认证后修改学校信息**：如果你已完成教育认证，但需要更改学校信息，请发送邮件至 [support@dify.ai](mailto:support@dify.ai) 寻求帮助。

-   **认证过期后修改学校信息**：当你的教育认证过期后，重新认证时可以填写新学校的信息。

## 如何续期 Dify 教育版认证？

教育版认证过期后，参照前文的 **完成 Dify 教育版认证** 章节，重新申请教育版认证。

## FAQ

-   **如何学习 Dify？**

1. 查阅官方文档：阅读 [Dify 官方文档](https://docs.dify.ai/)，获取完整的使用指南。

2. 参与社区交流：加入 [Dify Discord 社区](https://discord.com/invite/FngNHpbcY7)，与开发者交流分享你的使用心得。

-   **谁不能申请教育版认证？**

1.  未满 18 岁的用户。

2.  使用个人邮箱（如 Gmail）注册账号的用户。

-   **为什么我申请教育版认证被拒绝/认证被撤销？如果申请被拒绝/认证被撤销，我应该怎么办？**

当遇到以下情况时，你的教育版认证申请可能会被拒绝或撤销：

1. 在申请教育版认证时，未勾选 **同意条款与协议**
2. 未使用教育邮箱地址注册
3. 使用虚假学校或公司的邮箱地址
4. 提供虚假的个人或学校信息
5. 违规使用教育版特权

如遇申请被拒或认证被撤销，请发送邮件至 `<support@dify.ai>` 寻求帮助。

-   **当我毕业或离开学校后，教育版认证是否仍然有效？**

教育版认证只与你的教育邮箱状态直接关联。只要教育邮箱能正常使用，认证就会持续有效。

如果你的教育邮箱已停用，请发送邮件至 `<support@dify.ai>` 寻求帮助。

-   **我没有教育邮箱，应该如何申请教育版认证？**

目前，Dify 教育版认证主要通过教育邮箱进行身份验证。如果你没有教育邮箱，则暂时无法申请教育版认证。

-   **我目前已经订阅了 Dify 计划。当我申请教育版认证后，我的订阅计划会有什么变化？**

如果你当前有付费订阅，成功申请教育版认证后，可以在你当前的付费订阅周期结束后手动激活免费的专业版计划。

如果你订阅的是免费版计划，成功申请教育版认证后，需要你手动激活免费的专业版计划。

-   **我已经成功申请了教育版认证并获得了免费的专业版订阅，如果我不想继续使用，需要做什么？**

你无需进行任何操作，订阅会在有效期结束后自动失效。如果你想继续使用，只需在到期前重新申请教育版认证即可。

## 重要声明

Dify 教育版优惠仅限真实的学生、教师和教育机构使用，禁止通过虚假信息获取或用于商业用途。

我们会定期审查账户使用情况，对于滥用行为保留立即终止教育版资格和暂停账户的权利。

Dify 保留随时修改或终止教育版项目的权利，并对相关争议拥有最终解释权。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/dify-for-education.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Dify Premium
> 来源：`zh-hans/getting-started/dify-premium.mdx`

Dify Premium 是一款 AWS AMI 产品，允许自定义品牌，并可作为 EC2 一键部署到你的 AWS VPC 上。前往 [AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) 进行订阅并使用，它适合以下场景：

* 在中小型企业内，需在服务器上创建一个或多应用程序，并且关心数据私有化。
* 你对 [Dify Cloud](./zh-hans/getting-started/cloud)订阅计划感兴趣，但所需的用例资源超出了[计划](https://dify.ai/pricing)内所提供的资源。
* 你希望在组织内采用 Dify Enterprise 之前进行 POC 验证。

## 设置

如果这是你第一次访问 Dify，请输入管理员初始化密码（设置为你的 EC2 实例 ID）以开始设置过程。

部署 AMI 后，通过 EC2 控制台中找到的实例公有 IP 访问 Dify（默认使用 HTTP 端口 80）。

## 升级

在 EC2 实例中，运行以下命令：

```bash
git clone https://github.com/langgenius/dify.git /tmp/dify
mv -f /tmp/dify/docker/* /dify/
rm -rf /tmp/dify
docker-compose down
docker-compose pull
docker-compose -f docker-compose.yaml -f docker-compose.override.yaml up -d
```

> 本节介绍将旧社区版迁移到 Dify v1.0.0+ 的方法。对于将 Dify Premium 或社区版升级到此特定迁移范围*之后*的版本，请参考它们各自主要的升级说明。

> 版本 v1.0.0+ 包含插件功能，详细介绍请参考[此处](https://github.com/langgenius/dify/releases/tag/1.0.0) (v1.0.0 Release) 和 [v1.3.0 Release Notes](https://github.com/langgenius/dify/releases/tag/1.3.0) (关于uv切换)。

升级分为以下步骤：

1. 备份数据
2. 插件迁移
3. 主项目升级

### 1. 备份数据

1.1 运行 `cd` 命令至你的 Dify 项目路径，新建备份分支。

1.2 运行以下命令，备份你的 docker-compose YAML 文件（可选）。

```bash
cd docker
cp docker-compose.yaml docker-compose.yaml.$(date +%s).bak
```

1.3 运行命令停止服务，在 Docker 目录中执行备份数据命令。

```bash
docker compose down
tar -cvf volumes-$(date +%s).tgz volumes
```

### 2. 升级版本

`v1.0.0` 支持通过 Docker Compose 部署。运行 `cd` 命令至你的 Dify 项目路径，运行以下命令升级 Dify 版本：

```bash
git checkout 1.0.0 # 切换至 1.0.0 分支
cd docker
docker compose -f docker-compose.yaml up -d
```

### 3. 工具迁移为插件

> **关于命令执行和包管理的重要提示（针对v1.0.0迁移）：**
> *   **默认容器名称：** `docker exec` 命令示例使用了 `docker-api-1`。如果您的 API 容器有不同的名称或 ID（您可以使用 `docker ps` 查找），请相应调整命令。
> *   **Python 包管理器 (`uv` 与 `poetry`)：**
    *   从版本 [v1.3.0](https://github.com/langgenius/dify/releases/tag/1.3.0) 开始，Dify 已将 Python 包管理器从 `poetry` 切换到 `uv` 以提升性能。对于 Dify v1.3.0 或更新版本中的常规操作，标准命令是 `uv run flask ...`。
    *   **本特定章节专注于升级到 Dify v1.0.0。** 在 Dify v1.0.0 到 v1.3.0 (不含v1.3.0) 期间，`poetry` 是其包管理器。因此，下方示例中的 `flask` 命令正确地使用了 `poetry run ...`。代码示例首先在注释中强调了当前 `uv` 的标准用法，然后显示了与本特定 v1.0.0 迁移范围相关的 `poetry` 命令。

该步骤的目的：将此前社区版本所使用的工具及模型供应商，自动进行数据迁移并安装至新版本的插件环境中。

1. 运行 `docker ps` 命令，查看 API 容器的名称或 ID。默认名称通常是 `docker-api-1`。

示例：

```bash
docker ps
CONTAINER ID   IMAGE                                       COMMAND                  CREATED       STATUS                 PORTS                                                                                                                             NAMES
417241cd****   nginx:latest                                "sh -c 'cp /docker-e…"   3 hours ago   Up 3 hours             0.0.0.0:80->80/tcp, :::80->80/tcp, 0.0.0.0:443->443/tcp, :::443->443/tcp                                                          docker-nginx-1
f84aa773****   langgenius/dify-api:1.0.0                   "/bin/bash /entrypoi…"   3 hours ago   Up 3 hours             5001/tcp                                                                                                                          docker-worker-1
a3cb19c2****   langgenius/dify-api:1.0.0                   "/bin/bash /entrypoi…"   3 hours ago   Up 3 hours             5001/tcp                                                                                                                          docker-api-1
```

运行命令 `docker exec -it docker-api-1 bash` 进入容器终端（如果您的容器名称不同，请使用对应的名称），在容器内运行：

```bash
# 对于 Dify v1.3.0+ 的环境，标准命令是 'uv run ...'。
uv run flask extract-plugins --workers=20
#
# 如果您此处描述的社区版部分的迁移目标版本是 Dify v1.0.0 至 v1.3.0 (不含v1.3.0) 之间，请使用 'poetry':
# poetry run flask extract-plugins --workers=20
```

> 如果在按照本指南为 v1.0.0 版本迁移执行命令时发生错误（例如，找不到 `uv` 或 `poetry`），请确保按照该版本最初的先决条件，在服务器上正确设置了 `poetry` 环境。如果在运行 `poetry` 命令后终端提示输入，请按 **"回车"** 跳过。

此命令将提取当前环境中使用的所有模型和工具。workers 参数将决定提取过程中的所使用的并行进程数，可根据需要进行调整。命令运行完成后将生成 `plugins.jsonl` 文件保存结果，该文件包含了当前 Dify 实例中所有工作区的插件信息。

确保你的网络正常访问公网，并支持访问：`https://marketplace.dify.ai`。在 `docker-api-1` 容器内继续运行以下命令：

```bash
# 对于 Dify v1.3.0+ 的环境，标准命令是 'uv run ...'。
uv run flask install-plugins --workers=2
#
# 如果您此处描述的社区版部分的迁移目标版本是 Dify v1.0.0 至 v1.3.0 (不含v1.3.0) 之间，请使用 'poetry':
# poetry run flask install-plugins --workers=2
```

此命令将下载并安装所有必要的插件到最新的社区版本中。当终端出现 `Install plugins completed.` 标识时，迁移完成。

## 定制化

就像自托管部署一样，你可以根据需要修改 EC2 实例中 `.env` 下的环境变量。然后使用以下命令重新启动 Dify：

```bash
docker-compose down
docker-compose -f docker-compose.yaml -f docker-compose.override.yaml up -d
```

## 自定义 WebApp & 品牌

你可以在设置里的 **定制** 中启用此功能，启用 **移除 Powered by Dify** 并上传您自己的标志。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/dify-premium.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 宝塔面板部署
> 来源：`zh-hans/getting-started/install-self-hosted/bt-panel.mdx`

### 前提条件

> 安装 Dify 之前, 请确保你的机器已满足最低安装要求：
>
> * CPU >= 2 Core
> * RAM >= 4 GiB

<table>
  <thead>
    <tr>
      <th>操作系统</th>
      <th>软件</th>
      <th>描述</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Linux platforms</td>
      <td>
        <p>宝塔面板正式版 9.2.0 及以上版本</p>
      </td>
      <td>请参阅<a href="https://www.bt.cn/new/download.html">安装宝塔面板</a>  以获取更多信息。</td>
    </tr>
  </tbody>
</table>
### 部署 Dify
1. 登录宝塔面板，在菜单栏中点击 Docker，根据提示安装 Docker 和 Docker Compose 服务。
2. 在`Docker-应用商店`中找到 `Dify`，点击`安装`
3. 设置域名等基本信息，点击`确定`
   - 名称：应用名称，默认`Dify-随机字符`
   - 版本选择：默认`latest`
   - 域名：如需通过域名直接访问，请在此配置域名并将域名解析到服务器
   - 允许外部访问：如你需通过`IP+Port`直接访问，请勾选，如你已经设置了域名，请不要勾选此处
   - 端口：默认`8088`，可自行修改
4. 提交后面板会自动进行应用初始化，大概需要`1-3`分钟，初始化完成后即可访问。

### 访问 Dify

你可以先前往管理员初始化页面设置设置管理员账户：

```bash
# 使用域名
http://yourdomain/install

# 使用IP+端口

http://your_server_ip:8088/install
```

Dify 主页面：

```bash
# 使用域名
http://yourdomain/

# 使用IP+端口

http://your_server_ip:8088/
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/install-self-hosted/bt-panel.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Docker Compose 部署
> 来源：`zh-hans/getting-started/install-self-hosted/docker-compose.mdx`

### 前提条件

> 安装 Dify 之前, 请确保你的机器已满足最低安装要求：
>
> * CPU >= 2 Core
> * RAM >= 4 GiB

<table>
  <thead>
    <tr>
      <th>操作系统</th>
      <th>软件</th>
      <th>描述</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>macOS 10.14 or later</td>
      <td>Docker Desktop</td>
      <td>为 Docker 虚拟机（VM）至少分配 2 个虚拟 CPU(vCPU) 和 8GB 初始内存，否则安装可能会失败。有关更多信息，请参考 <a href="https://docs.docker.com/desktop/install/mac-install/">《在 Mac 内安装 Docker 桌面端》</a>。</td>
    </tr>
    <tr>
      <td>Linux platforms</td>
      <td>
        <p>Docker 19.03 or later</p>
        <p>Docker Compose 1.28 or later</p>
      </td>
      <td>请参阅<a href="https://docs.docker.com/engine/install/">安装 Docker</a> 和<a href="https://docs.docker.com/compose/install/">安装 Docker Compose</a> 以获取更多信息。</td>
    </tr>
    <tr>
      <td>Windows with WSL 2 enabled</td>
      <td>
        <p>Docker Desktop</p>
        <p></p>
      </td>
      <td>我们建议将源代码和其他数据绑定到 Linux 容器中时，将其存储在 Linux 文件系统中，而不是 Windows 文件系统中。有关更多信息，请参阅<a href="https://docs.docker.com/desktop/windows/install/#wsl-2-backend">使用 WSL 2 后端在 Windows 上安装 Docker Desktop</a>。</td>
    </tr>
  </tbody>
</table>
### 克隆 Dify 代码仓库

克隆 Dify 源代码至本地环境。

```bash
# 假设当前最新版本为 0.15.3
git clone https://github.com/langgenius/dify.git --branch 0.15.3
```

### 启动 Dify

1.  进入 Dify 源代码的 Docker 目录

    ```bash
    cd dify/docker
    ```
2.  复制环境配置文件

    ```bash
    cp .env.example .env
    ```
3.  启动 Docker 容器

    根据你系统上的 Docker Compose 版本，选择合适的命令来启动容器。你可以通过 `$ docker compose version` 命令检查版本，详细说明请参考 [Docker 官方文档](https://docs.docker.com/compose/#compose-v2-and-the-new-docker-compose-command)：

    * 如果版本是 Docker Compose V2，使用以下命令：

    ```bash
    docker compose up -d
    ```

    * 如果版本是 Docker Compose V1，使用以下命令：

    ```bash
    docker-compose up -d
    ```

运行命令后，你应该会看到类似以下的输出，显示所有容器的状态和端口映射：

```Shell
[+] Running 11/11
 ✔ Network docker_ssrf_proxy_network  Created                                                                 0.1s 
 ✔ Network docker_default             Created                                                                 0.0s 
 ✔ Container docker-redis-1           Started                                                                 2.4s 
 ✔ Container docker-ssrf_proxy-1      Started                                                                 2.8s 
 ✔ Container docker-sandbox-1         Started                                                                 2.7s 
 ✔ Container docker-web-1             Started                                                                 2.7s 
 ✔ Container docker-weaviate-1        Started                                                                 2.4s 
 ✔ Container docker-db-1              Started                                                                 2.7s 
 ✔ Container docker-api-1             Started                                                                 6.5s 
 ✔ Container docker-worker-1          Started                                                                 6.4s 
 ✔ Container docker-nginx-1           Started                                                                 7.1s
```

最后检查是否所有容器都正常运行：

```bash
docker compose ps
```

在这个输出中，你应该可以看到包括 3 个业务服务 `api / worker / web`，以及 6 个基础组件 `weaviate / db / redis / nginx / ssrf_proxy / sandbox` 。

```bash
NAME                  IMAGE                              COMMAND                   SERVICE      CREATED              STATUS                        PORTS
docker-api-1          langgenius/dify-api:0.6.13         "/bin/bash /entrypoi…"   api          About a minute ago   Up About a minute             5001/tcp
docker-db-1           postgres:15-alpine                 "docker-entrypoint.s…"   db           About a minute ago   Up About a minute (healthy)   5432/tcp
docker-nginx-1        nginx:latest                       "sh -c 'cp /docker-e…"   nginx        About a minute ago   Up About a minute             0.0.0.0:80->80/tcp, :::80->80/tcp, 0.0.0.0:443->443/tcp, :::443->443/tcp
docker-redis-1        redis:6-alpine                     "docker-entrypoint.s…"   redis        About a minute ago   Up About a minute (healthy)   6379/tcp
docker-sandbox-1      langgenius/dify-sandbox:0.2.1      "/main"                   sandbox      About a minute ago   Up About a minute             
docker-ssrf_proxy-1   ubuntu/squid:latest                "sh -c 'cp /docker-e…"   ssrf_proxy   About a minute ago   Up About a minute             3128/tcp
docker-weaviate-1     semitechnologies/weaviate:1.19.0   "/bin/weaviate --hos…"   weaviate     About a minute ago   Up About a minute             
docker-web-1          langgenius/dify-web:0.6.13         "/bin/sh ./entrypoin…"   web          About a minute ago   Up About a minute             3000/tcp
docker-worker-1       langgenius/dify-api:0.6.13         "/bin/bash /entrypoi…"   worker       About a minute ago   Up About a minute             5001/tcp
```

通过这些步骤，你可以在本地成功安装 Dify。

### 更新 Dify

进入 dify 源代码的 docker 目录，按顺序执行以下命令：

```bash
cd dify/docker
docker compose down
git pull origin main
docker compose pull
docker compose up -d
```

#### 同步环境变量配置 (重要！)

* 如果 `.env.example` 文件有更新，请务必同步修改你本地的 `.env` 文件。
* 检查 `.env` 文件中的所有配置项，确保它们与你的实际运行环境相匹配。你可能需要将 `.env.example` 中的新变量添加到 `.env` 文件中，并更新已更改的任何值。

### 访问 Dify

你可以先前往管理员初始化页面设置设置管理员账户：

```bash
# 本地环境
http://localhost/install

# 服务器环境
http://your_server_ip/install
```

Dify 主页面：

```bash
# 本地环境
http://localhost

# 服务器环境
http://your_server_ip
```

### 自定义配置

编辑 `.env` 文件中的环境变量值。然后重新启动 Dify：

```bash
docker compose down
docker compose up -d
```

完整的环境变量集合可以在 `docker/.env.example` 中找到。

### 更多

如果有疑问，请前往[常见问题](faq)帮助。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/install-self-hosted/docker-compose.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 环境变量说明
> 来源：`zh-hans/getting-started/install-self-hosted/environments.mdx`

> **信息提示：**

本文档可能未及时更新，请优先参考最新的配置文件：

- [docker-compose.yaml](https://github.com/langgenius/dify/blob/5f8d20b5b2bb51f19547467167b18d9c0f6ffbb8/docker/docker-compose.yaml)

- [.env.example](https://github.com/langgenius/dify/blob/5f8d20b5b2bb51f19547467167b18d9c0f6ffbb8/docker/.env.example)

## 公共变量

### CONSOLE_API_URL

控制台 API 后端 URL，用于拼接授权回调，传空则为同域。范例：`https://api.console.dify.ai`。

### CONSOLE_WEB_URL

控制台 web **前端** URL，用于拼接部分前端地址，以及 CORS 配置使用，传空则为同域。范例：`https://console.dify.ai`

### SERVICE_API_URL

Service API URL，用于 **前端** 展示 Service API Base URL，传空则为同域。范例：`https://api.dify.ai`

### APP_API_URL

WebApp API 后端 URL，用于声明 **前端** API 后端地址，传空则为同域。范例：`https://app.dify.ai`

### APP_WEB_URL

WebApp URL，用于预览文件、**前端** 展示下载用的 URL，以及作为多模型输入接口，传空则为同域。范例：`https://udify.app/`

### FILES_URL

文件预览或下载 URL 前缀，用于将文件预览或下载 URL 给前端展示或作为多模态模型输入； 为了防止他人伪造，图片预览 URL 是带有签名的，并且有 5 分钟过期时间。

***

## 服务端

### MODE

启动模式，仅使用 Docker 启动时可用，源码启动无效。

* api：启动 API Server。
* worker：启动异步队列 worker。

### DEBUG

调试模式，默认 false，建议本地开发打开该配置，可防止 monkey patch 导致的一些问题出现。

### FLASK_DEBUG

Flask 调试模式，开启可在接口输出 trace 信息，方便调试。

### SECRET_KEY

一个用于安全地签名会话 cookie 并在数据库上加密敏感信息的密钥。初次启动需要设置该变量。可以运行 `openssl rand -base64 42` 生成一个强密钥。

### DEPLOY_ENV

部署环境。

* PRODUCTION（默认）：生产环境。
* TESTING：测试环境，前端页面会有明显颜色标识，该环境为测试环境。

### LOG_LEVEL

日志输出等级，默认为 INFO。生产建议设置为 ERROR。

### MIGRATION_ENABLED

当设置为 true 时，会在容器启动时自动执行数据库迁移，仅使用 Docker 启动时可用，源码启动无效。源码启动需要在 api 目录手动执行 `flask db upgrade`。

### CHECK_UPDATE_URL

是否开启检查版本策略，若设置为 false，则不调用 `https://updates.dify.ai` 进行版本检查。由于目前国内无法直接访问基于 CloudFlare Worker 的版本接口，设置该变量为空，可以屏蔽该接口调用。

### TEXT_GENERATION_TIMEOUT_MS

默认 60000，单位为 ms，用于指定文本生成和工作流的超时时间，防止因某些进程运行超时而导致整体服务不可用。

### CSP_WHITELIST

内容安全策略（CSP）白名单，默认不开启。在此变量中填写被放行的域名列表后即视为开启，有助于减少潜在的 XSS 攻击。开启后，白名单将自动包含以下域名：

```url
*.sentry.io http://localhost:* http://127.0.0.1:* https://analytics.google.com https://googletagmanager.com https://api.github.com
```

### 容器启动相关配置

仅在使用 Docker 镜像或者 Docker-compose 启动时有效。

* DIFY_BIND_ADDRESS：API 服务绑定地址，默认：0.0.0.0，即所有地址均可访问。
* DIFY_PORT：API 服务绑定端口号，默认 5001。
* SERVER_WORKER_AMOUNT：API 服务 Server worker 数量，即 gevent worker 数量，公式：`cpu 核心数 x 2 + 1`。可参考：https://docs.gunicorn.org/en/stable/design.html#how-many-workers
* SERVER_WORKER_CLASS：默认为 gevent，若为 windows，可以切换为 sync 或 solo。
* GUNICORN_TIMEOUT：请求处理超时时间，默认 200，建议 360，以支持更长的 sse 连接时间。
* CELERY_WORKER_CLASS：和 `SERVER_WORKER_CLASS` 类似，默认 gevent，若为 windows，可以切换为 sync 或 solo。
* CELERY_WORKER_AMOUNT：Celery worker 数量，默认为 1，按需设置。
* HTTP_PROXY：HTTP 代理地址，用于解决国内无法访问 OpenAI、HuggingFace 的问题。注意，若代理部署在宿主机 (例如 `http://127.0.0.1:7890`)，此处代理地址应当和接入本地模型时一样，使用 Docker 容器内部的宿主机地址（例如 `http://192.168.1.100:7890` 或 `http://172.17.0.1:7890`）。
* HTTPS_PROXY：HTTPS 代理地址，用于解决国内无法访问 OpenAI、HuggingFace 的问题。同上。

### 数据库配置

数据库使用 PostgreSQL，请使用 public schema。

* DB_USERNAME：用户名
* DB_PASSWORD：密码
* DB_HOST：数据库 host
* DB_PORT：数据库端口号，默认 5432
* DB_DATABASE：数据库 database
* SQLALCHEMY_POOL_SIZE：数据库连接池大小，默认 30 个连接数，可适当增加。
* SQLALCHEMY_POOL_RECYCLE：数据库连接池回收时间，默认 3600 秒。
* SQLALCHEMY_ECHO：是否打印 SQL，默认 false。

### Redis 配置

该 Redis 配置用于缓存以及对话时的 pub/sub。

* REDIS_HOST：Redis host
* REDIS_PORT：Redis port，默认 6379
* REDIS_DB：Redis Database，默认为 0，请和 Session Redis、Celery Broker 分开用不同 Database。
* REDIS_USERNAME：Redis 用户名，默认为空
* REDIS_PASSWORD：Redis 密码，默认为空，强烈建议设置密码。
* REDIS_USE_SSL：是否使用 SSL 协议进行连接，默认 false
* REDIS_USE_SENTINEL：使用 Redis Sentinel 连接 Redis 服务器
* REDIS_SENTINELS：哨兵节点，格式：`<sentinel1_ip>:<sentinel1_port>,<sentinel2_ip>:<sentinel2_port>,<sentinel3_ip>:<sentinel3_port>`
* REDIS_SENTINEL_SERVICE_NAME：哨兵服务名，同 Master Name
* REDIS_SENTINEL_USERNAME：哨兵的用户名
* REDIS_SENTINEL_PASSWORD：哨兵的密码
* REDIS_SENTINEL_SOCKET_TIMEOUT：哨兵超时时间，默认值：0.1，单位：秒

### Celery 配置

* CELERY_BROKER_URL

  格式如下（直连模式）：

  ```
  redis://<redis_username>:<redis_password>@<redis_host>:<redis_port>/<redis_database>
  ```

  范例：`redis://:difyai123456@redis:6379/1`

  哨兵模式：

  ```
  sentinel://<sentinel_username>:<sentinel_password>@<sentinel_host>:<sentinel_port>/<redis_database>
  ```

  范例：`sentinel://localhost:26379/1;sentinel://localhost:26380/1;sentinel://localhost:26381/1`

* BROKER_USE_SSL

  若设置为 true，则使用 SSL 协议进行连接，默认 false。

* CELERY_USE_SENTINEL

  若设置为 true，则启用哨兵模式，默认 false。

* CELERY_SENTINEL_MASTER_NAME

  哨兵的服务名，即 Master Name。

* CELERY_SENTINEL_SOCKET_TIMEOUT

  哨兵连接超时时间，默认值：0.1，单位：秒。

### CORS 配置

用于设置前端跨域访问策略。

* CONSOLE_CORS_ALLOW_ORIGINS

  控制台 CORS 跨域策略，默认为 `*`，即所有域名均可访问。
* WEB_API_CORS_ALLOW_ORIGINS

  WebAPP CORS 跨域策略，默认为 `*`，即所有域名均可访问。

详细配置可参考：[跨域 / 身份相关指南](https://docs.dify.ai/v/zh-hans/learn-more/faq/install-faq#id-3.-an-zhuang-shi-hou-wu-fa-deng-lu-deng-lu-cheng-gong-dan-hou-xu-jie-kou-jun-ti-shi-401)

### 文件存储配置

用于存储知识库上传的文件、团队 / 租户的加密密钥等等文件。

* STORAGE_TYPE

  存储设施类型

  * local（默认）：本地文件存储，若选择此项则需要设置下方 `STORAGE_LOCAL_PATH` 配置。
  * s3：S3 对象存储，若选择此项则需要设置下方 S3_ 开头的配置。
  * azure-blob：Azure Blob 存储，若选择此项则需要设置下方 AZURE_BLOB_ 开头的配置。
  * aliyun-oss：阿里云 OSS 存储，若选择此项则需要设置下方 ALIYUN_OSS_ 开头的配置。
  * huawei-obs：Huawei OBS 存储，若选择此项则需要设置下方 HUAWEI_OBS_ 开头的配置。
  * volcengine-tos：Volcengine TOS 存储，若选择此项则需要设置下方 VOLCENGINE_TOS_ 开头的配置。
  * tencent-cos：腾讯云 COS 存储，若选择此项则需要设置下方 TENCENT_COS_ 开头的配置。

* STORAGE_LOCAL_PATH

  默认为 storage，即存储在当前目录的 storage 目录下。若使用 Docker 或 Docker-compose 进行部署，请务必将两个容器中 `/app/api/storage` 目录挂载到同一个本机目录，否则可能会出现文件找不到的报错。

* S3_ENDPOINT：S3 端点地址
* S3_BUCKET_NAME：S3 桶名称
* S3_ACCESS_KEY：S3 Access Key
* S3_SECRET_KEY：S3 Secret Key
* S3_REGION：S3 地域信息，如：us-east-1
* AZURE_BLOB_ACCOUNT_NAME: your-account-name 如 'difyai'
* AZURE_BLOB_ACCOUNT_KEY: your-account-key 如 'difyai'
* AZURE_BLOB_CONTAINER_NAME: your-container-name 如 'difyai-container'
* AZURE_BLOB_ACCOUNT_URL: 'https://your_account_name.blob.core.windows.net'
* ALIYUN_OSS_BUCKET_NAME: your-bucket-name 如 'difyai'
* ALIYUN_OSS_ACCESS_KEY: your-access-key 如 'difyai'
* ALIYUN_OSS_SECRET_KEY: your-secret-key 如 'difyai'
* ALIYUN_OSS_ENDPOINT: https://oss-ap-southeast-1-internal.aliyuncs.com # 参考[文档](https://help.aliyun.com/zh/oss/user-guide/regions-and-endpoints)
* ALIYUN_OSS_REGION: ap-southeast-1 # 参考[文档](https://help.aliyun.com/zh/oss/user-guide/regions-and-endpoints)
* ALIYUN_OSS_AUTH_VERSION: v4
* ALIYUN_OSS_PATH: your-path # 路径不要使用斜线 "/" 开头，阿里云 OSS 不支持。参考[文档](https://api.aliyun.com/troubleshoot?q=0016-00000005)
* HUAWEI_OBS_BUCKET_NAME: your-bucket-name 如 'difyai'
* HUAWEI_OBS_SECRET_KEY: your-secret-key 如 'difyai'
* HUAWEI_OBS_ACCESS_KEY: your-access-key 如 'difyai'
* HUAWEI_OBS_SERVER: your-server-url # 参考[文档](https://support.huaweicloud.com/sdk-python-devg-obs/obs_22_0500.html)。
* VOLCENGINE_TOS_BUCKET_NAME: your-bucket-name 如 'difyai'。
* VOLCENGINE_TOS_SECRET_KEY: your-secret-key 如 'difyai'。
* VOLCENGINE_TOS_ACCESS_KEY: your-access-key 如 'difyai'。
* VOLCENGINE_TOS_REGION: your-region 如 'cn-guangzhou' # 参考[文档](https://www.volcengine.com/docs/6349/107356)。
* VOLCENGINE_TOS_ENDPOINT: your-endpoint 如 'tos-cn-guangzhou.volces.com' # 参考[文档](https://www.volcengine.com/docs/6349/107356)。
* TENCENT_COS_BUCKET_NAME: your-bucket-name 如 'difyai'
* TENCENT_COS_SECRET_KEY: your-secret-key 如 'difyai'
* TENCENT_COS_SECRET_ID: your-secret-id 如 'difyai'
* TENCENT_COS_REGION: COS 地域信息，参考[文档](https://cloud.tencent.com/document/product/436/6224)。
* TENCENT_COS_SCHEME: 指定使用 http/https 协议来访问 COS。

### 向量数据库配置

* VECTOR_STORE

  **可使用的枚举类型包括：**

  * `weaviate`
  * `qdrant`
  * `milvus`
  * `zilliz` 与 `milvus` 一致
  * `myscale`
  * `pinecone` (暂未开放)
  * `tidb_vector`
  * `analyticdb`
  * `couchbase`
  * `oceanbase`
  * `tablestore`
  * `lindorm`
  * `tencent`
  * `matrixone`

* WEAVIATE_ENDPOINT

  Weaviate 端点地址，如：`http://weaviate:8080`。

* WEAVIATE_API_KEY

  连接 Weaviate 使用的 api-key 凭据。

* WEAVIATE_BATCH_SIZE

  Weaviate 批量创建索引 Object 的数量，默认 100。可参考此[文档](https://weaviate.io/developers/weaviate/manage-data/import#how-to-set-batch-parameters)。

* WEAVIATE_GRPC_ENABLED

  是否使用 gRPC 方式与 Weaviate 进行交互，开启后性能会大大增加，本地可能无法使用，默认为 true。

* QDRANT_URL

  Qdrant 端点地址，如：`https://your-qdrant-cluster-url.qdrant.tech/`

* QDRANT_API_KEY

  连接 Qdrant 使用的 api-key 凭据。

* PINECONE_API_KEY

  连接 Pinecone 使用的 api-key 凭据。

* PINECONE_ENVIRONMENT

  Pinecone 所在的环境，如：`us-east4-gcp`

* MILVUS_URI

  Milvus 的 URI 配置。例如：`http://host.docker.internal:19530`。对于 [Zilliz Cloud](https://docs.zilliz.com.cn/docs/free-trials)，请将 URI 和 TOKEN 分别设置为 Public Endpoint 和 API Key。

* MILVUS_TOKEN

  Milvus TOKEN 配置，默认为空。

* MILVUS_USER

  Milvus 用户名配置，默认为空。

* MILVUS_PASSWORD

  Milvus 密码配置，默认为空。

* MYSCALE_HOST

  MyScale host 配置。

* MYSCALE_PORT

  MyScale port 配置。

* MYSCALE_USER

  MyScale 用户名配置，默认为 `default`。

* MYSCALE_PASSWORD

  MyScale 密码配置，默认为空。

* MYSCALE_DATABASE

  MyScale 数据库配置，默认为 `default`。

* MYSCALE_FTS_PARAMS

  MyScale 全文搜索配置，如需多语言支持，请参考 [MyScale 文档](https://myscale.com/docs/en/text-search/#understanding-fts-index-parameters)，默认为空（仅支持英语）。

* TIDB_VECTOR_HOST

  TiDB Vector host 配置，如：`xxx.eu-central-1.xxx.tidbcloud.com`

* TIDB_VECTOR_PORT

  TiDB Vector 端口号配置，如：`4000`

* TIDB_VECTOR_USER

  TiDB Vector 用户配置，如：`xxxxxx.root`

* TIDB_VECTOR_PASSWORD

  TiDB Vector 密码配置

* TIDB_VECTOR_DATABASE

  TiDB Vector 数据库配置，如：`dify`

* ANALYTICDB_KEY_ID

  用于阿里云 OpenAPI 认证的访问密钥 ID。请阅读 [Analyticdb 文档](https://help.aliyun.com/zh/analyticdb/analyticdb-for-postgresql/support/create-an-accesskey-pair) 来创建你的 AccessKey。

* ANALYTICDB_KEY_SECRET

  用于阿里云 OpenAPI 认证的访问密钥秘密。

* ANALYTICDB_INSTANCE_ID

  你的 AnalyticDB 实例的唯一标识符，例如 `gp-xxxxxx`。请阅读 [Analyticdb 文档](https://help.aliyun.com/zh/analyticdb/analyticdb-for-postgresql/getting-started/create-an-instance-1) 来创建你的实例。

* ANALYTICDB_REGION_ID

  AnalyticDB 实例所在区域的标识符，例如 `cn-hangzhou`。

* ANALYTICDB_ACCOUNT

  用于连接 AnalyticDB 实例的账户名称。请阅读 [Analyticdb 文档](https://help.aliyun.com/zh/analyticdb/analyticdb-for-postgresql/getting-started/createa-a-privileged-account) 来创建账户。

* ANALYTICDB_PASSWORD

  用于连接 AnalyticDB 实例的账户密码。

* ANALYTICDB_NAMESPACE

  在 AnalyticDB 实例内要操作的命名空间 (schema)，例如 `dify`。如果此命名空间不存在，将自动创建。

* ANALYTICDB_NAMESPACE_PASSWORD

  命名空间 (schema) 的密码。如果命名空间不存在，将使用此密码进行创建。

* COUCHBASE_CONNECTION_STRING

  Couchbase 集群的连接 string 字符串。

* COUCHBASE_USER

  数据库用户名。

* COUCHBASE_PASSWORD

  数据库密码。

* COUCHBASE_BUCKET_NAME

   Bucket 名称。

* COUCHBASE_SCOPE_NAME

   Scope 名称。

* OCEANBASE_VECTOR_HOST

  OceanBase Vector 数据库的 Host。

* OCEANBASE_VECTOR_PORT

  OceanBase Vector 数据库的端口。

* OCEANBASE_VECTOR_USER

  OceanBase Vector 数据库的用户名。

* OCEANBASE_VECTOR_PASSWORD

  OceanBase Vector 数据库的密码。

* OCEANBASE_VECTOR_DATABASE

  OceanBase Vector 数据库的库名。

* OCEANBASE_CLUSTER_NAME

  OceanBase 集群名，仅用于 Docker 部署。

* OCEANBASE_MEMORY_LIMIT

  OceanBase 内存使用上限，仅用于 Docker 部署。

* TABLESTORE_ENDPOINT

  Tablestore 访问 Endpoint。

* TABLESTORE_INSTANCE_NAME

  Tablestore 访问实例名。

* TABLESTORE_ACCESS_KEY_ID

  Tablestore 访问 ID。

* TABLESTORE_ACCESS_KEY_SECRET

  Tablestore 访问密钥。

* LINDORM_URL

  LINDORM 搜索引擎地址，可从[控制台](https://lindorm.console.aliyun.com/) 获得。

* LINDORM_USERNAME

  LINDORM 用户名

* LINDORM_PASSWORD

  LINDORM 访问密码

* TENCENT_VECTOR_DB_URL

  腾讯云向量数据库访问地址，[控制台](https://console.cloud.tencent.com/vdb) 获得。

* TENCENT_VECTOR_DB_API_KEY

  向量数据库服务端的API密钥（密码），用于进行身份认证。 [密钥管理](https://cloud.tencent.com/document/product/1709/95108)。

* TENCENT_VECTOR_DB_USERNAME

  向量数据库账号，默认root， [账号与权限管理](https://cloud.tencent.com/document/product/1709/115833)。

* TENCENT_VECTOR_DB_TIMEOUT

  设置默认请求超时时间。

* TENCENT_VECTOR_DB_DATABASE

  数据库（Database）是按照数据结构来组织、存储和管理数据的仓库，一个实例可以创建多个 Database。
  [新建Database](https://cloud.tencent.com/document/product/1709/95822)。

* TENCENT_VECTOR_DB_SHARD

  指定分片数（Shards）。

* TENCENT_VECTOR_DB_REPLICAS

  指定副本数（Replica）。

* TENCENT_VECTOR_DB_ENABLE_HYBRID_SEARCH

  指定是否开启HybridSearch。[稀疏向量文档](https://cloud.tencent.com/document/product/1709/110110)。

* MATRIXONE_HOST

  Matrxone 数据库 host 配置，默认为 matrixone。

* MATRIXONE_PORT

  Matrxone 数据库 port 配置，默认为 6001。

* MATRIXONE_USER

  Matrxone 数据库 user 配置，默认为 dump。

* MATRIXONE_PASSWORD

  Matrxone 数据库 password 配置，默认为 111。

* MATRIXONE_DATABASE

  Matrxone 数据库 database 配置，默认为 dify。

### 知识库配置

* UPLOAD_FILE_SIZE_LIMIT

  上传文件大小限制，默认 15M

* UPLOAD_FILE_BATCH_LIMIT

  每次上传文件数上限，默认 5 个。

* ETL_TYPE

  **可使用的枚举类型包括：**

  * dify：Dify 自研文件 Extract 方案
  * Unstructured：Unstructured.io 文件 Extract 方案

* UNSTRUCTURED_API_URL

  Unstructured API 路径，当 ETL_TYPE 为 Unstructured 需要配置。

  如：`http://unstructured:8000/general/v0/general`

* TOP_K_MAX_VALUE

  RAG 的最大 top-k 值，默认值为 10。

### 多模态模型配置

* MULTIMODAL_SEND_IMAGE_FORMAT

  多模态模型输入时，发送图片的格式，默认为 `base64`，可选 `url`。 `url` 模式下，调用的延迟会比 `base64` 模式下低，一般建议使用兼容更好的 `base64` 模式。 若配置为 `url`，则需要将 `FILES_URL` 配置为外部可访问的地址，以便多模态模型可以访问到图片。

* UPLOAD_IMAGE_FILE_SIZE_LIMIT

  上传图片文件大小限制，默认 10M。

### Sentry 配置

用于应用监控和错误日志跟踪。

* SENTRY_DSN

  Sentry DSN 地址，默认为空，为空时则所有监控信息均不上报 Sentry。

* SENTRY_TRACES_SAMPLE_RATE

  Sentry events 的上报比例，若为 0.01，则为 1%。

* SENTRY_PROFILES_SAMPLE_RATE

  Sentry profiles 的上报比例，若为 0.01，则为 1%。

### Notion 集成配置

Notion 集成配置，变量可通过申请 Notion integration 获取：[https://www.notion.so/my-integrations](https://www.notion.so/my-integrations)

* NOTION_CLIENT_ID
* NOTION_CLIENT_SECRET

### 邮件相关配置

* MAIL_TYPE
  * resend
    * MAIL_DEFAULT_SEND_FROM：发件人的电子邮件名称，例如：no-reply [no-reply@dify.ai](mailto:no-reply@dify.ai)，非必需。
    * RESEND_API_KEY：用于 Resend 邮件提供程序的 API 密钥，可以从 API 密钥获取。
  * smtp
    * SMTP_SERVER：SMTP 服务器地址
    * SMTP_PORT：SMTP 服务器端口号
    * SMTP_USERNAME：SMTP 用户名
    * SMTP_PASSWORD：SMTP 密码
    * SMTP_USE_TLS：是否使用 TLS，默认为 false
    * MAIL_DEFAULT_SEND_FROM：发件人的电子邮件名称，例如：no-reply [no-reply@dify.ai](mailto:no-reply@dify.ai)，非必需。

### 模型供应商 & 工具 位置配置

用于指定应用中可以使用的模型供应商和工具。你可以自定义哪些工具和模型供应商可用，以及它们在应用界面中的顺序和包含 / 排除情况。

详见可用的 [工具](https://github.com/langgenius/dify/blob/main/api/core/tools/provider/_position.yaml) 和 [模型供应商](https://github.com/langgenius/dify/blob/main/api/core/model_runtime/model_providers/_position.yaml)。

* POSITION_TOOL_PINS

  将列出的工具固定在列表顶部，确保它们在界面中置顶出现。（使用逗号分隔的值，**中间不留空格**。）

  示例: `POSITION_TOOL_PINS=bing,google`

* POSITION_TOOL_INCLUDES

  指定要在应用中包含的工具。只有此处列出的工具才可用。如果未设置，则除非在 POSITION_TOOL_EXCLUDES 中指定，否则所有工具都会包含在内。（使用逗号分隔的值，**中间不留空格**。）

  示例: `POSITION_TOOL_INCLUDES=bing,google`

* POSITION_TOOL_EXCLUDES

  排除在应用中显示或使用的特定工具。此处列出的工具将从可用选项中省略，除非它们被固定。（使用逗号分隔的值，**中间不留空格**。）

  示例: `POSITION_TOOL_EXCLUDES=yahoo,wolframalpha`

* POSITION_PROVIDER_PINS

  将列出的模型供应商固定在列表顶部，确保它们在界面中置顶出现。（使用逗号分隔的值，**中间不留空格**。）

  示例: `POSITION_PROVIDER_PINS=openai,openllm`

* POSITION_PROVIDER_INCLUDES

  指定要在应用中包含的模型供应商。只有此处列出的供应商才可用。如果未设置，则除非在 POSITION_PROVIDER_EXCLUDES 中指定，否则所有供应商都会包含在内。（使用逗号分隔的值，**中间不留空格**。）

  示例: `POSITION_PROVIDER_INCLUDES=cohere,upstage`

* POSITION_PROVIDER_EXCLUDES

  排除在应用中显示特定模型供应商。此处列出的供应商将从可用选项中移除，除非它们被置顶。（使用逗号分隔的值，**中间不留空格**。）

  示例: `POSITION_PROVIDER_EXCLUDES=openrouter,ollama`

### 其他

* INVITE_EXPIRY_HOURS：成员邀请链接有效时间（小时），默认：72。
* HTTP_REQUEST_NODE_MAX_TEXT_SIZE：workflow 工作流中 HTTP 请求节点的最大文本大小，默认 1MB。
* HTTP_REQUEST_NODE_MAX_BINARY_SIZE：workflow 工作流中 HTTP 请求节点的最大二进制大小，默认 10MB。

***

## Web 前端

### SENTRY_DSN

Sentry DSN 地址，默认为空，为空时则所有监控信息均不上报 Sentry。

## 已废弃

### CONSOLE_URL

> ⚠️ 修改于 0.3.8，于 0.4.9 废弃，替代为：`CONSOLE_API_URL` 和 `CONSOLE_WEB_URL`。

控制台 URL，用于拼接授权回调、控制台前端地址，以及 CORS 配置使用，传空则为同域。范例：`https://console.dify.ai`。

### API_URL

> ⚠️ 修改于 0.3.8，于 0.4.9 废弃，替代为 `SERVICE_API_URL`。

API Url，用于给前端展示 Service API Base Url，传空则为同域。范例：`https://api.dify.ai`

### APP_URL

> ⚠️ 修改于 0.3.8，于 0.4.9 废弃，替代为 `APP_API_URL` 和 `APP_WEB_URL`。

WebApp Url，用于显示文件预览或下载 URL 到前端作为多模型输入，传空则为同域。范例：`https://udify.app/`

### Session 配置

> ⚠️ 该配置从 0.3.24 版本起废弃。

仅 API 服务使用，用于验证接口身份。

* SESSION_TYPE： Session 组件类型
  * redis（默认）
    选择此项，则需要设置下方 SESSION_REDIS_ 开头的环境变量。
  * sqlalchemy
    选择此项，则使用当前数据库连接，并使用 sessions 表进行读写 session 记录。

* SESSION_REDIS_HOST：Redis host
* SESSION_REDIS_PORT：Redis port，默认 6379
* SESSION_REDIS_DB：Redis Database，默认为 0，请和 Redis、Celery Broker 分开用不同 Database。
* SESSION_REDIS_USERNAME：Redis 用户名，默认为空
* SESSION_REDIS_PASSWORD：Redis 密码，默认为空，强烈建议设置密码。
* SESSION_REDIS_USE_SSL：是否使用 SSL 协议进行连接，默认 false

### Cookie 策略配置

> ⚠️ 该配置从 0.3.24 版本起废弃。

用于设置身份校验的 Session Cookie 浏览器策略。

* COOKIE_HTTPONLY

  Cookie HttpOnly 配置，默认为 true。

* COOKIE_SAMESITE

  Cookie SameSite 配置，默认为 Lax。

* COOKIE_SECURE

  Cookie Secure 配置，默认为 false。

## 文档分段长度配置

### INDEXING_MAX_SEGMENTATION_TOKENS_LENGTH 

文档分段长度配置，用于控制处理长文本时的分段大小。默认值：4000。

**较大分段**
- 可在单个分段内保留更多上下文，适合需要处理复杂或上下文相关任务的场景。
- 分段数量减少，从而降低处理时间和存储需求。

**较小分段**
- 提供更高的粒度，适合精确提取或总结文本内容。
- 减少超出模型 token 限制的风险，更适配限制严格的模型。

**配置建议**
- 较大分段：适合上下文依赖性强的任务，例如情感分析或长文档总结。
- 较小分段：适合精细分析场景，例如关键词提取或段落级内容处理。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/install-self-hosted/environments.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 常见问题
> 来源：`zh-hans/getting-started/install-self-hosted/faq.mdx`

### 1. 长时间未收到密码重置邮件应如何处理？

你需要在 `.env` 文件内配置 `Mail` 参数项，详细说明请参考 [《环境变量说明：邮件相关配置》](./zh-hans/getting-started/install-self-hosted/environments#you-jian-xiang-guan-pei-zhi)。

修改配置后，运行以下命令重启服务。

```bash
docker compose down
docker compose up -d
```

如果依然没能收到邮件，请检查邮件服务是否正常，以及邮件是否进入了垃圾邮件列表。

### 2. 如果 workflow 太复杂超出节点上限如何处理？

在社区版你可以在`web/app/components/workflow/constants.ts` 手动调整 MAX\_TREE\_DEPTH 单条分支深度的上限，我们的默认值是 50，在这里要提醒自部署的情况下过深的分支可能会影响性能。

### 3. 如何指定工作流各节点的运行时间？

你可以在 `.env` 文件内修改 `TEXT_GENERATION_TIMEOUT_MS` 变量，调整各节点的运行时间，防止因某些进程运行超时而导致整体应用服务不可用。

### 4. 如何重置管理员密码？

如果你通过 Docker Compose 部署，你可以运行以下 Docker Compose 命令行重置密码。

```bash
docker exec -it docker-api-1 flask reset-password
```

请按照提示输入邮箱地址和新密码，例如：

```bash
dify@my-pc:~/hello/dify/docker$ docker compose up -d
[+] Running 9/9
 ✔ Container docker-web-1         Started                                                              0.1s 
 ✔ Container docker-sandbox-1     Started                                                              0.1s 
 ✔ Container docker-db-1          Started                                                              0.1s 
 ✔ Container docker-redis-1       Started                                                              0.1s 
 ✔ Container docker-weaviate-1    Started                                                              0.1s 
 ✔ Container docker-ssrf_proxy-1  Started                                                              0.1s 
 ✔ Container docker-api-1         Started                                                              0.1s 
 ✔ Container docker-worker-1      Started                                                              0.1s 
 ✔ Container docker-nginx-1       Started                                                              0.1s 
dify@my-pc:~/hello/dify/docker$ docker exec -it docker-api-1 flask reset-password
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml
sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml
Email: hello@dify.ai
New password: newpassword4567
Password confirm: newpassword4567
Password reset successfully.
```

### 5. 如何修改页面端口？

如果你使用 Docker Compose 部署，你可以通过修改 `.env` 配置来自定义 Dify 的访问端口。

你需要修改 Nginx 相关配置：

```bash
EXPOSE_NGINX_PORT=80
EXPOSE_NGINX_SSL_PORT=443
```

其他相关的部署问题请参考[本地部署相关](../../learn-more/faq/install-faq)。

### 6. docker-api-1 出现数据库连接报错如何处理？

**问题详情**：访问 `http://localhost` 时提示 `Internal Server Error` 错误；且 `docker-api-1` 的日志中出现了类似错误：

```bash
FATAL:  no pg_hba.conf entry for host "172.19.0.7", user "postgres", database "dify", no encryption
```

**解决办法**：修改 db 容器下的 `/var/lib/postgresql/pgdata/pg_hba.conf`，将报错提示中所对应的网段添加至授权名单，例如：

```bash
docker exec -it docker-db-1 sh -c "echo 'host all all 172.19.0.0/16 trust' >> /var/lib/postgresql/data/pgdata/pg_hba.conf"
docker-compose restart
```

### 7. 如何修改知识库文件上传大小限制？

请修改 `.env` 文件中的 `UPLOAD_FILE_SIZE_LIMIT` 参数默认限制，同时还需要同步修改 `NGINX_CLIENT_MAX_BODY_SIZE` 参数的值以避免潜在异常。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/install-self-hosted/faq.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 使用源代码本地启动
> 来源：`zh-hans/getting-started/install-self-hosted/local-source-code.mdx`

## 前提条件

### 设置 Docker 和 Docker Compose

> 在安装 Dify 之前，请确保您的设备符合以下最低系统要求：
> - CPU >= 2 核
> - RAM >= 4 GiB

| 操作系统                | 软件                                          | 说明                                                                                                                                                                                                                                                                                         |
| ----------------------- | --------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| macOS 10.14 或更高版本  | Docker Desktop                                | 将 Docker 虚拟机(VM)设置为至少使用 2 个虚拟 CPU(vCPU)和 8 GB 的初始内存。否则，安装可能会失败。更多信息，请参考 [Docker Desktop for Mac 安装指南](https://docs.docker.com/desktop/mac/install/)。                                                                                          |
| Linux 平台              | Docker 19.03 或更高版本 Docker Compose 1.25.1 或更高版本 | 请参考 [Docker 安装指南](https://docs.docker.com/engine/install/) 和 [Docker Compose 安装指南](https://docs.docker.com/compose/install/) 了解如何分别安装 Docker 和 Docker Compose。                                                                                                 |
| 启用 WSL 2 的 Windows   | Docker Desktop                                | 我们建议将源代码和绑定到 Linux 容器的其他数据存储在 Linux 文件系统中，而不是 Windows 文件系统中。更多信息，请参考 [Windows 上使用 WSL 2 后端的 Docker Desktop 安装指南](https://docs.docker.com/desktop/windows/install/#wsl-2-backend)。                                                 |

> 如果需要使用 OpenAI TTS，系统必须安装 `FFmpeg` 才能正常运行。更多详情，请参考：[链接](https://docs.dify.ai/getting-started/install-self-hosted/install-faq#id-14.-what-to-do-if-this-error-occurs-in-text-to-speech)。

### 克隆 Dify 仓库

运行 git 命令克隆 [Dify 仓库](https://github.com/langgenius/dify)。

```Bash
git clone https://github.com/langgenius/dify.git
```

### 使用 Docker Compose 启动中间件

Dify 后端服务需要一系列用于存储（如 PostgreSQL / Redis / Weaviate（如果本地不可用））和扩展能力（如 Dify 的 [sandbox](https://github.com/langgenius/dify-sandbox) 和 [plugin-daemon](https://github.com/langgenius/dify-plugin-daemon) 服务）的中间件。通过运行以下命令使用 Docker Compose 启动中间件：

```Bash
cd docker
cp middleware.env.example middleware.env
docker compose -f docker-compose.middleware.yaml up -d
```

---

## 设置后端服务

后端服务包括：

1. API 服务：为前端服务和 API 访问提供 API 请求服务
2. Worker 服务：为数据集处理、工作区、清理等异步任务提供服务

### 环境准备

需要 Python 3.12。推荐使用 [pyenv](https://github.com/pyenv/pyenv) 快速安装 Python 环境。

要安装额外的 Python 版本，请使用 pyenv install。

```Bash
pyenv install 3.12
```

要切换到 "3.12" Python 环境，请使用以下命令：

```Bash
pyenv global 3.12
```

### 启动 API 服务

1. 导航到 `api` 目录：

    ```
    cd api
    ```

2. 准备环境变量配置文件

    ```
    cp .env.example .env
    ```

3. 生成随机密钥并替换 .env 文件中的 SECRET_KEY 值

    ```
    awk -v key="$(openssl rand -base64 42)" '/^SECRET_KEY=/ sub(/=.*/, "=" key) 1' .env > temp_env && mv temp_env .env
    ```

4. 安装依赖

    使用 [uv](https://docs.astral.sh/uv/getting-started/installation/) 管理依赖。
    通过运行以下命令使用 `uv` 安装所需依赖：

    ```
    uv sync
    ```

    > 对于 macOS：使用 `brew install libmagic` 安装 libmagic。

5. 执行数据库迁移

    执行数据库迁移到最新版本：

    ```
    uv run flask db upgrade
    ```

6. 启动 API 服务

    ```
    uv run flask run --host 0.0.0.0 --port=5001 --debug
    ```

    预期输出：

    ```
    * Debug mode: on
    INFO:werkzeug:WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
     * Running on all addresses (0.0.0.0)
     * Running on http://127.0.0.1:5001
    INFO:werkzeug:Press CTRL+C to quit
    INFO:werkzeug: * Restarting with stat
    WARNING:werkzeug: * Debugger is active!
    INFO:werkzeug: * Debugger PIN: 695-801-919
    ```

### 启动 Worker 服务

要从队列中消费异步任务，例如数据集文件导入和数据集文档更新，请按照以下步骤启动 Worker 服务：

- 对于 macOS 或 Linux

    ```
    uv run celery -A app.celery worker -P gevent -c 1 --loglevel INFO -Q dataset,generation,mail,ops_trace
    ```

    如果您使用 Windows 系统启动 Worker 服务，请使用以下命令：

- 对于 Windows

    ```
    uv run celery -A app.celery worker -P solo --without-gossip --without-mingle -Q dataset,generation,mail,ops_trace --loglevel INFO
    ```

    预期输出：

    ```
    -------------- celery@bwdeMacBook-Pro-2.local v5.4.0 (opalescent)
    --- ***** -----
    -- ******* ---- macOS-15.4.1-arm64-arm-64bit 2025-04-28 17:07:14
    - *** --- * ---
    - ** ---------- [config]
    - ** ---------- .> app:         app_factory:0x1439e8590
    - ** ---------- .> transport:   redis://:**@localhost:6379/1
    - ** ---------- .> results:     postgresql://postgres:**@localhost:5432/dify
    - *** --- * --- .> concurrency: 1 (gevent)
      -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
      --- ***** -----
      -------------- [queues]
      .> dataset          exchange=dataset(direct) key=dataset
      .> generation       exchange=generation(direct) key=generation
      .> mail             exchange=mail(direct) key=mail
      .> ops_trace        exchange=ops_trace(direct) key=ops_trace

    [tasks]
    . schedule.clean_embedding_cache_task.clean_embedding_cache_task
    . schedule.clean_messages.clean_messages
    . schedule.clean_unused_datasets_task.clean_unused_datasets_task
    . schedule.create_tidb_serverless_task.create_tidb_serverless_task
    . schedule.mail_clean_document_notify_task.mail_clean_document_notify_task
    . schedule.update_tidb_serverless_status_task.update_tidb_serverless_status_task
    . tasks.add_document_to_index_task.add_document_to_index_task
    . tasks.annotation.add_annotation_to_index_task.add_annotation_to_index_task
    . tasks.annotation.batch_import_annotations_task.batch_import_annotations_task
    . tasks.annotation.delete_annotation_index_task.delete_annotation_index_task
    . tasks.annotation.disable_annotation_reply_task.disable_annotation_reply_task
    . tasks.annotation.enable_annotation_reply_task.enable_annotation_reply_task
    . tasks.annotation.update_annotation_to_index_task.update_annotation_to_index_task
    . tasks.batch_clean_document_task.batch_clean_document_task
    . tasks.batch_create_segment_to_index_task.batch_create_segment_to_index_task
    . tasks.clean_dataset_task.clean_dataset_task
    . tasks.clean_document_task.clean_document_task
    . tasks.clean_notion_document_task.clean_notion_document_task
    . tasks.deal_dataset_vector_index_task.deal_dataset_vector_index_task
    . tasks.delete_account_task.delete_account_task
    . tasks.delete_segment_from_index_task.delete_segment_from_index_task
    . tasks.disable_segment_from_index_task.disable_segment_from_index_task
    . tasks.disable_segments_from_index_task.disable_segments_from_index_task
    . tasks.document_indexing_sync_task.document_indexing_sync_task
    . tasks.document_indexing_task.document_indexing_task
    . tasks.document_indexing_update_task.document_indexing_update_task
    . tasks.duplicate_document_indexing_task.duplicate_document_indexing_task
    . tasks.enable_segments_to_index_task.enable_segments_to_index_task
    . tasks.mail_account_deletion_task.send_account_deletion_verification_code
    . tasks.mail_account_deletion_task.send_deletion_success_task
    . tasks.mail_email_code_login.send_email_code_login_mail_task
    . tasks.mail_invite_member_task.send_invite_member_mail_task
    . tasks.mail_reset_password_task.send_reset_password_mail_task
    . tasks.ops_trace_task.process_trace_tasks
    . tasks.recover_document_indexing_task.recover_document_indexing_task
    . tasks.remove_app_and_related_data_task.remove_app_and_related_data_task
    . tasks.remove_document_from_index_task.remove_document_from_index_task
    . tasks.retry_document_indexing_task.retry_document_indexing_task
    . tasks.sync_website_document_indexing_task.sync_website_document_indexing_task

    2025-04-28 17:07:14,681 INFO [connection.py:22]  Connected to redis://:**@localhost:6379/1
    2025-04-28 17:07:14,684 INFO [mingle.py:40]  mingle: searching for neighbors
    2025-04-28 17:07:15,704 INFO [mingle.py:49]  mingle: all alone
    2025-04-28 17:07:15,733 INFO [worker.py:175]  celery@bwdeMacBook-Pro-2.local ready.
    2025-04-28 17:07:15,742 INFO [pidbox.py:111]  pidbox: Connected to redis://:**@localhost:6379/1.
    ```

---

## 设置 Web 服务

启动用于前端页面的 web 服务。

### 环境准备

要启动 web 前端服务，需要 [Node.js v22 (LTS)](http://nodejs.org/) 和 [PNPM v10](https://pnpm.io/)。

- 安装 NodeJS

  请访问 [https://nodejs.org/en/download](https://nodejs.org/en/download) 并选择适合您操作系统的 v18.x 或更高版本的安装包。推荐使用 LTS 版本进行常规使用。

- 安装 PNPM

  按照 [安装指南](https://pnpm.io/installation) 安装 PNPM。或者直接使用 `npm` 运行以下命令安装 `pnpm`。

    ```
    npm i -g pnpm
    ```

### 启动 Web 服务

1.  进入 web 目录

    ```
    cd web
    ```

2.  安装依赖

    ```
    pnpm install --frozen-lockfile
    ```

3.  准备环境变量配置文件

    在当前目录中创建一个名为 `.env.local` 的文件，并从 `.env.example` 复制内容。根据您的需求修改这些环境变量的值：

    ```
    # For production release, change this to PRODUCTION
    NEXT_PUBLIC_DEPLOY_ENV=DEVELOPMENT
    # The deployment edition, SELF_HOSTED or CLOUD
    NEXT_PUBLIC_EDITION=SELF_HOSTED
    # The base URL of console application, refers to the Console base URL of WEB service if console domain is
    # different from api or web app domain.
    # example: http://cloud.dify.ai/console/api
    NEXT_PUBLIC_API_PREFIX=http://localhost:5001/console/api
    # The URL for Web APP, refers to the Web App base URL of WEB service if web app domain is different from
    # console or api domain.
    # example: http://udify.app/api
    NEXT_PUBLIC_PUBLIC_API_PREFIX=http://localhost:5001/api

    # SENTRY
    NEXT_PUBLIC_SENTRY_DSN=
    NEXT_PUBLIC_SENTRY_ORG=
    NEXT_PUBLIC_SENTRY_PROJECT=
    ```

4.  构建 web 服务

    ```
    pnpm build
    ```

5.  启动 web 服务

    ```
    pnpm start
    ```

    预期输出：

    ```
       ▲ Next.js 15
       - Local:        http://localhost:3000
       - Network:      http://0.0.0.0:3000

     ✓ Starting...
     ✓ Ready in 73ms
    ```

### 访问 Dify

通过浏览器访问 [http://127.0.0.1:3000](http://127.0.0.1:3000/) 即可享受 Dify 所有激动人心的功能。

干杯！🍻

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/install-self-hosted/local-source-code.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 部署社区版
> 来源：`zh-hans/getting-started/install-self-hosted/readme.mdx`

Dify 社区版即开源版本，你可以通过以下两种方式之一部署 Dify 社区版：

* [Docker Compose 部署](./zh-hans/getting-started/install-self-hosted/docker-compose)
* [本地源码启动](./zh-hans/getting-started/install-self-hosted/local-source-code)

在 GitHub 上查看 [Dify 社区版](https://github.com/langgenius/dify)开源代码。

### 贡献代码

为了确保正确审查，所有代码贡献 - 包括来自具有直接提交更改权限的贡献者 - 都必须提交 PR 请求并在合并分支之前得到核心开发人员的批准。

我们欢迎所有人提交 PR！如果你愿意提供帮助，可以在 [贡献指南](https://github.com/langgenius/dify/blob/main/CONTRIBUTING_CN.md) 中了解有关如何为项目做出贡献的更多信息。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/install-self-hosted/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 单独启动前端 Docker 容器
> 来源：`zh-hans/getting-started/install-self-hosted/start-the-frontend-docker-container.mdx`

当单独开发后端时，可能只需要源码启动后端服务，而不需要本地构建前端代码并启动，因此可以直接通过拉取 docker 镜像并启动容器的方式来启动前端服务，以下为具体步骤：

### 直接使用 DockerHub 镜像

```Bash
docker run -it -p 3000:3000 -e CONSOLE_API_URL=http://127.0.0.1:5001 -e APP_API_URL=http://127.0.0.1:5001 langgenius/dify-web:latest
```

### 源码构建 Docker 镜像

1.  构建前端镜像

    ```
    cd web && docker build . -t dify-web
    ```
2.  启动前端镜像

    ```
    docker run -it -p 3000:3000 -e CONSOLE_API_URL=http://127.0.0.1:5001 -e APP_API_URL=http://127.0.0.1:5001 dify-web
    ```
3. 当控制台域名和 Web APP 域名不一致时，可单独设置 `CONSOLE_URL` 和 `APP_URL`
4. 本地访问 [http://127.0.0.1:3000](http://127.0.0.1:3000)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/install-self-hosted/start-the-frontend-docker-container.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 部署 Dify 到 Zeabur
> 来源：`zh-hans/getting-started/install-self-hosted/zeabur.mdx`

[Zeabur](https://zeabur.com) 是一个服务部署平台，可以通过一键部署的方式部署 Dify。本指南将指导你如何将 Dify 部署到 Zeabur。

## 前置要求

在开始之前，你需要以下内容：

- 一个 Zeabur 账户。如果你没有账户，可以在 [Zeabur](https://zeabur.com/) 注册一个免费账户。
- 升级你的 Zeabur 账户到开发者计划（每月 5 美元）。你可以从 [Zeabur 定价](https://zeabur.com/pricing) 了解更多信息。

## 部署 Dify 到 Zeabur

Zeabur 团队准备了一个一键部署模板，你只需点击下面的按钮即可开始：

[![Deploy to Zeabur](https://zeabur.com/button.svg)](https://zeabur.com/1D4DOW)

点击按钮后，你将被导航到 Zeabur 上的模板页面，你可以在那里查看部署的详细信息和说明。

<figure>![Zeabur Template Overview](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/getting-started/install-self-hosted/fc58c921d332857fb644d4c869162bb5.jpeg)<figcaption></figcaption></figure>

点击部署按钮后，你需要输入一个生成的域名，以便将域名绑定到你的 Dify 实例并注入到其他服务中作为环境变量。
然后选择你喜欢的区域，点击部署按钮，你的 Dify 实例将在几分钟内部署完成。

<figure>![Select Region](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/getting-started/install-self-hosted/43cdd302ca243f2a1d2475a857cc1e66.png)<figcaption></figcaption></figure>

部署完成后，你可以在 Zeabur 控制台中看到一个项目页面，如下图所示，你在部署过程中输入的域名将自动绑定到 NGINX 服务，你可以通过该域名访问你的 Dify 实例。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/getting-started/install-self-hosted/7aa82d91ab9e798245b9df18221637b2.png)

你也可以在 NGINX 服务页面的 Networking 选项卡中更改域名。你可以参考 [Zeabur 文档](https://zeabur.com/docs/deploy/domain-binding) 了解更多信息。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/install-self-hosted/zeabur.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 特性与技术规格
> 来源：`zh-hans/getting-started/readme/features-and-specifications.mdx`
> 摘要：对于已经熟悉 LLM 应用技术栈的技术人士来说，这份文档将是你了解 Dify 独特优势的捷径。让你能够明智地比较和选择，甚至向同事和朋友推荐。

> **信息提示：**

在 Dify，我们采用透明化的产品特性和技术规格政策，确保你在全面了解我们产品的基础上做出决策。这种透明度不仅有利于你的技术选型，也促进了社区成员对产品的深入理解和积极贡献。

### 项目基础信息

<table>
  <thead>
    <tr>
      <th>项目属性</th>
      <th>详细信息</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>项目设立</td>
      <td>2023 年 3 月</td>
    </tr>
    <tr>
      <td>开源协议</td>
      <td>[基于 Apache License 2.0 有限商业许可](./zh-hans/policies/open-source)</td>
    </tr>
    <tr>
      <td>官方研发团队</td>
      <td>超过 15 名全职员工</td>
    </tr>
    <tr>
      <td>社区贡献者</td>
      <td>超过 800 人（截止 2025 Q2）</td>
    </tr>
    <tr>
      <td>后端技术</td>
      <td>Python/Flask/PostgreSQL</td>
    </tr>
    <tr>
      <td>前端技术</td>
      <td>Next.js</td>
    </tr>
    <tr>
      <td>代码行数</td>
      <td>超过 13 万行</td>
    </tr>
    <tr>
      <td>发版周期</td>
      <td>平均每周一次</td>
    </tr>
  </tbody>
</table>

### 技术特性

<table>
  <thead>
    <tr>
      <th>特性类别</th>
      <th>详细信息</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>LLM 推理引擎</td>
      <td>Dify Runtime (自 v0.4 起移除了 LangChain)</td>
    </tr>
    <tr>
      <td>商业模型支持</td>
      <td><p><strong>10+ 家</strong>，包括 OpenAI 与 Anthropic</p><p>新的主流模型通常在 48 小时内完成接入</p></td>
    </tr>
    <tr>
      <td>MaaS 供应商支持</td>
      <td><strong>7 家</strong>，Hugging Face，Replicate，AWS Bedrock，NVIDIA，GroqCloud，together.ai，OpenRouter</td>
    </tr>
    <tr>
      <td>本地模型推理 Runtime 支持</td>
      <td><strong>6 家</strong>，Xoribits（推荐），OpenLLM，LocalAI，ChatGLM，Ollama，NVIDIA TIS</td>
    </tr>
    <tr>
      <td>OpenAI 接口标准模型接入支持</td>
      <td><strong>∞ 家</strong></td>
    </tr>
    <tr>
      <td>多模态技术</td>
      <td>
        <p>ASR 模型</p>
        <p>GPT-4o 规格的富文本模型</p>
      </td>
    </tr>
    <tr>
      <td>预置应用类型</td>
      <td>
        <p>对话型应用</p>
        <p>文本生成应用</p>
        <p>Agent</p>
        <p>工作流</p>
      </td>
    </tr>
    <tr>
      <td>Prompt 即服务编排</td>
      <td>
        <p>广受好评的可视化的 Prompt 编排界面，在同一个界面中修改 Prompt 并预览效果</p>
        <p><strong>编排模式</strong></p>
        <ul>
          <li>简易模式编排</li>
          <li>Assistant 模式编排</li>
          <li>Flow 模式编排</li>
        </ul>
        <p><strong>Prompt 变量类型</strong></p>
        <ul>
          <li>字符串</li>
          <li>单选枚举</li>
          <li>外部 API</li>
          <li>文件（Q3 即将推出）</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>Agentic Workflow 特性</td>
      <td>
        <p>行业领先的可视化流程编排界面，所见即所得的节点调试，可插拔的 DSL，原生的代码运行时，构建更复杂、可靠、稳定的 LLM 应用。</p>
        <p><strong>支持节点</strong></p>
        <ul>
          <li>LLM</li>
          <li>知识库检索</li>
          <li>问题分类</li>
          <li>条件分支</li>
          <li>代码执行</li>
          <li>模板转换</li>
          <li>HTTP 请求</li>
          <li>工具</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>RAG 特性</td>
      <td>
        <p>首创的可视化的知识库管理界面，支持分段预览和召回效果测试。</p>
        <p><strong>索引方式</strong></p>
        <ul>
          <li>关键词</li>
          <li>文本向量</li>
          <li>由 LLM 辅助的问题-分段模式</li>
        </ul>
        <p><strong>检索方式</strong></p>
        <ul>
          <li>关键词</li>
          <li>文本相似度匹配</li>
          <li>混合检索</li>
          <li>N 选 1 模式（即将下线）</li>
          <li>多路召回</li>
        </ul>
        <p><strong>召回优化技术</strong></p>
        <ul>
          <li>使用 ReRank 模型</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>ETL 技术</td>
      <td>
        <p>支持对 TXT、Markdown、PDF、HTML、DOC、CSV 等格式文件进行自动清洗，内置的 Unstructured 服务开启后可获得最大化支持。</p>
        <p>支持同步来自 Notion 的文档为知识库。</p>
        <p>支持同步网页为知识库。</p>
      </td>
    </tr>
    <tr>
      <td>向量数据库支持</td>
      <td>Qdrant（推荐），Weaviate，Zilliz/Milvus，Pgvector，Pgvector-rs，Chroma，OpenSearch，TiDB，Tencent Cloud VectorDB，Oracle，Relyt，Analyticdb，Couchbase，OceanBase，Tablestore，Lindorm，OpenGauss，Matrixone</td>
    </tr>
    <tr>
      <td>Agent 技术</td>
      <td>
        <p>ReAct，Function Call</p>
        <p><strong>工具支持</strong></p>
        <ul>
          <li>可调用 OpenAI Plugin 标准的工具</li>
          <li>可直接加载 OpenAPI Specification 的 API 作为工具</li>
        </ul>
        <p><strong>内置工具</strong></p>
        <ul>
          <li>40+ 款（截止 2024 Q2）</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>日志</td>
      <td>支持，可基于日志进行标注</td>
    </tr>
    <tr>
      <td>标注回复</td>
      <td>
        <p>基于经人类标注的 Q&A 对，可用于相似度对比回复</p>
        <p>可导出为供模型微调环节使用的数据格式</p>
      </td>
    </tr>
    <tr>
      <td>内容审查机制</td>
      <td>OpenAI Moderation 或外部 API</td>
    </tr>
    <tr>
      <td>团队协同</td>
      <td>工作空间与多成员管理支持</td>
    </tr>
    <tr>
      <td>API 规格</td>
      <td>RESTful，已覆盖大部分功能</td>
    </tr>
    <tr>
      <td>部署方式</td>
      <td>Docker，Helm</td>
    </tr>
  </tbody>
</table>

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/readme/features-and-specifications.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 模型供应商列表
> 来源：`zh-hans/getting-started/readme/model-providers.mdx`

Dify 为以下模型提供商提供原生支持：

<table>
  <thead>
    <tr>
      <th>Provider</th>
      <th>LLM</th>
      <th>Text Embedding</th>
      <th>Rerank</th>
      <th>Speech to text</th>
      <th>TTS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>OpenAI</td>
      <td>✔️(🛠️)(👓)</td>
      <td>✔️</td>
      <td></td>
      <td>✔️</td>
      <td>✔️</td>
    </tr>
    <tr>
      <td>Anthropic</td>
      <td>✔️(🛠️)</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Azure OpenAI</td>
      <td>✔️(🛠️)(👓)</td>
      <td>✔️</td>
      <td></td>
      <td>✔️</td>
      <td>✔️</td>
    </tr>
    <tr>
      <td>Gemini</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Google Cloud</td>
      <td>✔️(👓)</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Nvidia API Catalog</td>
      <td>✔️</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Nvidia NIM</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Nvidia Triton Inference Server</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>AWS Bedrock</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>OpenRouter</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Cohere</td>
      <td>✔️</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>together.ai</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Ollama</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Mistral AI</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>groqcloud</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Replicate</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Hugging Face</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Xorbits inference</td>
      <td>✔️</td>
      <td>✔️</td>
      <td>✔️</td>
      <td>✔️</td>
      <td>✔️</td>
    </tr>
    <tr>
      <td>智谱</td>
      <td>✔️(🛠️)(👓)</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>百川</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>讯飞星火</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Minimax</td>
      <td>✔️(🛠️)</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>通义千问</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td>✔️</td>
    </tr>
    <tr>
      <td>文心一言</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>月之暗面</td>
      <td>✔️(🛠️)</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Tencent Cloud</td>
      <td></td>
      <td></td>
      <td></td>
      <td>✔️</td>
      <td></td>
    </tr>
    <tr>
      <td>阶跃星辰</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>火山引擎</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>零一万物</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>360 智脑</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Azure AI Studio</td>
      <td>✔️</td>
      <td></td>
      <td>✔️</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>deepseek</td>
      <td>✔️(🛠️)</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>腾讯混元</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>SILICONFLOW</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Jina AI</td>
      <td></td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>ChatGLM</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Xinference</td>
      <td>✔️(🛠️)(👓)</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>OpenLLM</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>LocalAI</td>
      <td>✔️</td>
      <td>✔️</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
    </tr>
    <tr>
      <td>OpenAI API-Compatible</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td>✔️</td>
      <td></td>
    </tr>
    <tr>
      <td>PerfXCloud</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Lepton AI</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>novita.ai</td>
      <td>✔️</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Amazon Sagemaker</td>
      <td>✔️</td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text Embedding Inference</td>
      <td></td>
      <td>✔️</td>
      <td>✔️</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPUStack</td>
      <td>✔️(🔧️)(👓)</td>
      <td>✔️</td>
      <td>✔️</td>
      <td>✔️</td>
      <td>✔️</td>
    </tr>
  </tbody>
</table>

其中 (🛠️) 代表支持 Function Calling，(👓) 代表视觉能力。

这张表格我们会一直保持更新。同时，我们也留意着社区成员们所提出的关于模型供应商的各种[请求](https://github.com/langgenius/dify/discussions/categories/ideas)。如果你有需要的模型供应商却没在上面找到，不妨动手参与进来，通过提交一个PR（Pull Request）来做出你的贡献。欢迎查阅我们的[贡献指南](../../community/contribution)指南了解更多。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/getting-started/readme/model-providers.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 标注回复
> 来源：`zh-hans/guides/annotation/annotation-reply.mdx`

标注回复功能通过人工编辑标注为应用提供了可定制的高质量问答回复能力。

适用情景：

* **特定领域的定制化回答：** 在企业、政府等客服或知识库问答情景时，对于某些特定问题，服务提供方希望确保系统以明确的结果来回答问题，因此需要对在特定问题上定制化输出结果。比如定制某些问题的“标准答案”或某些问题“不可回答”。
* **POC 或 DEMO 产品快速调优：** 在快速搭建原型产品，通过标注回复实现的定制化回答可以高效提升问答结果的生成预期，提升客户满意度。

标注回复功能相当于提供了另一套检索增强系统，可以跳过 LLM 的生成环节，规避 RAG 的生成幻觉问题。

### 使用流程

1. 在开启标注回复功能之后，你可以对 LLM 对话回复内容进行标注，你可以将 LLM 回复的高质量答案直接添加为一条标注，也可以根据自己的需求编辑一条高质量答案，这些编辑的标注内容会被持久化保存；
2. 当用户再次提问相似的问题时，会将问题向量化并查询中与之相似的标注问题；
3. 如果找到匹配项，则直接返回标注中与问题相对应的答案，不再传递至 LLM 或 RAG 过程进行回复；
4. 如果没有找到匹配项，则问题继续常规流程（传递至 LLM 或 RAG）；
5. 关闭标注回复功能后，系统将一直不再继续从标注内匹配回复。

![标注回复流程](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/7bebcf85d52f65d5649956f47ed33d43.png)

### 提示词编排中开启标注回复

进入“应用构建->添加功能”开启标注回复开关：

![提示词编排中开启标注回复](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/1aaba1cc8c3f7ceece1b4de8ba4b0038.png)

开启时需要先设置标注回复的参数，可设置参数包括：Score 阈值 和 Embedding 模型

**Score 阈值**：用于设置标注回复的匹配相似度阈值，只有高于阈值分数的标注会被召回。

**Embedding 模型**：用于对标注文本进行向量化，切换模型时会重新生成嵌入。

点击保存并启用时，该设置会立即生效，系统将对所有已保存的标注利用 Embedding 模型生成嵌入保存。

![标注回复参数设置](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/cf48a6175713ab19c8a0dce5271bb5c2.png)

### 在会话调试页添加标注

你可以在调试与预览页面直接在模型回复信息上添加或编辑标注。

![添加标注回复](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/a876fdbcfcae8e9b274fc2985666cc39.png)

编辑成你需要的高质量回复并保存。

![编辑标注回复](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/38a546a5959703466597f7e06713b2c6.png)

再次输入同样的用户问题，系统将使用已保存的标注直接回复用户问题。

![通过已保存的标注回复用户问题](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/11197a74c9f1f24117f188fb5ebd2632.png)

### 日志与标注中开启标注回复

进入“应用构建->日志与标注->标注”开启标注回复开关：

![日志与标注中开启标注回复](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/9244726b55026866de18d225b3b78c73.png)

### 在标注后台设置标注回复参数

标注回复可设置的参数包括：Score 阈值 和 Embedding 模型

**Score 阈值**：用于设置标注回复的匹配相似度阈值，只有高于阈值分数的标注会被召回。

**Embedding 模型**：用于对标注文本进行向量化，切换模型时会重新生成嵌入。

![设置标注回复参数](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/0b382b1a804875dc4d387587cd30145d.png)

### 批量导入标注问答对

在批量导入功能内，你可以下载标注导入模板，按模板格式编辑标注问答对，编辑好后在此批量导入。

![批量导入标注问答对](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/796d2413092c639907e55b59a38c1527.png)

### 批量导出标注问答对

通过标注批量导出功能，你可以一次性导出系统内已保存的所有标注问答对。

![批量导出标注问答对](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/81e38ef807dc5057720d9c2bc46ab469.png)

### 查看标注回复命中历史

在标注命中历史功能内，你可以查看所有命中该条标注的编辑历史、命中的用户问题、回复答案、命中来源、匹配相似分数、命中时间等信息，你可以根据这些系统信息持续改进你的标注内容。

![查看标注回复命中历史](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/b3957b38a97e6611006d0fa43b05e52b.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/annotation/annotation-reply.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 日志与标注
> 来源：`zh-hans/guides/annotation/logs.mdx`

> **警告：**

请确保你的应用在收集用户数据时遵守当地法规。通常的做法是发布隐私政策并征得用户的同意。

日志（Logs）功能用以观察与标记 Dify 应用的工作表现，Dify 为应用的全部交互过程记录了日志，无论你是通过 WebApp 或 API 调用的，如果你是 Prompt 工程师或 LLM 运营人员，它将为你提供可视化的 LLM 应用运营体验。

### 使用日志控制台

你可以在应用的左侧导航找到**日志（Logs）**，该页面通常展示了：

* 所选时间内用户与 AI 应用的聊天互动记录
* 用户输入与 AI 输出的结果，对于对话型应用通常是一系列的消息流
* 用户、运营人员的评价，以及运营人员的改进标注

注意，如果团队中的多位协作者对同一条日志进行标注，最后标注的记录将覆盖此前的标注。

> 对于 Free 级别的团队而言，日志记录仅保留最近 30 天的互动记录。如需保留更长时间的互动历史，请访问[价格页](https://dify.ai/pricing)升级为更高级别的团队或部署[社区版](https://docs.dify.ai/zh-hans/getting-started/install-self-hosted/docker-compose)。

### 改进标注

> **信息提示：**

这些标记将在 Dify 的后续版本中供模型微调使用，以提升模型的准确性与回复风格，当前预览版仅支持标记。

![标记日志以改进](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/annotation/67586ad70a7ae79c18e61f1267cc8d8f.png)

点击一条日志会在界面右侧打开日志详情面板，在该面板中运营人员可以对一次互动进行标注：

* 对表现较佳的消息点赞
* 对表现不佳的消息点踩
* 对改进的结果标记改进回复，这代表了你期望 AI 回复的文本

注意，如果团队中的多位管理员对同一条日志进行标注，最后标注的记录将覆盖此前的标注。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/annotation/logs.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Agent
> 来源：`zh-hans/guides/application-orchestrate/agent.mdx`

### 定义

智能助手（Agent Assistant），利用大语言模型的推理能力，能够自主对复杂的人类任务进行目标规划、任务拆解、工具调用、过程迭代，并在没有人类干预的情况下完成任务。

### 如何使用智能助手

为了方便快速上手使用，你可以在“探索”中找到智能助手的应用模板，添加到自己的工作区，或者在此基础上进行自定义。在全新的 Dify 工作室中，你也可以从零编排一个专属于你自己的智能助手，帮助你完成财务报表分析、撰写报告、Logo 设计、旅程规划等任务。

![](https://assets-docs.dify.ai/2025/04/f6bd1785840a6693eb0f6b2b9b87d774.png)

选择智能助手的推理模型，智能助手的任务完成能力取决于模型推理能力，我们建议在使用智能助手时选择推理能力更强的模型系列如 gpt-4 以获得更稳定的任务完成效果。

![选择智能助手的推理模型](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/c27751cbc6250569087d0b15ca2e69c2.png)

你可以在“提示词”中编写智能助手的指令，为了能够达到更优的预期效果，你可以在指令中明确它的任务目标、工作流程、资源和限制等。

![编排智能助手的指令提示词](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/34fa9ee865c612fb10aa51befd2ea396.png)

### 添加助手需要的工具

在“上下文”中，你可以添加智能助手可以用于查询的知识库工具，这将帮助它获取外部背景知识。

在“工具”中，你可以添加需要使用的工具。工具可以扩展 LLM 的能力，比如联网搜索、科学计算或绘制图片，赋予并增强了 LLM 连接外部世界的能力。Dify 提供了两种工具类型：**第一方工具**和**自定义工具**。

你可以直接使用 Dify 生态提供的第一方内置工具，或者轻松导入自定义的 API 工具（目前支持 OpenAPI / Swagger 和 OpenAI Plugin 规范）。

![添加助手需要的工具](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/cf59361ae13c2aa2a0762bc0064c6a17.png)

“工具”功能允许用户借助外部能力，在 Dify 上创建出更加强大的 AI 应用。例如你可以为智能助理型应用（Agent）编排合适的工具，它可以通过任务推理、步骤拆解、调用工具完成复杂任务。

另外工具也可以方便将你的应用与其他系统或服务连接，与外部环境交互。例如代码执行、对专属信息源的访问等。你只需要在对话框中谈及需要调用的某个工具的名字，即可自动调用该工具。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/7adb47ad645fb7f1bd95848e78cb6a0f.png)

### 配置 Agent

在 Dify 上为智能助手提供了 Function calling（函数调用）和 ReAct 两种推理模式。已支持 Function Call 的模型系列如 gpt-3.5/gpt-4 拥有效果更佳、更稳定的表现，尚未支持 Function calling 的模型系列，我们支持了 ReAct 推理框架实现类似的效果。

在 Agent 配置中，你可以修改助手的迭代次数限制。

![Function Calling 模式](https://assets-docs.dify.ai/2025/04/8e150e070d55e90028a55db2ec8055af.png)

![ReAct 模式](https://assets-docs.dify.ai/2025/04/64a320f30d050736ee03c5ac25d8d0a8.png)

### 配置对话开场白

你可以为智能助手配置一套会话开场白和开场问题，配置的对话开场白将在每次用户初次对话中展示助手可以完成什么样的任务，以及可以提出的问题示例。

![配置会话开场白和开场问题](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/fc25255198c756ac939ec913fe36d7f9.png)

### 添加文件上传

部分多模态 LLM 已原生支持处理文件，例如 [Claude 3.5 Sonnet](https://docs.anthropic.com/en/docs/build-with-claude/pdf-support) 或 [Gemini 1.5 Pro](https://ai.google.dev/api/files)。你可以在 LLM 的官方网站了解文件上传能力的支持情况。

选择具备读取文件的 LLM，开启 “文档” 功能。无需复杂配置即可让当前 Chatbot 具备文件识别能力。

![](https://assets-docs.dify.ai/2024/11/9f0b7a3c67b58c0bd7926501284cbb7d.png)

### 调试与预览

编排完智能助手之后，你可以在发布成应用之前进行调试与预览，查看助手的任务完成效果。

![调试与预览](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/cd4a7ffded1a86d5e4aed1b9df36dc64.png)

### 应用发布

![应用发布为 Webapp](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/44b15a78c45e21afafd110864f78f33e.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-orchestrate/agent.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 敏感内容审查
> 来源：`zh-hans/guides/application-orchestrate/app-toolkits/moderation-tool.mdx`

我们在与 AI 应用交互的过程中，往往在内容安全性，用户体验，法律法规等方面有较为苛刻的要求，此时我们需要“敏感词审查”功能，来为终端用户创造一个更好的交互环境。 在提示词编排页面，点击“添加功能”，找到底部的工具箱“内容审核”：

![Content moderation](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/app-toolkits/09c3d5be9b7194e54d0333242c501719.png)

### 功能一：调用 OpenAI Moderation API

OpenAI 和大多数 LLM 公司提供的模型，都带有内容审查功能，确保不会输出包含有争议的内容，比如暴力，性和非法行为，并且 OpenAI 还开放了这种内容审查能力，具体可以参考 [platform.openai.com](https://platform.openai.com/docs/guides/moderation/overview) 。现在你也可以直接在 Dify 上调用 OpenAI Moderation API，你可以审核输入内容或输出内容，只要输入对应的“预设回复”即可。

![OpenAI Moderation API](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/app-toolkits/6b09f91a05c993e0aa6bb56eca71e607.png)

### 功能二：自定义关键词

开发者可以自定义需要审查的敏感词，比如把“kill”作为关键词，在用户输入的时候作审核动作，要求预设回复内容为“The content is violating usage policies.”可以预见的结果是当用户在终端输入包含“kill”的语料片段，就会触发敏感词审查工具，返回预设回复内容。

![Keywords](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/app-toolkits/644c2b024f59497aed3cd8ac984c96e3.png)

### 功能三： 敏感词审查 Moderation 扩展

不同的企业内部往往有着不同的敏感词审查机制，企业在开发自己的 AI 应用如企业内部知识库 ChatBot，需要对员工输入的查询内容作敏感词审查。为此，开发者可以根据自己企业内部的敏感词审查机制写一个 API 扩展，具体可参考 [敏感内容审查](./zh-hans/guides/tools/extensions/api-based/moderation)，从而在 Dify 上调用，实现敏感词审查的高度自定义和隐私保护。

![Moderation Settings](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/app-toolkits/d8b6dff6fce6d70795b87aefc56eb02b.png)

比如我们在自己的本地服务中自定义敏感词审查规则：不能查询有关美国总统的名字的问题。当用户在`query`变量输入"Trump"，则在对话时会返回 "Your content violates our usage policy." 测试效果如下：

![Moderation Test](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/app-toolkits/970c894a68f017def62c0f7253b0f44e.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-orchestrate/app-toolkits/moderation-tool.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 应用工具箱
> 来源：`zh-hans/guides/application-orchestrate/app-toolkits/readme.mdx`

在 **工作室 -- 应用编排** 内点击 **添加功能**，打开应用工具箱

应用工具箱为 Dify 的应用提供了不同的附加功能：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/app-toolkits/87ac4bc0e0c2b9a36fba0fc2f0155905.png)

### 对话开场白

在对话类应用中，AI 会主动说第一句话或者提出问题，你可以编辑开场白的内容包括开场问题。使用对话开场白可以引导用户提问，交代应用背景，降低对话提问的使用门槛。

![对话开场白](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/app-toolkits/46b849a2cee82c70d54ac8fbca75c85c.png)

### 下一步问题建议

设置下一步问题建议可以在每次对话交互后，让 AI 根据之前的对话内容继续生成 3 个提问，引导下一轮对话。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/app-toolkits/cff3de9733e586e64a70fcc0ac633119.png)

### 文字转语音

开启后可以将 AI 回复的内容转换成自然的语音播放。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/app-toolkits/ba6f3ede45ef594a1886ef9182149a73.png)

### 语音转文字

开启后可以在应用内录音并将语音自动转换成文本。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/app-toolkits/4f8bfc129a68f5da0f96723e80bd72d2.png)

### 引用与归属

开启功能后，当 LLM 引用知识库内容来回答问题时，可以在回复内容下面查看到具体的引用段落信息，包括原始分段文本、分段序号、匹配度等。

具体介绍请查看[引用与归属](./zh-hans/guides/knowledge-base/retrieval-test-and-citation#id-2-yin-yong-yu-gui-shu)。

### 内容审查

我们在与 AI 应用交互的过程中，往往在内容安全性，用户体验，法律法规等方面有较为苛刻的要求，此时我们需要“敏感内容审查”功能，来为终端用户创造一个更好的交互环境。

具体介绍请查看[敏感内容审查](./zh-hans/guides/application-orchestrate/app-toolkits/moderation-tool)。

### 标注回复

标注回复功能通过人工编辑标注为应用提供了可定制的高质量问答回复能力。

查看[标注回复](./zh-hans/guides/annotation/annotation-reply)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-orchestrate/app-toolkits/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 聊天助手
> 来源：`zh-hans/guides/application-orchestrate/chatbot-application.mdx`

对话型应用采用一问一答模式与用户持续对话。

### 适用场景

对话型应用可以用在客户服务、在线教育、医疗保健、金融服务等领域。这些应用可以帮助组织提高工作效率、减少人工成本和提供更好的用户体验。

### 如何编排

对话型应用的编排支持：对话前提示词，变量，上下文，开场白和下一步问题建议。

下面以做一个 **面试官** 的应用为例来介绍编排对话型应用。

#### 创建应用

在首页点击 “创建应用” 按钮创建应用。填上应用名称，应用类型选择**聊天助手**。

![](https://assets-docs.dify.ai/2024/12/572b246b74431dd550c5b61d9215dbaa.png)

#### 编排应用

创建应用后会自动跳转到应用概览页。点击左侧菜单 **编排** 来编排应用。

![应用编排](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/f19f991c1295c2ed3230ef27fc47818e.png)

**填写提示词**

提示词用于约束 AI 给出专业的回复，让回应更加精确。你可以借助内置的提示生成器，编写合适的提示词。提示词内支持插入表单变量，例如 `{{input}}`。提示词中的变量的值会替换成用户填写的值。

示例：

1. 输入提示指令，要求给出一段面试场景的提示词。
2. 右侧内容框将自动生成提示词。
3. 你可以在提示词内插入自定义变量。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/9dbd67eacb701500c64e61978d35b812.png)

为了更好的用户体验，可以加上对话开场白：`你好，{{name}}。我是你的面试官，Bob。你准备好了吗？`。点击页面底部的 “添加功能” 按钮，打开 “对话开场白” 的功能：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/9c81c98c4b58f894ed92e06a4b9bcf87.png)

编辑开场白时，还可以添加数个开场问题：

![描述文字](https://assets-docs.dify.ai/2025/04/2698f7edc53d7886007c6c78faba698e.png)

#### 添加上下文

如果想要让 AI 的对话范围局限在[知识库](../knowledge-base/)内，例如企业内的客服话术规范，可以在“上下文”内引用知识库。

![](https://assets-docs.dify.ai/2025/04/f99d63b2c6ab6c5bd20d036374cd803c.png)

#### 添加文件上传

部分多模态 LLM 已原生支持处理文件，例如 [Claude 3.5 Sonnet](https://docs.anthropic.com/en/docs/build-with-claude/pdf-support) 或 [Gemini 1.5 Pro](https://ai.google.dev/api/files)。你可以在 LLM 的官方网站了解文件上传能力的支持情况。

选择具备读取文件的 LLM，开启 “文档” 功能。无需复杂配置即可让当前 Chatbot 具备文件识别能力。

![](https://assets-docs.dify.ai/2024/11/823399d85e8ced5068dc9da4f693170e.png)

#### 调试

在右侧填写用户输入项，输入内容进行调试。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/21640904df527d7487b4ac646738971b.png)

若 LLM 给出的回答结果不理想，你可以调整提示词或切换不同底层模型进行效果对比。如需更进一步，同时查看不同模型对于同一个问题的回答情况，请参考[多模型调试](./multiple-llms-debugging)。

#### 发布应用

调试好应用后，点击右上角的 **“发布”** 按钮生成独立的 AI 应用。除了通过公开 URL 体验该应用，你也进行基于 APIs 的二次开发、嵌入至网站内等操作。详情请参考[发布](./zh-hans/guides/application-publishing)。

如果想定制已发布的应用，可以 Fork 我们的开源的 [WebApp 的模板](https://github.com/langgenius/webapp-conversation)。基于模板改成符合你的情景与风格需求的应用。

### 常见问题

**如何在聊天助手内添加第三方工具？**

聊天助手类型应用不支持添加第三方工具，你可以在 [Agent 类型](./zh-hans/guides/application-orchestrate/agent)应用内添加第三方工具。

**如何在创建聊天助手应用时，使用元数据功能筛选知识库内文档？**

如需了解如何使用元数据功能筛选文档，请参阅 [在应用内集成知识库](https://docs.dify.ai/zh-hans/guides/knowledge-base/integrate-knowledge-within-application) 中的“**使用元数据筛选知识 > 聊天助手**”章节。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-orchestrate/chatbot-application.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 创建应用
> 来源：`zh-hans/guides/application-orchestrate/creating-an-application.mdx`

你可以通过 3 种方式在 Dify 的工作室内创建应用：

* 基于应用模板创建（新手推荐）
* 创建一个空白应用
* 通过 DSL 文件（本地/在线）创建应用

## 从模板创建应用

初次使用 Dify 时，你可能对于应用创建比较陌生。为了帮助新手用户快速了解在 Dify 上能够构建哪些类型的应用，Dify 团队内的提示词工程师已经创建多场景、高质量的应用模板。

你可以从导航选择 「工作室 」，在应用列表内选择 「从模板创建」。

![](https://assets-docs.dify.ai/2025/04/30b22b65fd5dc3843a264aaad28c3495.png)

任意选择某个模板，并将其添加至工作区。

#### 创建一个新应用

如果你需要在 Dify 上创建一个空白应用，你可以从导航选择 「工作室」 ，在应用列表内选择 「从空白创建 」。

![](https://assets-docs.dify.ai/2025/04/dc7550d48fbd76528d7ea88588e207c8.png)

Dify 上可以创建 5 种不同的应用类型，分别是聊天助手、文本生成应用、Agent、Chatflow 和 Workflow。

创建应用时，你需要给应用起一个名字、选择合适的图标，或者上传喜爱的图片用作图标、使用一段清晰的文字描述此应用的用途，以便后续应用在团队内的使用。

<iframe
  src="https://www.motionshot.app/walkthrough/6765339bcf1efee248025520/embed?fullscreen=1&hideCopy=1&hideDownload=1&hideSteps=1"
  width="80%"
  height="300px"
  frameborder="0"
  allowfullscreen
></iframe>

### 通过 DSL 文件创建应用

> **信息提示：**

Dify DSL 是由 Dify.AI 所定义的 AI 应用工程文件标准，文件格式为 YML。该标准涵盖应用在 Dify 内的基本描述、模型参数、编排配置等信息。

    如果你从社区或其它人那里获得了一个应用模板（DSL 文件），可以从工作室选择 「 导入DSL 文件 」。DSL 文件导入后将直接加载原应用的所有配置信息。

    ![导入 DSL 文件创建应用](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/6615ef40b8c0027563a5a4ca0c315ff1.png)

    你也可以通过 URL 导入 DSL 文件，参考的链接格式：

    ```url
    https://example.com/your_dsl.yml
    ```

    ![通过 URL 导入 DSL 文件](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/63d45c8f397dd65258dd4b322f0a43fa.jpeg)

    > 导入 DSL 文件时将校对文件版本号。如果 DSL 版本号差异较大，有可能会出现兼容性问题。详细说明请参考 [应用管理：导入](https://docs.dify.ai/zh-hans/guides/management/app-management#dao-ru-ying-yong)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-orchestrate/creating-an-application.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 多模型调试
> 来源：`zh-hans/guides/application-orchestrate/multiple-llms-debugging.mdx`

聊天助手应用类型支持 **“多个模型进行调试”** 功能，你可以同时批量检视不同模型对于相同问题的回答效果。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/d0de3f1edca55af986a6b213876ed3ff.png)

最多支持同时添加 4 个大模型。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-orchestrate/74003eeacf3f4f8f0d7cb6c3ad20c84a.png)

调试时如果发现效果较好的模型，点击 **“单一模型进行调试”** 即可进入至当前模型的单独调试页面。

![](https://assets-docs.dify.ai/2025/02/d273dee2ec4c04f7208a4f7a8b3a86db.png)

## 常见问题

### 1. 添加大模型时没有看到其它模型应该如何处理？

前往 [“增加新供应商”](./zh-hans/guides/model-configuration/new-provider)，按照页面提示手动添加多个模型的 Key。

### 2. 如何退出多模型调试模式？

选择任意模型，点击 **“单一模型进行调试”** 选项即可退出多模型调试模式。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-orchestrate/multiple-llms-debugging.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 构建应用
> 来源：`zh-hans/guides/application-orchestrate/readme.mdx`

在 Dify 中，一个“应用”是指基于 GPT 等大语言模型构建的实际场景应用。通过创建应用，你可以将智能 AI 技术应用于特定的需求。它既包含了开发 AI 应用的工程范式，也包含了具体的交付物。

简而言之，一个应用为开发者交付了：

* 封装友好的 API，可由后端或前端应用直接调用，通过 Token 鉴权
* 开箱即用、美观且托管的 WebApp，你可以 WebApp 的模板进行二次开发
* 一套包含提示词工程、上下文管理、日志分析和标注的易用界面

你可以任选**其中之一**或**全部**，来支撑你的 AI 应用开发。

### 应用类型

Dify 中提供了五种应用类型：

* **聊天助手**：基于 LLM 构建对话式交互的助手
* **文本生成应用**：面向文本生成类任务的助手，例如撰写故事、文本分类、翻译等
* **Agent**：能够分解任务、推理思考、调用工具的对话式智能助手
* **对话流**：适用于定义等复杂流程的多轮对话场景，具有记忆功能的应用编排方式
* **工作流**：适用于自动化、批处理等单轮生成类任务的场景的应用编排方式

文本生成应用与聊天助手的区别见下表：

<table><thead><tr><th width="180.33333333333331"></th><th>文本生成应用</th><th>聊天助手</th></tr></thead><tbody><tr><td>WebApp 界面</td><td>表单+结果式</td><td>聊天式</td></tr><tr><td>WebAPI 端点</td><td><code>completion-messages</code></td><td><code>chat-messages</code></td></tr><tr><td>交互方式</td><td>一问一答</td><td>多轮对话</td></tr><tr><td>流式结果返回</td><td>支持</td><td>支持</td></tr><tr><td>上下文保存</td><td>当次</td><td>持续</td></tr><tr><td>用户输入表单</td><td>支持</td><td>支持</td></tr><tr><td>知识库与插件</td><td>支持</td><td>支持</td></tr><tr><td>AI 开场白</td><td>不支持</td><td>支持</td></tr><tr><td>情景举例</td><td>翻译、判断、索引</td><td>聊天</td></tr></tbody></table>

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-orchestrate/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 基于前端模板再开发
> 来源：`zh-hans/guides/application-publishing/based-on-frontend-templates.mdx`

如果开发者是从头开发新产品或者在产品原型设计阶段，你可以使用 Dify 快速发布 AI 站点。与此同时，Dify 希望开发者能够充分自由的创造不同形式的前端应用，为此我们提供了：

* **SDK**，用于在各种语言中快速接入 Dify API
* **WebApp Template**，每种类型应用的 WebApp 开发脚手架

WebApp Template 是基于 MIT 协议开源的，你可以充分自由的修改并部署他们，以实现 Dify 的所有能力。或者作为你实现自己 App 的一份参考代码。

你可以在 GitHub 中找到这些 Template：

* [对话型应用](https://github.com/langgenius/webapp-conversation)
* [文本生成型应用](https://github.com/langgenius/webapp-text-generator)

使用 WebApp 模板最快的方法就是在 GitHub 中点击「使用这个模板」，它相当于 Fork 了一个新的仓库。随后你需要配置 Dify 的 App ID 和 API Key，类似这样：

````javascript

```

More config in `config/index.ts`:
```js

  "title": 'Chat APP',
  "description": '',
  "copyright": '',
  "privacy_policy": '',
  "default_language": 'zh-Hans'
}

````

> App ID 可以在 App 的 URL 内获取，其中的长串英文字符为唯一的 App ID。

每一种 WebApp 模板都提供了 README 文件，内含部署方式的说明。通常，WebApp 模板都包含了一个轻后端服务，这是为了确保开发者的 API KEY 不会直接暴露给用户。

这些 WebApp 模板能够帮助你快速搭建起 AI 应用原型，并使用 Dify 的所有能力。如果你基于它们开发了自己的应用或新的模板，欢迎你与我们分享。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-publishing/based-on-frontend-templates.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 基于 APIs 开发
> 来源：`zh-hans/guides/application-publishing/developing-with-apis.mdx`

Dify 基于“**后端即服务**”理念为所有应用提供了 API，为 AI 应用开发者带来了诸多便利。通过这一理念，开发者可以直接在前端应用中获取大型语言模型的强大能力，而无需关注复杂的后端架构和部署过程。

#### 使用 Dify API 的好处

* 让前端应用直接安全地调用 LLM 能力，省去后端服务的开发过程
* 在可视化的界面中设计应用，并在所有客户端中实时生效
* 对 LLM 供应商的基础能力进行了良好封装
* 随时切换 LLM 供应商，并对 LLM 的密钥进行集中管理
* 在可视化的界面中运营你的应用，例如分析日志、标注及观察用户活跃
* 持续为应用提供更多工具能力、插件能力和知识库

#### 如何使用

选择一个应用，在应用（Apps）左侧导航中可以找到**访问 API（API Access）**。在该页面中你可以查看 Dify 提供的 API 文档，并管理可访问 API 的凭据。

![访问 API](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/97ff5a5d3fd280c617af917ca6c09322.png)

例如你是一个咨询公司的开发部分，你可以基于公司的私有数据库提供 AI 能力给终端用户或开发者，但开发者无法掌握你的数据和 AI 逻辑设计，从而使得服务可以安全、可持续的交付并满足商业目的。

> **警告：**

在最佳实践中，API 密钥应通过后端调用，而不是直接以明文暴露在前端代码或请求中，这样可以防止你的应用被滥用或攻击。

你可以为一个应用**创建多个访问凭据**，以实现交付给不同的用户或开发者。这意味着 API 的使用者虽然使用了应用开发者提供的 AI 能力，但背后的 Promp 工程、知识库和工具能力是经封装的。

#### 文本生成型应用

可用于生成高质量文本的应用，例如生成文章、摘要、翻译等，通过调用 completion-messages 接口，发送用户输入得到生成文本结果。用于生成文本的模型参数和提示词模板取决于开发者在 Dify 提示词编排页的设置。

你可以在**应用 -> 访问 API** 中找到该应用的 API 文档与范例请求。

例如，创建文本补全信息的 API 的调用示例：

```bash title="cURL"
curl --location --request POST 'https://api.dify.ai/v1/completion-messages' \
--header 'Authorization: Bearer ENTER-YOUR-SECRET-KEY' \
--header 'Content-Type: application/json' \
--data-raw '{
    "inputs": {},
    "response_mode": "streaming",
    "user": "abc-123"
}'
```

```python title="Python"

url = "https://api.dify.ai/v1/completion-messages"

headers = 
    'Authorization': 'Bearer ENTER-YOUR-SECRET-KEY',
    'Content-Type': 'application/json',

data = {
    "inputs": {"text": 'Hello, how are you?'},
    "response_mode": "streaming",
    "user": "abc-123"
}

response = requests.post(url, headers=headers, data=json.dumps(data))

print(response.text)
```

#### 对话型应用

可用于大部分场景的对话型应用，采用一问一答模式与用户持续对话。要开始一个对话请调用 `chat-messages` 接口，每次对话开始都会产生出新的 `conversation\_id`，通过该`conversation\_id` 传回接口就可继续保持该会话。

> **重要说明**: Service API 不共享 WebApp 创建的对话。通过 API 创建的对话与 WebApp 界面中创建的对话是相互隔离的。

#### `conversation_id` 的注意事项：

- **生成 `conversation_id`：** 开始新对话时，请将 `conversation_id` 字段留空。系统将生成并返回一个新的 `conversation_id`，未来的交互中会使用该 `conversation_id` 继续对话。
- **处理现有会话中的 `conversation_id`：** 生成 `conversation_id` 后，对 API 的未来调用应包含此 `conversation_id`，以确保与 Dify 机器人的对话连续性。传递上一个 `conversation_id` 时，将忽略任何新的 `inputs`，仅处理正在进行的对话的 `query`。
- **管理动态变量：** 如果在会话期间需要修改逻辑或变量，你可以使用会话变量（特定于会话的变量）来调整 bot 的行为或回应。

你可以在**应用 -> 访问 API** 中找到该应用的 API 文档与范例请求。

例如，发送对话信息的 `chat-messages` API的调用示例：

```bash title="cURL"
curl --location --request POST 'https://api.dify.ai/v1/chat-messages' \
--header 'Authorization: Bearer ENTER-YOUR-SECRET-KEY' \
--header 'Content-Type: application/json' \
--data-raw '{
    "inputs": {},
    "query": "eh",
    "response_mode": "streaming",
    "conversation_id": "1c7e55fb-1ba2-4e10-81b5-30addcea2276",
    "user": "abc-123"
}'

```

```python title="Python"

url = 'https://api.dify.ai/v1/chat-messages'
headers = 
    'Authorization': 'Bearer ENTER-YOUR-SECRET-KEY',
    'Content-Type': 'application/json',

data = {
    "inputs": {},
    "query": "eh",
    "response_mode": "streaming",
    "conversation_id": "1c7e55fb-1ba2-4e10-81b5-30addcea2276",
    "user": "abc-123"
}

response = requests.post(url, headers=headers, data=json.dumps(data))

print(response.text)
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-publishing/developing-with-apis.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 嵌入网站
> 来源：`zh-hans/guides/application-publishing/embedding-in-websites.mdx`

Dify 支持将你的 AI 应用嵌入到业务网站中，你可以使用该能力在几分钟内制作具有业务数据的官网 AI 客服、业务知识问答等应用。

可以使用 3 种不同的方式将你的 AI 应用嵌入网站，分别为 `<iframe>` 标签方式，`<script>` 标签方式，和安装 Dify Chrome 浏览器扩展方式。

点击 WebApp 卡片上的嵌入按钮，复制嵌入代码，粘贴到你网站的目标位置。

## 使用 `<iframe>` 标签方式

将 `<iframe>` 代码复制到你网站用于显示 AI 应用的标签中，如 `<div>`、`<section>` 等标签。

    ![显示嵌入网站的代码示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/1e2e8c9adc620f9d6b4ea157119e8659.png)

## 使用 `<script>` 标签方式

将 `<script>` 代码复制到你网站 `<head>` 或 `<body>` 标签中。这会在你的网站上显示一个 Dify 聊天机器人气泡按钮。

如果将 script 代码粘贴到官网的 `<body>` 处，你将得到一个官网 AI 机器人：

  ![展示嵌入到网站后的 AI 机器人效果](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/f5a5e95e1120906669b3c1ad4e186dea.png)

## 安装 Dify Chrome 浏览器扩展方式

按照提示，安装 [Dify Chrome 浏览器扩展](https://chromewebstore.google.com/detail/dify-chatbot/ceehdapohffmjmkdcifjofadiaoeggaf)。

## 自定义 Dify 聊天机器人气泡按钮

当你在网站中使用 Dify 聊天机器人气泡按钮时（即，使用 `<script>` 标签方式将你的 AI 应用嵌入网站），你可以自定义按钮的样式、位置和其他设置。

Dify 聊天机器人气泡按钮可以通过以下配置选项进行自定义：

```javascript
window.difyChatbotConfig = {
    // 必填项，由 Dify 自动生成
    token: 'YOUR_TOKEN',
    // 可选项，默认为 false
    isDev: false,
    // 可选项，当 isDev 为 true 时，默认为 '[https://dev.udify.app](https://dev.udify.app)'，否则默认为 '[https://udify.app](https://udify.app)'
    baseUrl: 'YOUR_BASE_URL',
    // 可选项，可以接受除 `id` 以外的任何有效的 HTMLElement 属性，例如 `style`、`className` 等
    containerProps: {},
    // 可选项，是否允许拖动按钮，默认为 `false`
    draggable: false,
    // 可选项，允许拖动按钮的轴，默认为 `both`，可以是 `x`、`y`、`both`
    dragAxis: 'both',
    // 可选项，在 dify 聊天机器人中设置的输入对象
    inputs: 
        // 键是变量名
        // 例如：
        // name: "NAME"
    ,
    // 可选项，在 dify 聊天机器人中设置的系统变量
    systemVariables: 
        // 例如：
        // user_id: 'USER_ID',
        // conversation_id: 'CONVERSATION_ID',
    ,
    // 可选项，在 dify 聊天机器人中设置的用户信息变量
    userVariables: 
        // 例如：
        // avatar_url: 'AVATAR_URL',
        // name: 'NAME',
    ,
};
```

### 覆盖默认按钮样式

你可以使用 CSS 变量或 `containerProps` 选项来覆盖默认按钮样式。根据 CSS 优先级使用这些方法实现自定义样式。

*   **修改 CSS 变量**

    支持以下 CSS 变量进行自定义：

    ```css
    /* 按钮距离底部的距离，默认为 `1rem` */
    --dify-chatbot-bubble-button-bottom

    /* 按钮距离右侧的距离，默认为 `1rem` */
    --dify-chatbot-bubble-button-right

    /* 按钮距离左侧的距离，默认为 `unset` */
    --dify-chatbot-bubble-button-left

    /* 按钮距离顶部的距离，默认为 `unset` */
    --dify-chatbot-bubble-button-top

    /* 按钮背景颜色，默认为 `#155EEF` */
    --dify-chatbot-bubble-button-bg-color

    /* 按钮宽度，默认为 `50px` */
    --dify-chatbot-bubble-button-width

    /* 按钮高度，默认为 `50px` */
    --dify-chatbot-bubble-button-height

    /* 按钮边框半径，默认为 `25px` */
    --dify-chatbot-bubble-button-border-radius

    /* 按钮盒阴影，默认为 `rgba(0, 0, 0, 0.2) 0px 4px 8px 0px)` */
    --dify-chatbot-bubble-button-box-shadow

    /* 按钮悬停变换，默认为 `scale(1.1)` */
    --dify-chatbot-bubble-button-hover-transform
    ```

    例如，要将按钮背景颜色更改为 #ABCDEF，请添加以下 CSS：

    ```css
    #dify-chatbot-bubble-button 
        --dify-chatbot-bubble-button-bg-color: #ABCDEF;

    ```

*   **使用 `containerProps` 选项**

    使用 `style` 属性设置内联样式：

    ```javascript
    window.difyChatbotConfig = {
        // ... 其他配置
        containerProps: {
            style: {
                backgroundColor: '#ABCDEF',
                width: '60px',
                height: '60px',
                borderRadius: '30px',
            },
            // 对于较小的样式覆盖，也可以使用字符串作为 `style` 属性的值：
            // style: 'background-color: #ABCDEF; width: 60px;',
        },
    }
    ```

    使用 `className` 属性应用 CSS 类：

    ```javascript
    window.difyChatbotConfig = {
        // ... 其他配置
        containerProps: {
            className: 'dify-chatbot-bubble-button-custom my-custom-class',
        },
    };
    ```

## 向嵌入网站的应用传递 `inputs`

你可以向嵌入你的网站的 AI 应用传递初始输入。支持四种类型的输入：

1. **`text-input`**：接受任何值。如果输入字符串的长度超过允许的最大长度，将被截断。
2. **`paragraph`**：类似于 `text-input`，接受任何值并在字符串长度超过最大长度时截断。
3. **`number`**：接受数字或数字字符串。如果提供的是字符串，将使用 `Number` 函数将其转换为数字。
4. **`options`**：接受任何值，前提是它匹配预先配置的选项之一。

使用 `<iframe>` 标签方式和使用 `<script>` 标签方式将 AI 应用嵌入网站时，传递 `inputs` 的方法亦有所不同。

以下以传入变量名为 `name`，值为 `apple` 的情形为例。

### 使用 `<iframe>` 标签方式

如果你的 AI 应用是使用 `<iframe>` 标签方式嵌入网站的，你可以通过向其 URL 追加参数的方式传递 `inputs`。

你需要将传入变量的值先使用 GZIP 压缩，并以 base64 编码，再将得到的 base64 值使用 encodeURIComponent 编码，最后附加到 URL 上。

例如，变量名为 `name`，值为 `apple`，首先压缩 `apple`，得到 base64 编码 `H4sIAAAAAAAAA0ssKMhJBQBQ0C6pBQAAAA==`，再使用 encodeURIComponent 编码得到 `H4sIAAAAAAAAA0ssKMhJBQBQ0C6pBQAAAA%3D%3D`。最后的输入值 URL 将如下所示： `http://localhost/chatbot/token?name=H4sIAAAAAAAAA0ssKMhJBQBQ0C6pBQAAAA%3D%3D`。

### 使用 `<script>` 标签方式

如果你的 AI 应用是使用 `<script>` 标签方式嵌入网站的，则只需要通过前文提到的配置选项即可传递 `inputs`。示例配置：

```javascript
window.difyChatbotConfig = {
    // ... 其他配置
    inputs: {
        name: 'apple',
    },
}
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-publishing/embedding-in-websites.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 对话型应用
> 来源：`zh-hans/guides/application-publishing/launch-your-webapp-quickly/conversation-application.mdx`

对话型应用采用一问一答模式与用户持续对话。对话型应用支持以下能力（请确认应用编排时有开启以下功能）：

* 对话前填写的变量。
* 对话的创建、置顶、删除。
* 对话开场白。
* 下一步问题建议。
* 语音转文字。
* 引用和归属

### 对话前填写的变量

如你在应用编排时有设置变量的填写要求，则在对话前需要按提示填写信息才可进入对话窗口：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/ea12b7209fcaad39d92b6c54c296f9cd.png)

填写必要内容，点击 "开始对话" 按钮，开始聊天。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/852c2412400eccbc17fa5be9794b7c47.png)

移动到 AI 的回答上，可以复制会话内容，给回答 "赞" 和 "踩"。

  ![AI回答上的操作选项](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/b3a455772b1e0da2f6088905481a605f.png)

### 对话的创建、置顶和删除

点击 "新对话" 按钮开始一个新的对话。移动到一个会话上，可以对会话进行 "置顶" 和 "删除" 操作。

  ![对话的创建、置顶和删除操作](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/4cc8ee74dbc85e009897f9724f700f37.png)

### 对话开场白

若在应用编排时开启了「对话开场白」功能，则在创建一个新对话时 AI 应用会自动发起第一句对话：

  ![AI自动发起的对话开场白](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/04424010033e55d31ac4b559ab1d7c7a.png)

### 下一步问题建议

若在应用编排时开启了「下一步问题建议」功能，则在对话后系统自动生成 3 个相关问题建议：

  ![系统生成的下一步问题建议](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/276c48b41e13ee93056dcc0ccd26f17c.png)

### 语音转文字

若在应用编排时开启了「语音转文字」功能，则在 Web 应用端的输入框看到语音输入的图标，点击图标即可语音输入转成文字：

_请注意确保你使用的设备环境已经授权使用麦克风。_

  ![语音转文字功能界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/3a64c79792f1166301403f6c44cf4c85.png)

### 引用与归属

开启该功能后，当 LLM 回复问题来自知识库的内容时，可以在回复内容下面查看到具体的引用段落信息，包括原始分段文本、分段序号、匹配度等。

详细说明请参考[《引用与归属》](./zh-hans/guides/knowledge-base/retrieval-test-and-citation)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-publishing/launch-your-webapp-quickly/conversation-application.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 工作流应用
> 来源：`zh-hans/guides/application-publishing/launch-your-webapp-quickly/flow-app.mdx`

调试完成之后点击右上角的「发布」可以将该工作流保存并快速发布成为不同类型的应用。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/output (4) (3).png)**

对话型应用支持发布为：

* 直接运行
* 嵌入网站
* 访问 API

工作流应用支持发布为：

* 直接运行
* 批处理
* 访问 API
* 发布为工具

你也可以点击 **恢复** 预览上一次发布的应用版本，确认恢复将会使用上一次发布的工作流版本覆盖当前的工作流版本。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-publishing/launch-your-webapp-quickly/flow-app.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 发布为公开 Web 站点
> 来源：`zh-hans/guides/application-publishing/launch-your-webapp-quickly/readme.mdx`

使用 Dify 创建 AI 应用的一个好处在于，你可以在几分钟内就发布一个可供用户在互联网上公开访问的 Web 应用，该应用将根据你的 Prompt 和编排设置进行工作。

* 如果你使用的是自部署的开源版，该应用将运行在你的服务器上
* 如果你使用的是云服务，该应用将托管至网址 [https://udify.app/](https://udify.app/)

***

### 发布 AI 站点

在应用监测页中，你可以找到 WebApp 的管理卡片。打开访问开关后，你可以得到一个能够在互联网上公开分享的网址。

![](https://assets-docs.dify.ai/2025/03/40a972bc270777a3bedd1b2bc5d34114.png)

我们对以下两种应用类型均预置了漂亮的 WebApp 界面：

* 文本生成型（[前往预览](./text-generator)）
* 对话型（[前往预览](./conversation-application)）

***

### 设置你的 AI 站点

点击 WebApp 卡片上的**设置**按钮，为 AI 站点配置一些选项，它们都会被最终用户所见：

![](https://assets-docs.dify.ai/2025/04/2985d21d7e186c01a8d700378246b9a1.png)

> **信息提示：**

界面语言目前已支持：英文，中文，繁体中文，葡萄牙语，德语，日本语，韩语，乌克兰语，越南语。如果你需要增加更多语言，可以在 GitHub 内提交 Issue[ 寻求支持](./zh-hans/community/support)或者提交 PR 贡献代码。

***

### 嵌入你的 AI 站点

除了将应用发布为一个公开的 AI 网站，你还可以将它嵌入并集成至你的网站、博客或其它任意网页中。详细说明请参考 [《嵌入网站》](./zh-hans/guides/application-publishing/embedding-in-websites)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-publishing/launch-your-webapp-quickly/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 文本生成型应用
> 来源：`zh-hans/guides/application-publishing/launch-your-webapp-quickly/text-generator.mdx`

文本生成类应用是一种根据用户提供的提示，自动生成高质量文本的应用。它可以生成各种类型的文本，例如文章摘要、翻译等。

文本生成型应用支持如下功能：

1. 运行一次。
2. 批量运行。
3. 保存运行结果。
4. 生成更多类似结果。

下面我们分别来介绍。

### 运行一次

输入查询内容，点击运行按钮，右侧会生成结果，如下图所示：

  ![文本生成应用运行一次的界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/c211c29aa03c4985bc5a90d2a6903e59.png)

在生成的结果部分，点 "复制" 按钮可以将内容复制到剪贴板。点 "保存" 按钮可以保存内容。可以在 "已保存" 选项卡中看到保存过的内容。也可以对生成的内容点 "赞" 和 "踩"。

### 批量运行

有时，我们需要运行一个应用很多次。比如：有个 Web 应用可以根据主题来生成文章。现在要生成 100 篇不同主题的文章。那么这个任务要做 100 次，很麻烦。而且，必须等一个任务完成才能开始下一个任务。

上面的场景，用批量运行功能，操作便利(把主题录入一个 `csv` 文件，只需执行一次)，也节约了生成的时间(多个任务同时运行)。使用方式如下：

#### 第 1 步 进入批量运行页面

点击 "批量运行" 选项卡，则会进入批量运行页面。

  ![批量运行页面界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/1983dbeda4308ce4d4ee592db91d264b.png)

#### 第 2 步 下载模板并填写内容

点击下载模板按钮，下载模板。编辑模板，填写内容，并另存为 `.csv` 格式的文件。

  ![下载模板按钮位置](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/e39c10e8f250ab3446466f2b85601798.png)

#### 第 3 步 上传文件并运行

  ![上传文件并运行界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/2ff10da8d0d9a728531ccdb8edc10ad4.png)

如果需要导出生成的内容，可以点右上角的下载 "按钮" 来导出为 `csv` 文件。

**注意:** 上传的的 `csv` 文件的编码必须是 `Unicode` 的编码。否则会运行结果失败。解决方案：用 Excel，WPS 等导出为 `csv` 文件时，编码选择 `Unicode`。

### 保存运行结果

点击生成结果下面的 "保存" 按钮，可以保存运行结果。在 "已保存" 选项卡中，可以看到所有已保存的内容。

  ![保存运行结果界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/fff0654787d9b26fefc7b38a8b1e1233.png)

### 生成更多类似结果

如果在应用编排时开启了 "更多类似" 的功能。在 Web 应用中可以点击 "更多类似" 的按钮来生成和当前结果相似的内容。如下图所示：

  ![生成更多类似结果界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/application-publishing/launch-your-webapp-quickly/9436fc90b8af59afd2e654f29f614c6e.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-publishing/launch-your-webapp-quickly/text-generator.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Web 应用设置
> 来源：`zh-hans/guides/application-publishing/launch-your-webapp-quickly/web-app-settings.mdx`

Web 应用是给应用使用者用的。应用开发者在 Dify 创建一个应用，就会获得一个对应的 Web 应用。Web 应用的使用者无需登陆，即可使用。Web 应用已适配不同尺寸的设备：PC，平板和手机。

Web 应用的内容和应用发布的配置一致。当修改了应用的配置，并在应用的提示词编排页点 “发布” 按钮发布后，Web 应用的内容也会根据当前应用的配置做更新。

我们可以在应用概览页开启和关闭对 Web 应用的访问，以及修改 Web 应用的站点信息：

* 图标
* 名称
* 应用描述
* 界面语言
* 版权信息
* 隐私政策链接

Web 应用的功能表现取决于开发者在编排应用时是否开启该功能，例如：

* 对话开场白
* 对话前填写的变量
* 下一步问题建议
* 语音转文字
* 引用和归属
* 更多类似的答案（文本型应用）
* ......

在下面的章节，我们会分别介绍 Web 应用的两种类型：

* 文本生成型
* 对话型

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-publishing/launch-your-webapp-quickly/web-app-settings.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 将 Dify 应用部署为 MCP 服务器
> 来源：`zh-hans/guides/application-publishing/publish-mcp.mdx`

Dify 现已支持将你的应用部署为 [MCP](https://modelcontextprotocol.io/introduction)（模型上下文协议，一种让 AI 工具之间相互通信的标准协议）服务器。通过这一功能，你可以轻松将 Dify 应用集成到如 Claude Desktop 这样的 AI 助手，或像 Cursor 这样的开发环境中，让这些工具能够直接调用你的 Dify 应用，实现无缝扩展。

  如果你希望在 Dify 工作流或智能体中使用 MCP 工具，请参考[相关指南](./zh-hans/guides/tools/mcp)。

## 配置 Dify 应用为 MCP 服务器

在 Dify 应用的配置页面中，你可以找到 MCP 服务器的相关配置选项。该功能默认关闭，开启后，Dify 将为当前应用自动生成唯一的 MCP 服务器地址。此地址将作为外部工具访问你应用的专用接口。

  MCP 服务器地址包含了敏感的身份验证信息，应等同于 API Key 妥善保管。如怀疑信息泄露，可点击"重新生成"，获取新的服务器地址，原有地址将立即失效。

![CleanShot 2025-07-07 at 08.18.02.png](images/CleanShot2025-07-07at08.18.02.png)

## 与 Claude Desktop 集成

要将 Dify 应用集成到 Claude Desktop，请依次选择：个人资料 > 设置 > 集成 > 添加集成。在"集成 URL"一栏，填写你 Dify 应用的 MCP 服务器地址即可。

## 与 Cursor 集成

在 Cursor 中集成 Dify 应用，只需在项目根目录下创建或编辑 `.cursor/mcp.json` 文件，内容如下：

```json
{
  "mcpServers": {
    "your-server-name": {
      "url": "your-server-url"
    }
  }
}
```

请将 `url` 部分替换为你的 Dify 应用的 MCP 服务器地址。保存文件后，重启 Cursor 即可自动识别这一配置，并将 Dify 应用作为工具集成。该配置支持添加多个应用，只需在 `mcpServers` 对象下增加新的条目即可。

## 实用建议

- **描述信息的清晰性**

  在编写工具描述和参数说明时，应从 AI 处理数据的角度出发。说明越明确、具体，AI 的调用效果就越好。例如，与其简单写"输入数据"，不如详细说明为："包含用户姓名、邮箱和偏好设置的 JSON 对象"。

- **延迟（Latency）管理**

  MCP 协议负责通信层，但 Dify 应用的响应速度依然至关重要。如果你的应用处理时间较长（例如超过 30 秒），用户将在客户端直接感知到延迟。建议增加进度提示，或将复杂流程拆解为多个更快的小步骤，以提升整体体验。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/application-publishing/publish-mcp.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 外部知识库 API
> 来源：`zh-hans/guides/knowledge-base/api-documentation/external-knowledge-api-documentation.mdx`

## 端点

```
POST <your-endpoint>/retrieval
```

## 请求头

该 API 用于连接团队内独立维护的知识库，如需了解更多操作指引，请参考阅读 [连接外部知识库](./zh-hans/guides/knowledge-base/connect-external-knowledge-base)。你可以在 HTTP 请求头的 `Authorization` 字段中使用 `API-Key` 来验证权限。身份验证逻辑由您在检索 API 中定义，如下所示：

```
Authorization: Bearer API_KEY
```

## 请求体元素

请求接受以下 JSON 格式的数据。

| 属性 | 是否必需 | 类型 | 描述 | 示例值 |
|------|----------|------|------|--------|
| knowledge_id | 是 | 字符串 | 知识库唯一 ID | AAA-BBB-CCC |
| query | 是 | 字符串 | 用户的查询 | Dify 是什么？ |
| retrieval_setting | 是 | 对象 | 知识检索参数 | 见下文 |
| metadata_condition | 否 | 对象 | 原数组筛选 | 见下文 |

`retrieval_setting` 属性是一个包含以下键的对象：

| 属性 | 是否必需 | 类型 | 描述 | 示例值 |
|------|----------|------|------|--------|
| top_k | 是 | 整数 | 检索结果的最大数量 | 5 |
| score_threshold | 是 | 浮点数 | 结果与查询相关性的分数限制，范围：0~1 | 0.5 |

`metadata_condition` 属性是一个包含以下键的对象：

| 属性 | 是否必需 | 类型 | 描述 | 示例值 |
|------|----------|------|------|--------|
| logical_operator | 否 | 字符串 | 逻辑操作符，取值为 `and` 或 `or`，默认 `and` | and |
| conditions | 是 | 数组（对象） | 条件列表 | 见下文 |

`conditions` 数组中的每个对象包含以下键：

| 属性 | 是否必需 | 类型 | 描述 | 示例值 |
|------|----------|------|------|--------|
| name | 是 | 数组（字符串） | 需要筛选的 metadata 名称 | `["category", "tag"]` |
| comparison_operator | 是 | 字符串 | 比较操作符 | `contains` |
| value | 否 | 字符串 | 对比值，当操作符为 `empty`、`not empty`、`null`、`not null` 时可省略 | `"AI"` |

支持的 `comparison_operator` 操作符：

- `contains`：包含某个值
- `not contains`：不包含某个值
- `start with`：以某个值开头
- `end with`：以某个值结尾
- `is`：等于某个值
- `is not`：不等于某个值
- `empty`：为空
- `not empty`：不为空
- `=`：等于
- `≠`：不等于
- `>`：大于
- `<`：小于
- `≥`：大于等于
- `≤`：小于等于
- `before`：在某个日期之前
- `after`：在某个日期之后

## 请求语法

```json
POST <your-endpoint>/retrieval HTTP/1.1
-- 请求头
Content-Type: application/json
Authorization: Bearer your-api-key
-- 数据
{
    "knowledge_id": "your-knowledge-id",
    "query": "你的问题",
    "retrieval_setting":{
        "top_k": 2,
        "score_threshold": 0.5
    }
}
```

## 响应元素

如果操作成功，服务将返回 HTTP 200 响应。服务以 JSON 格式返回以下数据。

| 属性 | 是否必需 | 类型 | 描述 | 示例值 |
|------|----------|------|------|--------|
| records | 是 | 对象列表 | 从知识库查询的记录列表 | 见下文 |

`records` 属性是一个包含以下键的对象列表：

| 属性 | 是否必需 | 类型 | 描述 | 示例值 |
|------|----------|------|------|--------|
| content | 是 | 字符串 | 包含知识库中数据源的文本块 | Dify：GenAI 应用程序的创新引擎 |
| score | 是 | 浮点数 | 结果与查询的相关性分数，范围：0~1 | 0.5 |
| title | 是 | 字符串 | 文档标题 | Dify 简介 |
| metadata | 否 | json | 包含数据源中文档的元数据属性及其值 | 见示例 |

## 响应语法

```json
HTTP/1.1 200
Content-type: application/json
{
    "records": [{
                    "metadata": {
                            "path": "s3://dify/knowledge.txt",
                            "description": "dify 知识文档"
                    },
                    "score": 0.98,
                    "title": "knowledge.txt",
                    "content": "这是外部知识的文档。"
            },
            {
                    "metadata": {
                            "path": "s3://dify/introduce.txt",
                            "description": "dify 介绍"
                    },
                    "score": 0.66,
                    "title": "introduce.txt",
                    "content": "GenAI 应用程序的创新引擎"
            }
    ]
}
```

## 错误

如果操作失败，服务将返回以下错误信息（JSON 格式）：

| 属性 | 是否必需 | 类型 | 描述 | 示例值 |
|------|----------|------|------|--------|
| error_code | 是 | 整数 | 错误代码 | 1001 |
| error_msg | 是 | 字符串 | API 异常描述 | 无效的 Authorization 头格式。预期格式为 `Bearer <api-key>`'。 |

`error_code` 属性有以下类型：

| 代码 | 描述 |
|------|------|
| 1001 | 无效的 Authorization 头格式 |
| 1002 | 授权失败 |
| 2001 | 知识库不存在 |

### HTTP 状态码

**AccessDeniedException**
由于缺少访问权限，请求被拒绝。请检查您的权限并重试。
HTTP 状态码：403

**InternalServerException**
发生内部服务器错误。请重试您的请求。
HTTP 状态码：500

## 开发示例

你可以通过以下视频了解如何开发外部知识库插件 —— 以 Llamacloud 为例。

<iframe
  src="https://www.youtube.com/embed/FaOzKZRS-2E"
  width="100%"
  height="315"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
/>

如需了解功能原理，请参考插件 [GitHub 地址](https://github.com/langgenius/dify-official-plugins/tree/main/extensions/llamacloud)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/api-documentation/external-knowledge-api-documentation.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 连接外部知识库
> 来源：`zh-hans/guides/knowledge-base/connect-external-knowledge-base.mdx`

> 为做出区别，独立于 Dify 平台之外的知识库在本文内均被统称为 **“外部知识库”** 。

## 功能简介

对于内容检索有着更高要求的进阶开发者而言，Dify 平台内置的知识库功能和文本检索和召回机制**存在限制，无法轻易变更文本召回结果。**

出于对文本检索和召回的精确度有着更高追求，以及对内部资料的管理需求，部分团队选择自主研发 RAG 算法并独立维护文本召回系统、或将内容统一托管至云厂商的知识库服务（例如 [AWS Bedrock](https://aws.amazon.com/bedrock/)）。

作为中立的 LLM 应用开发平台，Dify 致力于给予开发者更多选择权。

**连接外部知识库**功能可以将 Dify 平台与外部知识库建立连接。通过 API 服务，AI 应用能够获取更多信息来源。这意味着：

* Dify 平台能够直接获取托管在云服务提供商知识库内的文本内容，开发者无需将内容重复搬运至 Dify 中的知识库；
* Dify 平台能够直接获取自建知识库内经算法处理后的文本内容，开发者仅需关注自建知识库的信息检索机制，并不断优化与提升信息召回的准确度。

  ![](https://assets-docs.dify.ai/2025/03/f5fb91d18740c1e2d3938d4d106c4d3c.png)

以下是连接外部知识的详细步骤：

> **步骤：**

        为了确保你的外部知识库与 Dify 连接成功，请在建立 API 服务前仔细阅读由 Dify 编写的[外部知识库 API 规范](./zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/maintain-dataset-via-api)。

        > 目前， Dify 连接外部知识库时仅具备检索权限，暂不支持对外部知识库进行优化与修改，开发者需自行维护外部知识库。

        前往 **“知识库”** 页，点击右上角的 **“外部知识库 API”**，轻点 **“添加外部知识库 API”**。

        按照页面提示，依次填写以下内容：

        * 知识库的名称，允许自定义名称，用于区分所连接的不同外部知识 API；
        * API 接口地址，外部知识库的连接地址，示例 `api-endpoint/retrieval`；详细说明请参考[外部知识库 API](./zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/maintain-dataset-via-api)；
        * API Key，外部知识库连接密钥，详细说明请参考[外部知识库 API](./zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/maintain-dataset-via-api)；

        ![](https://assets-docs.dify.ai/2025/03/727221d849615cd2e52b3fd1e6c10129.png)

        前往 **“知识库”** 页，点击添加知识库卡片下方的 **“连接外部知识库”** 跳转至参数配置页面。

        ![](https://assets-docs.dify.ai/2025/03/efae240731f7fa9693da809c08878188.png)

        填写以下参数：

        * **知识库名称与描述**
        * **外部知识库 API** 选择在第二步中关联的外部知识库 API；Dify 将通过 API 连接的方式，调用存储在外部知识库的文本内容；
        * **外部知识库 ID** 指定需要被关联的特定的外部知识库 ID，详细说明请参考[外部知识库 API](./zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/maintain-dataset-via-api)。
        *   **调整召回设置**

            **Top K：** 用户发起提问时，将请求外部知识 API 获取相关性较高的内容分段。该参数用于筛选与用户问题相似度较高的文本片段。默认值为 3，数值越高，召回存在相关性的文本分段也就越多。

            **Score 阈值：** 文本片段筛选的相似度阈值，只召回超过设置分数的文本片段，默认值为 0.5。数值越高说明对于文本与问题要求的相似度越高，预期被召回的文本数量也越少，结果也会相对而言更加精准。

        ![](https://assets-docs.dify.ai/2025/03/d6345c3af3c2b3befb25fba4dc553a73.png)

        建立与外部知识库的连接后，开发者可以在 **“召回测试”** 中模拟可能的问题关键词，预览从外部知识库召回的文本分段。若对于召回结果不满意，可以尝试修改召回参数或自行调整外部知识库的检索设置。

        ![](https://assets-docs.dify.ai/2025/03/c5977a5d48dc116589cf2f99e67ccfaa.png)

        - **Chatbot / Agent 类型应用**

        在 Chatbot / Agent 类型应用内的编排页中的 **“上下文”** 内，选中带有 `EXTERNAL` 标签的外部知识库。

        ![](https://assets-docs.dify.ai/2025/03/e7df9d7360186ee0f0e156c166f84a3b.png)

        - **Chatflow / Workflow 类型应用**

        在 Chatflow / Workflow 类型应用内添加 **“知识检索”** 节点，选中带有 `EXTERNAL` 标签的外部知识库。

        ![](https://assets-docs.dify.ai/2025/03/4e1cbdcf4a9e6e7c2535a53e478054e3.png)<figcaption></figcaption>

        在 **“知识库”** 页，外部知识库的卡片右上角会带有 **EXTERNAL** 标签。进入需要修改的知识库，点击 **“设置”** 修改以下内容：

        * **知识库名称和描述**
        * **可见范围** 提供 「 只有我 」 、 「 所有团队成员 」 和 「部分团队成员」 三种权限范围。不具有权限的人将无法访问该知识库。若选择将知识库公开至其它成员，则意味着其它成员同样具备该知识库的查看、编辑和删除权限。
        *   **召回设置**

            **Top K:** 用户发起提问时，将请求外部知识 API 获取相关性较高的内容分段。该参数用于筛选与用户问题相似度较高的文本片段。默认值为 3，数值越高，召回存在相关性的文本分段也就越多。

            **Score 阈值：** 文本片段筛选的相似度阈值，只召回超过设置分数的文本片段，默认值为 0.5。数值越高说明对于文本与问题要求的相似度越高，预期被召回的文本数量也越少，结果也会相对而言更加精准。

        外部知识库所关联的 **“外部知识库 API”** 和 **“外部知识 ID”** 不支持修改，如需修改请关联新的 “外部知识库 API” 并重新进行连接。

### 外部知识库连接示例

#### AWS Bedrock

#### LlamaCloud

[Dify 插件市场](https://marketplace.dify.ai/)内提供了 LlamaCloud 插件，可以帮助你快速连接 LlamaCloud 知识库，在 Dify 平台中使用由 LlamaCloud 提供的检索功能，而无需编写自定义 API。

插件市场中搜索 `LlamaCloud` 即可快速安装插件。

按照插件配置向导，填写 LlamaCloud 的 API 密钥和其他必要信息。完成配置后，您可以在知识库列表中看到连接的外部知识库。

**视频教程**

以下视频详细展示了如何使用 LlamaCloud 插件连接外部知识库：

<iframe
  src="https://www.youtube.com/embed/FaOzKZRS-2E"
  width="100%"
  height="315"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
/>

如需了解功能原理，请参考插件 [GitHub 地址](https://github.com/langgenius/dify-official-plugins/tree/main/extensions/llamacloud)。

## 常见问题

**连接外部知识库 API 时异常，出现报错如何处理？**

以下是返回信息各个错误码所对应的错误提示与解决办法：

| 错误码  | 错误提示                        | 解决办法                           |
| ---- | --------------------------- | ------------------------------ |
| 1001 | 无效的 Authorization header 格式 | 请检查请求的 Authorization header 格式 |
| 1002 | 验证异常                        | 请检查所填写的 API Key 是否正确           |
| 2001 | 知识库不存在                      | 请检查外部知识库                       |

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/connect-external-knowledge-base.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 2. 指定分段模式
> 来源：`zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/chunking-and-cleaning-text.mdx`

将内容上传至知识库后，接下来需要对内容进行分段与数据清洗。**该阶段是内容的预处理与数据结构化过程，长文本将会被划分为多个内容分段。**

* **分段**

由于大语言模型的上下文窗口有限，无法一次性处理和传输整个知识库的内容，因此需要对文档中的长文本分段为内容块。即便部分大模型已支持上传完整的文档文件，但实验表明，检索效率依然弱于检索单个内容分段。

LLM 能否精准地回答出知识库中的内容，关键在于知识库对内容块的检索与召回效果。类似于在手册中查找关键章节即可快速得到答案，而无需逐字逐句分析整个文档。经过分段后，知识库能够基于用户问题，采用分段 TopK 召回模式，召回与问题高度相关的内容块，补全关键信息从而提高回答的精准性。

在进行问题与内容块的语义匹配时，合理的分段大小非常关键，它能够帮助模型准确地找到与问题最相关的内容，减少噪音信息。过大或过小的分段都可能影响召回的效果。

Dify 提供了 **"通用分段"** 和 **"父子分段"** 两种分段模式，分别适应不同类型的文档结构和应用场景，满足不同的知识库检索和召回的效率与准确性要求。

* **清洗**

为了保证文本召回的效果，通常需要在将数据录入知识库之前便对其进行清理。例如，文本内容中存在无意义的字符或者空行可能会影响问题回复的质量，需要对其清洗。Dify 已内置的自动清洗策略，详细说明请参考 [ETL](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/chunking-and-cleaning-text)。

LLM 收到用户问题后，能否精准地回答出知识库中的内容，取决于知识库对内容块的检索和召回效果。匹配与问题相关度高的文本分段对 AI 应用生成准确且全面的回应至关重要。

好比在智能客服场景下，仅需帮助 LLM 定位至工具手册的关键章节内容块即可快速得到用户问题的答案，而无需重复分析整个文档。在节省分析过程中所耗费的 Tokens 的同时，提高 AI 应用的问答质量。

### 分段模式

知识库支持两种分段模式：**通用模式**与**父子模式**。如果你是首次创建知识库，建议选择父子模式。

> **信息提示：**

**注意**：原 **"自动分段与清洗"** 模式已自动更新为 **"通用"** 模式。无需进行任何更改，原知识库保持默认设置即可继续使用。选定分段模式并完成知识库的创建后，后续无法变更。知识库内新增的文档也将遵循同样的分段模式。

![通用模式与父子分段模式](https://assets-docs.dify.ai/2024/12/b3052a6aae6e4d0e5701dde3a859e326.png)

#### 通用模式

系统按照用户自定义的规则将内容拆分为独立的分段。当用户输入问题后，系统自动分析问题中的关键词，并计算关键词与知识库中各内容分段的相关度。根据相关度排序，选取最相关的内容分段并发送给 LLM，辅助其处理与更有效地回答。

在该模式下，你需要根据不同的文档格式或场景要求，参考以下设置项，手动设置文本的**分段规则**。

* **分段标识符**，默认值为 `\n`，即按照文章段落进行分块。你可以遵循[正则表达式语法](https://regexr.com/)自定义分块规则，系统将在文本出现分段标识符时自动执行分段。例如  的含义是按照句子进行分段。下图是不同语法的文本分段效果：

![不同分段标识符语法的分段效果](https://assets-docs.dify.ai/2024/12/2c19c1c1a0446c00e3c07d6f4c8968e4.png)

* **分段最大长度**，指定分段内的文本字符数最大上限，超出该长度时将强制分段。默认值为 500 Tokens，分段长度的最大上限为 4000 Tokens；
* **分段重叠长度**，指的是在对数据进行分段时，段与段之间存在一定的重叠部分。这种重叠可以帮助提高信息的保留和分析的准确性，提升召回效果。建议设置为分段长度 Tokens 数的 10-25%；

**文本预处理规则，** 过滤知识库内部分无意义的内容。提供以下选项：

* 替换连续的空格、换行符和制表符
* 删除所有 URL 和电子邮件地址

配置完成后，点击"预览区块"即可查看分段后的效果。你可以直观的看到每个区块的字符数。如果重新修改了分段规则，需要重新点击按钮以查看新的内容分段。

若同时批量上传了多个文档，轻点顶部的文档标题，快速切换并查看其它文档的分段效果。

![通用模式](https://assets-docs.dify.ai/2024/12/b3ec2ce860550563234ca22967abdd17.png)

分段规则设置完成后，接下来需指定索引方式。支持"高质量索引"和"经济索引"，详细说明请参考[设定索引方法](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/setting-indexing-methods)。

#### **父子模式**

与**通用模式**相比，父子模式采用双层分段结构来平衡检索的精确度和上下文信息,让精准匹配与全面的上下文信息二者兼得。

其中，父区块（Parent-chunk）保持较大的文本单位（如段落），提供丰富的上下文信息；子区块（Child-chunk）则是较小的文本单位（如句子），用于精确检索。系统首先通过子区块进行精确检索以确保相关性，然后获取对应的父区块来补充上下文信息，从而在生成响应时既保证准确性又能提供完整的背景信息。你可以通过设置分隔符和最大长度来自定义父子区块的分段方式。

例如在 AI 智能客服场景下，用户输入的问题将定位至解决方案文档内某个具体的句子，随后将该句子所在的段落或章节，联同发送至 LLM，补全该问题的完整背景信息，给出更加精准的回答。

其基本机制包括：

* **子分段匹配查询**：
  * 将文档拆分为较小、集中的信息单元（例如一句话），更加精准的匹配用户所输入的问题。
  * 子分段能快速提供与用户需求最相关的初步结果。
* **父分段提供上下文**：
  * 将包含匹配子分段的更大部分（如段落、章节甚至整个文档）视作父分段并提供给大语言模型（LLM）。
  * 父分段能为 LLM 提供完整的背景信息，避免遗漏重要细节，帮助 LLM 输出更贴合知识库内容的回答。

![父子召回原理图](https://assets-docs.dify.ai/2024/12/3e6820c10bd7c5f6884930e3a14e7b66.png)

在该模式下，你需要根据不同的文档格式或场景要求，手动分别设置父子分段的**分段规则**。

**父分段：**

父分段设置提供以下分段选项：

* **段落**

根据预设的分隔符规则和最大块长度将文本拆分为段落。每个段落视为父分段，适用于文本量较大，内容清晰且段落相对独立的文档。支持以下设置项：

* **分段标识符**，默认值为 `\n`，即按照文本段落分段。你可以遵循[正则表达式语法](https://regexr.com/)自定义分块规则，系统将在文本出现分段标识符时自动执行分段。
* **分段最大长度**，指定分段内的文本字符数最大上限，超出该长度时将强制分段。默认值为 500 Tokens，分段长度的最大上限为 4000 Tokens；

* **全文**

不进行段落分段，而是直接将全文视为单一父分段。出于性能原因，仅保留文本内的前 10000 Tokens 字符，适用于文本量较小，但段落间互有关联，需要完整检索全文的场景。

![父子模式下的段落和全文预览](https://assets-docs.dify.ai/2024/12/e3814336710d445a99a9ded3d251622b.png)

**子分段：**

子分段文本是在父文本分段基础上，由分隔符规则切分而成，用于查找和匹配与问题关键词最相关和直接的信息。如果使用默认的子分段规则，通常呈现以下分段效果：

* 当父分段为段落时，子分段对应各个段落中的单个句子。
* 父分段为全文时，子分段对应全文中各个单独的句子。

在子分段内填写以下分段设置：

* **分段标识符**，默认值为 ，即按照句子进行分段。你可以遵循[正则表达式语法](https://regexr.com/)自定义分块规则，系统将在文本出现分段标识符时自动执行分段。
* **分段最大长度**，指定分段内的文本字符数最大上限，超出该长度时将强制分段。默认值为 200 Tokens，分段长度的最大上限为 4000 Tokens；

你还可以使用**文本预处理规则**过滤知识库内部分无意义的内容：

* 替换连续的空格、换行符和制表符
* 删除所有 URL 和电子邮件地址

配置完成后，点击"预览区块"即可查看分段后的效果。你可以查看父分段的整体字符数。背景标蓝的字符为子分块，同时显示当前子段的字符数。

如果重新修改了分段规则，需要重新点击"预览区块"按钮以查看新的内容分段。若同时批量上传了多个文档，轻点顶部的文档标题，快速切换至其它文档并预览内容的分段效果。

![父子分段模式](https://assets-docs.dify.ai/2024/12/af5c9a68f85120a6ea687bf93ecfb80a.png)

为了确保内容检索的准确性，父子分段模式仅支持使用["高质量索引"](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/chunking-and-cleaning-text)。

### 两种模式的区别是什么？

两者的主要区别在于内容区块的分段形式。**通用模式**的分段结果为多个独立的内容分段，而**父子模式**采用双层结构进行内容分段，即单个父分段的内容（文档全文或段落）内包含多个子分段内容（句子）。

不同的分段方式将影响 LLM 对于知识库内容的检索效果。在相同文档中，采用父子检索所提供的上下文信息会更全面，且在精准度方面也能保持较高水平，大大优于传统的单层通用检索方式。

![通用模式与父子模式的内容检索效果对比](https://assets-docs.dify.ai/2024/12/0b614c6a07c6ea2151fe17d85ce6a1d1.png)

### 阅读更多

选定分段模式后，接下来你可以参考以下文档分别设定索引方式和检索方式，完成知识库的创建。

  了解更多高质量索引和经济索引的详细信息

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/chunking-and-cleaning-text.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 1. 导入文本数据
> 来源：`zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/import-content-data/readme.mdx`

轻点 Dify 平台顶部导航中 **"知识库"** → "**创建知识库"**。你可以通过上传本地文件或导入在线数据两种方式上传文档至知识库内。

### **上传本地文件**

拖拽或选中文件进行上传，**支持批量上传**，同时上传的文件数量限制取决于[订阅计划](https://dify.ai/pricing)。

**本地上传文档文件存在以下限制：**

* 单文档的上传大小限制为 **15MB**
* 不同 SaaS 版本的[订阅计划](https://dify.ai/pricing)限定了**批量上传个数、文档上传总数、向量存储空间**

![创建知识库](https://assets-docs.dify.ai/2025/01/22064cb61356e4c005c4072d5d066cf6.png)

### **导入在线数据**

创建知识库时支持通过在线数据导入。知识库支持导入以下两种在线数据：

  了解如何从 Notion 导入数据

  了解如何从网站导入数据

引用在线数据的知识库后续无法新增本地文档，也无法变更为本地文件类型的知识库，以防止单一知识库存在多种数据来源而造成管理困难。

### 后续导入

如果还没有准备好文档或其它内容数据，可以先创建一个空知识库，在后续上传本地文档或导入在线数据。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/import-content-data/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 1.1 从 Notion 导入数据
> 来源：`zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/import-content-data/sync-from-notion.mdx`

Dify 知识库支持从 Notion 导入，并支持后续的数据自动同步。

### 授权验证

1. 在创建知识库，选择数据源时，点击 **同步自 Notion 内容-- 去绑定，根据提示完成授权验证。**
2. 你也可以：进入 **设置 -- 数据来源 -- 添加数据源** 中点击 Notion 来源 **绑定** ，完成授权验证。

![绑定 Notion](https://assets-docs.dify.ai/2024/12/f1d5bcdcfbd57407e0bce1597df4daad.png)

### 导入 Notion 数据

完成验证授权后，进入创建知识库页面，点击**同步自 Notion 内容**，选择需要的授权页面进行导入。

![Import from notion](https://assets-docs.dify.ai/2025/01/ac130faeb40a59662c2f63b9680d061e.png)

### 进行分段和清洗

接下来，选择知识库的**分段设置**和**索引方式**，**保存并处理**。等待 Dify 自动处理数据。Dify 不仅可以导入 Notion 的普通类型页面，同时也支持导入并汇总保存 database 类型下的页面属性。

_**请注意：暂不支持导入图片和文件，表格类数据会被转换为文本展示。**_

![预览 Notion 页的分段结果](https://assets-docs.dify.ai/2024/12/ab1b1aa690adad153cac0a321b6b7585.png)

### 同步 Notion 数据

如果你的 Notion 内容有更新，可以在知识库的 **文档列表页**中点击对应内容页的 **同步** 按钮进行数据同步。同步文档涉及嵌入过程，因此将消耗嵌入模型的 Tokens。

![同步 Notion 内容](https://assets-docs.dify.ai/2024/12/af7cabd98c3aac392819d9041cc408de.png)

### 社区版 Notion 的集成配置方法

Notion 分为**内部集成**（internal integration）和**外部集成**（public integration）两种方式，两种集成方式的具体区别请参阅 [Notion 官方文档](https://developers.notion.com/docs/authorization)。

### 1、**使用 internal 集成方式**

首先，在集成的设置页面中[创建集成](https://www.notion.so/my-integrations)。默认情况下，所有集成都以内部集成开始；内部集成将与你选择的工作区相关联，因此你需要是工作区所有者才能创建集成。

具体操作步骤：

点击“**New integration**”按钮，类型默认是 **Internal**（不可修改），选择关联的空间，输入集成名称并上传 logo 后，点击“Submit”，集成创建成功。

![](https://assets-docs.dify.ai/2025/04/f66f75df7e5601508c69377f813cdbcc.png)

创建集成后，你可以根据需要在 Capabilities 选项卡下更新其设置，并在 Secrets 下点击 “Show” 按钮然后复制 Secrets。

![](https://assets-docs.dify.ai/2025/04/83c1f1699ec4165b56ae8fea304d35f5.png)

复制后回到 Dify 源代码下，在 **.env** 文件里配置相关环境变量，环境变量如下：

```
NOTION_INTEGRATION_TYPE = internal or NOTION_INTEGRATION_TYPE = public
NOTION_INTERNAL_SECRET=you-internal-secret
```

### 2、**使用 Public 集成方式**

**需要将 internal 集成升级为 public 集成**，导航到集成的 Distribution 页面，然后切换开关以公开集成。将开关切换到公共设置，你需要在下面的 Organization Information 表单中填写其他信息，包括你的公司名称、网站和重定向 URL 等信息，然后点击“Submit”按钮。

![](https://assets-docs.dify.ai/2025/04/c37759d54f8e72685e1cacffa23d2e9f.png)

在集成的设置页面中成功公开集成后，你将能够在密钥选项卡中访问集成的密钥：

![](https://assets-docs.dify.ai/2025/04/c4af8b95298c6b86d80406bec09c31e7.png)

回到 Dify 源代码下，在 **.env** 文件里配置相关环境变量，环境变量如下：

```
NOTION_INTEGRATION_TYPE=public
NOTION_CLIENT_SECRET=you-client-secret
NOTION_CLIENT_ID=you-client-id
```

配置完成后，即可在知识库中操作 Notion 的数据导入及同步功能。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/import-content-data/sync-from-notion.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 1.2 从网页导入数据
> 来源：`zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/import-content-data/sync-from-website.mdx`

知识库支持通过第三方工具如 [Jina Reader](https://jina.ai/reader), [Firecrawl ](https://www.firecrawl.dev/)抓取公开网页中的内容，解析为 Markdown 内容并导入至知识库。

> **信息提示：**

Jina Reader 和 Firecrawl 均是开源的网页解析工具，能将网页将其转换为干净并且方便 LLM 识别的 Markdown 格式文本，同时提供了易于使用的 API 服务。

下文将分别介绍 Firecrawl 和 Jina Reader 的使用方法。

## Firecrawl

### 配置 Firecrawl 凭据

点击右上角头像，然后前往 **DataSource** 页面，点击 Firecrawl 右侧的 Configure 按钮。

![配置 Firecrawl](https://assets-docs.dify.ai/2024/12/d468cf996f591b4b2bd0ffb5de62bad4.png)

登录 [Firecrawl 官网](https://www.firecrawl.dev/) 完成注册，获取 API Key 后按照页面提示填入并点击保存。

### 使用 Firecrawl 抓取网页内容

在知识库创建页选择 **Sync from website**，provider 选中 Firecrawl，填入需要抓取的目标 URL。

设置中的配置项包括：是否抓取子页面、抓取页面数量上限、页面抓取深度、排除页面、仅抓取页面、提取内容。完成配置后点击 **Run**，预览将要被抓取的目标页面链接。

![执行抓取](https://assets-docs.dify.ai/2024/12/3e63b4ced9770e21d5132c3aa8e5d2de.png)

导入网页解析的文本后存储至知识库的文档中，查看导入结果。点击 **Add URL** 可以继续导入新的网页。抓取完成后，网页中的内容将会被收录至知识库内。

---

## Jina Reader

### 配置 Jina Reader 凭据

点击右上角头像，然后前往 **DataSource** 页面，点击 Jina Reader 右侧的 Configure 按钮。

![配置 Jina Reader](https://assets-docs.dify.ai/2024/12/28b37f9b36fe808b2d3302c48fce5ea3.png)

登录[ Jina Reader 官网](https://jina.ai/reader) 完成注册，获取 API Key 后并按照页面提示填入并保存。

### 使用 Jina Reader 抓取网页内容

在知识库创建页选择 **Sync from website**，provider 选中 Jina Reader，填写需要抓取的目标 URL。

![网页抓取配置](https://assets-docs.dify.ai/2024/12/f9170b2a2ab1be94bc85ff3ed3c3e723.png)

设置中的配置项包括：是否抓取子页面、抓取页面数量上限、是否使用 sitemap 抓取。完成配置后点击 **Run** 按钮，预览将要被抓取的页面链接。

![执行抓取](https://assets-docs.dify.ai/2024/12/a875f21a751551c03109c76308c577ee.png)

导入网页解析的文本后存储至知识库的文档中，查看导入结果。如需继续添加网页，轻点右侧 **Add URL** 按钮继续导入新的网页。

![导入网页解析文本至知识库内](https://assets-docs.dify.ai/2024/12/03494dc3c882ac1c74b464ea931e2533.png)

抓取完成后，网页中的内容将会被收录至知识库内。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/import-content-data/sync-from-website.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 知识库创建步骤
> 来源：`zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/readme.mdx`

创建知识库并上传文档大致分为以下步骤：

1. 创建知识库。通过上传本地文件、导入在线数据或创建一个空的知识库。

选择通过上传本地文件或导入在线数据的方式创建知识库

2. 指定分段模式。该阶段是内容的预处理与数据结构化过程，长文本将会被划分为多个内容分段。你可以在此环节预览文本的分段效果。

了解如何设置文本分段和清洗规则

3. 设定索引方法和检索设置。知识库在接收到用户查询问题后，按照预设的检索方式在已有的文档内查找相关内容，提取出高度相关的信息片段供语言模型生成高质量答案。

了解如何配置检索方式和相关设置

5. 等待分段嵌入
6. 完成上传，在应用内关联知识库并使用。你可以参考[在应用内集成知识库](./zh-hans/guides/knowledge-base/integrate-knowledge-within-application)，搭建出能够基于知识库进行问答的 LLM 应用。如需修改或管理知识库，请参考[知识库管理与文档维护](./zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/introduction)。

![完成知识库的创建](https://assets-docs.dify.ai/2024/12/a3362a1cd384cb2b539c9858de555518.png)

### 参考阅读

#### ETL

在 RAG 的生产级应用中，为了获得更好的数据召回效果，需要对多源数据进行预处理和清洗，即 ETL （_extract, transform, load_）。为了增强非结构化/半结构化数据的预处理能力，Dify 支持了可选的 ETL 方案：**Dify ETL** 和[ ](https://docs.unstructured.io/welcome)[**Unstructured ETL** ](https://unstructured.io/)。Unstructured 能够高效地提取并转换你的数据为干净的数据用于后续的步骤。Dify 各版本的 ETL 方案选择：

* SaaS 版不可选，默认使用 Unstructured ETL；
* 社区版可选，默认使用 Dify ETL ，可通过[环境变量](./zh-hans/getting-started/install-self-hosted/environments)开启 Unstructured ETL；

文件解析支持格式的差异：

| DIFY ETL | Unstructured ETL |
| --- | --- |
| txt、markdown、md、pdf、html、htm、xlsx、xls、docx、csv | txt、markdown、md、pdf、html、htm、xlsx、xls、docx、csv、eml、msg、pptx、ppt、xml、epub |

不同的 ETL 方案在文件提取效果的方面也会存在差异，想了解更多关于 Unstructured ETL 的数据处理方式，请参考[官方文档](https://docs.unstructured.io/open-source/core-functionality/partitioning)。

#### **Embedding**

**Embedding 嵌入**是一种将离散型变量（如单词、句子或者整个文档）转化为连续的向量表示的技术。它可以将高维数据（如单词、短语或图像）映射到低维空间，提供一种紧凑且有效的表示方式。这种表示不仅减少了数据的维度，还保留了重要的语义信息，使得后续的内容检索更加高效。

**Embedding 模型**是一种专门用于将文本向量化的大语言模型，它擅长将文本转换为密集的数值向量，有效捕捉语义信息。

> 如需了解更多，请参考：[《Dify：Embedding 技术与 Dify 知识库设计/规划》](https://mp.weixin.qq.com/s/vmY_CUmETo2IpEBf1nEGLQ)。

#### **元数据**

如需使用元数据功能管理知识库，请参阅 [元数据](./zh-hans/guides/knowledge-base/metadata)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 3. 设定索引方法与检索设置
> 来源：`zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/setting-indexing-methods.mdx`

选定内容的分段模式后，接下来设定对于结构化内容的**索引方法**与**检索设置**。

## 设定索引方法

正如搜索引擎通过高效的索引算法匹配与用户问题最相关的网页内容，索引方式是否合理将直接影响 LLM 对知识库内容的检索效率以及回答的准确性。

提供 **高质量** 与 **经济** 两种索引方法，其中分别提供不同的检索设置选项：

  原 Q&A 模式（仅适用于社区版）已成为高质量索引方法下的一个可选项。

    **高质量**

    在高质量模式下，使用 Embedding 嵌入模型将已分段的文本块转换为数字向量，帮助更加有效地压缩与存储大量文本信息；**使得用户问题与文本之间的匹配能够更加精准**。

    将内容块向量化并录入至数据库后，需要通过有效的检索方式调取与用户问题相匹配的内容块。高质量模式提供向量检索、全文检索和混合检索三种检索设置。关于各个设置的详细说明，请继续阅读[检索设置](#指定检索方式)。

    选择高质量模式后，当前知识库的索引方式无法在后续降级为 **“经济”索引模式**。如需切换，建议重新创建知识库并重选索引方式。

    > 如需了解更多关于嵌入技术与向量的说明，请参考[《Embedding 技术与 Dify》](https://mp.weixin.qq.com/s/vmY_CUmETo2IpEBf1nEGLQ)。

    ![高质量模式](https://assets-docs.dify.ai/2024/12/51442c8fcd05479616a3dd8279a4853a.png)

    **启用 Q\&A 模式（可选，仅适用于[社区版](./zh-hans/getting-started/install-self-hosted/faq)）**

    开启该模式后，系统将对已上传的文本进行分段。总结内容后为每个分段自动生成 Q\&A 匹配对。与常见的 「Q to P」（用户问题匹配文本段落）策略不同，QA 模式采用 「Q to Q」（问题匹配问题）策略。

    这是因为 「常见问题」 文档里的文本**通常是具备完整语法结构的自然语言**，Q to Q 模式会令问题和答案的匹配更加清晰，并同时满足一些高频和高相似度问题的提问场景。

    > **Q\&A 模式仅支持处理 「中英日」 三语。启用该模式后可能会消耗更多的 LLM Tokens，并且无法使用**[**经济型索引方法**](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/setting-indexing-methods)**。**

    ![Q\&A Chunking](https://assets-docs.dify.ai/2024/12/70960a237d4f5eaed2dbf46a2cca2bf7.png)

    当用户提问时，系统会找出与之最相似的问题，然后返回对应的分段作为答案。这种方式更加精确，因为它直接针对用户问题进行匹配，可以更准确地帮助用户检索真正需要的信息。

    ![Q to P 与 Q to Q 的索引模式区别](https://assets-docs.dify.ai/2024/12/8745ccabff56290eae329a9d3592f745.png)

    **经济**

    在经济模式下，每个区块内使用 10 个关键词进行检索，降低了准确度但无需产生费用。对于检索到的区块，仅提供倒排索引方式选择最相关的区块，详细说明请阅读[下文](#指定检索方式)。

    选择经济型索引方式后，若感觉实际的效果不佳，可以在知识库设置页中升级为 **“高质量”索引方式**。

    ![经济模式](https://assets-docs.dify.ai/2024/12/3b86e6b484da39452c164cb6372a7242.png)

## 指定检索方式 <a href="#retrieval_settings" id="retrieval_settings"></a>

知识库在接收到用户查询问题后，按照预设的检索方式在已有的文档内查找相关内容，提取出高度相关的信息片段供语言模型生成高质量答案。这将决定 LLM 所能获取的背景信息，从而影响生成结果的准确性和可信度。

常见的检索方式包括基于向量相似度的语义检索，以及基于关键词的精准匹配：前者将文本内容块和问题查询转化为向量，通过计算向量相似度匹配更深层次的语义关联；后者通过倒排索引，即搜索引擎常用的检索方法，匹配问题与关键内容。

不同的索引方法对应差异化的检索设置。

    **高质量索引**

    在高质量索引方式下，Dify 提供向量检索、全文检索与混合检索设置：

    ![检索设置](https://assets-docs.dify.ai/2024/12/9b02fc353324221cc91f185a350775b6.png)

    **向量检索**

    **定义：** 向量化用户输入的问题并生成查询文本的数学向量，比较查询向量与知识库内对应的文本向量间的距离，寻找相邻的分段内容。

    ![向量检索](https://assets-docs.dify.ai/2024/12/620044faa47a5037f85b32a27a56fce5.png)

    **向量检索设置：**

    **Rerank 模型：** 默认关闭。开启后将使用第三方 Rerank 模型再一次重排序由向量检索召回的内容分段，以优化排序结果。帮助 LLM 获取更加精确的内容，辅助其提升输出的质量。开启该选项前，需前往“设置” → “模型供应商”，提前配置 Rerank 模型的 API 秘钥。

    > 开启该功能后，将消耗 Rerank 模型的 Tokens，详情请参考对应模型的价格说明。

    **TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。默认值为 3，数值越高，预期被召回的文本分段数量越多。

    **Score 阈值：** 用于设置文本片段筛选的相似度阈值，只召回超过设置分数的文本片段，默认值为 0.5。数值越高说明对于文本与问题要求的相似度越高，预期被召回的文本数量也越少。

    > TopK 和 Score 设置仅在 Rerank 步骤生效，因此需要添加并开启 Rerank 模型才能应用两者中的设置参数。

    ***

    **全文检索**

    **定义：** 关键词检索，即索引文档中的所有词汇。用户输入问题后，通过明文关键词匹配知识库内对应的文本片段，返回符合关键词的文本片段；类似搜索引擎中的明文检索。

    ![全文检索](https://assets-docs.dify.ai/2024/12/513bff1ca38ec746b3246502b0311b39.png)

    **Rerank 模型：** 默认关闭。开启后将使用第三方 Rerank 模型再一次重排序由全文检索召回的内容分段，以优化排序结果。向 LLM 发送经过重排序的分段，辅助其提升输出的内容质量。开启该选项前，需前往“设置” → “模型供应商”，提前配置 Rerank 模型的 API 秘钥。

    > 开启该功能后，将消耗 Rerank 模型的 Tokens，详情请参考对应模型的价格说明。

    **TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。数值越高，预期被召回的文本分段数量越多。

    **Score 阈值：** 用于设置文本片段筛选的相似度阈值，只召回超过设置分数的文本片段，默认值为 0.5。数值越高说明对于文本与问题要求的相似度越高，预期被召回的文本数量也越少。

    > TopK 和 Score 设置仅在 Rerank 步骤生效，因此需要添加并开启 Rerank 模型才能应用两者中的设置参数。

    ***

    **混合检索**

    **定义：** 同时执行全文检索和向量检索，或 Rerank 模型，从查询结果中选择匹配用户问题的最佳结果。

    ![混合检索](https://assets-docs.dify.ai/2024/12/bd2621bfe8a1a8e21fca0743ec495a9e.png)

    在混合检索设置内可以选择启用 **“权重设置”** 或 **“Rerank 模型”**。

    *   **权重设置**

        允许用户赋予语义优先和关键词优先自定义的权重。关键词检索指的是在知识库内进行全文检索（Full Text Search），语义检索指的是在知识库内进行向量检索（Vector Search）。

        *   **将语义值拉至 1**

            **仅启用语义检索模式**。借助 Embedding 模型，即便知识库中没有出现查询中的确切词汇，也能通过计算向量距离的方式提高搜索的深度，返回正确内容。此外，当需要处理多语言内容时，语义检索能够捕捉不同语言之间的意义转换，提供更加准确的跨语言搜索结果。
        *   **将关键词的值拉至 1**

            **仅启用关键词检索模式**。通过用户输入的信息文本在知识库全文匹配，适用于用户知道确切的信息或术语的场景。该方法所消耗的计算资源较低，适合在大量文档的知识库内快速检索。
        *   **自定义关键词和语义权重**

            除了将不同的数值拉至 1，你还可以不断调试二者的权重，找到符合业务场景的最佳权重比例。

    > 语义检索指的是比对用户问题与知识库内容中的向量距离。距离越近，匹配的概率越大。参考阅读：[《Dify：Embedding 技术与 Dify 知识库设计/规划》](https://mp.weixin.qq.com/s/vmY_CUmETo2IpEBf1nEGLQ)。

    ***

    *   **Rerank 模型**

        默认关闭。开启后将使用第三方 Rerank 模型再一次重排序由混合检索召回的内容分段，以优化排序结果。向 LLM 发送经过重排序的分段，辅助其提升输出的内容质量。开启该选项前，需前往“设置” → “模型供应商”，提前配置 Rerank 模型的 API 秘钥。

        > 开启该功能后，将消耗 Rerank 模型的 Tokens，详情请参考对应模型的价格说明。

    **“权重设置”** 和 **“Rerank 模型”** 设置内支持启用以下选项：

    **TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。数值越高，预期被召回的文本分段数量越多。

    **Score 阈值：** 用于设置文本片段筛选的相似度阈值，即：只召回超过设置分数的文本片段。系统默认关闭该设置，即不会对召回的文本片段相似值过滤。打开后默认值为 0.5。数值越高，预期被召回的文本数量越少。

    **倒排索引**

    在经济索引方式下，仅提供**倒排索引方式**。这是一种用于快速检索文档中关键词的索引结构，常用于在线搜索引擎。倒排索引仅支持 **TopK** 设置项。

    **TopK：**

    用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。数值越高，预期被召回的文本分段数量越多。

    ![倒排索引](https://assets-docs.dify.ai/2024/12/b417cd028131d34779993fbcbb8dbdd7.png)

## 阅读更多

指定检索设置后，你可以参考以下文档查看在实际场景下，关键词与内容块的匹配情况。

  查看实际场景下的关键词与内容块匹配情况

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/setting-indexing-methods.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 常见问题
> 来源：`zh-hans/guides/knowledge-base/faq.mdx`

## 1. 导入文档与查询响应速度缓慢，如何排查原因？

通常情况下，上传文档后的 Embedding 过程将耗费大量资源，有可能造成速度缓慢。请检查服务器负载，将日志切换为 debug 模式或检查 Embedding 的返回时间。

## 2. 上传至知识库的文档内容较多，分段后内容异常，如何处理？

请检查服务器负载的内存占用情况，查看是否出现内存泄漏问题。

## 3. 知识库的文件处理一直显示为“排队中”，如何处理？

此问题有可能是由于与 redis 服务的连接中断，导致任务无法退出。建议重启 Worker 节点。

## 4. 如何优化应用对知识库内容的检索结果？

你可以通过调整检索设置，比较不同的参数进行优化。具体操作请参考[检索设置](./zh-hans/guides/knowledge-base/knowledge-base-creation/introduction)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/faq.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 混合检索
> 来源：`zh-hans/guides/knowledge-base/indexing-and-retrieval/hybrid-search.mdx`

### 为什么需要混合检索？

RAG 检索环节中的主流方法是向量检索，即语义相关度匹配的方式。技术原理是通过将外部知识库的文档先拆分为语义完整的段落或句子，并将其转换（Embedding）为计算机能够理解的一串数字表达（多维向量），同时对用户问题进行同样的转换操作。

计算机能够发现用户问题与句子之间细微的语义相关性，比如 “猫追逐老鼠” 和 “小猫捕猎老鼠” 的语义相关度会高于 “猫追逐老鼠” 和 “我喜欢吃火腿” 之间的相关度。在将相关度最高的文本内容查找到后，RAG 系统会将其作为用户问题的上下文一起提供给大模型，帮助大模型回答问题。

除了能够实现复杂语义的文本查找，向量检索还有其他的优势：

* 相近语义理解（如老鼠/捕鼠器/奶酪，谷歌/必应/搜索引擎）
* 多语言理解（跨语言理解，如输入中文匹配英文）
* 多模态理解（支持文本、图像、音视频等的相似匹配）
* 容错性（处理拼写错误、模糊的描述）

虽然向量检索在以上情景中具有明显优势，但有某些情况效果不佳。比如：

* 搜索一个人或物体的名字（例如，伊隆·马斯克，iPhone 15）
* 搜索缩写词或短语（例如，RAG，RLHF）
* 搜索 ID（例如， `gpt-3.5-turbo` ， `titan-xlarge-v1.01` ）

而上面这些的缺点恰恰都是传统关键词搜索的优势所在，传统关键词搜索擅长：

* 精确匹配（如产品名称、姓名、产品编号）
* 少量字符的匹配（通过少量字符进行向量检索时效果非常不好，但很多用户恰恰习惯只输入几个关键词）
* 倾向低频词汇的匹配（低频词汇往往承载了语言中的重要意义，比如“你想跟我去喝咖啡吗？”这句话中的分词，“喝”“咖啡”会比“你”“想”“吗”在句子中承载更重要的含义）

对于大多数文本搜索的情景，首要的是确保潜在最相关结果能够出现在候选结果中。向量检索和关键词检索在检索领域各有其优势。混合搜索正是结合了这两种搜索技术的优点，同时弥补了两方的缺点。

在混合检索中，你需要在数据库中提前建立向量索引和关键词索引，在用户问题输入时，分别通过两种检索器在文档中检索出最相关的文本。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (178).png)**

“混合检索”实际上并没有明确的定义，本文以向量检索和关键词检索的组合为示例。如果我们使用其他搜索算法的组合，也可以被称为“混合检索”。比如，我们可以将用于检索实体关系的知识图谱技术与向量检索技术结合。

不同的检索系统各自擅长寻找文本（段落、语句、词汇）之间不同的细微联系，这包括了精确关系、语义关系、主题关系、结构关系、实体关系、时间关系、事件关系等。可以说没有任何一种检索模式能够适用全部的情景。**混合检索通过多个检索系统的组合，实现了多个检索技术之间的互补。**

### **向量检索**

定义：通过生成查询嵌入并查询与其向量表示最相似的文本分段。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (167).png)**

**TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。

**Score 阈值：** 用于设置文本片段筛选的相似度阈值，即：只召回超过设置分数的文本片段。系统默认关闭该设置，即不会对召回的文本片段相似值过滤。打开后默认值为 0.5 。

**Rerank 模型：** 你可以在“模型供应商”页面配置 Rerank 模型的 API 秘钥之后，在检索设置中打开“Rerank 模型”，系统会在语义检索后对已召回的文档结果再一次进行语义重排序，优化排序结果。设置 Rerank 模型后，TopK 和 Score 阈值设置仅在 Rerank 步骤生效。

### **全文检索**

定义：索引文档中的所有词汇，从而允许用户查询任意词汇，并返回包含这些词汇的文本片段。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (173).png)**

**TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。

**Rerank 模型：** 你可以在“模型供应商”页面配置 Rerank 模型的 API 秘钥之后，在检索设置中打开“Rerank 模型”，系统会在全文检索后对已召回的文档结果再一次进行语义重排序，优化排序结果。设置 Rerank 模型后，TopK 和 Score 阈值设置仅在 Rerank 步骤生效。

### **混合检索**

同时执行全文检索和向量检索，并应用重排序步骤，从两类查询结果中选择匹配用户问题的最佳结果，需配置 Rerank 模型 API。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (169).png)**

**TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。

**Rerank 模型：** 你可以在“模型供应商”页面配置 Rerank 模型的 API 秘钥之后，在检索设置中打开“Rerank 模型”，系统会在混合检索后对已召回的文档结果再一次进行语义重排序，优化排序结果。设置 Rerank 模型后，TopK 和 Score 阈值设置仅在 Rerank 步骤生效。

### 创建数据集时设置检索模式

进入“数据集->创建数据集”页面并在检索设置中设置不同的检索模式：

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (170).png)**

### 数据集设置中修改检索模式

进入“数据集->选择数据集->设置”页面中可以对已创建的数据集修改不同的检索模式。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (171).png)**

### 提示词编排中修改检索模式

进入“提示词编排->上下文->选择数据集->设置”页面中可以在创建应用时修改不同的检索模式。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (172).png)**

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/indexing-and-retrieval/hybrid-search.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 重排序
> 来源：`zh-hans/guides/knowledge-base/indexing-and-retrieval/rerank.mdx`

### 为什么需要重排序？

混合检索能够结合不同检索技术的优势获得更好的召回结果，但在不同检索模式下的查询结果需要进行合并和归一化（将数据转换为统一的标准范围或分布，以便更好地进行比较、分析和处理），然后再一起提供给大模型。这时候我们需要引入一个评分系统：重排序模型（Rerank Model）。

**重排序模型会计算候选文档列表与用户问题的语义匹配度，根据语义匹配度重新进行排序，从而改进语义排序的结果**。其原理是计算用户问题与给定的每个候选文档之间的相关性分数，并返回按相关性从高到低排序的文档列表。常见的 Rerank 模型如：Cohere rerank、bge-reranker 等。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (179).png)**

在大多数情况下，在重排序之前会有一次前置检索，这是由于计算查询与数百万个文档之间的相关性得分将会非常低效。所以，**重排序一般都放在搜索流程的最后阶段，非常适合用于合并和排序来自不同检索系统的结果**。

不过，重排序并不是只适用于不同检索系统的结果合并，即使是在单一检索模式下，引入重排序步骤也能有效帮助改进文档的召回效果，比如我们可以在关键词检索之后加入语义重排序。

在具体实践过程中，除了将多路查询结果进行归一化之外，在将相关的文本分段交给大模型之前，我们一般会限制传递给大模型的分段个数（即 TopK，可以在重排序模型参数中设置），这样做的原因是大模型的输入窗口存在大小限制（一般为 4K、8K、16K、128K 的 Token 数量），你需要根据选用的模型输入窗口的大小限制，选择合适的分段策略和 TopK 值。

需要注意的是，即使模型上下文窗口很足够大，过多的召回分段会可能会引入相关度较低的内容，导致回答的质量降低，所以重排序的 TopK 参数并不是越大越好。

重排序并不是搜索技术的替代品，而是一种用于增强现有检索系统的辅助工具。**它最大的优势是不仅提供了一种简单且低复杂度的方法来改善搜索结果，允许用户将语义相关性纳入现有的搜索系统中，而且无需进行重大的基础设施修改。**

以 Cohere Rerank 为例，你只需要注册账户和申请 API ，接入只需要两行代码。另外，他们也提供了多语言模型，也就是说你可以将不同语言的文本查询结果进行一次性排序。

### 如何配置 Rerank 模型？

Dify 目前已支持 Cohere Rerank 模型，进入“模型供应商-> Cohere”页面填入 Rerank 模型的 API 秘钥：

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (163).png)**

###

### 如何获取 Cohere Rerank 模型？

登录：[https://cohere.com/rerank](https://cohere.com/rerank)，在页内注册并申请 Rerank 模型的使用资格，获取 API 秘钥。

###

### 数据集检索模式中设置 Rerank 模型

进入“数据集->创建数据集->检索设置”页面并在添加 Rerank 设置。除了在创建数据集可以设置 Rerank ，你也可以在已创建的数据集设置内更改 Rerank 配置，在应用编排的数据集召回模式设置中更改 Rerank 配置。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (132).png)**

**TopK：** 用于设置 Rerank 后返回相关文档的数量。

**Score 阈值：** 用于设置 Rerank 后返回相关文档的最低分值。设置 Rerank 模型后，TopK 和 Score 阈值设置仅在 Rerank 步骤生效。

### 数据集多路召回模式中设置 Rerank 模型

进入“提示词编排->上下文->设置”页面中设置为多路召回模式时需开启 Rerank 模型。

查看更多关于多路召回模式的说明，[《多路召回》](./zh-hans/guides/knowledge-base/integrate-knowledge-within-application)。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (133).png)**

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/indexing-and-retrieval/rerank.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 检索增强生成（RAG）
> 来源：`zh-hans/guides/knowledge-base/indexing-and-retrieval/retrieval-augment.mdx`

### RAG 的概念解释

向量检索为核心的 RAG 架构已成为解决大模型获取最新外部知识，同时解决其生成幻觉问题时的主流技术框架，并且已在相当多的应用场景中落地实践。

开发者可以利用该技术低成本地构建一个 AI 智能客服、企业智能知识库、AI 搜索引擎等，通过自然语言输入与各类知识组织形式进行对话。以一个有代表性的 RAG 应用为例：

在下图中，当用户提问时 “美国总统是谁？” 时，系统并不是将问题直接交给大模型来回答，而是先将用户问题在知识库中（如下图中的维基百科）进行向量搜索，通过语义相似度匹配的方式查询到相关的内容（拜登是美国现任第46届总统…），然后再将用户问题和搜索到的相关知识提供给大模型，使得大模型获得足够完备的知识来回答问题，以此获得更可靠的问答结果。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (180).png)**

**为什么需要这样做呢？**

我们可以把大模型比做是一个超级专家，他熟悉人类各个领域的知识，但他也有自己的局限性，比如他不知道你个人的一些状况，因为这些信息是你私人的，不会在互联网上公开，所以他没有提前学习的机会。

当你想雇佣这个超级专家来充当你的家庭财务顾问时，需要允许他在接受你的提问时先翻看一下你的投资理财记录、家庭消费支出等数据。这样他才能根据你个人的实际情况提供专业的建议。

**这就是 RAG 系统所做的事情：帮助大模型临时性地获得他所不具备的外部知识，允许它在回答问题之前先找答案。**

根据上面这个例子，我们很容易发现 RAG 系统中最核心是外部知识的检索环节。专家能不能向你提供专业的家庭财务建议，取决于能不能精确找到他需要的信息，如果他找到的不是投资理财记录，而是家庭减肥计划，那再厉害的专家都会无能为力。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/indexing-and-retrieval/retrieval-augment.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 召回模式
> 来源：`zh-hans/guides/knowledge-base/indexing-and-retrieval/retrieval.mdx`

当用户构建知识库问答类的 AI 应用时，如果在应用内关联了多个知识库，此时需要应用 Dify 的召回策略决定从哪些知识库中检索内容。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/zh-rag-multiple.png)**

### 召回设置

根据用户意图同时匹配所有知识库，从多路知识库查询相关文本片段，经过重排序步骤，从多路查询结果中选择匹配用户问题的最佳结果，需配置 Rerank 模型 API。在多路召回模式下，检索器会在所有与应用关联的知识库中去检索与用户问题相关的文本内容，并将多路召回的相关文档结果合并，并通过 Rerank 模型对检索召回的文档进行语义重排序。

在多路召回模式下，建议配置 Rerank 模型。你可以阅读 [重排序](./zh-hans/learn-more/extended-reading/retrieval-augment/rerank) 了解更多。

以下是多路召回模式的技术流程图：

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (134).png)**

由于多路召回模式不依赖于模型的推理能力或知识库描述，该模式在多知识库检索时能够获得质量更高的召回效果，除此之外加入 Rerank 步骤也能有效改进文档召回效果。因此，当创建的知识库问答应用关联了多个知识库时，我们更推荐将召回模式配置为多路召回。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/indexing-and-retrieval/retrieval.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 在应用内集成知识库
> 来源：`zh-hans/guides/knowledge-base/integrate-knowledge-within-application.mdx`

知识库可以作为外部知识提供给大语言模型用于精确回复用户问题，你可以在 Dify 的[所有应用类型](./zh-hans/guides/application-orchestrate/chatbot-application)内关联已创建的知识库。

以聊天助手为例，使用流程如下：

1. 进入 **工作室 -- 创建应用 --创建聊天助手**
2. 进入 **上下文设置** 点击 **添加** 选择已创建的知识库
3. 在 **上下文设置 -- 参数设置** 内配置**召回策略**
4. 在 **元数据筛选** 板块中配置元数据的筛选条件，使用元数据功能筛选知识库内的文档
5. 在 **添加功能** 内打开 **引用和归属**
6. 在 **调试与预览** 内输入与知识库相关的用户问题进行调试
7. 调试完成之后**保存并发布**为一个 AI 知识库问答类应用

***

### 关联知识库并指定召回模式

如果当前应用的上下文涉及多个知识库，需要设置召回模式以使得检索的内容更加精确。进入 **上下文 -- 参数设置 -- 召回设置**。

#### 召回设置

检索器会在所有与应用关联的知识库中去检索与用户问题相关的文本内容，并将多路召回的相关文档结果合并，以下是召回策略的技术流程图：

![](https://assets-docs.dify.ai/2025/03/745b9de1cdd9465bfbad2ddc5f27bd12.png)

根据用户意图同时检索所有添加至 **“上下文”** 的知识库，在多个知识库内查询相关文本片段，选择所有和用户问题相匹配的内容，最后通过 Rerank 策略找到最适合的内容并回答用户。该方法的检索原理更为科学。

![](https://assets-docs.dify.ai/2024/12/3e0c9be17f054d211c4385ab74d47dfb.png)

举例：A 应用的上下文关联了 K1、K2、K3 三个知识库，当用户输入问题后，将在三个知识库内检索并汇总多条内容。为确保能找到最匹配的内容，需要通过 Rerank 策略确定与用户问题最相关的内容，确保结果更加精准与可信。

在实际问答场景中，每个知识库的内容来源和检索方式可能都有所差异。针对检索返回的多条混合内容，Rerank 策略是一个更加科学的内容排序机制。它可以帮助确认候选内容列表与用户问题的匹配度，改进多个知识间排序的结果以找到最匹配的内容，提高回答质量和用户体验。

考虑到 Rerank 的使用成本和业务需求，多路召回模式提供了以下两种 Rerank 设置：

**权重设置**

该设置无需配置外部 Rerank 模型，重排序内容**无需额外花费**。可以通过调整语义或关键词的权重比例条，选择最适合的内容匹配策略。

*   **语义值为 1**

    仅启用语义检索模式。借助 Embedding 模型，即便知识库中没有出现查询中的确切词汇，也能通过计算向量距离的方式提高搜索的深度，返回正确内容。此外，当需要处理多语言内容时，语义检索能够捕捉不同语言之间的意义转换，提供更加准确的跨语言搜索结果。

    > 语义检索指的是比对用户问题与知识库内容中的向量距离。距离越近，匹配的概率越大。参考阅读：[《Dify：Embedding 技术与 Dify 数据集设计/规划》](https://mp.weixin.qq.com/s/vmY\_CUmETo2IpEBf1nEGLQ)。
*   **关键词值为 1**

    仅启用关键词检索模式。通过用户输入的信息文本在知识库全文匹配，适用于用户知道确切的信息或术语的场景。该方法所消耗的计算资源较低，适合在大量文档的知识库内快速检索。
*   **自定义关键词和语义权重**

    除了仅启用语义检索或关键词检索模式，我们还提供了灵活的自定义权重设置。你可以通过不断调试二者的权重，找到符合业务场景的最佳权重比例。

**Rerank 模型**

Rerank 模型是一种外部评分系统，它会计算用户问题与给定的每个候选文档之间的相关性分数，从而改进语义排序的结果，并按相关性返回从高到低排序的文档列表。

虽然此方法会产生一定的额外花费，但是更加擅长处理知识库内容来源复杂的情况，例如混合了语义查询和关键词匹配的内容，或返回内容存在多语言的情况。

Dify 目前支持多个 Rerank 模型，进入 “模型供应商” 页填入 Rerank 模型（例如 Cohere、Jina AI 等模型）的 API Key。

  ![](https://assets-docs.dify.ai/2025/03/07094b0052fd058e4c31856365feb1ca.png)

**可调参数**

*   **TopK**

    用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小，动态调整分段数量。数值越高，预期被召回的文本分段数量越多。
*   **Score 阈值**

    用于设置文本片段筛选的相似度阈值。向量检索的相似度分数需要超过设置的分数后才会被召回，数值越高，预期被召回的文本数量越少。

### 使用元数据筛选知识

#### 聊天流/工作流

在 **聊天流/工作流** 的 **知识检索** 节点中，你可以使用 **元数据筛选** 功能精确检索文档。该功能有助于你根据文档的元数据字段（如标签、类别或访问权限）优化检索结果。

##### 配置步骤

1.  选择筛选模式

    - **禁用模式**（默认）：禁用 **元数据筛选** 功能，不配置任何筛选条件。

    - **自动模式**：系统会根据传输给该 **知识检索** 节点的 **查询变量** 自动配置筛选条件，适用于简单的筛选需求。

    > 启用自动模式后，你依然需要在 **模型** 栏中选择合适的大模型以执行文档检索任务。

    ![model_selection](https://assets-docs.dify.ai/2025/03/fe387793ad9923660f9f9470aacff01b.png)

    -  **手动模式**：用户可以手动配置筛选条件，自由设置筛选规则，适用于复杂的筛选需求。

![](https://assets-docs.dify.ai/2025/03/ec6329e265e035e3a0d6941c9313a19d.png)

2.  如果你选择了 **手动模式**，请参照以下步骤配置筛选条件：

    1.  点击 **条件** 按钮，弹出配置框。

    ![conditions](https://assets-docs.dify.ai/2025/03/cd80d150f6f5646350b7ac8dfee46429.png)

    2. 点击配置框中的 **+添加条件** 按钮：

        - 可以从下拉列表中选择一个已选中知识库内的元数据字段，添加到筛选条件列表中。

        > 如果你同时选择了多个知识库，下拉列表只会显示这些知识库共有的元数据字段。

        - 可以在 **搜索元数据** 搜索框中搜索你需要的字段，添加到筛选条件列表中。

    ![add_condition](https://assets-docs.dify.ai/2025/03/72678c4174f753f306378b748fbe6635.png)

    3.  如果需要添加多条字段，可以重复点击 **+添加条件** 按钮。

    ![add_more_fields](https://assets-docs.dify.ai/2025/03/aeb518c40aabdf467c9d2c23016d0a16.png)

    4.  配置字段类型的筛选条件：

    | 字段类型 | 筛选条件 | 筛选条件说明与示例 |
    | --- | --- | --- |
    | 字符串 | is | 字段的值必须与你输入的值完全匹配。例如，如果你设置筛选条件为 `is "Published"`，则只会返回标记为 "Published" 的文档。 |
    |  | is not | 字段的值不能与你输入的值匹配。例如，如果你设置筛选条件为 `is not "Draft"`，则会返回所有未标记为 "Draft" 的文档。 |
    |  | is empty | 字段的值为空。如果你配置了此条件，可以检索到未标记该字符串的文档。 |
    |  | is not empty | 字段的值不为空。如果你配置了此条件，可以检索到标记了该字符串的文档。 |
    |  | contains | 字段的值包含你输入的文本。例如，如果你设置筛选条件为 `contains "Report"`，则会返回所有包含"Report"的文档，如"Monthly Report" 或 "Annual Report"。 |
    |  | not contains | 字段的值不包含你输入的文本。例如，如果你设置筛选条件为 `not contains "Draft"`，则会返回所有不包含 "Draft" 的文档。 |
    |  | starts with | 字段的值以你输入的文本开头。例如，如果你设置筛选条件为 `starts with "Doc"`，则会返回所有以"Doc"开头的文档，如 "Doc1"、"Document"等。 |
    |  | ends with | 字段的值以你输入的文本结尾。例如，如果你设置筛选条件为 `ends with "2024"`，则会返回所有以"2024"结尾的文档，如"Report 2024"、"Summary 2024"等。 |
    | 数字 | = | 字段的值必须等于你输入的数字。例如，`= 10` 会匹配所有数字标记为 10 的文档。 |
    |  | ≠ | 字段的值不能等于你输入的数字。例如，`≠ 5` 会返回所有数字未标记为 5 的文档。 |
    |  | > | 字段的值必须大于你输入的数字。例如，`100` 会返回所有数字标记为大于 100 的文档。 |
    |  | &lt; | 字段的值必须小于你输入的数字。例如，`< 50` 会返回所有数字标记为小于 50 的文档。 |
    |  | ≥ | 字段的值必须大于或等于你输入的数字。例如，`≥ 20` 会返回所有数字标记为大于或等于 20 的文档。 |
    |  | ≤ | 字段的值必须小于或等于你输入的数字。例如，`≤ 200` 会返回所有数字标记为小于或等于 200 的文档。 |
    |  | is empty | 字段未设置值。例如，`is empty` 会返回所有该字段未标记数字的文档。 |
    |  | is not empty | 字段已设置值。例如，`is not empty` 会返回所有该字段已标记数字的文档。 |
    | 时间 | is | 字段的时间值必须与你选择的时间完全匹配。例如，`is "2024-01-01"` 只会返回标记为 2024 年 1 月 1 日的文档。 |
    |  | before | 字段的时间值必须早于你选择的时间。例如，`before "2024-01-01"` 会返回所有标记为 2024 年 1 月 1 日之前的文档。 |
    |  | after | 字段的时间值必须晚于你选择的时间。例如，`after "2024-01-01"` 会返回所有标记为 2024 年 1 月 1 日之后的文档。 |
    |  | is empty | 字段的时间值为空。如果你配置了此条件，可以检索到未标记该时间信息的文档。 |
    |  | is not empty | 字段的时间值不为空。如果你配置了此条件，可以检索到标记了该时间信息的文档。 |

    5.  选择并添加元数据筛选值：
    -  **变量**：选择 **变量（Variable）**，并选择该**聊天流/工作流**中需要用于筛选文档的变量。

    ![variable](https://assets-docs.dify.ai/2025/03/4c2c55ffcf0f72553fabdf23f86597d0.png)

    -  **常量**：选择 **常量（Constant）**，并手动输入你需要的常量值。

    > **时间** 字段类型仅支持使用常量筛选文档。如果你选用时间字段筛选文档，系统会弹出时间选择器，供你选择具体的时间节点。

    ![date_picker](https://assets-docs.dify.ai/2025/03/593da1575ddc995d938bd0cc3847cf3c.png)

> **警告：**

    当你输入常量筛选值时，该筛选值必须与该元数据字段值的文本完全一致，系统才能返回该文档。例如，当你设置筛选条件为 `starts with "App"` 或 `contains "App"` 时，系统会返回标记为 “Apple” 的文档，但不会返回标记为 “apple” 或 “APPLE” 的文档。

    6.  配置筛选条件之间的逻辑关系 `AND` 或 `OR`。
        - `AND`：当一个文档满足所有筛选条件时，才能检索到该文档。
        - `OR`：只要一个文档满足其中任意一个筛选条件，就可以检索到该文档。

    ![logic](https://assets-docs.dify.ai/2025/03/822dac015308dc5c01768afc0697c1ad.png)

    7.  关闭弹窗，系统将自动保存你的选择。

#### 聊天助手

在**聊天助手**中，**元数据筛选** 功能位于界面左下方的 **上下文** 板块下方，配置方法与**聊天流/工作流**中的操作一致。你可以按照相同的步骤配置元数据筛选条件。

![chatbot](https://assets-docs.dify.ai/2025/03/9d9a64bde687a686f24fd99d6f193c57.png)

### 在知识库内查看已关联的应用

知识库将会在左侧信息栏中显示已关联的应用数量。将鼠标悬停至圆形信息图标时将显示所有已关联的 Apps 列表，点击右侧的跳转按钮即可快速查看对应的应用。

![查看已关联的应用](https://assets-docs.dify.ai/2024/12/28899b9b0eba8996f364fb74e5b94c7f.png)

### 常见问题

1. **如何选择多路召回中的 Rerank 设置？**

如果用户知道确切的信息或术语，可以通过关键词检索精确发挥匹配结果，那么请将 “权重设置” 中的**关键词设置为 1**。

如果知识库内并未出现确切词汇，或者存在跨语言查询的情况，那么推荐使用 “权重设置” 中的**语义设置为 1**。

如果业务人员对于用户的实际提问场景比较熟悉，想要主动调整语义或关键词的比值，那么推荐自行调整 “权重设置” 里的比值。

如果知识库内容较为复杂，无法通过语义或关键词等简单条件进行匹配，同时要求较为精准的回答，愿意支付额外的费用，那么推荐使用 **Rerank 模型** 进行内容检索。

2. **为什么会出现找不到 “权重设置” 或要求必须配置 Rerank 模型等情况，应该如何处理？**

以下是知识库检索方式对文本召回的影响情况：

![](https://assets-docs.dify.ai/2025/03/3e581e276770632a508bb311d4b35add.png)

3. **引用多个知识库时，无法调整 “权重设置”，提示错误应如何处理？**

出现此问题是因为上下文内所引用的多个知识库内所使用的嵌入模型（Embedding）不一致，为避免检索内容冲突而出现此提示。推荐设置在“模型供应商”内设置并启用 Rerank 模型，或者统一知识库的检索设置。

4. **为什么在多路召回模式下找不到“权重设置”选项，只能看到 Rerank 模型？**

请检查你的知识库是否使用了“经济”型索引模式。如果是，那么将其切换为“高质量”索引模式。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/integrate-knowledge-within-application.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 管理知识库
> 来源：`zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/introduction.mdx`

> 知识库管理页仅面向团队所有者、团队管理员、拥有编辑权限的角色开放。

点击 Dify 平台顶部的“知识库”按钮，选择需要管理的知识库。轻点左侧导航中的**设置**进行调整。

你可以在此处调整知识库名称、描述、可见权限、索引模式、Embedding 模型和检索设置。

![知识库设置](https://assets-docs.dify.ai/2024/12/20fc93428f8f20f7acfce665c4ed4ddf.png)

* **知识库名称**，用于区分不同的知识库。
* **知识库描述**，用于描述知识库内文档代表的信息。
* **可见权限**，提供 **“只有我”** 、**“所有团队成员”** 和 **“部分团队成员”** 三种权限范围。不具有权限的人将无法访问该知识库。若选择将知识库公开至其它成员，则意味着其它成员同样具备该知识库的查看、编辑和删除权限。
* **索引方法**，详细说明请参考[索引方法文档](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/setting-indexing-methods)。
* **Embedding 模型**， 修改知识库的嵌入模型，修改 Embedding 模型将对知识库内的所有文档重新嵌入，原先的嵌入将会被删除。
* **检索设置**，详细说明请参考[检索设置文档](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/setting-indexing-methods)。

***

### 查看知识库内已关联的应用

知识库将会在左侧信息栏中显示已关联的应用数量。将鼠标悬停至圆形信息图标时将显示所有已关联的 Apps 列表，点击右侧的跳转按钮即可快速查看对应的应用。

![查看已关联应用](https://assets-docs.dify.ai/2024/12/28899b9b0eba8996f364fb74e5b94c7f.png)

***

你可以通过网页维护或 API 两种方式维护知识库内的文档。

#### 维护知识库内文档

支持管理知识库内的文档和对应的文档分段。详细说明请参考以下文档：

  详细说明请参考此文档

#### 使用 API 维护知识库

Dify 知识库提供整套标准 API ，开发者通过 API 调用对知识库内的文档、分段进行增删改查等日常管理维护操作，请参考以下文档：

  详细说明请参考此文档

![](https://assets-docs.dify.ai/2025/03/59f9f945a1d20a26c87662292d577db2.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/introduction.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 通过 API 维护知识库
> 来源：`zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/maintain-dataset-via-api.mdx`

> 鉴权、调用方式与应用 Service API 保持一致，不同之处在于，所生成的单个知识库 API token 具备操作当前账号下所有可见知识库的权限，请注意数据安全。

### 使用知识库 API 的优势

通过 API 维护知识库可大幅提升数据处理效率，你可以通过命令行轻松同步数据，实现自动化操作，而无需在用户界面进行繁琐操作。

主要优势包括:

* 自动同步: 将数据系统与 Dify 知识库无缝对接，构建高效工作流程；
* 全面管理: 提供知识库列表，文档列表及详情查询等功能，方便你自建数据管理界面；
* 灵活上传: 支持纯文本和文件上传方式,可针对分段（Chunks）内容的批量新增和修改操作；
* 提高效率: 减少手动处理时间，提升 Dify 平台使用体验。

### 如何使用

进入知识库页面，在左侧的导航中切换至 **API** 页面。在该页面中你可以查看 Dify 提供的知识库 API 文档，并可以在 **API 密钥** 中管理可访问知识库 API 的凭据。

![](https://assets-docs.dify.ai/2025/03/82ef51dc6886fb8301a2b85a920b12d0.png)

### API 调用示例

#### 通过文本创建文档

输入示例：

```json
curl --location --request POST 'https://api.dify.ai/v1/datasets/dataset_id/document/create_by_text' \
--header 'Authorization: Bearer api_key' \
--header 'Content-Type: application/json' \
--data-raw '{"name": "text","text": "text","indexing_technique": "high_quality","process_rule": {"mode": "automatic"}}'
```

输出示例：

```json
{
  "document": {
    "id": "",
    "position": 1,
    "data_source_type": "upload_file",
    "data_source_info": {
        "upload_file_id": ""
    },
    "dataset_process_rule_id": "",
    "name": "text.txt",
    "created_from": "api",
    "created_by": "",
    "created_at": 1695690280,
    "tokens": 0,
    "indexing_status": "waiting",
    "error": null,
    "enabled": true,
    "disabled_at": null,
    "disabled_by": null,
    "archived": false,
    "display_status": "queuing",
    "word_count": 0,
    "hit_count": 0,
    "doc_form": "text_model"
  },
  "batch": ""
}
```

#### 通过文件创建文档

输入示例：

```json
curl --location --request POST 'https://api.dify.ai/v1/datasets/dataset_id/document/create_by_file' \
--header 'Authorization: Bearer api_key' \
--form 'data="{"indexing_technique":"high_quality","process_rule":{"rules":{"pre_processing_rules":[{"id":"remove_extra_spaces","enabled":true},"id":"remove_urls_emails","enabled":true],"segmentation":"separator":"###","max_tokens":500},"mode":"custom"}}";type=text/plain' \
--form 'file=@"/path/to/file"'
```

输出示例：

```json
{
  "document": {
    "id": "",
    "position": 1,
    "data_source_type": "upload_file",
    "data_source_info": {
      "upload_file_id": ""
    },
    "dataset_process_rule_id": "",
    "name": "Dify.txt",
    "created_from": "api",
    "created_by": "",
    "created_at": 1695308667,
    "tokens": 0,
    "indexing_status": "waiting",
    "error": null,
    "enabled": true,
    "disabled_at": null,
    "disabled_by": null,
    "archived": false,
    "display_status": "queuing",
    "word_count": 0,
    "hit_count": 0,
    "doc_form": "text_model"
  },
  "batch": ""
}

```

#### **创建空知识库**

> **信息提示：**

  仅用来创建空知识库

输入示例：

```bash
curl --location --request POST 'https://api.dify.ai/v1/datasets' \
--header 'Authorization: Bearer api_key' \
--header 'Content-Type: application/json' \
--data-raw '"name": "name", "permission": "only_me"'
```

输出示例：

```json

  "id": "",
  "name": "name",
  "description": null,
  "provider": "vendor",
  "permission": "only_me",
  "data_source_type": null,
  "indexing_technique": null,
  "app_count": 0,
  "document_count": 0,
  "word_count": 0,
  "created_by": "",
  "created_at": 1695636173,
  "updated_by": "",
  "updated_at": 1695636173,
  "embedding_model": null,
  "embedding_model_provider": null,
  "embedding_available": null

```

#### **知识库列表**

输入示例：

```bash
curl --location --request GET 'https://api.dify.ai/v1/datasets?page=1&limit=20' \
--header 'Authorization: Bearer api_key'
```

输出示例：

```json
{
  "data": [
    {
      "id": "",
      "name": "知识库名称",
      "description": "描述信息",
      "permission": "only_me",
      "data_source_type": "upload_file",
      "indexing_technique": "",
      "app_count": 2,
      "document_count": 10,
      "word_count": 1200,
      "created_by": "",
      "created_at": "",
      "updated_by": "",
      "updated_at": ""
    },
    ...
  ],
  "has_more": true,
  "limit": 20,
  "total": 50,
  "page": 1
}
```

#### 删除知识库

输入示例：

```json
curl --location --request DELETE 'https://api.dify.ai/v1/datasets/dataset_id' \
--header 'Authorization: Bearer api_key'
```

输出示例：

```json
204 No Content
```

#### 通过文本更新文档

此接口基于已存在知识库，在此知识库的基础上通过文本更新文档

输入示例：

```bash
curl --location --request POST 'https://api.dify.ai/v1/datasets/dataset_id/documents/document_id/update_by_text' \
--header 'Authorization: Bearer api_key' \
--header 'Content-Type: application/json' \
--data-raw '"name": "name","text": "text"'
```

输出示例：

```json
{
  "document": {
    "id": "",
    "position": 1,
    "data_source_type": "upload_file",
    "data_source_info": {
      "upload_file_id": ""
    },
    "dataset_process_rule_id": "",
    "name": "name.txt",
    "created_from": "api",
    "created_by": "",
    "created_at": 1695308667,
    "tokens": 0,
    "indexing_status": "waiting",
    "error": null,
    "enabled": true,
    "disabled_at": null,
    "disabled_by": null,
    "archived": false,
    "display_status": "queuing",
    "word_count": 0,
    "hit_count": 0,
    "doc_form": "text_model"
  },
  "batch": ""
}
```

#### 通过文件更新文档

此接口基于已存在知识库，在此知识库的基础上通过文件更新文档的操作。

输入示例：

```bash
curl --location --request POST 'https://api.dify.ai/v1/datasets/dataset_id/documents/document_id/update_by_file' \
--header 'Authorization: Bearer api_key' \
--form 'data="{"name":"Dify","indexing_technique":"high_quality","process_rule":{"rules":{"pre_processing_rules":[{"id":"remove_extra_spaces","enabled":true},"id":"remove_urls_emails","enabled":true],"segmentation":"separator":"###","max_tokens":500},"mode":"custom"}}";type=text/plain' \
--form 'file=@"/path/to/file"'
```

输出示例：

```json
{
  "document": {
    "id": "",
    "position": 1,
    "data_source_type": "upload_file",
    "data_source_info": {
      "upload_file_id": ""
    },
    "dataset_process_rule_id": "",
    "name": "Dify.txt",
    "created_from": "api",
    "created_by": "",
    "created_at": 1695308667,
    "tokens": 0,
    "indexing_status": "waiting",
    "error": null,
    "enabled": true,
    "disabled_at": null,
    "disabled_by": null,
    "archived": false,
    "display_status": "queuing",
    "word_count": 0,
    "hit_count": 0,
    "doc_form": "text_model"
  },
  "batch": "20230921150427533684"
}
```

#### **获取文档嵌入状态（进度）**

输入示例：

```bash
curl --location --request GET 'https://api.dify.ai/v1/datasets/dataset_id/documents/batch/indexing-status' \
--header 'Authorization: Bearer api_key'
```

输出示例：

```json
{
  "data":[{
    "id": "",
    "indexing_status": "indexing",
    "processing_started_at": 1681623462.0,
    "parsing_completed_at": 1681623462.0,
    "cleaning_completed_at": 1681623462.0,
    "splitting_completed_at": 1681623462.0,
    "completed_at": null,
    "paused_at": null,
    "error": null,
    "stopped_at": null,
    "completed_segments": 24,
    "total_segments": 100
  }]
}
```

#### **删除文档**

输入示例：

```bash
curl --location --request DELETE 'https://api.dify.ai/v1/datasets/dataset_id/documents/document_id' \
--header 'Authorization: Bearer api_key'
```

输出示例：

```bash

  "result": "success"

```

#### **知识库文档列表**

输入示例：

```bash
curl --location --request GET 'https://api.dify.ai/v1/datasets/dataset_id/documents' \
--header 'Authorization: Bearer api_key'
```

输出示例：

```json
{
  "data": [
    {
      "id": "",
      "position": 1,
      "data_source_type": "file_upload",
      "data_source_info": null,
      "dataset_process_rule_id": null,
      "name": "dify",
      "created_from": "",
      "created_by": "",
      "created_at": 1681623639,
      "tokens": 0,
      "indexing_status": "waiting",
      "error": null,
      "enabled": true,
      "disabled_at": null,
      "disabled_by": null,
      "archived": false
    },
  ],
  "has_more": false,
  "limit": 20,
  "total": 9,
  "page": 1
}
```

#### **新增分段**

输入示例：

```bash
curl --location --request POST 'https://api.dify.ai/v1/datasets/dataset_id/documents/document_id/segments' \
--header 'Authorization: Bearer api_key' \
--header 'Content-Type: application/json' \
--data-raw '{"segments": [{"content": "1","answer": "1","keywords": ["a"]}]}'
```

输出示例：

```json
{
  "data": [{
    "id": "",
    "position": 1,
    "document_id": "",
    "content": "1",
    "answer": "1",
    "word_count": 25,
    "tokens": 0,
    "keywords": [
        "a"
    ],
    "index_node_id": "",
    "index_node_hash": "",
    "hit_count": 0,
    "enabled": true,
    "disabled_at": null,
    "disabled_by": null,
    "status": "completed",
    "created_by": "",
    "created_at": 1695312007,
    "indexing_at": 1695312007,
    "completed_at": 1695312007,
    "error": null,
    "stopped_at": null
  }],
  "doc_form": "text_model"
}

```

### 查询文档分段

输入示例：

```bash
curl --location --request GET 'https://api.dify.ai/v1/datasets/dataset_id/documents/document_id/segments' \
--header 'Authorization: Bearer api_key' \
--header 'Content-Type: application/json'
```

输出示例：

```bash
{
  "data": [{
    "id": "",
    "position": 1,
    "document_id": "",
    "content": "1",
    "answer": "1",
    "word_count": 25,
    "tokens": 0,
    "keywords": [
        "a"
    ],
    "index_node_id": "",
    "index_node_hash": "",
    "hit_count": 0,
    "enabled": true,
    "disabled_at": null,
    "disabled_by": null,
    "status": "completed",
    "created_by": "",
    "created_at": 1695312007,
    "indexing_at": 1695312007,
    "completed_at": 1695312007,
    "error": null,
    "stopped_at": null
  }],
  "doc_form": "text_model"
}
```

### 删除文档分段

输入示例：

```bash
curl --location --request DELETE 'https://api.dify.ai/v1/datasets/dataset_id/documents/document_id/segments/segment_id' \
--header 'Authorization: Bearer api_key' \
--header 'Content-Type: application/json'
```

输出示例：

```bash

  "result": "success"

```

### 更新文档分段

输入示例：

```bash
curl --location --request POST 'https://api.dify.ai/v1/datasets/dataset_id/documents/document_id/segments/segment_id' \
--header 'Authorization: Bearer api_key' \
--header 'Content-Type: application/json'\
--data-raw '{"segment": {"content": "1","answer": "1", "keywords": ["a"], "enabled": false}}'
```

输出示例：

```bash
{
  "data": [{
    "id": "",
    "position": 1,
    "document_id": "",
    "content": "1",
    "answer": "1",
    "word_count": 25,
    "tokens": 0,
    "keywords": [
        "a"
    ],
    "index_node_id": "",
    "index_node_hash": "",
    "hit_count": 0,
    "enabled": true,
    "disabled_at": null,
    "disabled_by": null,
    "status": "completed",
    "created_by": "",
    "created_at": 1695312007,
    "indexing_at": 1695312007,
    "completed_at": 1695312007,
    "error": null,
    "stopped_at": null
  }],
  "doc_form": "text_model"
}
```

#### 新增知识库元数据字段

输入示例：

```bash
curl --location 'https://api.dify.ai/v1/datasets/dataset_id/metadata' \
--header 'Content-Type: application/json' \
--header 'Authorization: Bearer api_key' \
--data '
    "type":"string",
    "name":"test"
'
```

输出示例：

```json

    "id": "9f63c91b-d60e-4142-bb0c-c81a54dc2db5",
    "type": "string",
    "name": "test"

```

#### 更新知识库元数据字段

输入示例：

```bash
curl --location --request PATCH 'https://api.dify.ai/v1/datasets/dataset_id/metadata/metadata_id' \
--header 'Authorization: Bearer api_key' \
--header 'Content-Type: application/json'\
--data-raw '"name": "test"'
```

输出示例：

```json

  "id": "abc",
  "type": "string",
  "name": "test",

```

#### 删除知识库元数据字段

输入示例：

```bash
curl --location --request DELETE 'https://api.dify.ai/v1/datasets/dataset_id/metadata/metadata_id' \
--header 'Authorization: Bearer api_key'
```

输出示例：

```bash
200 success
```

#### 启用/禁用知识库元数据中的内置字段

输入示例：

```bash
curl --location --request DELETE 'https://api.dify.ai/v1/datasets/dataset_id/metadata/built-in/action' \
--header 'Authorization: Bearer api_key'
```

输出示例：

```json
200 success
```

#### 修改文档的元数据（赋值）

输入示例：

```bash
curl --location 'https://api.dify.ai/v1/datasets/dataset_id/documents/metadata' \
--header 'Content-Type: application/json' \
--header 'Authorization: Bearer api_key'
--data '{
    "operation_data":[
        {
            "document_id": "3e928bc4-65ea-4201-87c8-cbcc5871f525",
            "metadata_list": [
                    {
                    "id": "1887f5ec-966f-4c93-8c99-5ad386022f46",
                    "value": "dify",
                    "name": "test"
                }
            ]
        }
    ]
}'
```

输出示例：

```json
200 success
```

#### 数据集的元数据列表

输入示例：

```bash
curl --location 'https://api.dify.ai/v1/datasets/dataset_id/metadata' \
--header 'Authorization: Bearer api_key'
```

输出示例：

```json
{
  "doc_metadata": [
    {
      "id": "550e8400-e29b-41d4-a716-446655440000",
      "type": "string",
      "name": "title",
      "use_count": 42
    },

      "id": "6ba7b810-9dad-11d1-80b4-00c04fd430c8",
      "type": "number",
      "name": "price",
      "use_count": 28
    ,

      "id": "7ba7b810-9dad-11d1-80b4-00c04fd430c9",
      "type": "time",
      "name": "created_at",
      "use_count": 35

  ],
  "built_in_field_enabled": true
}
```

### 错误信息

| 错误信息 | 错误码 | 原因描述 |
|------|--------|---------|
| no_file_uploaded | 400 | 请上传你的文件  |
| too_many_files | 400 | 只允许上传一个文件  |
| file_too_large | 413 | 文件大小超出限制  |
| unsupported_file_type | 415 | 不支持的文件类型。目前只支持以下内容格式：`txt`, `markdown`, `md`, `pdf`, `html`, `html`, `xlsx`, `docx`, `csv` |
| high_quality_dataset_only | 400 | 当前操作仅支持"高质量"知识库  |
| dataset_not_initialized | 400 | 知识库仍在初始化或索引中。请稍候  |
| archived_document_immutable | 403 | 归档文档不可编辑  |
| dataset_name_duplicate | 409 | 知识库名称已存在，请修改你的知识库名称  |
| invalid_action | 400 | 无效操作  |
| document_already_finished | 400 | 文档已处理完成。请刷新页面或查看文档详情  |
| document_indexing | 400 | 文档正在处理中，无法编辑  |
| invalid_metadata | 400 | 元数据内容不正确。请检查并验证  |

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/maintain-dataset-via-api.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 维护知识库内文档
> 来源：`zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/maintain-knowledge-documents.mdx`

### 添加文档

知识库是文档的集合。文档支持本地上传，或导入其它在线数据源。知识库内的文档对应数据源中的一个文件单位，例如 Notion 库内的一篇文档或新的在线文档网页。

点击“知识库” → “文档列表” → “添加文件”，在已创建的知识库内上传新的文档。

![在知识库内上传新文档](https://assets-docs.dify.ai/2024/12/424ab491aaebe09b490a36d26c9fa8da.png)

### 启用 / 禁用 / 归档 / 删除文档

**启用**：处于正常使用状态的文档，支持编辑内容与被知识库检索。对于已被禁用的文档，允许重新启用。已归档的文档需撤销归档状态后才能重新启用。

**禁用**：对于不希望在使用 AI 应用时被检索的文档，可以关闭文档右侧的蓝色开关按钮以禁用文档。禁用文档后，仍然可以编辑当前内容。

**归档**：对于一些不再使用的旧文档数据，如果不想删除可以将其归档。归档后的数据就只能查看或删除，无法重新编辑。你可以在知识库文档列表，点击归档按钮；或在文档详情页内进行归档。**归档操作支持撤销。**

**删除**：⚠️ 危险操作。对于一些错误文档或明显有歧义的内容，可以点击文档右侧菜单按钮中的删除。删除后的内容将无法被找回，请进行谨慎操作。

> 以上选项均支持选中多个文档后批量操作。

![禁用或归档文档](https://assets-docs.dify.ai/2024/12/5e0e64859a1ac51602d167ec55ef9350.png)

### 注意事项

如果你的知识库中有部分文档长时间未更新或未检索时，为了确保知识库的高效运行，系统会暂时禁用这部分不活跃的文档。

* 对于 Sandbox/Free 版本用户，未使用知识库的将在 **7 天** 后自动禁用；
* 对于 Professional/Team 版本用户，未使用知识库的将在 **30 天** 后自动禁用。

你随时可以前往知识库中重新启用它们以恢复正常使用。付费用户可以使用 **“一键恢复”** 功能快速启用所有被禁用的文档。

![一键恢复被禁用的文档](https://assets-docs.dify.ai/2024/12/bf6485b17aec716741eb65e307c2274c.png)

***

## 管理文本分段

### 查看文本分段

知识库内已上传的每个文档都会以文本分段（Chunks）形式进行存储。点击文档标题，在详情页中查看当前文档的分段列表，每页默认展示 10 个区块，你可以在网页底部调整每页的展示数量。

每个内容区块展示前 2 行的预览内容。若需要查看更加分段内的完整内容，轻点“展开分段”按钮即可查看。

![展开内容分段](https://assets-docs.dify.ai/2024/12/86cc80f17fab1eea75aa73ee681e4663.png)

你可以通过筛选栏快速查看所有已启用 / 未启用的文档。

![筛选文档分段](https://assets-docs.dify.ai/2025/01/47ef07319175a102bfd1692dcc6cac9b.png)

不同的[文本分段模式](../create-knowledge-and-upload-documents/chunking-and-cleaning-text)对应不同的文本分段查看方式：

    **通用模式**

    [通用模式](../create-knowledge-and-upload-documents/#tong-yong)下的文本分段为独立的区块。若希望查看区块内的完整内容，轻点右上角的全屏 icon 进入全屏阅读模式。

    ![进入全屏阅读模式](https://assets-docs.dify.ai/2024/12/c37a1a247092cda9433a10243543698f.png)

    点击顶部文档标题即可快速切换至当前知识库内的其它文档。

    ![通用模式-内容分段](https://assets-docs.dify.ai/2024/12/4422286c6d254e13c1ab59b147f0ffbf.png)

    **父子模式**

    [父子模式](../create-knowledge-and-upload-documents/#fu-zi-fen-duan)下的内容分为父分段和子分段。

    *   **父分段**

        选择知识库内的文档后，你将会首先看到父分段的内容。父分段存在 **“段落”** 分段与 **“全文”** 分段两种模式，提供更加完整的上下文信息。下图为不同分段模式的文本预览差异。

    ![段落与全文的预览差异](https://assets-docs.dify.ai/2024/12/b3961da2536dc922496ef6646315b9f4.png)

    *   **子分段**

        子分段一般为段落中的某个句子（较小的文本块），包含细节信息。各个分块均会展示字符数以及被检索召回的次数。轻点“子分段”即可查看更多详细内容。若希望查看区块内的完整内容，轻点区块右上角的全屏 icon 进入全屏阅读模式。

    ![父子模式-内容分段](https://assets-docs.dify.ai/2024/12/c0776f91e155bb1c961ae255bb98f39e.png)

    **Q&A 模式**

    在 Q&A 模式下，一个内容区块包含问题与答案，轻点任意文档标题即可查看文本分段。

    ![Q&A 模式 - 查看文本分段](https://assets-docs.dify.ai/2024/12/98e2486f6c5e06b4ece1b81d078afa08.png)

***

### 检查分段质量

文档分段对于知识库应用的问答效果有明显影响，在将知识库与应用关联之前，建议人工检查分段质量。

检查分段质量时，一般需要关注以下几种情况：

* **过短的文本分段**，导致语义缺失；
* **过长的文本分段**，导致语义噪音影响匹配准确性；
* **明显的语义截断**，在使用最大分段长度限制时会出现强制性的语义截断，导致召回时缺失内容；

![分段质量检查示例](https://assets-docs.dify.ai/2024/12/ee081e98c1649aea4a5c2b15b88e11aa.png)
![分段质量检查示例](https://assets-docs.dify.ai/2024/12/ac47381ae4be183768dd025c37c049fa.png)
![分段质量检查示例](https://assets-docs.dify.ai/2024/12/b8ab7ac84028b0b16c3948f35015e069.png)

***

### 添加文本分段

知识库中的文档支持单独添加文本分段，不同的分段模式对应不同的分段添加方法。

添加文本分段为付费功能，请前往[此处](https://dify.ai/pricing)升级账号以使用功能。

    点击分段列表顶部的“添加分段”按钮，可以在文档内自行添加一个或批量添加多个自定义分段。

    ![通用模式 - 添加分段](https://assets-docs.dify.ai/2024/12/552ff4ab9e77130ad09aaef878b19cc9.png)

    点击分段列表顶部的「 添加分段 」按钮，可以在文档内自行添加一个或批量添加多个自定义**父分段。**

    ![父子模式 — 添加分区](https://assets-docs.dify.ai/2024/12/ed4be3bf178e3a41d53bcc10255ad3b2.png)

    填写内容后，勾选尾部“连续新增”钮后，可以继续添加文本。

    点击分段列表顶部的 「 添加分段 」 按钮，可以在文档内自行添加一个或批量添加多个问题-答案内容对区块。

***

### 编辑文本分段

    你可以对已添加的分段内容直接进行编辑或修改，包括修改分段内的文本内容或关键词。

    ![编辑文档分段](https://assets-docs.dify.ai/2024/12/8220e412e4c5a2bf729fb5dfcc1b7f4c.png)

    父分段包含其本身所包含的子分段内容，两者相互独立。你可以单独修改父分段或子分段的内容。

    ![修改父分段](https://assets-docs.dify.ai/2024/12/7eedfee59a3c978cc4a29d9cf06fbbcc.png)

    修改父分段后，点击 **“保存”** 后将不会影响子分段的内容。如需重新生成子分段内容，轻点 **“保存并重新生成子分段”**。

    在 Q&A 分段模式下，一个内容区块包含问题与答案。点击需要编辑的文本分段，可以分别对问题和答案内容做出修改；同时也支持修改当前区块的关键词。
    ![](https://assets-docs.dify.ai/2025/04/5f0495ad5c7c50246d38440ab0abb6fa.png)

### 修改已上传文档的文本分段

已创建的知识库支持重新配置文档分段。

    - 可在单个分段内保留更多上下文，适合需要处理复杂或上下文相关任务的场景。
    - 分段数量减少，从而降低处理时间和存储需求。

    - 提供更高的粒度，适合精确提取或总结文本内容。
    - 减少超出模型 token 限制的风险，更适配限制严格的模型。

你可以访问 **分段设置**，点击 **保存并处理** 按钮以保存对分段设置的修改，并重新触发当前文档的分段流程。当你保存设置并完成嵌入处理后，文档的分段列表将自动更新。

![Chunk Settings](https://assets-docs.dify.ai/2025/01/36cb20be8aae1f368ebf501c0d579051.png)

![](https://assets-docs.dify.ai/2025/04/896a2b3175c6e2a1139716fc9eecad99.png)

***

### 元数据管理

如需了解元数据的相关信息，请参阅 [元数据](./zh-hans/guides/knowledge-base/metadata)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/maintain-knowledge-documents.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 知识库管理与文档维护
> 来源：`zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance.mdx`

## 知识库管理

> 知识库管理页仅面向团队所有者、团队管理员、编辑权限角色开放。

在 Dify 团队首页中，点击顶部的 “知识库” tab 页，选择需要管理的知识库，轻点左侧导航中的**设置**进行调整。你可以调整知识库名称、描述、可见权限、索引模式、Embedding 模型和检索设置。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (8).png)**

**知识库名称**，用于区分不同的知识库。

**知识库描述**，用于描述知识库内文档代表的信息。

**可见权限**，提供 **「 只有我 」** 、 **「 所有团队成员 」** 和 **「部分团队成员」** 三种权限范围。不具有权限的人将无法访问该知识库。若选择将知识库公开至其它成员，则意味着其它成员同样具备该知识库的查看、编辑和删除权限。

**索引模式**，详细说明请[参考文档](./zh-hans/guides/knowledge-base/knowledge-base-creation/introduction)。

**Embedding 模型**， 修改知识库的嵌入模型，修改 Embedding 模型将对知识库内的所有文档重新嵌入，原先的嵌入将会被删除。

**检索设置**，详细说明请[参考文档](./zh-hans/guides/knowledge-base/knowledge-base-creation/introduction)。

***

### 使用 API 维护知识库

Dify 知识库提供整套标准 API ，开发者通过 API 调用对知识库内的文档、分段进行增删改查等日常管理维护操作，请参考[知识库 API 文档](./zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/maintain-dataset-via-api)。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (231).png)**

## 维护知识库中的文本

### 添加文档

知识库（Knowledge）是一些文档（Documents）的集合。文档可以由开发者或运营人员上传，或由同步其它数据源（对应数据源中的一个文件单位，例如 Notion 库内的一篇文档或新的在线文档网页）。

点击 「知识库」 > 「文档列表 ，然后轻点 「 添加文件 」，即可在已创建的知识库内上传新的文档。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (10).png)**

***

### 禁用或归档文档

**禁用**：数据集支持将暂时不想被索引的文档或分段进行禁用，在数据集文档列表，点击禁用按钮，则文档被禁用；也可以在文档详情，点击禁用按钮，禁用整个文档或某个分段，禁用的文档将不会被索引。禁用的文档点击启用，可以取消禁用。

**归档**：一些不再使用的旧文档数据，如果不想删除可以将它进行归档，归档后的数据就只能查看或删除，不可以进行编辑。在数据集文档列表，点击归档按钮，则文档被归档，也可以在文档详情，归档文档。归档的文档将不会被索引。归档的文档也可以点击撤销归档。

***

### 查看文本分段

知识库内已上传的每个文档都会以文本分段（Chunks）的形式进行存储，你可以在分段列表内查看每一个分段的具体文本内容。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (88).png)**

***

### 检查分段质量

文档分段对于知识库应用的问答效果有明显影响，在将知识库与应用关联之前，建议人工检查分段质量。

通过字符长度、标识符或者 NLP 语义分段等机器自动化的分段方式虽然能够显著减少大规模文本分段的工作量，但分段质量与不同文档格式的文本结构、前后文的语义联系都有关系，通过人工检查和订正可以有效弥补机器分段在语义识别方面的缺点。

检查分段质量时，一般需要关注以下几种情况：

* **过短的文本分段**，导致语义缺失；

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (234).png)**

* **过长的文本分段**，导致语义噪音影响匹配准确性；

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (237).png)**

* **明显的语义截断**，在使用最大分段长度限制时会出现强制性的语义截断，导致召回时缺失内容；

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (236).png)**

***

### 添加文本分段

在分段列表内点击 「 添加分段 」 ，可以在文档内自行添加一个或批量添加多个自定义分段。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (90).png)**

批量添加分段时，你需要先下载 CSV 格式的分段上传模板，并按照模板格式在 Excel 内编辑所有的分段内容，再将 CSV 文件保存后上传。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (92).png)**

***

### 编辑文本分段

在分段列表内，你可以对已添加的分段内容直接进行编辑修改。包括分段的文本内容和关键词。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (93).png)**

***

### 元数据管理

除了用于标记不同来源文档的元数据信息，例如网页数据的标题、网址、关键词、描述等。元数据将被用于知识库的分段召回过程中，作为结构化字段参与召回过滤或者显示引用来源。

> **信息提示：**

  元数据过滤及引用来源功能当前版本尚未支持。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/image (230).png)**

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 创建步骤
> 来源：`zh-hans/guides/knowledge-base/knowledge-base-creation/introduction.mdx`

创建知识库并上传文档大致分为以下步骤：

1. 创建知识库。通过上传本地文件、导入在线数据或创建一个空的知识库。

  通过上传本地文件、导入在线数据或创建一个空的知识库。

2. 指定分段模式。该阶段是内容的预处理与数据结构化过程，长文本将会被划分为多个内容分段。你可以在此环节预览文本的分段效果。

  了解文本分段和数据清洗流程

3. 设定索引方法和检索设置。知识库在接收到用户查询问题后，按照预设的检索方式在已有的文档内查找相关内容，提取出高度相关的信息片段供语言模型生成高质量答案。

  了解如何设置索引方法和检索参数

4. 等待分段嵌入
5. 完成上传，在应用内关联知识库并使用。你可以参考[在应用内集成知识库](./zh-hans/guides/knowledge-base/integrate-knowledge-within-application)，搭建出能够基于知识库进行问答的 LLM 应用。如需修改或管理知识库，请参考[知识库管理与文档维护](./zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/introduction)。

![完成知识库的创建](https://assets-docs.dify.ai/2024/12/a3362a1cd384cb2b539c9858de555518.png)

***

### 参考阅读

#### ETL

在 RAG 的生产级应用中，为了获得更好的数据召回效果，需要对多源数据进行预处理和清洗，即 ETL （_extract, transform, load_）。为了增强非结构化/半结构化数据的预处理能力，Dify 支持了可选的 ETL 方案：**Dify ETL** 和[**Unstructured ETL**](https://docs.unstructured.io/welcome)。Unstructured 能够高效地提取并转换你的数据为干净的数据用于后续的步骤。Dify 各版本的 ETL 方案选择：

* SaaS 版不可选，默认使用 Unstructured ETL；
* 社区版可选，默认使用 Dify ETL ，可通过[环境变量](./zh-hans/getting-started/install-self-hosted/environments)开启 Unstructured ETL；

文件解析支持格式的差异：

| DIFY ETL                                       | Unstructured ETL                                                         |
| ---------------------------------------------- | ------------------------------------------------------------------------ |
| txt、markdown、md、pdf、html、htm、xlsx、xls、docx、csv | txt、markdown、md、pdf、html、htm、xlsx、xls、docx、csv、eml、msg、pptx、ppt、xml、epub |

不同的 ETL 方案在文件提取效果的方面也会存在差异，想了解更多关于 Unstructured ETL 的数据处理方式，请参考[官方文档](https://docs.unstructured.io/open-source/core-functionality/partitioning)。

***

#### **Embedding**

**Embedding 嵌入**是一种将离散型变量（如单词、句子或者整个文档）转化为连续的向量表示的技术。它可以将高维数据（如单词、短语或图像）映射到低维空间，提供一种紧凑且有效的表示方式。这种表示不仅减少了数据的维度，还保留了重要的语义信息，使得后续的内容检索更加高效。

**Embedding 模型**是一种专门用于将文本向量化的大语言模型，它擅长将文本转换为密集的数值向量，有效捕捉语义信息。

> 如需了解更多，请参考：[《Dify：Embedding 技术与 Dify 知识库设计/规划》](https://mp.weixin.qq.com/s/vmY_CUmETo2IpEBf1nEGLQ)。

***

#### **元数据**

如需使用元数据功能管理知识库，请参阅 [元数据](./zh-hans/guides/knowledge-base/metadata)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-base-creation/introduction.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 创建知识库 & 上传文档
> 来源：`zh-hans/guides/knowledge-base/knowledge-base-creation/upload-documents.mdx`

创建知识库并上传文档大致分为以下步骤：

1. 在 Dify 团队内创建知识库，从本地选择你需要上传的文档；
2. 选择分段与清洗模式，预览效果；
3. 配置索引方式和检索设置；
4. 等待分段嵌入；
5. 完成上传，在应用内关联并使用 🎉

以下是各个步骤的详细说明：

## 1 创建知识库

在 Dify 主导航栏中点击知识库，在该页面你可以看到团队内的知识库，点击“**创建知识库”** 进入创建向导。

- 拖拽或选中文件进行上传，批量上传的文件数量取决于[订阅计划](https://dify.ai/pricing);
- 如果还没有准备好文档，可以先创建一个空知识库;
- 如果你在创建知识库时选择了使用外部数据源（Notion 或同步 Web 站点），该知识库的类型不可更改；此举是为了防止单一知识库存在多数据源而造成的管理困难。如果你需要使用多个数据源，建议创建多个知识库并使用 [多路召回](./zh-hans/learn-more/extended-reading/retrieval-augment/rerank) 模式在同一个应用内引用多个知识库。

**上传文档存在以下限制：**

- 单文档的上传大小限制为 15MB；

  **[图片缺失] 未命名插图 (zh-hans/images/en-upload-files-1.png)**

***

## 2 选择分段与清洗策略

将内容上传至知识库后，需要先对内容进行分段与数据清洗，该阶段可以被理解为是对内容预处理与结构化。

* **分段**

  大语言模型存在有限的上下文窗口，无法将知识库中的所有内容发送至 LLM。因此可以将整段长文本分段处理，再基于用户问题，召回与关联度最高的段落内容，即采用分段 TopK 召回模式。此外，将用户问题与文本分段进行语义匹配时，合适的分段大小有助于找到知识库内关联性最高的文本内容，减少信息噪音。

* **清洗**

  为了保证文本召回的效果，通常需要在将数据录入知识库之前便对其进行清理。例如，如果文本内容中存在无意义的字符或者空行，可能会影响问题回复的质量。关于 Dify 内置的清洗策略，详细说明请参考 [ETL](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/import-content-data/readme)。

支持以下两种策略：

* **自动分段与清洗**
* **自定义**

    #### 自动分段与清洗

    自动模式适合对分段规则与预处理规则尚不熟悉的初级用户。在该模式下，Dify 将为你自动分段与清洗内容文件。

      **[图片缺失] Automatic segmentation and cleaning (zh-hans/images/en-upload-files-2.avif)**

    #### 自定义

    自定义模式适合对于文本处理有明确需求的进阶用户。在自定义模式下，你可以根据不同的文档格式和场景要求，手动配置文本的分段规则和清洗策略。

    **分段规则：**

    * **分段标识符**，指定标识符，系统将在文本中出现该标识符时分段。例如填写 `\n`（[正则表达式](https://regexr.com/)中的换行符），文本换行时将自动分段；
    * **分段最大长度**，根据分段的文本字符数最大上限来进行分段，超出该长度时将强制分段。一个分段的最大长度为 4000 Tokens；
    * **分段重叠长度**，分段重叠指的是在对数据进行分段时，段与段之间存在一定的重叠部分。这种重叠可以帮助提高信息的保留和分析的准确性，提升召回效果。建议设置为分段长度 Tokens 数的 10-25%；

    **文本预处理规则：** 文本预处理规则可以帮助过滤知识库内部分无意义的内容。

    * 替换连续的空格、换行符和制表符；
    * 删除所有 URL 和电子邮件地址；

      **[图片缺失] 未命名插图 (zh-hans/images/en-upload-files-3.webp)**

## 3 索引方式

指定内容的预处理方法（分段与清洗）后，接下来需要指定对结构化内容的索引方式。索引方式将直接影响 LLM 对知识库内容的检索效率以及回答的准确性。

系统提供以下三种索引方式，你可以根据实际需求调整每种方式内的[检索设置](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/chunking-and-cleaning-text)：

* 高质量
* 经济

    在高质量模式下，将首先调用 Embedding 嵌入模型（支持切换）将已分段的文本转换为数字向量，帮助开发者更有效地实现大量文本信息的压缩与存储；同时还能够在用户与 LLM 对话时提供更高的准确度。
    > 如需了解更多，请参考[《Embedding 技术与 Dify》](https://mp.weixin.qq.com/s/vmY\_CUmETo2IpEBf1nEGLQ)。
    高质量索引方式提供向量检索、全文检索和混合检索三种检索设置。关于更多检索设置的说明，请阅读 [检索设置](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/chunking-and-cleaning-text)。

      **[图片缺失] 未命名插图 (zh-hans/images/en-upload-files-4.webp)**

    使用离线的向量引擎与关键词索引方式，降低了准确度但无需额外花费 Token，产生费用。检索方式仅提供倒排索引，详细说明请阅读[下文](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/import-content-data/sync-from-notion)。

      **[图片缺失] 未命名插图 (zh-hans/images/en-upload-files-5.webp)**

***

## 4 检索设置

在**高质量索引方式**下，Dify 提供以下 3 种检索方案：

* **向量检索**
* **全文检索**
* **混合检索**

    **定义：** 向量化用户输入的问题并生成查询向量，比较查询向量与知识库内对应的文本向量距离，寻找最近的分段内容。

      **[图片缺失] 未命名插图 (zh-hans/images/en-upload-files-8.png)**

    **向量检索设置：**

    **Rerank 模型：** 使用第三方 Rerank 模型对向量检索召回后的分段再一次进行语义重排序，优化排序结果。在“模型供应商”页面配置 Rerank 模型的 API 秘钥之后，在检索设置中打开“Rerank 模型”。

    **TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。默认值为 3，数值越高，预期被召回的文本分段数量越多。

    **Score 阈值：** 用于设置文本片段筛选的相似度阈值，只召回超过设置分数的文本片段，默认值为 0.5。数值越高说明对于文本与问题要求的相似度越高，预期被召回的文本数量也越少。

    > TopK 和 Score 设置仅在 Rerank 步骤生效，因此需要添加并开启 Rerank 模型才能应用两者中的设置。

    **定义：** 关键词检索，即索引文档中的所有词汇。用户输入问题后，通过明文关键词匹配知识库内对应的文本片段，返回符合关键词的文本片段；类似搜索引擎中的明文检索。

      **[图片缺失] 未命名插图 (zh-hans/images/en-upload-files-9.png)**

    **Rerank 模型：** 使用第三方 Rerank 模型对全文检索召回后的分段再一次进行语义重排序，优化排序结果。在“模型供应商”页面配置 Rerank 模型的 API 秘钥之后，在检索设置中打开“Rerank 模型”。

    **TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。数值越高，预期被召回的文本分段数量越多。

    **Score 阈值：** 用于设置文本片段筛选的相似度阈值，只召回超过设置分数的文本片段，默认值为 0.5。数值越高说明对于文本与问题要求的相似度越高，预期被召回的文本数量也越少。

    > TopK 和 Score 设置仅在 Rerank 步骤生效，因此需要添加并开启 Rerank 模型才能应用两者中的设置。

    **定义：** 同时执行全文检索和向量检索，并应用重排序步骤，从两类查询结果中选择匹配用户问题的最佳结果。在此模式下可以指定“权重设置”（无需配置 Rerank 模型 API）或选择 Rerank 模型进行检索。

      **[图片缺失] 未命名插图 (zh-hans/images/en-upload-files-10.png)**

    在混合检索设置内可以选择启用**“权重设置”**或**“Rerank 模型”**。

    **权重设置：** 允许用户赋予语义优先和关键词优先自定义的权重。关键词检索指的是在知识库内进行全文检索（Full Text Search），语义检索指的是在知识库内进行向量检索（Vector Search）。

    * **语义值为 1**

    仅启用语义检索模式。借助 Embedding 模型，即便知识库中没有出现查询中的确切词汇，也能通过计算向量距离的方式提高搜索的深度，返回正确内容。此外，当需要处理多语言内容时，语义检索能够捕捉不同语言之间的意义转换，提供更加准确的跨语言搜索结果。

    > 语义检索指的是比对用户问题与知识库内容中的向量距离。距离越近，匹配的概率越大。参考阅读：[《Dify：Embedding 技术与 Dify 数据集设计/规划》](https://mp.weixin.qq.com/s/vmY\_CUmETo2IpEBf1nEGLQ)。

    * **关键词值为 1**

    仅启用关键词检索模式。通过用户输入的信息文本在知识库全文匹配，适用于用户知道确切的信息或术语的场景。该方法所消耗的计算资源较低，适合在大量文档的知识库内快速检索。

    * **自定义关键词和语义权重**

    除了仅启用语义检索或关键词检索模式，我们还提供了灵活的自定义权重设置。你可以通过不断调试二者的权重，找到符合业务场景的最佳权重比例。

    ***

    **Rerank 模型：** 你可以在“模型供应商”页面配置 Rerank 模型的 API 秘钥之后，在检索设置中打开“Rerank 模型”，系统会在混合检索后对已召回的文档结果再一次进行语义重排序，优化排序结果。

    ***

    **“权重设置”** 和 **“Rerank 模型”** 设置内支持启用以下选项：

    **TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。数值越高，预期被召回的文本分段数量越多。

    **Score 阈值：**用于设置文本片段筛选的相似度阈值，即：只召回超过设置分数的文本片段。系统默认关闭该设置，即不会对召回的文本片段相似值过滤。打开后默认值为 0.5。数值越高，预期被召回的文本数量越少。

***

在**经济索引方式**下，Dify 仅提供 1 种检索设置：

#### **倒排索引**

倒排索引是一种用于快速检索文档中关键词的索引结构，它的基本原理是将文档中的关键词映射到包含这些关键词的文档列表，从而提高搜索效率。具体原理请参考[《倒排索引》](https://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95)。

**TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。数值越高，预期被召回的文本分段数量越多。

  **[图片缺失] 未命名插图 (zh-hans/images/en-upload-files-8.png)**

指定检索设置后，你可以参考[召回测试/引用归属](./zh-hans/guides/knowledge-base/retrieval-test-and-citation)查看关键词与内容块的匹配情况。

## 5 完成上传

配置完上文所述的各项配置后，轻点“保存并处理”即可完成知识库的创建。你可以参考 [在应用内集成知识库](./zh-hans/guides/knowledge-base/integrate-knowledge-within-application)，搭建出能够基于知识库进行问答的 LLM 应用。

***

## 参考阅读

#### ETL

在 RAG 的生产级应用中，为了获得更好的数据召回效果，需要对多源数据进行预处理和清洗，即 ETL （_extract, transform, load_）。为了增强非结构化/半结构化数据的预处理能力，Dify 支持了可选的 ETL 方案：**Dify ETL** 和[ ](https://docs.unstructured.io/welcome)[**Unstructured ETL** ](https://unstructured.io/)。

> Unstructured 能够高效地提取并转换您的数据为干净的数据用于后续的步骤。Dify 各版本的 ETL 方案选择：

文件解析支持格式的差异：

| DIFY ETL                                       | Unstructured ETL                                                         |
| ---------------------------------------------- | ------------------------------------------------------------------------ |
| txt、markdown、md、pdf、html、htm、xlsx、xls、docx、csv | txt、markdown、md、pdf、html、htm、xlsx、xls、docx、csv、eml、msg、pptx、ppt、xml、epub |

> **信息提示：**
不同的 ETL 方案在文件提取效果的方面也会存在差异，想了解更多关于 Unstructured ETL 的数据处理方式，请参考[官方文档](https://docs.unstructured.io/open-source/core-functionality/partitioning)。

**Embedding 模型**

**Embedding 嵌入**是一种将离散型变量（如单词、句子或者整个文档）转化为连续的向量表示的技术。它可以将高维数据（如单词、短语或图像）映射到低维空间，提供一种紧凑且有效的表示方式。这种表示不仅减少了数据的维度，还保留了重要的语义信息，使得后续的内容检索更加高效。

**Embedding 模型**是一种专门用于将文本向量化的大语言模型，它擅长将文本转换为密集的数值向量，有效捕捉语义信息。

> 如需了解更多，请参考：[《Dify：Embedding 技术与 Dify 数据集设计/规划》](https://mp.weixin.qq.com/s/vmY\_CUmETo2IpEBf1nEGLQ)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-base-creation/upload-documents.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 数据源授权
> 来源：`zh-hans/guides/knowledge-base/knowledge-pipeline/authorize-data-source.mdx`

Dify 支持多种外部数据源的连接，为了确保数据安全和访问控制，不同的数据源需要进行相应的授权配置。根据数据源的特性，Dify 提供两种主要的授权方式：**API Key** 和 **OAuth**，以确保你能够安全地访问和导入所需的数据。

## 数据源授权界面入口

在 Dify 中，你可以通过以下两种方式进入数据源授权配置界面：

### 方式一：通过知识流水线编排界面

进入知识流水线编排界面，添加需要的数据源。选中数据源节点，在右侧面板中，点击**绑定**。

![流水线授权界面](./images/knowledge-base/authorize-data-1.PNG)

### 方式二：设置界面
点击右上角头像，选择**设置**，点击**数据来源**。进入数据来源页面后，选择需要授权的数据源，点击**配置**。

![设置授权界面](./images/knowledge-base/authorize-data-2.PNG)

## 支持数据源及授权方式

| 数据源       | API Key | OAuth |
|-------------|---------|-------|
| Notion      | ✅      | ✅    |
| Jina Reader | ✅      |       |
| Firecrawl   | ✅      |       |
| Google Drive|         | ✅    |
| Dropbox     | ✅      | ✅    |
| OneDrive    |         | ✅    |

## 授权方式和流程

### API Key 授权
API Key 授权是一种基于密钥的身份验证方式，适用于企业级服务和开发者工具。用户需要在对应的服务提供商处生成 API Key，然后在 Dify 中进行配置。

#### 授权流程
1. 在数据源配置界面，选择对应的数据源，点击右侧的**配置**，选择**添加 API Key**。

   ![添加API Key](./images/knowledge-base/authorize-data-3.PNG)

2. 在弹出的配置面板中，填写对应信息。完成后，点击**保存**完成授权。

   ![API Key配置](./images/knowledge-base/authorize-data-4.png)

API 密钥将被安全加密储存，配置成功后会显示 **Connected** 状态，你可以在知识流水线中使用该数据源。

![API Key 配置完成](./images/knowledge-base/authorize-data-6.png)

### OAuth 授权
OAuth 是一种开放标准的授权协议，允许用户在不暴露密码的情况下，授权第三方应用访问其在特定服务提供商上的资源。Dify 提供两种 OAuth 授权配置方式：默认配置和自定义配置。

#### 授权流程
1. 在数据源配置界面，选择对应的数据源，点击右侧的**配置**，选择**添加 OAuth**。

   ![添加OAuth](./images/knowledge-base/authorize-data-7.png)

2. 在授权页面中查看并确认权限范围后，点击**允许访问**。
   <div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
      <div style={{flex: 1, minWidth: '300px'}}>
         ![OAuth权限确认](./images/knowledge-base/authorize-data-8.png)
      </div>
      <div style={{flex: 1, minWidth: '300px'}}>
         ![允许访问](./images/knowledge-base/authorize-data-9.png)
      </div>
   </div>

#### OAuth 客户端设置
Dify 提供默认和自定义两种 OAuth 客户端配置方式。

![OAuth客户端设置](./images/knowledge-base/authorize-data-10.png)

- **默认客户端**  
  仅 SaaS 版本支持默认客户端，你可以使用 Dify 官方预配置并维护的 OAuth 客户端参数，在 SaaS 版本一键添加 OAuth 凭据，无需进行额外的配置。

- **自定义客户端**  
  Dify 所有版本均支持自定义客户端。对于 SaaS 版本中尚未提供的默认配置数据源，你需要前往第三方平台自行注册并获取 OAuth 客户端参数。

**授权流程**
1. 在数据源配置界面，选择对应的数据源，点击右侧的**配置**，选择**添加 OAuth** 右侧的**设置图标**，进入 OAuth 客户端设置。

   ![自定义OAuth设置](./images/knowledge-base/authorize-data-11.png)

2. 点击**自定义**，输入 **Client ID** 和 **Client Secret**。点击**保存并授权**完成 OAuth 授权流程。

   ![自定义OAuth配置](./images/knowledge-base/authorize-data-12.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-pipeline/authorize-data-source.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 步骤一：创建知识流水线
> 来源：`zh-hans/guides/knowledge-base/knowledge-pipeline/create-knowledge-pipeline.mdx`

![创建知识流水线](./images/knowledge-base/create-knowledge-pipeline-1.png)

点击顶部的**知识库**，在左侧点击**通过知识流水线创建知识库**，你可以通过以下 3 种方式来创建知识流水线。

### 方式一：从零开始构建

![从零开始](./images/knowledge-base/create-knowledge-pipeline-2.png)

点击**空白知识流水线**即可从零开始构建自定义知识流水线。
如果你需要根据数据特点和业务需求自定义处理策略，建议选择从空白知识流水线开始。

### 方式二：通过模版创建

Dify 提供了两种模版方案： **内置流水线**（Built-in) 和**自定义** （Customized)。两种模版的卡片信息都包含了知识库名称、简介描述和标签（包含分段模式）。

![通过模版创建](./images/knowledge-base/create-knowledge-pipeline-4-1.png)

#### 内置流水线（Built-in Pipeline)

内置流水线为预置的知识流水线模版，针对常见的文档数据结构进行优化，你可以根据不同的文档类型和使用场景选择适合的处理方式。点击**选择**即可开始使用。

![内置模板](./images/knowledge-base/create-knowledge-pipeline-4.png)

**模版类型**

| 模版名称 | 分段结构 | 索引方式 | 检索设置 | 说明 |
|---------|---------|---------|---------|------|
| 通用模式（General Mode） | 通用模式 | 经济 | 倒排索引 | 将文档内容分割成较小的段落块（通用块），直接用于匹配用户查询和检索。 |
| 父子模式（Parent-child Structure) | 父子模式 | 高质量 | 混合检索 | 采用了高级分块策略，将文档文本分成较大的"父块"和较小的"子块"。其中，"父块"包含了"子块"。这样既保证了检索的精确性，又维持了上下文的完整性。 |
| 简单问答（Simple Q&A) | 问答模式 | 高质量 | 向量搜索 | 将表格数据转化为一问一答的形式，通过问题匹配来快速找到对应的答案信息。适用于结构化表格数据。 |
| 复杂 PDF （含图片和表格）（Complex PDF with Images & Tables） | 父子模式 | 高质量 | 混合检索 - 加权评分 | 提取 PDF 文件内的图像和表格内容。 |
| LLM 上下文增强（Contextual Enriching Using LLM) | 父子模式 | 高质量 | 混合检索 - 加权评分 | 将文档内的图片和表格提取出来，使用大型语言模型自动生成描述性注释，实现上下文的智能增强。 |
| Markdown 转换（Convert to Markdown) | 父子模式 | 高质量 | 混合检索 - 加权评分 | 专为 DOCX、XLSX 和 PPTX 等 Office 原生文件格式设计，将其转换为 Markdown 格式以便更好地进行信息处理。⚠️ 注意：不推荐使用 PDF 文件。 |
| LLM 生成问答（LLM Generated Q&A) | 问答模式 | 高质量 | 向量搜索 - 加权评分 | 使用大型语言模型自动生成结构化的问答对，通过问题匹配机制找到相关的答案信息。 |

点击模版卡片上的详情按钮，即可在弹窗中预览选中的流水线的编排结构、流水线简介和分段模式。点击使用此知识流水线模版进行编排。

![模板详情](./images/knowledge-base/create-knowledge-pipeline-5.png)

#### 自定义（Customized）

![自定义模板](./images/knowledge-base/create-knowledge-pipeline-6.png)

自定义模版为用户创建和发布为知识流水线的方案，你可以选择使用该模版、导出 DSL，或点击详情进行快速预览。

![模板操作](./images/knowledge-base/create-knowledge-pipeline-7.png)

点击模版卡片上的选择按钮，即可从该自定义模版开始创建知识库。你也可以在预览该流水线模版时，点击右侧的使用此知识流水线按钮开始创建。点击 ... 可以编辑流水线信息、导出知识流水线或者删除模版。

### 方式三：导入知识流水线

![导入DSL](./images/knowledge-base/create-knowledge-pipeline-3.png)

在完成知识流水线的编排后，你可以保存和导出知识流水线，并分享给其他人。知识库使用者可以导入知识流水线，快速复用已构建的知识流水线，并在此基础上针对不同情景或需求进行修改。与工作流 DSL 类似，知识流水线基于相同的 YAML 格式标准，用于定义知识库内的处理流程和配置。

知识流水线包含以下内容：

| 名称          | 包含                         |
|--------------|------------------------------|
| 数据源        | 文件上传、网站、在线文档和在线网盘 |
| 数据处理流程   | 文档提取、内容分块和清洗策略      |
| 知识库储存配置 | 索引方式、检索设置和存储参数      |
| 节点连接      | 节点间的连接和处理顺序           |
| 用户输入表单   | 自定义的参数输入字段（如有配置）   |

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-pipeline/create-knowledge-pipeline.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 步骤二：知识流水线编排
> 来源：`zh-hans/guides/knowledge-base/knowledge-pipeline/knowledge-pipeline-orchestration.mdx`

想象一下你正在搭建一条生产流水线，每个站点执行特定任务，你将不同它们连接起来将每个零部件组装最终成品。知识流水线编排与此类似，你组合不同节点，将原始文档数据通过每个节点逐步转化为可搜索的知识库。在 Dify 里，你通过可视化的方式，拖放和连接不同节点，对文档数据进行提取和分块处理，并配置索引方式和检索策略。

在这个章节，你将了解知识流水线的过程，理解不同节点的含义和配置，如何自定义构建数据处理流程，从而高效地管理和优化知识库。

### 界面状态
进入知识流水线编排界面时，你会看到：
- **标签页状态**：Documents（文档）、Retrieval Test（召回测试）和 Settings（设置）标签页将显示为置灰且不可用状态
- **必要步骤**：您必须完成知识流水线的配置、调试和发布后，才能上传文件或使用其他功能

如果你选择了**空白知识流水线**，你将看到仅包含知识库节点的画布。你可以跟随该节点旁的指引，逐步完成流水线创建。

![空白流水线](./images/knowledge-base/create-knowledge-pipeline-8.png)

如果选择**特定的流水线模版**，编排界面将直接显示该流水线模版。

![模板流水线](./images/knowledge-base/create-knowledge-pipeline-9.png)

## 知识流水线处理流程

在开始之前，我们先拆解知识流水线的处理流程，你可以更好地理解数据是如何一步步转化为可用的知识库。

> **提示：**

**数据源配置 → 数据处理节点（文档提取器 + 分块器）→ 知识库节点(分块结构+索引配置) → 配置用户输入表单 → 测试发布**

1. **数据源配置**：来自各种数据源的原始内容（本地文件、Notion、网页等）
2. **数据处理节点配置**：处理和转换数据内容
   - 提取器 (Extractor) → 解析和结构化原始文档内容
   - 分块器 (Chunker) → 将结构化内容分割为适合处理的片段
3. **知识库节点配置**：设置知识库的分段结构和检索策略
4. **用户输入表单配置**：定义流水线使用者需要输入的参数
5. **测试与发布**：验证并正式启用知识库

## 步骤一：数据源配置

在一个知识库里，你可以选择单一或多个数据源。每个数据源可以被多次选中，并包含不同配置。目前，Dify 支持 5 种数据源：文件上传、在线网盘、在线数据和 Web Crawler。

你也可以前往 [Dify Marketplace](https://marketplace.dify.ai)，获得更多数据源。

### 文件上传

用户可以直接选择本地文件进行上传，以下是配置选项和限制。

<div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
  <div style={{flex: 1, minWidth: '200px'}}>
    ![](./images/knowledge-base/knowledge-pipeline-orchestration-1.PNG)
  </div>
  <div style={{flex: 2, minWidth: '300px'}}>
      **配置选择**

      | 配置项 | 说明 |
      |--------|------|
      | 文件格式 | 支持 pdf, xlxs, docs 等，用户可自定义选择 |
      | 上传方式 | 通过拖拽或选择文件或文件夹上传本地文件，支持批量上传 |

      **限制**

      | 限制项 | 说明 |
      |--------|------|
      | 文件数量 | 每次最多上传 50 个文件 |
      | 文件大小 | 每个文件大小不超过 15MB |
      | 储存限制 | 不同 SaaS 版本的订阅计划对文档上传总数和向量存储空间有所限制 |

      **输出变量**

      | 输出变量 | 变量格式 |
      |----------|----------|
      | `x Document` | 单个文档 |
  </div>
</div>
---

### 在线数据

#### Notion

将知识库连接 Notion 工作区，可直接导入 Notion 页面和数据库内容，支持后续的数据自动同步。

<div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
  <div style={{flex: 1, minWidth: '200px'}}>
    ![Notion](./images/knowledge-base/knowledge-pipeline-orchestration-2.PNG)
  </div>
  <div style={{flex: 2, minWidth: '300px'}}>
      **配置选项说明**

      | 配置项 | 选项 | 输出变量 | 说明 |
      |--------|------|----------|------|
      | Extractor | 开启 | `x Content` | 输出结构化处理的页面信息 |
      | | 关闭 | `x Document` | 输出页面的原始文本信息 |
  </div>
</div>

### 网页爬虫

将网页内容转化为大型语言模型容易识别的格式，知识库支持 Jina Reader 和 Firecrawl，提供灵活的网页解析能力。

#### Jina Reader

开源网页解析工具，提供简洁易用的 API 服务，适合快速抓取和处理网页内容。

<div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
  <div style={{flex: 1, minWidth: '200px'}}>
    ![Jina Reader](./images/knowledge-base/knowledge-pipeline-orchestration-3.png)
  </div>
  <div style={{flex: 2, minWidth: '300px'}}>
      **参数配置和说明**

      | 参数 | 类型 | 说明 |
      |------|------|------|
      | URL | 必填 | 目标网页地址 |
      | 爬取子页面 (Crawl sub-page) | 可选 | 是否抓取链接页面 |
      | 使用站点地图 (Use sitemap) | 可选 | 利用网站地图进行爬取 |
      | 爬取页数限制 (Limit) | 必填 | 设置最大抓取页面数量 |
      | 启用内容提取器 (Enable Extractor) | 可选 | 选择数据提取方式 |
  </div>
</div>

#### Firecrawl

开源网页解析工具，提供更精细的爬取控制选项和 API 服务，支持复杂网站结构的深度爬取，适合需要批量处理和精确控制的场景。

<div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
  <div style={{flex: 1, minWidth: '200px'}}>
    ![Firecrawl](./images/knowledge-base/knowledge-pipeline-orchestration-4.png)
  </div>
  <div style={{flex: 2, minWidth: '300px'}}>
      **参数配置和说明**

      | 参数 | 类型 | 说明 |
      |------|------|------|
      | URL | 必填 | 目标网页地址 |
      | 爬取页数限制 (Limit) | 必填 | 设置最大抓取页面数量 |
      | 爬取子页面 (Crawl sub-page) | 可选 | 是否抓取链接页面 |
      | 最大爬取深度 (Max depth) | 可选 | 控制爬取层级深度 |
      | 排除路径 (Exclude paths) | 可选 | 设置不爬取的页面路径 |
      | 仅包含路径 (Include only paths) | 可选 | 限制只爬取指定路径 |
      | 启用内容提取器 (Enable Extractor) | 可选 | 选择数据处理方式 |
      | 只提取主要内容 | 可选 | 过滤页面辅助信息 |
   </div>
</div>

### 在线网盘 (Online Drive)

连接你的在线云储存服务（例如 Google Drive、Dropbox、OneDrive），Dify 将自动检索云储存中的文件，你可以勾选并导入相应文档进行下一步处理，无需手动下载文件再进行上传。

> **提示：**

关于第三方数据源授权，请前往[数据源授权](./zh-hans/guides/knowledge-base/knowledge-pipeline/authorize-data-source)。

---

## 步骤二：配置数据处理节点

该阶段是内容的预处理与数据结构化过程，这一部分将会把数据源进行提取、分段并转换为适合知识库存储和检索的格式。你可以将这一步想象成备餐过程——处理原材料、进行清理、切分成小块，并整理好一切，以便在有人需要时能迅速"烹制"出这道"菜肴"。

### 文档处理

由于知识库无法直接理解 PDF、Word 等各种文档格式，提取器负责将这些文档"解读"成系统可以处理的文本内容。它支持多种常见文件格式，确保你的文档内容能够被正确提取和处理，并转换为大型语言模型可以有效使用的格式。 你可以选择 Dify 文档提取器来处理文件，也可以根据你的需求从 Dify Marketplace 中选择更多工具。Marketplace 提供了如 Dify Extractor 以及 MinerU、Unstructured 等第三方工具。

#### 文档提取器 (Doc Extractor)

![文档提取器](./images/knowledge-base/knowledge-pipeline-orchestration-4-1.png)

文档提取器节点可以理解为一个信息处理中心，通过识别并读取输入变量中的文件，提取信息后转化为下一个节点可使用的格式。

> **提示：**

关于文档提取器的详细功能和配置方法，请参考[文档提取器](./zh-hans/guides/workflow/node/doc-extractor)。

#### Dify 提取器 (Dify Extractor)

Dify Extractor 是 Dify 开发的一款内置文档解析器。它支持多种常见文件格式，并针对 Doc 文件进行了专门优化。它能够从文档中提取图片，进行存储并返回图片的 URL。

![Dify Extractor](./images/knowledge-base/knowledge-pipeline-orchestration-5.png)

#### MinerU

<div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
   <div style={{flex: 1, minWidth: '200px'}}>
      ![MinerU](./images/knowledge-base/knowledge-pipeline-orchestration-6.png)
   </div>
   <div style={{flex: 2, minWidth: '300px'}}>
      MinerU 是一款高质量文档解析器，可将文档转换为机器可读格式（Markdown、JSON），专注于保留复杂结构和数学符号。

      与基础 PDF 提取器相比，MinerU 会移除页眉、页脚和页码，同时保持语义连贯性。它还能自动检测扫描 PDF 和乱码文档，支持 84 种语言的 OCR 功能。建议使用 MinerU 处理包含复杂公式的科学论文（自动转换为 LaTex）、多栏布局、包含混合内容（文本+图片+表格）的学术出版物文档。
  </div>
</div>

#### Unstructured

<div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
   <div style={{flex: 1, minWidth: '200px'}}>
      ![Unstructured](./images/knowledge-base/knowledge-pipeline-orchestration-7.png)
   </div>
   <div style={{flex: 2, minWidth: '300px'}}>
      Unstructured 将文档转换为结构化的机器可读格式，具有高度可定制的处理策略。它提供多种提取策略（auto、hi_res、fast、OCR-only）和分块方法（by_title、by_page、by_similarity）来处理各种文档类型，提供详细的元素级元数据，包括坐标、置信度分数和布局信息。推荐用于企业文档工作流、混合文件类型处理以及需要精确控制文档处理参数的场景。
   </div>
 </div>

你可前往 [Dify Marketplace](https://marketplace.dify.ai) 探索更多工具。

### 分块器 (Chunker)

在构建 AI 应用时，我们需要处理大量和不同种类的文档内容，比如产品手册、技术文档或论文等。和人类有限的注意力相似，大型语言模型无法同时处理过多的信息。因此，在信息提取后，分块器将大段的文档内容拆分成更小、更易于管理的片段（称为"块"）。这就好比一本很厚的书，被分成了许多章节，你可以通过阅读目录快速定位到相关内容所在章节。

当 AI 应用需要回答问题时，良好的分块策略能够提供足够的上下文信息，并包含完整的语义。这样，当检索到对应的片段时，大型语言模型能够基于这个片段中的信息生成较为准确的答案。

不同类型的文档需要不同的分块策略，比如产品手册可能需要按照产品型号进行分块，确保产品功能介绍的完整性；论文则需要根据逻辑结构进行分块，确保论点叙述的流畅性。基于这样的多样性，Dify 提供了 3 种分块器，帮助你根据不同文档类型和使用场景进行选择和使用。

#### 分块器类型概述

| 类型 | 特点 | 使用场景 |
|------|------|----------|
| 通用分块器 | 固定大小分块，支持自定义分隔符 | 结构简单的基础文档 |
| 父子分块器 | 双层分段结构，平衡匹配精准度和上下文 | 需要较多上下文信息的复杂文档结构 |
| 问答处理器 | 处理表格中的问答组合 | CSV 和 Excel 的结构化问答数据 |

#### 通用文本预处理规则

| 处理选项 | 说明 |
|----------|------|
| 替换连续空格、换行符和制表符 | 将文档中的连续空格、换行符和制表符替换为单个空格 |
| 移除所有 URL 和邮箱地址 | 自动识别并移除文本中的网址链接和邮箱地址 |

#### 通用分块器 (General Chunker)

基础文档分块处理，适用于结构相对简单的文档，你可以参考下面的配置对文本的分块、文本预处理规则进行配置。

**输入输出变量**

| 类型 | 变量 | 说明 |
|------|------|------|
| 输入变量 | `x Content` | 完整的文档内容块，通用分块器将其拆分为若干小段 |
| 输出变量 | `x Array[Chunk]` | 分块后的内容数组，每个片段适合进行检索和分析 |

**分块设置 (Chunk Settings)**

| 配置项 | 说明 |
|--------|------|
| 分段标识符 (Delimiter) | 默认值为 `\n`，即按照文本段落分段。你可以遵循正则表达式语法自定义分块规则，系统将在文本出现分段标识符时自动执行分段。 |
| 分段最大长度 (Maximum Chunk Length) | 指定分段内的文本字符数最大上限，超出该长度时将强制分段。 |
| 分段重叠长度 (Chunk Overlap) | 对数据进行分段时，段与段之间存在一定的重叠部分。这种重叠可以帮助提高信息的保留和分析的准确性，提升召回效果。 |

#### 父子分块器 (Parent-child Chunker)

父子分块器采用双层分段结构解决了上下文与准确度之间的矛盾，在检索增强生成（RAG）系统中实现了准确匹配与全面的上下文信息的平衡。

**父子检索的工作机制**

- **使用子分块匹配查询**：使用小而精准的信息片段（通常简洁到段落中的单个句子）来匹配用户查询。这些子分块能够实现精确且相关的初始检索。
- **父分块提供丰富的上下文**：检索包含匹配子分块的更大范围内容（如段落、章节甚至整个文档）。这些父分块为大语言模型（LLM）提供全面的上下文信息。

**输入输出变量**

| 类型 | 变量 | 说明 |
|------|------|------|
| 输入变量 | `x Content` | 完整的文档内容块，通用分块器将其拆分为若干小段 |
| 输出变量 | `x Array[ParentChunk]` | 父分块数组 |

**分块设置 (Chunk Settings)**

| 配置项 | 说明 |
|--------|------|
| 父分块分隔符 (Parent Delimiter) | 设置父分块的分割标识符 |
| 父分块最大长度 (Parent Maximum Chunk Length) | 控制父分块的最大字符数 |
| 子分块分隔符 (Child Delimiter) | 设置子分块的分割标识符 |
| 子分块最大长度 (Child Maximum Chunk Length) | 控制子分块的最大字符数 |
| 父块模式 (Parent Mode) | 选择"段落"（将文本分割为段落）或"完整文档"（使用整个文档作为父分块）进行直接检索 |

#### 问答处理器 Q&A Processor (Extractor+Chunker)

问答处理器结合了提取和分块功能，专门用于处理 CSV 和 Excel 文件的结构化问答数据集，比如常见问题（FAQ）列表、排班表等。

**输入输出变量**

| 类型 | 变量 | 说明 |
|------|------|------|
| 输入变量 | `x Document` | 单个文档 |
| 输出变量 | `x Array[QAChunk]` | 问答分块数组 |

**变量配置**

| 名称 | 说明 |
|------|------|
| 问题所在的列 | 将内容所在的列设置为问题 |
| 答案所在的列 | 将内容所在的列设置为答案 |

## 步骤三：配置知识库节点

在完成数据处理后，我们将进入知识流水线的最后一个环节 — 知识库节点。你可以根据实际需求，在这个节点选择不同的索引方法和检索策略，以获得最适合的检索效果和成本控制。

知识库节点配置分为以下部分：输入变量、分段结构、索引方式以及检索设置。

### 分段结构 (Chunk Structure)

![分段结构](./images/knowledge-base/knowledge-pipeline-orchestration-8.png)

分段结构决定了知识库如何组织和索引你的文档内容。你可以根据文档类型、使用场景和成本考虑来选择最适合的结构模式。

知识库支持两种分段模式：通用模式与父子模式。如果你是首次创建知识库，建议选择父子模式。

> **警告：**

   **重要提醒**：分段结构一旦保存发布后无法修改，请根据实际需求进行选择。

#### 通用模式

适用于大多数标准文档处理场景。
通用模式提供灵活的索引选项，你可以根据对质量和成本的不同要求选择合适的索引方法。通用模式支持高质量和经济的索引方式，以及多种检索设置。

#### 父子模式

父子模式能够在检索时，提供精确匹配和对应的上下文信息，适用于需要保持完整上下文的专业文档。父子模式仅支持 HQ （高质量）模式，检索时提供子分块匹配和父分块上下文。

#### 问答模式 (Question-Answer)

在使用结构化问答数据时，你可以创建问题与答案配对的文档。这些文档会根据问题部分进行索引，从而使系统能够根据查询相似性检索到相关的答案。问答模式仅支持 HQ（高质量）模式。

### 输入变量 (Input Variable)

输入变量用于接收来自数据处理节点的处理结果，用作知识库构建的数据源。你需要将前面配置的分块器节点的输出，连接到知识库节点并作为输入。

该节点根据所选的分段结构，支持不同类型的标准输入：
- **通用模式**：`x Array[Chunk]` - 通用分块数组
- **父子模式**：`x Array[ParentChunk]` - 父分块数组
- **问答模式**：`x Array[QAChunk]` - 问答分块数组

### 索引方式 (Index Method) 与检索设置 (Retrieval Setting)

索引方式决定了知识库如何建立内容索引，检索设置则基于所选的索引方式提供相应的检索策略。你可以这么理解，索引方式决定了整理文档的方式，而检索设置告知使用者可以用什么方法来查找文档。

知识库提供了两种索引方式：高质量和经济，分别提供不同的检索设置选项。
在高质量模式下，使用 Embedding 嵌入模型将已分段的文本块转换为数字向量，帮助更加有效地压缩与存储大量文本信息。这使得即使用户的问题用词与文档不完全相同，系统也能找到语义相关的准确答案。

> **提示：**

请查看[设定索引方法与检索设置](./zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/setting-indexing-methods)，了解更多详情。

#### 索引方式和检索设置

| 索引方式 | 可用检索设置 | 说明 |
|----------|--------------|------|
| 高质量 | 向量搜索 | 基于语义相似度，理解查询深层含义。 |
| | 全文检索 | 基于关键词匹配的检索方式，提供全面的检索能力。 |
| | 混合检索 | 结合语义和关键词 |
| 经济 | 倒排索引 | 搜索引擎常用的检索方法，匹配问题与关键内容。 |

关于配置分段结构、索引方法、配置参数和检索设置，你也可以参考下方表格。

| 分段结构 | 可选索引方式 | 可配置参数 | 可用检索设置 |
|----------|--------------|------------|--------------|
| 通用模式 | 高质量   

 经济 | Embedding 嵌入模型   

 关键词数量 | 向量检索   
 全文检索   
 混合检索   
 倒排索引 |
| 父子模式 | 高质量（仅支持） | Embedding Model 嵌入模型 | 向量检索   
 全文检索   
 混合检索 |
| 问答模式 | 高质量（仅支持） | Embedding Model 嵌入模型 | 向量检索   
 全文检索   
 混合检索 |

## 步骤四：配置用户输入表单

用户输入表单对于收集流水线运行所需的有效初始信息非常重要。类似于工作流中的[开始节点](./zh-hans/guides/workflow/node/start)，这个表单从用户那里收集必要的相信信息，比如：需要上传的文件、文档处理的特定参数等，确保流水线拥有提供准确结果所需要的所有信息。

通过这种方式，你可以为不同的使用场景创建特定的的输入表单，提高流水线对于不同数据源和文档处理流程的灵活性和易用性。

### 创建用户输入表单

你可以通过下面两种方式，创建用户输入表单。

1. **知识流水线编排界面**
   点击输入字段（Input Field）开始创建和配置输入表单。

   ![输入表单](./images/knowledge-base/knowledge-pipeline-orchestration-9.png)

2. **节点参数面板**
   选中节点，在右侧的面板需要填写的参数内，点击最下方的`+ 创建用户输入字段`（+ Create user input)来创建新的输入项。新增的输入项将会汇总到输入字段（Input Field）的表单内。

   ![节点参数](./images/knowledge-base/knowledge-pipeline-orchestration-10.png)

### 输入类型

#### 非共享输入 (Unique Inputs for Each Entrance)

![非共享输入](./images/knowledge-base/knowledge-pipeline-orchestration-11.png)

这类输入适用于每个数据源及其下游节点，用户只需在选择对应数据源时填写这些字段，比如不同数据源的URL。

在数据源右侧点击"+"按钮，为该数据源添加字段。这个字段只能被该数据源及其后续连接的节点引用。

![数据源字段](./images/knowledge-base/knowledge-pipeline-orchestration-12.png)

#### 全局共享输入 (Global Inputs for All Entrance)

![全局共享输入](./images/knowledge-base/knowledge-pipeline-orchestration-13.png)

全局共享输入可以被所有节点引用。这类输入适用于通用处理参数，比如分隔符、最大分块长度、文档处理配置等。无论用户选择哪个数据源，都需要填写这些字段。

在全局共享输入右侧点击"+"按钮，添加的字段将被任意节点引用。

### 支持字段类型和填写说明

知识流水线支持以下七种类型的输入变量。
<div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
  <div style={{flex: 1, minWidth: '200px'}}>
      ![字段类型](./images/knowledge-base/knowledge-pipeline-orchestration-14.png)
  </div>
  <div style={{flex: 2, minWidth: '300px'}}>
   | 字段类型 | 说明 |
   |----------|------|
   | 文本 | 短文本，由知识库使用者自行填写，最大长度为 256 字符 |
   | 段落 | 长文本，知识库使用者可以输入较长字符 |
   | 下拉选项 | 由编排者预设的固定选项供使用者选择，使用者无法自行填写内容 |
   | 布尔值 | 只有真/假两个取值 |
   | 数字 | 只能输入数字 |
   | 单文件 | 上传单个文件，支持多种文件类型（文档、图片、音频、视频和其他文件类型） |
   | 文件列表 | 批量上传文件，支持多种文件类型（文档、图片、音频、视频和其他文件类型） |
   </div>
</div>

> **提示：**

   请前往[输入字段](./zh-hans/guides/workflow/node/start#%E8%BE%93%E5%85%A5%E5%AD%97%E6%AE%B5)，了解关于支持字段的更多说明。

所有类型的输入项包含：必填项、非必填项和更多设置，可以通过勾选设置为是否为必填。

| 名称 | 说明 | 示例 |
|------|------|------|
| **必填项** | | |
| 变量名称 Variable Name | 系统内部标识名称，通常使用英文和下划线进行命名 | `user_email` |
| 显示名称 Display Name | 界面展示的名称，通常是简洁易读的文字 | 用户邮箱 |
| **类型特定设置** | 不同字段类型的特殊要求 | 文本的最大长度为 100 字符 |
| **更多设置** | | |
| 默认值 Default Value | 用户未输入时的默认值 | 数字字段默认为0， 文本字段默认为空 |
| 占位符 Placeholder | 输入框空白时的提示文字 | 请输入您的邮箱 |
| 提示 Tooltip | 解释或指引用户进行填写的文字，通常在用户鼠标悬停时显示 | 请输入有效的邮箱地址 |
| **特殊非必填信息** | 根据不同字段类型的额外设置选项 | 邮箱格式验证 |

配置完成后，点击右上角的预览按钮，你可以在弹出的表单预览界面中浏览。你可以拖拽调整字段的分组，如果出现感叹号，则表明移动后引用失效。

![表单预览](./images/knowledge-base/knowledge-pipeline-orchestration-15.png)

## 步骤五：为知识库命名

![命名知识库](./images/knowledge-base/create-knowledge-pipeline-11.png)

默认情况下，知识库名称为"Untitled + 序号”，权限设置为"仅自己可见”，图表为橙色书本。如果你使用 DSL文件导入，则将使用其保存的图标。

点击左侧面板中的设置并填写以下信息：
- **名称和图标** 
为你的知识库命名。你还可以选择一个 emoji、上传图片或粘贴图片 URL 作为知识库的图标。
- **知识库描述**
  简要描述您的知识库。这有助于 AI 更好地理解和检索您的数据。如果留空，Dify 将应用默认的检索策略。
- **权限** 
  从下拉菜单中选择适当的访问权限。

## 步骤六：测试

在完成编排后，你需要先验证配置的完整性，然后测试流水线运行效果，确认各项设置正确无误，最后发布知识库。

### 检查配置完成度

在进行测试前，建议先检查配置的完整性，避免因遗漏配置而导致测试失败。

点击右上角的检查清单按钮，系统会显示遗漏部分。

![检查清单](./images/knowledge-base/knowledge-pipeline-orchestration-16.png)

完成所有的配置后，可以通过测试运行来预览知识流水线的运行效果，确认各项设置准确无误，再进行发布。

### 测试运行 (Test Run)

![测试运行](./images/knowledge-base/knowledge-pipeline-orchestration-17.png)

1. **开始测试**：点击右上角的测试运行（Test Run)按钮。
2. **导入测试文件**：在右侧弹出的数据源窗口中，导入文件。

> **警告：**

   **重要提醒**：为了便于调试和观测，在测试运行状态下，每次仅允许上传一个文件。

3. **填写参数**：导入成功后，根据你之前配置的用户输入表单填写对应参数
4. **开始试运行**：点击下一步，开始测试整个流水线。

在测试期间，你可以访问[运行历史](./zh-hans/guides/workflow/debug-and-preview/history-and-logs#%E5%BA%94%E7%94%A8%E8%B0%83%E8%AF%95%E5%8E%86%E5%8F%B2)（记录所有运行记录，包括运行时间、执行状态和输入/输出参数概要）和[变量检查](./zh-hans/guides/workflow/debug-and-preview/variable-inspect)（位于底部面板，它显示每个节点的输入/输出数据，帮助你识别问题和验证数据流），以实现高效的故障排除和错误修复。

![测试工具](./images/knowledge-base/knowledge-pipeline-orchestration-18.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-pipeline/knowledge-pipeline-orchestration.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 步骤五：管理和使用知识库
> 来源：`zh-hans/guides/knowledge-base/knowledge-pipeline/manage-knowledge-base.mdx`

创建知识库后，你可以继续对其进行管理和优化，以确保它能为你的应用程序提供准确的的上下文信息。通过以下方式，你可以对知识库文件的进行更新、进行召回测试、修改流水线和修改知识库的属性等：

### 流水线

浏览编排的流水线，并对节点和配置进行修改。

> **提示：**

    你可前往[管理知识库文档](./zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/introduction)，了解更多内容。

![知识管理](./images/knowledge-base/create-knowledge-pipeline-21.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-pipeline/manage-knowledge-base.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 步骤三：发布知识流水线
> 来源：`zh-hans/guides/knowledge-base/knowledge-pipeline/publish-knowledge-pipeline.mdx`

完成知识流水线的编排和调试后，点击**发布**并在弹窗中点击**确认**，即成功发布知识流水线。

<div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
  <div style={{flex: 1, minWidth: '200px'}}>
    ![发布确认](./images/knowledge-base/create-knowledge-pipeline-12-1.png)
  </div>
  <div style={{flex: 2, minWidth: '300px'}}>
    ![发布成功](./images/knowledge-base/create-knowledge-pipeline-12.png)
  </div>
</div>

> **警告：**

  **注意：知识流水线发布后，分段结构无法进行修改。**
  由于分段结构会影响知识库的存储方式和检索召回策略，为确保数据一致性和用户体验，当前每个知识库仅支持**一种分段结构**。

<div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
  <div style={{flex: 2, minWidth: '200px'}}>
    ![发布完成](./images/knowledge-base/create-knowledge-pipeline-13.png)
  </div>
  <div style={{flex: 3, minWidth: '300px'}}>
    成功发布后，你可以进行如下操作：  

    **添加文档（Go to add documents)**  
    点击此选项可以跳转到知识库选择数据源界面，你可以直接上传文档。  

    **访问 API（Access API Reference)**
    前往 API 文档页面，你可以获取知识库的 API 调用方法和说明。  

    **发布为流水线（Publish as a Knowledge Pipeline)**  
    你可以点击发布为知识流水线将该流水线保存为可复用的模版，该模版将出现在自定义模版中。
  </div>
</div>

> **警告：**

    限制说明：Sandbox 不支持发布为知识流水线功能。如需保存并发布为知识流水线，请[升级](https://dify.ai/pricing)至 Professional 或者 Team 方案。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-pipeline/publish-knowledge-pipeline.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 通过知识流水线创建知识库
> 来源：`zh-hans/guides/knowledge-base/knowledge-pipeline/readme.mdx`

知识流水线是构建处理文档流程的一种解决方案，你能够像编排工作流一样对不同节点进行可视化地组合和配置，并选择使用不同工具来优化数据处理过程。

它主要包含四个环节，每个环节由不同的节点和工具组成，形成完整的数据处理链路：

**数据源 → 数据提取 → 数据处理 → 知识库存储**

每个步骤都有特定的用途：从各种来源收集内容，将其转换为可处理的文本，优化以便搜索，并以能够快速、准确检索的格式进行存储。

此外，Dify 还提供不同使用场景的知识流水线模板，帮助提升数据索引和检索结果的准确度。本章节将帮助你了解知识流水线的创建方式、流程以及相应节点，让你能快速搭建和优化自己的知识库。

> **步骤：**

      从内置模板、空白知识库流水线开始创建，或导入现有流水线。

      了解知识库流水线的工作原理，编排不同节点，构建你需要的的数据处理流程。

      测试配置无误后，发布流水线，准备进行文档处理。

      添加文档，经过处理后构建成可搜索的知识库。

      日常维护文档、测试检索效果、修改设置等。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-pipeline/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 步骤四：上传文件
> 来源：`zh-hans/guides/knowledge-base/knowledge-pipeline/upload-files.mdx`

完成知识流水线的编排、调试并发布成功后，你能通过以下两种方式上传文件：

   A. 在发布成功的弹窗哪点击前往文档。进入文档页面后，点击添加文件进行上传。
   <div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
      <div style={{flex: 1, minWidth: '200px'}}>
         ![方式A-1](./images/knowledge-base/create-knowledge-pipeline-14.png)
      </div>
      <div style={{flex: 2, minWidth: '300px'}}>
         ![方式A-2](./images/knowledge-base/create-knowledge-pipeline-15.png)
      </div>
   </div>
   B. 在发布的下拉菜单中，点击去添加文档。进入选择数据源页面，选择对应数据源开始上传文件。
   <div style={{display: 'flex', flexWrap: 'wrap', gap: '30px'}}>
      <div style={{flex: 1, minWidth: '200px'}}>
         ![方式B-1](./images/knowledge-base/create-knowledge-pipeline-16.png)
      </div>
      <div style={{flex: 2, minWidth: '300px'}}>
         ![方式B-2](./images/knowledge-base/create-knowledge-pipeline-17.png)
      </div>
   </div>

### 上传流程

1. **选择数据源**  
   从流水线配置的数据源类型中进行选择。目前，Dify 支持 4 种数据源
   **文件上传（pdf, docx 等）、在线网盘（Google Drive, OneDrive 等）、在线文档（Notion)和 网页爬虫（Jina Reader 和 Firecrawl）。**
   请前往 [Dify Marketplace](https://marketplace.dify.ai/) 获取更多数据源支持。

2. **填写文件处理相关参数和变量**  
   如果你在知识流水线的编排过程中配置了用户输入字段，需要在这一步填写所需的参数和变量。完成填写后，点击**预览分段**可进行预览。  
   点击保存并处理完成知识库创建，进入数据处理阶段。

> **警告：**

      注意：分段结构与知识流水线内保持一致，不会因用户输入的文件处理参数和变量而改变。

   ![参数填写](./images/knowledge-base/create-knowledge-pipeline-18.png)

3. **文档处理**  
   跟踪文档处理的进度。嵌入完成后，点击**前往文档**。
   ![处理进度](./images/knowledge-base/create-knowledge-pipeline-19.png)

4. **查看文件列表**  
   点击**前往文档**，前往知识库文档界面。在这里，你可以浏览上传文件数量、处理进程和状态等。
   ![文档列表](./images/knowledge-base/create-knowledge-pipeline-20.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-pipeline/upload-files.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 知识库请求频率限制
> 来源：`zh-hans/guides/knowledge-base/knowledge-request-rate-limit.mdx`

为了维护 Dify 云服务系统的稳定性，并提升所有用户的知识库使用体验，我们将从 **2025 年 2 月 24 日** 起引入知识库请求频率限制（Knowledge Request Rate Limit）。

## 什么是知识库请求频率限制？

知识库请求频率限制，指一个工作区在知识库中每分钟可执行的最大操作数。这些操作包括数据集创建、文档管理，以及在应用或工作流中的知识库查询。

## 不同订阅版本的限制

-   **Sandbox**：10 次/分钟
-   **Professional**：100 次/分钟
-   **Team**：1,000 次/分钟

例如，对于 **Sandbox 用户**，如果在 1 分钟内执行了 10 次命中测试，该用户的工作区将在接下来的 1 分钟内暂时无法执行受知识库请求频率限制的操作。

## 哪些操作会受到知识库请求频率限制？

当你执行以下操作时，会受到知识库请求频率限制：

1.  创建空数据集
2.  删除数据集
3.  更新数据集设置
4.  上传文档
5.  删除文档
6.  更新文档
7.  禁用文档
8.  启用文档
9.  归档文档
10. 恢复文档
11. 暂停文档处理
12. 恢复文档处理
13. 新增分段
14. 删除分段
15. 更新分段
16. 批量导入分段
17. 命中测试
18. App 或 Workflow 中查询知识库（多路召回虽然会多次查询知识库，但是只记作一次请求）

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/knowledge-request-rate-limit.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 元数据
> 来源：`zh-hans/guides/knowledge-base/metadata.mdx`

## 什么是元数据？

### 定义

元数据是用于描述其他数据的信息。简单来说，它是"关于数据的数据"。它就像一本书的目录或标签，可以为你介绍数据的内容、来源和用途。
通过提供数据的上下文，元数据能帮助你在知识库内快速查找和管理数据。

### 知识库元数据定义

-   **字段（Field）**：元数据字段是用于描述文档特定属性的标识项，每个字段代表文档的某个特征或信息。例如"author""language"等。

-   **字段值（Value）**：字段值是该字段的具体信息或属性，例如"Jack""English"。

![field_name_and_value](https://assets-docs.dify.ai/2025/03/b6a197aa21ab92db93869fcbfa156b62.png)

-   **字段值计数（Value Count）**：字段值计数是指在某条元数据字段中标记的字段值数量，包括重复项。例如，此处的"3"是字段值计数，指该字段中有 3 个独特的字段值。

![metadata_field](https://assets-docs.dify.ai/2025/03/330f26e90438cf50167c4cb6ce30e458.png)

-   **值类型（Value Type）**：值类型指字段值的类型。
   -   目前，Dify 的元数据功能支持以下三种值类型：
       -   **字符串**（String）：文本值。
       -   **数字**（Number）：数值。
       -   **时间**（Time）：日期和时间。

![value_type](https://assets-docs.dify.ai/2025/03/f6adc7418869334805361535c8cd6874.png)

## 如何管理知识库元数据？

### 管理知识库元数据字段

在知识库管理界面，你可以创建、修改和删除元数据字段。

> 注意：所有在此界面进行的更新均为**全局更新**，这意味着对元数据字段列表的任何更改都会影响整个知识库，包括所有文档中标记的元数据。

#### 元数据管理界面简介

**进入元数据管理界面**

在知识库管理界面，点击右上方的 **元数据** 按钮，进入元数据管理界面。

![metadata_entrance](https://assets-docs.dify.ai/2025/03/bd43305d49cc1511683b4a098c8f6e5a.png)

![metadata_panel](https://assets-docs.dify.ai/2025/03/6000c85b5d2e29a2a5af5e0a047a7a59.png)

**知识库元数据字段的类型**

在知识库中，元数据字段分为两类：**内置元数据（Built-in）** 和 **自定义元数据**。

<table>
  <thead>
    <tr>
      <th> </th>
      <th>内置元数据（Built-in）</th>
      <th>自定义元数据</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>显示位置</td>
      <td>知识库界面 元数据 栏的下半部分。</td>
      <td>知识库界面 元数据 栏的上半部分。</td>
    </tr>
    <tr>
      <td>启用方式</td>
      <td>默认禁用，需要手动开启才能生效。</td>
      <td>由用户根据需求自由添加。</td>
    </tr>
    <tr>
      <td>生成方式</td>
      <td>启用后，由系统自动提取相关信息并生成字段值。</td>
      <td>用户手动添加，完全由用户自定义。</td>
    </tr>
    <tr>
      <td>修改权限</td>
      <td>一旦生成，无法修改字段与字段值。</td>
      <td>可以删除或编辑字段名称，也可以修改字段值。</td>
    </tr>
    <tr>
      <td>应用范围</td>
      <td>启用后，适用于已上传和新上传的所有文档。</td>
      <td>添加元数据字段后，字段会储存在知识库的元数据列表中/需要手动设置，才能将该字段应用于具体文档。</td>
    </tr>
    <tr>
      <td>字段</td>
      <td>
        由系统预定义，包括：
        <ul>
          <li>document_name (string)：文件名</li>
          <li>uploader (string)：上传者</li>
          <li>upload_date (time)：上传日期</li>
          <li>last_update_date (time)：最后更新时间</li>
          <li>source (string)：文件来源</li>
        </ul>
      </td>
      <td>在初始状态下，知识库无自定义元数据字段，需要用户手动添加。</td>
    </tr>
    <tr>
      <td>字段值类型</td>
      <td>
        <ul>
          <li>字符串 (string)：文本值</li>
          <li>数字 (number)：数值</li>
          <li>时间 (time)：日期和时间</li>
        </ul>
      </td>
      <td>
        <ul>
          <li>字符串 (string)：文本值</li>
          <li>数字 (number)：数值</li>
          <li>时间 (time)：日期和时间</li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

#### 新建元数据字段

1.  点击 **+添加元数据** 按钮，弹出 **新建元数据** 弹窗。

![new_metadata](https://assets-docs.dify.ai/2025/03/5086db42c40be64e54926b645c38c9a0.png)

2.  在 **字段值类型** 中选择元数据字段的值类型。

3.  在 **名称** 框中填写字段的名称。

> 字段名仅支持小写字母、数字和下划线（_）字符，不支持空格和大写字母。

![value_type](https://assets-docs.dify.ai/2025/03/f6adc7418869334805361535c8cd6874.png)

4.  点击 **保存** 按钮，保存字段。

![save_field](https://assets-docs.dify.ai/2025/03/f44114cc58d4ba11ba60adb2d04c9b4c.png)

#### 修改元数据字段

1.  点击单条元数据字段右侧的编辑按钮，弹出 **重命名** 弹窗。

![rename_field_1](https://assets-docs.dify.ai/2025/03/94327185cbe366bf99221abf2f5ef55a.png)

2.  在 **名称** 框中修改字段名称。

> 此弹窗仅支持修改字段名称，不支持修改字段值类型。

![](https://assets-docs.dify.ai/2025/03/2c84eeed42ccb052c8a2558f0d128853.png)

![rename_field_2](https://assets-docs.dify.ai/2025/03/2c84eeed42ccb052c8a2558f0d128853.png)

3.  点击 **保存** 按钮，保存修改后的字段。

> 修改并保存后，该字段将在知识库中的所有相关文档中同步更新。

![same_renamed_field](https://assets-docs.dify.ai/2025/03/022e42c170b40c35622b9b156c8cc159.png)

#### 删除元数据字段

点击单条元数据字段右侧的删除按钮，可以删除该字段。

> 如果删除单条字段，该字段及该字段下包含的字段值将从知识库的所有文档中删除。

![delete_field](https://assets-docs.dify.ai/2025/03/022e42c170b40c35622b9b156c8cc159.png)

### 编辑文档元数据信息

#### 批量编辑文档元数据信息

你可以在知识库管理界面批量编辑文档的元数据信息。

**打开编辑元数据弹窗**

1. 打开知识库管理界面，在文档列表左侧的白色方框中勾选你希望批量操作的文档。勾选后，页面下方会弹出操作选项。

![edit_metadata_entrance](https://assets-docs.dify.ai/2025/03/18b0c435604db6173acba41662474446.png)

2. 点击操作选项中的 **元数据**，弹出 **编辑元数据** 弹窗。

![edit_metadata](https://assets-docs.dify.ai/2025/03/719f3c31498f23747fed7d7349fd64ba.png)

**批量新增元数据信息**

1.  在 **编辑元数据** 弹窗中点击底部的 **+添加元数据** 按钮，弹出操作弹窗。

![add_metadata](https://assets-docs.dify.ai/2025/03/d4e4f87447c3e445d5b7507df1126c7b.png)

-  如需为选中文档添加已创建的字段：

   -   可以从下拉列表中选择已有的字段，添加到字段列表中。

   -   可以在 **搜索元数据** 搜索框中搜索你需要的字段，添加到该文档的字段列表中。

![existing_field](https://assets-docs.dify.ai/2025/03/ea9aab2c4071bf2ec75409b05725ac1f.png)

-  如需为选中文档新建字段，可以点击弹窗左下角的 **+新建元数据** 按钮，并参考前文的 **新建元数据字段** 章节新建字段。

   > 在 **+新建元数据** 弹窗中新建的元数据字段，将自动同步至知识库字段列表中。

![new_metadata_field](https://assets-docs.dify.ai/2025/03/e32211f56421f61b788943ba40c6959e.png)

-  如需管理已创建的字段，可以点击该弹窗右下角的 **管理** 按钮，跳转到知识库的管理界面。

![manage_field](https://assets-docs.dify.ai/2025/03/82561edeb747b100c5295483c6238ffa.png)

2.  *（可选）* 新增字段后，在字段值框内填写该字段相应的字段值。

![value_for_field](https://assets-docs.dify.ai/2025/03/aabfe789f607a1db9062beb493213376.png)

-  如果值类型为 **时间**，在填写字段值时会弹出时间选择器，供你选择具体时间。

![date_picker](https://assets-docs.dify.ai/2025/03/65df828e605ebfb4947fccce189520a3.png)

3.  点击 **保存** 按钮，保存操作。

**批量删改元数据信息**

1.  在 **编辑元数据** 弹窗中删改元数据信息：

-   **添加字段值**： 在需要添加元数据值的字段框内直接输入所需值。

-   **重置字段值**： 将光标悬停在字段名左侧的蓝色圆点上，蓝点将变为 **重置** 按钮。点击蓝点，将字段框内修改后的内容重置为原始元数据值。

![reset_values](https://assets-docs.dify.ai/2025/03/01c0cde5a6eafa48e1c6e5438fc2fa6b.png)

-   **删除字段值**：

   -   删除一个字段值：在需要删除字段值的字段框内直接删除该字段值。

   -   删除多个字段值：点击 **多个值** 卡片的删除图标，清空所有选中文档的该元数据字段的值。

![multiple_values](https://assets-docs.dify.ai/2025/03/5c4323095644d2658881b783246914f1.png)

-   **删除单条元数据字段**： 点击字段最右侧的删除符号，删除该字段。删除后，该字段会被横线划掉且置灰。

   > 此操作仅会删除已选文档的该字段与字段值，字段本身依然保留在知识库中。

![delete_fields](https://assets-docs.dify.ai/2025/03/1b0318b898f951e307e3dc8cdc2f48d3.png)

2.  点击 **保存** 按钮，保存操作。

**调整批量操作的应用范围**

- **调整批量操作的应用范围**： 你可以使用 **编辑元数据** 弹窗左下角的 **应用于所有文档** 选框来调整编辑模式中改动的应用范围。

   -   **否（默认）**： 如果不选中该选项，编辑模式中的改动仅对原本已有该元数据字段的文档生效，其他文档不会受到影响。

   -   **是**： 如果选中该选项，编辑模式中的改动会对所有选中的文档生效。原本没有该字段的文档，会自动添加该字段。

![apply_all_changes](https://assets-docs.dify.ai/2025/03/4550c68960802c24271492b63a39ad05.png)

#### 编辑单篇文档元数据信息

你可以在文档详情界面中编辑单篇文档的元数据信息。

**进入文档元数据编辑模式**

1.  在文档详情界面，点击信息栏上方的 **开始标记** 按钮。

![details_page](https://assets-docs.dify.ai/2025/03/066cb8eaa89f6ec17aacd8b09f06771c.png)

2.  进入文档元数据编辑模式。

![start_labeling](https://assets-docs.dify.ai/2025/03/4806c56e324589e1711c407f6a1443de.png)

**新增文档元数据信息**

1.  在文档的元数据编辑模式中，点击 **+添加元数据** 按钮，弹出操作弹窗。

![add_metadata](https://assets-docs.dify.ai/2025/03/f9ba9b10bbcf6eaca787eed4fcde44da.png)

-  如需使用新建字段为该文档标记字段值，可以点击弹窗左下角的 **+ 新建元数据** 按钮，并参考前文的 **新建元数据字段** 章节新建字段。

   > 在文档页面新建的元数据字段，将自动同步至知识库字段列表中。

   ![new_fields](https://assets-docs.dify.ai/2025/03/739e7e51436259fca45d16065509fabb.png)

-  如需使用知识库已有的字段为该文档标记字段值，可以选择下列任意一种方式使用已有的字段：

   -   从下拉列表中选择知识库已有的字段，添加到该文档的字段列表中。

   -   在 **搜索元数据** 搜索框中搜索你需要的字段，添加到该文档的字段列表中。

   ![existing_fields](https://assets-docs.dify.ai/2025/03/5b1876e8bc2c880b3b774c97eba371ab.png)

-  如需管理知识库已有的字段，可以点击弹窗右下角的 **管理** 按钮，跳转到知识库的管理界面。

   ![manage_metadata](https://assets-docs.dify.ai/2025/03/8dc74a1d2cdd87294e58dbc3d6dd161b.png)

2.  *（可选）* 添加字段后，在字段名右侧的元数据栏中填写字段值。

![values_for_fields](https://assets-docs.dify.ai/2025/03/488107cbea73fd4583e043234fe2fd2e.png)

3.  点击右上角的 **保存** 按钮，保存字段值。

**删改文档元数据信息**

1.  在文档的元数据编辑模式中，点击右上角的 **编辑** 按钮，进入编辑模式。

![edit_mode](https://assets-docs.dify.ai/2025/03/bb33a0f9c6980300c0f979f8dc0d274d.png)

2.  删改文档元数据信息：
   -  **删改字段值**： 在字段名右侧的字段值框内，删除或修改字段值。

   > 此模式仅支持修改字段值，不支持修改字段名。

   -  **删除字段**： 点击字段值框右侧的删除按钮，删除字段。

   > 此操作仅会删除该文档的该字段与字段值，字段本身依然保留在知识库中。

![edit_metadata](https://assets-docs.dify.ai/2025/03/4c0c4d83d3ad240568f316abfccc9c2c.png)

3.  点击右上角的 **保存** 按钮，保存修改后的字段信息。

## 如何使用元数据功能在知识库中筛选文档？

请参阅 [在应用内集成知识库](./zh-hans/guides/knowledge-base/integrate-knowledge-within-application) 中的 **使用元数据筛选知识** 章节。

## API 信息

请参阅 [通过 API 维护知识库](./zh-hans/guides/knowledge-base/knowledge-and-documents-maintenance/maintain-dataset-via-api)。

## FAQ

- **元数据有什么作用？**

   - 提升搜索效率：用户可以根据元数据标签快速筛选和查找相关信息，节省时间并提高工作效率。

   - 增强数据安全性：通过元数据设置访问权限，确保只有授权用户能访问敏感信息，保障数据的安全性。

   - 优化数据管理能力：元数据帮助企业或组织有效分类和存储数据，提高数据的管理和检索能力，增强数据的可用性和一致性。

   - 支持自动化流程：元数据在文档管理、数据分析等场景中可以自动触发任务或操作，简化流程并提高整体效率。

- **知识库元数据管理列表中的元数据字段和某篇文档中的元数据值有什么区别？**

|  | 定义 | 性质 | 举例 |
| --- | --- | --- | --- |
| 元数据管理列表中的元数据字段 | 预定义的字段，用于描述文档的某些属性。 | 全局性字段。所有文档都可以使用这些字段。 | 作者、文档类型、上传日期。 |
| 某篇文档中的元数据值 | 每个文档按需标记的针对特定文档的信息。 | 文档特定的值。每个文档根据其内容会标记不同的元数据值。 | 文档 A 的"作者"字段值为"张三"，文档 B 的"作者"字段值为"李四"。 |

- **"在知识库管理界面删除某条元数据字段""在编辑元数据弹窗中删除已选文档的某条元数据字段"和"在文档详情界面删除某条元数据字段"有什么区别？**

| 操作方式 | 操作方法 | 影响范围 | 结果 |
| --- | --- | --- | --- |
| 在知识库管理界面删除某条元数据字段 | 在知识库管理界面，点击某条元数据字段右侧的删除图标，删除该字段。 | 从知识库管理列表中完全删除该元数据字段及其所有字段值。 | 该字段从知识库中移除，所有文档中的该字段及包含的所有字段值也会消失。 |
| 在编辑元数据弹窗中删除已选文档的某条元数据字段 | 在编辑元数据弹窗中，点击某条元数据字段右侧的删除图标，删除该字段。 | 仅删除已选文档的该字段与字段值，字段本身依然保留在知识库管理列表中。 | 选中文档中的字段与字段值被移除，但字段仍保留在知识库内，字段值计数会发生数值上的变化。 |
| 在文档详情界面删除某条元数据字段 | 在文档详情界面中的元数据编辑模式里，点击某条元数据字段右侧的删除图标，删除该字段。 | 仅删除该文档的该字段与字段值，字段本身依然保留在知识库管理列表中。 | 该文档中的字段与字段值被移除，但字段仍保留在知识库内，字段值计数会发生数值上的变化。 |

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/metadata.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 功能简介
> 来源：`zh-hans/guides/knowledge-base/readme.mdx`

知识库功能将 [RAG 管线](./zh-hans/learn-more/extended-reading/retrieval-augment/rerank)上的各环节可视化，提供了一套简单易用的用户界面来方便应用构建者管理个人或者团队的知识库，并能够快速集成至 AI 应用中。

开发者可以将企业内部文档、FAQ、规范信息等内容上传至知识库进行结构化处理，供后续 LLM 查询。

相比于 AI 大模型内置的静态预训练数据，知识库中的内容能够实时更新，确保 LLM 可以访问到最新的信息，避免因信息过时或遗漏而产生的问题。

LLM 接收到用户的问题后，将首先基于关键词在知识库内检索内容。知识库将根据关键词，召回相关度排名较高的内容区块，向 LLM 提供关键上下文以辅助其生成更加精准的回答。

开发者可以通过此方式确保 LLM 不仅仅依赖于训练数据中的知识，还能够处理来自实时文档和数据库的动态数据，从而提高回答的准确性和相关性。

**核心优势：**

• **实时性**：知识库中的数据可随时更新，确保模型获得最新的上下文。

• **精准性**：通过检索相关文档，LLM 能够基于实际内容生成高质量的回答，减少幻觉现象。

• **灵活性**：开发者可自定义知识库内容，根据实际需求调整知识的覆盖范围。

***

准备文本文件，例如：

* 长文本内容（TXT、Markdown、DOCX、HTML、JSON 甚至是 PDF）
* 结构化数据（CSV、Excel 等）
* 在线数据源（网页爬虫、Notion 等）

将文件上传至“知识库”即可自动完成数据处理。

> 如果你的团队内部已建有独立知识库，可以通过[连接外部知识库](./zh-hans/guides/knowledge-base/connect-external-knowledge-base)与 Dify 建立连接。

![](https://assets-docs.dify.ai/2025/04/4c2c02ef54a41d45aae3bead7cdd7319.png)

### 使用情景

例如你希望基于现有知识库和产品文档建立一个 AI 客服助手，可以在 Dify 中将文档上传至知识库，并建立一个对话型应用。如果使用传统方式，从文本训练到 AI 客服助手开发，可能需要花费数周的时间，且难以持续维护并进行有效迭代。在 Dify 内，仅需三分钟即可完成上述过程并开始获取用户反馈。

### 知识库与文档

在 Dify 中，知识库（Knowledge）是一系列文档（Documents）的集合，一个文档内可能包含多组内容分段（Chunks），知识库可以被整体集成至一个应用中作为检索上下文使用。文档可以由开发者或运营人员上传，或由其它数据源同步。

如果你已自建文档库，可以通过[连接外部知识库](./zh-hans/guides/knowledge-base/connect-external-knowledge-base)功能将自有知识库与 Dify 平台相关联。无需重复将内容上传至 Dify 平台内的知识库即可让 AI 应用实时读取自建知识库中的内容。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 召回测试/引用归属
> 来源：`zh-hans/guides/knowledge-base/retrieval-test-and-citation.mdx`

### 1 召回测试

Dify 知识库内提供了文本召回测试的功能，用于模拟用户输入关键词后调用知识库内容区块。召回的区块将按照分数高低进行排序并发送至 LLM。一般而言，问题与内容块的匹配度越高，LLM 所输出的答案也就更加贴近源文档，文本“训练效果”越好。

你可以使用不同的检索方式及参数配置，查看召回的内容区块质量与效果。不同的知识库分段模式对应不同的召回测试方法。

        在 **源文本** 输入框输入常见的用户问题，点击 **测试** 按钮即可在右侧的 **召回段落** 内查看召回结果。

        在通用模式下，内容区块相互独立；内容块右上角的分数为内容与关键词的匹配分数。得分越高，说明问题关键词与内容块的的匹配度越高。

        ![通用模式 - 召回内容块](https://assets-docs.dify.ai/2024/12/806967bb36e74fc744b34887cd3ebe52.png)

        轻点内容块即可查看所引用的内容详情。每个内容块底部将展示所引用的文档信息源，你可以借此判断该内容分段是否合理。

        ![查看召回内容详情](https://assets-docs.dify.ai/2024/12/419ac78ad21ea198b08f89c4f5fde485.png)

        在 **源文本** 输入框输入常见的用户问题，点击 **测试** 并在右侧的 **召回段落** 查看召回结果。在父子分段模式下，问题的关键词将命中子分段中的内容块，以取得更加精准的匹配效果。区块右上角的得分指的是子区块与关键词之间的匹配得分。

        你可以在预览区内查看具体的命中段落内容；匹配后将召回子分段所在父分段的完整上下文，向 AI 应用提供更加完整的信息。

        ![召回测试 - 父子分段模式](https://assets-docs.dify.ai/2024/12/6f0b99f97b138805bf4665d0c5c16f26.png)

        每个内容块底部将展示所引用的文档源，通常是文档中的某个段落或句子。轻点引用源右侧的“打开”按钮即可查看被引用的内容。

        分段详情页的左侧为父分段信息，右侧为被命中的子分段。关键词可能命中多个子分段，同时在开头显示与关键词的匹配分数。你可以基于详情信息判断当前的内容分段是否合理。

        ![查看召回内容详情](https://assets-docs.dify.ai/2024/12/22103227f8a25069d147160254f69512.png)

在 **记录** 内可以查看到历史的查询记录；若知识库已关联至应用内，由应用内发起的知识库查询记录也可以在此查看。

### 修改文本检索方式

点击源文本输入框右上角的图标即可更换当前知识库的检索方式与具体参数，保存之后仅在当前召回测试的调试过程中生效，你可以借此比较不同检索设置的效果。如果你想要修改当前知识库的检索方式，前往“知识库设置” > “检索设置”中进行设置。

![](https://assets-docs.dify.ai/2024/12/86b78cb114a843c9dedcba1fe12e3b02.png)

**召回测试建议步骤：**

1. 设计和整理能够覆盖用户常见问题的测试用例/测试问题集/指引内容；
2. 根据内容特点和使用场景（是否为问答内容、是否涉及多语言问答等），选择合适的检索策略。
3. 调整召回分段数量（TopK）和召回分数阈值（Score），根据实际的应用场景、包括文档本身的质量来选择合适的参数组合。

**TopK 值和召回阈值（Score ）如何配置**

* **TopK 代表按相似分数倒排时召回分段的最大个数**。TopK 值调小，将会召回更少分段，可能导致召回的相关文本不全；TopK 值调大，将召回更多分段，可能导致召回语义相关性较低的分段使得 LLM 回复质量降低。
* **召回阈值（Score）代表允许召回分段的最低相似分数。** 召回分数调小，将会召回更多分段，可能导致召回相关度较低的分段；召回分数阈值调大，将会召回更少分段，过大时将会导致丢失相关分段。

***

### 2 引用与归属

在应用内的“上下文”添加知识库后，可以在 **“添加功能”** 内开启 **“引用与归属”**。在应用内输入问题后，若涉及已关联的知识库文档，将标注内容的引用来源。你可以通过此方式检查知识库所召回的内容分段是否符合预期。

![](https://assets-docs.dify.ai/2025/03/a2e4db6635634e99a9aeb91341b53d1c.png)

开启功能后，当 LLM 引用知识库内容来回答问题时，可以在回复内容下面查看到具体的引用段落信息，包括**原始分段文本、分段序号、匹配度**等。点击引用分段上方的 **跳转至知识库**，可以快捷访问该分段所在的知识库分段列表，方便开发者进行调试编辑。

![](https://assets-docs.dify.ai/2025/03/1d82a0e1032f97e5832ed2ca7cb99fb2.png)

### 查看知识库内已关联的应用

知识库将会在左侧信息栏中显示已关联的应用数量。将鼠标悬停至圆形信息图标时将显示所有已关联的 Apps 列表，点击右侧的跳转按钮即可快速查看对应的应用。

![查看知识库内已关联的应用](https://assets-docs.dify.ai/2024/12/28899b9b0eba8996f364fb74e5b94c7f.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/knowledge-base/retrieval-test-and-citation.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 应用管理
> 来源：`zh-hans/guides/management/app-management.mdx`

## 编辑应用信息

创建应用后，如果你想要修改应用名称或描述，可以点击应用左上角的 「编辑信息」 ，重新修改应用的图标、名称或描述。

![编辑应用信息](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/management/ec718ad1050311b01a3f342ef1f45ae9.png)

## 复制应用

应用均支持复制操作，点击应用左上角的 「复制」。

## 导出应用

在 Dify 内创建的应用均支持以 DSL 格式进行导出，你可以自由地将配置文件导入至任意 Dify 团队。

通过以下两种方式导出 DSL 文件。

* 在 “工作室” 页点击应用菜单按钮中 “导出 DSL”；
* 进入应用的编排页后，点击左上角 “导出 DSL”。

![导出应用](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/management/544c18d770e230db93d6756bba98d8a7.png)

DSL 文件不包含自定义工具节点内已填写的授权信息，例如第三方服务的 API Key；如果环境变量中包含 `Secret`类型变量，导出文件时将提示是否允许导出该敏感信息。

![导出Secret选项](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/management/25ce002ef7f0392fc6b3b6975ae137ec.png)

> **提示：**

Dify DSL 格式文件是 Dify.AI 定义的 AI 应用工程文件标准，文件格式为 YML。该标准涵盖应用的基本描述、模型参数、编排配置等信息。

## 导入应用

将 DSL 文件上传至 Dify 平台内即可完成 Dify 应用的导入。导入 DSL 文件时会进行版本检查，如果导入较低版本的 DSL 文件将进行提示。

- 对于 SaaS 用户而言，在 SaaS 平台导出的 DSL 文件版本为最新版本。
- 对于社区版用户而言，建议参考[更新 Dify](./zh-hans/getting-started/install-self-hosted/docker-compose#更新-dify)更新社区版以导出更高版本的 DSL 文件，避免潜在的兼容性问题。

![导入应用](https://assets-docs.dify.ai/2024/11/487d2c1cc8b86666feb35ea8a346c053.png)

## 删除应用

如果你想要清理应用，可以点击应用左上角的 「删除」 。

> **提示：**

⚠️ 应用的删除操作无法撤销，所有用户将无法访问你的应用，应用内的所有 Prompt、编排配置和日志均会被删除。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/management/app-management.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 个人账号管理
> 来源：`zh-hans/guides/management/personal-account-management.mdx`

## 登录方式

Dify 不同版本支持的登录方式如下：

| 版本 | 登录方式 |
| :--- | :--- |
| 社区版 | 邮箱与密码 |
| 云服务 | GitHub 账户授权、Google 账户授权、邮箱与验证码 |

> 注意：Dify 的云服务版本账户，如果 GitHub 或 Google 账户的绑定邮箱与使用邮箱验证码登录的邮箱相同，系统会自动将它们关联为同一账户，无需手动绑定，避免重复注册。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/management/36e3f4fb5fc15ae6949e2b2693ecc9e7.png)

## 修改账号信息

如需修改个人账号的相关信息，请点击 Dify 团队首页右上角头像，轻点 **“账户”** 修改以下信息：

* 头像
* 用户名
* 邮箱
* 密码

> 注意：重置密码功能仅在社区版提供

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/management/700817f2c2e3ba0bfce873bb5c5316c9.png)

### 登录方式

支持通过邮箱+验证码、Google 授权和 Github 授权三种方式登录 Dify 平台。同一个 Dify 账户，可通过邮箱+验证码登录，或使用绑定相同邮箱的 Google/Github 账户授权登录，无需额外绑定操作。

### 切换界面语言

请点击 Dify 团队首页右上角头像，轻点 **“语言”** 修改显示语言。Dify 支持切换以下语言：

* English
* 简体中文
* 繁体中文
* Português(Brasil)
* Français(France)
* 日本語(日本)
* 한국어(대한민국)
* Русский(Россия)
* Italiano(Italia)
* ไทย(ประเทศไทย)
* Bahasa Indonesia
* Українська(Україна)

Dify 欢迎更多社区志愿者一同参与贡献更多语言版本，前往[ GitHub 代码仓库](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md)进行贡献！

### 查看账号关联的应用数据

你可以在账户页中查看当前账号所关联的应用数据。

### 删除个人账号

⚠️ 危险操作，请谨慎处理。

如需确认删除 Dify SaaS 服务账号，请点击右上角的头像，轻点下拉框中的“账号”，点击“删除账号”按钮。删除账号操作不可逆，相同的邮箱地址在 30 天内无法重新注册。当前账号所拥有的工作空间也会一并删除，并被自动移除出所有已加入的工作空间。

输入需要删除的邮箱，输入确认验证码后，系统将彻底删除账号的所有信息。

![删除个人账户](https://assets-docs.dify.ai/2024/12/ded326f27886b5884969c220ead998d7.png)

#### 常见问题

**1. 如果不小心删除了账户，可以撤销账户删除操作吗？**

删除账户后不可撤销。如有特殊情况，请在账户删除后 20 天内联系 `support@dify.ai` 并说明原因。

**2. 删除账户后，我在团队中的角色和数据会如何处理？**

删除账户后：
  1. 你以**团队所有者**角色所创建的工作空间（Workspace）将被解散并删除空间内所有数据，所有团队成员将失去访问权限。
  2. 你以**团队成员或管理员**角色所加入的工作空间（Workspace）将继续保留空间内的数据，包括由当前账号所创建的各个应用数据。你的账户将被移出工作空间的成员列表。

**3. 删除账户后，我可以重新使用相同的邮箱注册新账户吗？**

删除账户后，30 天内无法使用相同的邮箱重新注册新账户。

**4. 删除账户后，与第三方服务的授权（如 Google、GitHub）会被取消吗？**

是的，删除账户后，所有与第三方服务（如 Google、GitHub）的授权将自动取消。

**5. 删除账户后，我的 Dify 账户订阅服务会自动取消并退款吗？**

删除账户后，你的 Dify 账户订阅服务将自动取消且不可退款，未来将不会继续收取订阅费用。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/management/personal-account-management.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 订阅管理
> 来源：`zh-hans/guides/management/subscription-management.mdx`

### 升级 Dify 团队订阅

团队所有者和管理员具备升级团队订阅计划的权限。点击 Dify 团队首页右上角的 **“升级”** 按钮，选择合适的套餐，支付后即可升级团队。

### 管理 Dify 团队订阅

订阅 Dify 付费服务后（Professional 和 Team），团队所有者和管理员可以前往 **“设置”** → **“账单”**，管理团队的账单及订阅计划。

你可以在账单页查看团队内各项资源的使用情况。

![团队账单管理](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/management/8a0becb402c9abdb697f8ab6ff67c839.png)

### 常见问题

#### 1. 如何升级/降级团队，以及如何取消订阅？

团队所有者和管理员可以前往 **“设置”** → **“账单”**，轻点“管理账单及订阅”更改订阅方案。

* 从 Professional 升级至 Team 需补足当月差额，立即生效。
* 从 Team 降级至 Professional 立即生效。

![更改付费方案](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/management/5f330cc59a9c6646531876ba92b856f8.png)

如果取消订阅方案，**团队将在当月账单周期结束后**自动切换至 Sandbox/Free 版本。已超出的团队人数及团队资源将无法访问。

#### 2. 升级订阅计划后，团队的可用资源会有什么变化？

<table>
  <thead>
    <tr>
      <th></th>
      <th>Free</th>
      <th>Professional</th>
      <th>Team</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>成员数量</td>
      <td>1</td>
      <td>3</td>
      <td>50</td>
    </tr>
    <tr>
      <td>团队内的应用程序数限额</td>
      <td>5</td>
      <td>50</td>
      <td>200</td>
    </tr>
    <tr>
      <td>应用程序的<a href="/zh-hans/guides/annotation/logs">标记</a>回复数</td>
      <td>10</td>
      <td>2,000</td>
      <td>5,000</td>
    </tr>
    <tr>
      <td>知识库的文档上传数量</td>
      <td>50</td>
      <td>500</td>
      <td>1,000</td>
    </tr>
    <tr>
      <td>知识库的数据储存量</td>
      <td>50MB</td>
      <td>5GB</td>
      <td>20GB</td>
    </tr>
    <tr>
      <td>OpenAI 的对话额度</td>
      <td>总共 200</td>
      <td>每月 5,000</td>
      <td>每月 10,000</td>
    </tr>
  </tbody>
</table>

升级订阅计划后，OpenAI 的对话额度将被重置；已使用的计算资源则不会重置。

#### 3. 忘记及时续费怎么办？

如果忘记续费，团队将自动降级为 Sandbox/Free 版本。除了团队所有者以外，其他人无法继续访问团队。团队内超出的计算资源（例如文档、向量空间等）也会被锁定。

#### 4. 团队所有者账号删除后会影响团队吗？

一个团队需绑定一位团队所有者。如果团队所有者未及时转移至其他团队成员，当前团队的所有数据将一同被删除。

#### 5. 各个订阅版本间有什么区别？

详细的功能对比请参考 [Dify 定价页](https://dify.ai/pricing)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/management/subscription-management.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 团队成员管理
> 来源：`zh-hans/guides/management/team-members-management.mdx`

本文将介绍如何在 Dify 团队内管理成员。以下是各个 Dify 版本的团队成员上限。

| Sandbox / Free | Professional | Team | 社区版 | 企业版 |
| -------------- | ------------ | ---- | --- | --- |
| 1              | 3            | 50 | 不限制 | 不限制 |

### 添加成员

> **提示：**

仅团队所有者具备邀请团队成员的权限。

团队所有者点击右上角头像，然后轻点 **“成员”** → **“添加”**，输入邮箱，分配成员权限完成添加。

![为团队成员分配权限](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/management/764276a102e3264747c64f02dafa5f5d.png)

> 社区版团队需在[环境变量](https://docs.dify.ai/v/zh-hans/getting-started/install-self-hosted/environments)中添加并启用邮件服务，被邀成员才能收到邀请邮件。

- 若被邀请的成员未注册 Dify，将收到一封邀请邮件，点击邮件中的链接即可完成注册。
- 若被邀请成员已注册 Dify，系统将自动分配权限，**同时不再发送邀请邮件**。被邀成员可以在右上角头像处切换至新的 Workspace。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/management/93a6f055cfaf65dfe138e8ac332f71d1.png)

### 成员权限

团队成员分为所有者、管理员、编辑、成员。

* **所有者**
  * 角色描述：团队中的首位成员，拥有最高权限，负责整个团队的运营和管理工作。
  * 权限概览：拥有管理团队成员、调整成员权限、设置模型供应商、创建和删除应用、创建知识库、设置工具库等权限。
* **管理员**
  * 角色描述：团队中的管理员，负责管理团队成员和模型供应商。
  * 权限概览：无法调整成员权限；具备添加或移除团队成员、设置模型供应商、创建、编辑和删除应用、创建知识库、设置工具库等权限。
* **编辑**
  * 角色描述：团队中的普通成员，负责协作创建和编辑应用。
  * 权限概览：无法管理团队成员、无法设置模型供应商、无法设置工具库；具备创建、编辑和删除应用、创建知识库的权限。
* **成员**
  * 角色描述：团队中的普通成员，仅允许查看和使用团队内已创建的应用。
  * 权限概览：仅具备使用团队内应用、使用工具的权限。

### 移除成员

> **提示：**

仅团队所有者具备移除团队成员的权限。

点击 Dify 团队首页右上角头像，前往 **“设置”** → **“成员”** ，选择需要被移除的成员的角色，轻点 **“移除团队”**。

![移除成员](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/management/85c39a391714c110ec9e1769a8c52e06.png)

### 常见问题

#### 1. 如何转移团队所有者？

团队所有者具备最高权限，为了保持团队结构的稳定性，团队所有者一经创立无法手动转移。

#### 2. 如何删除团队？

出于团队数据安全考虑，团队所有者无法自助删除名下的团队。

#### 3. 如何删除团队成员账号？

团队所有者 / 管理员均无法删除团队成员的账号，删除账号需要账号所有人主动申请，无法被其他人删除。相较于删除账号，将成员移出团队同样可以关闭该用户对团队的访问权限。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/management/team-members-management.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 版本管理
> 来源：`zh-hans/guides/management/version-control.mdx`

## 简介

版本管理是 **Dify 聊天流/工作流管理界面** 中的一项核心功能，用于帮助用户高效地管理和发布应用的多个版本。

通过版本管理功能，用户可以清晰地区分应用的**草稿版本**和**已发布版本**，并在需要时回滚到**历史版本**。该功能可以让应用的迭代和管理更为简便和直观，确保应用的持续更新与稳定性。

## 相关定义

- **草稿版本（Current Draft）**： 草稿版本是 Dify 聊天流/工作流管理界面中**唯一呈现当前工作进度的版本**。用户可在此版本中编辑、修改与预览聊天流/工作流。

![current_draft](https://assets-docs.dify.ai/2025/03/38296a597c0ca31b5fb70be2234f2363.png)

- **已发布版本（Published Version）**： 用户发布到线上的所有版本，即最新发布版本和历史发布版本的统称。每一次发布操作都会生成一个新的已发布版本。

- **最新发布版本（Latest Version）**： 用户最近一次发布到线上的版本。Dify 在版本管理界面中将其标记为 `Latest` ，以便与其他历史发布版本区分。

![latest_version](https://assets-docs.dify.ai/2025/03/e4c06a0817c30cf9e8893487c889cb02.png)

- **历史发布版本（Previous Version）**： 用户曾经发布过，但现在已经不再处于当前线上状态的版本。

![prevous_version](https://assets-docs.dify.ai/2025/03/4cd05033b93d84b53496f3d02e88601f.png)

- **版本回滚（Restore）**： 版本管理中的版本回滚功能允许用户将应用恢复到某个历史版本。

![restore](https://assets-docs.dify.ai/2025/03/607a69b5355886b9ae8d23a08e818e35.jpg)

## 功能

- **查看所有版本**：在版本管理界面中，你可以查看所有已发布的版本，了解每个版本的详细信息。

- **查找所需版本**： 你可以使用筛选功能快速查找所需的特定版本。

- **发布新版本**： 你可以发布一个新的应用版本，并为该版本创建相应的版本名和版本描述。

- **编辑已发布版本的信息**： 你可以编辑已发布版本的版本名和版本描述。

- **删除历史版本**： 你可以删除不再需要的历史版本，清理版本列表。

- **回滚到历史版本**： 通过版本回滚功能，你可以将历史版本的内容加载到草稿中并进行修改。

## 如何查看所有版本？

1. 点击右上角的 **版本管理功能** 按钮，进入版本管理界面。

![view_all_versions](https://assets-docs.dify.ai/2025/03/eed667bbc9498425342c09039054cf98.png)

2. 版本管理界面显示了一个按时间倒序排列的版本列表。你可以在列表内查看过往版本的 **版本名、版本信息、发布时间、发布者**。

3. *（可选）* 如果版本列表超过当前可见的数量，你可以点击 **加载更多** 按钮，加载更多的版本记录。

![load_more](https://assets-docs.dify.ai/2025/03/df9aeb06128f11089dc2294f0338e2ca.png)

## 如何查找我需要的版本？

- **查找由我发布的版本**： 点击 **筛选** 按钮，弹出筛选框。该筛选框有两个选项：

  - **所有版本**： 显示所有版本，包括你自己和其他用户发布的版本。
  - **由我发布的版本**： 仅显示由你发布的版本。

  你可以根据需要选择合适的筛选项，以查看对应的版本。

![all_or_only_yours](https://assets-docs.dify.ai/2025/03/0bf8fef8858671a8fef160f49dd83dad.jpg)

- **查找已命名的版本**： 如果你只想查看已命名的版本，可以点击 **查找已命名的版本** 选项。启用该选项后，只有已命名版本会出现在版本列表中，其他未命名的版本将被隐藏。

![only_show_named_versions](https://assets-docs.dify.ai/2025/03/2473121caa2e25ad1a76ee42a4127fb4.jpg)

## 如何发布新版本？

1. 在 Dify 聊天流/工作流管理界面中完成聊天流/工作流创建后，点击面板的右上角的 **发布 > 发布更新** 按钮，即可直接发布当前版本。

![publish_new_version](https://assets-docs.dify.ai/2025/03/26f3f324ab4ecb965708d553ddd78d97.png)

2. 发布后，此最新发布版本将被标记为 `Latest` 。相关信息会显示在版本管理界面中。

![latest_version_marked](https://assets-docs.dify.ai/2025/03/67e95de17577bc272addad6c33f8ea59.png)

## 如何编辑已发布版本的信息？

1. 在版本管理界面，找到你需要编辑版本信息的版本，并点击该版本右上角的操作菜单。

- 如果你之前以默认名称保存了该版本，可以点击 **命名此版本**，更新版本名与版本信息。

![edit_version_info_1](https://assets-docs.dify.ai/2025/03/1d840edf979132a9bbf1e065f95e663c.jpg)

- 如果你已经为该版本填写过版本名，可以点击 **编辑版本信息** 修改版本名与版本信息。

![edit_version_info_1](https://assets-docs.dify.ai/2025/03/1d840edf979132a9bbf1e065f95e663c.jpg)

2. 点击 **发布**，发布版本信息。

![edit_version_info_2](https://assets-docs.dify.ai/2025/03/838e5a12aa277bada6c2a4a214450fa5.jpg)

## 如何删除历史版本？

1. 在版本管理界面，找到你需要删除的已发布版本，点击该版本右上角的操作菜单。

2. 选择 **删除**，弹出确认操作的弹窗。

![delete_version](https://assets-docs.dify.ai/2025/03/25ad1999fc9f6f44fcac04526ac5563a.jpg)

3. 点击 **删除**，该版本将从版本管理界面中删除。

![delete_version_confirm](https://assets-docs.dify.ai/2025/03/9326fd0463d024aac1907c83a37fe13b.jpg)

> **信息提示：**

- **草稿版本**（即 Current Draft）为当前聊天流 / 工作流界面正在编辑的草稿版本，无法删除。
- **最新发布版本**（即标记为 Latest 的版本）为用户最近一次发布到线上的版本，无法删除。

## 如何回滚到某个已发布版本？

1. 在版本管理界面，找到你需要回滚的历史版本，点击该版本右上角的操作菜单。

2. 选择 **回滚**，弹出确认操作的弹窗。

![restore_version](https://assets-docs.dify.ai/2025/03/c96b714accc29df8e46e711782a7a6a9.jpg)

3. 点击 **回滚**，当前的草稿版本将回滚为该历史版本。

![restore_version_confirm](https://assets-docs.dify.ai/2025/03/f3a6e13f2e910f5c7917f52fe77bdfca.jpg)

## 使用场景

以下用一个典型的用户使用场景来说明各版本之间的联系。

> 相同颜色代表相同的版本内容。

### 阶段一

- 系统自动新建 **草稿版本** Version A。

![phase 1](https://assets-docs.dify.ai/2025/03/35ece9d5d5d4d8c46a3fb5ceae4d0c15.jpeg)

### 阶段二：首次发布

- Version A 发布，成为 **最新发布版本**。
- 系统自动新建 **草稿版本** Version B。

![phase 2](https://assets-docs.dify.ai/2025/03/3d1f66cdeb08710f01462a6b0f3ed0a8.jpeg)

### 阶段三：再次发布

- Version B 发布，成为 **最新发布版本**。
- Version A 成为 **历史发布版本**。
- 系统自动新建 **草稿版本** Version C。

![phase 3](https://assets-docs.dify.ai/2025/03/92ffbf88a3cbeeeeab47c1bd8b4f7198.jpeg)

### 阶段四：回滚操作

- Version A 回滚至 **草稿版本**，覆盖 Version C。
- Version B 仍为 **最新发布版本**。

![phase 4](https://assets-docs.dify.ai/2025/03/541f1891416af90dab5b51bfec833249.jpeg)

### 阶段五：发布回滚

- Version A（回滚版）发布，成为 **最新发布版本**。
- Version A 与 Version B 成为 **历史发布版本**。
- 系统自动新建 **草稿版本** Version D。

![phase 5](https://assets-docs.dify.ai/2025/03/3572a4f2edef166c3f14e4ec4e68b297.jpeg)

### 全流程演示

![workflow](https://assets-docs.dify.ai/2025/03/dc7c15a4dfafb72ce7fffea294d5b5e5.gif)

## FAQ

- **草稿版本、已发布版本、最新发布版本和历史发布版本有什么区别？**

| 定义 | 操作方式 | 是否可以从线上访问 | 是否可以删除 | 是否可以回滚 |
|-----|---------|------------------|------------|------------|
| 草稿版本 | 当前正在编辑和修改的版本，代表用户的最新工作进度。 | 只能通过 发布 (Publish) 操作推送至线上环境。 | 不可以从线上访问，必须通过发布操作将其推送为最新发布版本才可以从线上访问。 | 无法删除。 |
| 最新发布版本 | 目前线上生效的版本，是最新的已发布版本。 | 是当前线上的版本，不能直接编辑，需通过发布新的草稿版本来更新。 | 可以从线上访问和使用。 | 可以通过回滚操作恢复到该版本内容。 |
| 历史发布版本 | 过去已发布并保存的版本，用户可回滚使用，但不再对外生效。 | 可以通过 回滚 (Restore) 操作将历史版本加载到草稿版本中，再进行编辑和发布。 | 不可以从线上访问，仅保存在版本列表里。 | 可以通过回滚操作恢复到该版本内容。 |
| 已发布版本 | 最新发布版本和历史发布版本的统称。 | / | / | / |

- **回滚到历史版本后，当前的草稿版本会丢失吗？**

当你选择回滚到历史版本后，系统会将你选择的历史版本的内容加载到新的草稿版本中。你可以继续在该草稿上进行修改并发布。

因此，回滚到历史版本后，当前的草稿版本将会丢失。请谨慎操作。

- **版本管理功能适用于哪些应用类型？**

目前，版本管理功能仅适用于 **聊天流** 和 **工作流** 应用类型。**聊天助手**、**文本生成应用** 以及 **Agent** 暂不支持此功能。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/management/version-control.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 自定义模型接入
> 来源：`zh-hans/guides/model-configuration/customizable-model.mdx`

> **警告：**

    “模型”已全面升级为“插件”生态，模型插件的详细开发说明请参考[插件开发](./zh-hans/plugins/quick-start/develop-plugins/model-plugin/README)。以下内容已归档。

### 介绍

供应商集成完成后，接下来为供应商下模型的接入，为了帮助理解整个接入过程，我们以`Xinference`为例，逐步完成一个完整的供应商接入。

需要注意的是，对于自定义模型，每一个模型的接入都需要填写一个完整的供应商凭据。

而不同于预定义模型，自定义供应商接入时永远会拥有如下两个参数，不需要在供应商 yaml 中定义。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/model-configuration/019f6cf5cf1e2a3bda953fea5fa1d158.png)

在前文中，我们已经知道了供应商无需实现`validate_provider_credential`，Runtime会自行根据用户在此选择的模型类型和模型名称调用对应的模型层的`validate_credentials`来进行验证。

#### 编写供应商 yaml

我们首先要确定，接入的这个供应商支持哪些类型的模型。

当前支持模型类型如下：

* `llm` 文本生成模型
* `text_embedding` 文本 Embedding 模型
* `rerank` Rerank 模型
* `speech2text` 语音转文字
* `tts` 文字转语音
* `moderation` 审查

`Xinference`支持`LLM`、`Text Embedding`和`Rerank`，那么我们开始编写`xinference.yaml`。

```yaml
provider: xinference #确定供应商标识
label: # 供应商展示名称，可设置 en_US 英文、zh_Hans 中文两种语言，zh_Hans 不设置将默认使用 en_US。
  en_US: Xorbits Inference
icon_small: # 小图标，可以参考其他供应商的图标，存储在对应供应商实现目录下的 _assets 目录，中英文策略同 label
  en_US: icon_s_en.svg
icon_large: # 大图标
  en_US: icon_l_en.svg
help: # 帮助
  title:
    en_US: How to deploy Xinference
    zh_Hans: 如何部署 Xinference
  url:
    en_US: https://github.com/xorbitsai/inference
supported_model_types: # 支持的模型类型，Xinference同时支持LLM/Text Embedding/Rerank
- llm
- text-embedding
- rerank
configurate_methods: # 因为Xinference为本地部署的供应商，并且没有预定义模型，需要用什么模型需要根据Xinference的文档自己部署，所以这里只支持自定义模型
- customizable-model
provider_credential_schema:
  credential_form_schemas:
```

随后，我们需要思考在 Xinference 中定义一个模型需要哪些凭据

* 它支持三种不同的模型，因此，我们需要有`model_type`来指定这个模型的类型，它有三种类型，所以我们这么编写

```yaml
provider_credential_schema:
  credential_form_schemas:
  - variable: model_type
    type: select
    label:
      en_US: Model type
      zh_Hans: 模型类型
    required: true
    options:
    - value: text-generation
      label:
        en_US: Language Model
        zh_Hans: 语言模型
    - value: embeddings
      label:
        en_US: Text Embedding
    - value: reranking
      label:
        en_US: Rerank
```

* 每一个模型都有自己的名称`model_name`，因此需要在这里定义

```yaml
  - variable: model_name
    type: text-input
    label:
      en_US: Model name
      zh_Hans: 模型名称
    required: true
    placeholder:
      zh_Hans: 填写模型名称
      en_US: Input model name
```

* 填写 Xinference 本地部署的地址

```yaml
  - variable: server_url
    label:
      zh_Hans: 服务器URL
      en_US: Server url
    type: text-input
    required: true
    placeholder:
      zh_Hans: 在此输入Xinference的服务器地址，如 https://example.com/xxx
      en_US: Enter the url of your Xinference, for example https://example.com/xxx
```

* 每个模型都有唯一的 model\_uid，因此需要在这里定义

```yaml
  - variable: model_uid
    label:
      zh_Hans: 模型 UID
      en_US: Model uid
    type: text-input
    required: true
    placeholder:
      zh_Hans: 在此输入你的 Model UID
      en_US: Enter the model uid
```

现在，我们就完成了供应商的基础定义。

#### 编写模型代码

然后我们以`llm`类型为例，编写`xinference.llm.llm.py`

在 `llm.py` 中创建一个 Xinference LLM 类，我们取名为 `XinferenceAILargeLanguageModel`（随意），继承 `__base.large_language_model.LargeLanguageModel` 基类，实现以下几个方法：

*   LLM 调用

    实现 LLM 调用的核心方法，可同时支持流式和同步返回。

    ```python
    def _invoke(self, model: str, credentials: dict,
                prompt_messages: list[PromptMessage], model_parameters: dict,
                tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,
                stream: bool = True, user: Optional[str] = None) \
            -> Union[LLMResult, Generator]:
        """
        Invoke large language model

        :param model: model name
        :param credentials: model credentials
        :param prompt_messages: prompt messages
        :param model_parameters: model parameters
        :param tools: tools for tool calling
        :param stop: stop words
        :param stream: is stream response
        :param user: unique user id
        :return: full response or stream response chunk generator result
        """
    ```

    在实现时，需要注意使用两个函数来返回数据，分别用于处理同步返回和流式返回，因为Python会将函数中包含 `yield` 关键字的函数识别为生成器函数，返回的数据类型固定为 `Generator`，因此同步和流式返回需要分别实现，就像下面这样（注意下面例子使用了简化参数，实际实现时需要按照上面的参数列表进行实现）：

    ```python
    def _invoke(self, stream: bool, **kwargs) \
            -> Union[LLMResult, Generator]:
        if stream:
              return self._handle_stream_response(**kwargs)
        return self._handle_sync_response(**kwargs)

    def _handle_stream_response(self, **kwargs) -> Generator:
        for chunk in response:
              yield chunk
    def _handle_sync_response(self, **kwargs) -> LLMResult:
        return LLMResult(**response)
    ```
*   预计算输入 tokens

    若模型未提供预计算 tokens 接口，可直接返回 0。

    ```python
    def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                     tools: Optional[list[PromptMessageTool]] = None) -> int:
      """
      Get number of tokens for given prompt messages

      :param model: model name
      :param credentials: model credentials
      :param prompt_messages: prompt messages
      :param tools: tools for tool calling
      :return:
      """
    ```

    有时候，也许你不需要直接返回0，所以你可以使用`self._get_num_tokens_by_gpt2(text: str)`来获取预计算的tokens，这个方法位于`AIModel`基类中，它会使用GPT2的Tokenizer进行计算，但是只能作为替代方法，并不完全准确。
*   模型凭据校验

    与供应商凭据校验类似，这里针对单个模型进行校验。

    ```python
    def validate_credentials(self, model: str, credentials: dict) -> None:
        """
        Validate model credentials

        :param model: model name
        :param credentials: model credentials
        :return:
        """
    ```
*   模型参数 Schema

    与自定义类型不同，由于没有在 yaml 文件中定义一个模型支持哪些参数，因此，我们需要动态实现模型参数的Schema。

    如Xinference支持`max_tokens` `temperature` `top_p` 这三个模型参数。

    但是有的供应商根据不同的模型支持不同的参数，如供应商`OpenLLM`支持`top_k`，但是并不是这个供应商提供的所有模型都支持`top_k`，我们这里举例 A 模型支持`top_k`，B模型不支持`top_k`，那么我们需要在这里动态生成模型参数的 Schema，如下所示：

    ```python
    def get_customizable_model_schema(self, model: str, credentials: dict) -> AIModelEntity | None:
        """
            used to define customizable model schema
        """
        rules = [
            ParameterRule(
                name='temperature', type=ParameterType.FLOAT,
                use_template='temperature',
                label=I18nObject(
                    zh_Hans='温度', en_US='Temperature'
                )
            ),
            ParameterRule(
                name='top_p', type=ParameterType.FLOAT,
                use_template='top_p',
                label=I18nObject(
                    zh_Hans='Top P', en_US='Top P'
                )
            ),
            ParameterRule(
                name='max_tokens', type=ParameterType.INT,
                use_template='max_tokens',
                min=1,
                default=512,
                label=I18nObject(
                    zh_Hans='最大生成长度', en_US='Max Tokens'
                )
            )
        ]

        # if model is A, add top_k to rules
        if model == 'A':
            rules.append(
                ParameterRule(
                    name='top_k', type=ParameterType.INT,
                    use_template='top_k',
                    min=1,
                    default=50,
                    label=I18nObject(
                        zh_Hans='Top K', en_US='Top K'
                    )
                )
            )

        """
            some NOT IMPORTANT code here
        """

        entity = AIModelEntity(
            model=model,
            label=I18nObject(
                en_US=model
            ),
            fetch_from=FetchFrom.CUSTOMIZABLE_MODEL,
            model_type=model_type,
            model_properties= 
                ModelPropertyKey.MODE:  ModelType.LLM,
            ,
            parameter_rules=rules
        )

        return entity
    ```
*   调用异常错误映射表

    当模型调用异常时需要映射到 Runtime 指定的 `InvokeError` 类型，方便 Dify 针对不同错误做不同后续处理。

    Runtime Errors:

    * `InvokeConnectionError` 调用连接错误
    * `InvokeServerUnavailableError` 调用服务方不可用
    * `InvokeRateLimitError` 调用达到限额
    * `InvokeAuthorizationError` 调用鉴权失败
    * `InvokeBadRequestError` 调用传参有误

    ```python
    @property
    def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
        """
        Map model invoke error to unified error
        The key is the error type thrown to the caller
        The value is the error type thrown by the model,
        which needs to be converted into a unified error type for the caller.

        :return: Invoke error mapping
        """
    ```

接口方法说明见：[Interfaces](https://github.com/langgenius/dify/blob/main/api/core/model_runtime/docs/zh_Hans/interfaces.md)，具体实现可参考：[llm.py](https://github.com/langgenius/dify-official-plugins/blob/main/models/anthropic/models/llm/llm.py)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/model-configuration/customizable-model.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接口方法
> 来源：`zh-hans/guides/model-configuration/interfaces.mdx`

> **警告：**

    “模型”已全面升级为“插件”生态，模型插件的详细开发说明请参考[插件开发](./zh-hans/plugins/quick-start/develop-plugins/model-plugin/README)。以下内容已归档。

这里介绍供应商和各模型类型需要实现的接口方法和参数说明。

## 供应商

继承 `__base.model_provider.ModelProvider` 基类，实现以下接口：

```python
def validate_provider_credentials(self, credentials: dict) -> None:
    """
    Validate provider credentials
    You can choose any validate_credentials method of model type or implement validate method by yourself,
    such as: get model list api

    if validate failed, raise exception

    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
    """
```

- `credentials` (object) 凭据信息

  凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 定义，传入如：`api_key` 等。

验证失败请抛出 `errors.validate.CredentialsValidateFailedError` 错误。

**注：预定义模型需完整实现该接口，自定义模型供应商只需要如下简单实现即可**

```python
class XinferenceProvider(Provider):
    def validate_provider_credentials(self, credentials: dict) -> None:
        pass
```

## 模型

模型分为 5 种不同的模型类型，不同模型类型继承的基类不同，需要实现的方法也不同。

### 通用接口

所有模型均需要统一实现下面 2 个方法：

- 模型凭据校验

  与供应商凭据校验类似，这里针对单个模型进行校验。

  ```python
  def validate_credentials(self, model: str, credentials: dict) -> None:
      """
      Validate model credentials

      :param model: model name
      :param credentials: model credentials
      :return:
      """
  ```

  参数：

  - `model` (string) 模型名称

  - `credentials` (object) 凭据信息

    凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

  验证失败请抛出 `errors.validate.CredentialsValidateFailedError` 错误。

- 调用异常错误映射表

  当模型调用异常时需要映射到 Runtime 指定的 `InvokeError` 类型，方便 Dify 针对不同错误做不同后续处理。

  Runtime Errors:

  - `InvokeConnectionError` 调用连接错误
  - `InvokeServerUnavailableError ` 调用服务方不可用
  - `InvokeRateLimitError ` 调用达到限额
  - `InvokeAuthorizationError`  调用鉴权失败
  - `InvokeBadRequestError ` 调用传参有误

  ```python
  @property
  def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
      """
      Map model invoke error to unified error
      The key is the error type thrown to the caller
      The value is the error type thrown by the model,
      which needs to be converted into a unified error type for the caller.

      :return: Invoke error mapping
      """
  ```

  也可以直接抛出对应 Errors，并做如下定义，这样在之后的调用中可以直接抛出`InvokeConnectionError`等异常。

    ```python
    @property
    def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
        return 
            InvokeConnectionError: [
              InvokeConnectionError
            ],
            InvokeServerUnavailableError: [
              InvokeServerUnavailableError
            ],
            InvokeRateLimitError: [
              InvokeRateLimitError
            ],
            InvokeAuthorizationError: [
              InvokeAuthorizationError
            ],
            InvokeBadRequestError: [
              InvokeBadRequestError
            ],

    ```

​	可参考 OpenAI `_invoke_error_mapping`。  

### LLM

继承 `__base.large_language_model.LargeLanguageModel` 基类，实现以下接口：

- LLM 调用

  实现 LLM 调用的核心方法，可同时支持流式和同步返回。

  ```python
  def _invoke(self, model: str, credentials: dict,
              prompt_messages: list[PromptMessage], model_parameters: dict,
              tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,
              stream: bool = True, user: Optional[str] = None) \
          -> Union[LLMResult, Generator]:
      """
      Invoke large language model

      :param model: model name
      :param credentials: model credentials
      :param prompt_messages: prompt messages
      :param model_parameters: model parameters
      :param tools: tools for tool calling
      :param stop: stop words
      :param stream: is stream response
      :param user: unique user id
      :return: full response or stream response chunk generator result
      """
  ```

  - 参数：

    - `model` (string) 模型名称

    - `credentials` (object) 凭据信息

      凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

    - `prompt_messages` (array[[PromptMessage](#PromptMessage)]) Prompt 列表

      若模型为 `Completion` 类型，则列表只需要传入一个 [UserPromptMessage](#UserPromptMessage) 元素即可；

      若模型为 `Chat` 类型，需要根据消息不同传入 [SystemPromptMessage](#SystemPromptMessage), [UserPromptMessage](#UserPromptMessage), [AssistantPromptMessage](#AssistantPromptMessage), [ToolPromptMessage](#ToolPromptMessage) 元素列表

    - `model_parameters` (object) 模型参数

      模型参数由模型 YAML 配置的 `parameter_rules` 定义。

    - `tools` (array[[PromptMessageTool](#PromptMessageTool)]) [optional] 工具列表，等同于 `function calling` 中的 `function`。

      即传入 tool calling 的工具列表。

    - `stop` (array[string]) [optional] 停止序列

      模型返回将在停止序列定义的字符串之前停止输出。

    - `stream` (bool) 是否流式输出，默认 True

      流式输出返回 Generator[[LLMResultChunk](#LLMResultChunk)]，非流式输出返回 [LLMResult](#LLMResult)。

    - `user` (string) [optional] 用户的唯一标识符

      可以帮助供应商监控和检测滥用行为。

  - 返回

    流式输出返回 Generator[[LLMResultChunk](#LLMResultChunk)]，非流式输出返回 [LLMResult](#LLMResult)。

- 预计算输入 tokens

  若模型未提供预计算 tokens 接口，可直接返回 0。

  ```python
  def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                     tools: Optional[list[PromptMessageTool]] = None) -> int:
      """
      Get number of tokens for given prompt messages

      :param model: model name
      :param credentials: model credentials
      :param prompt_messages: prompt messages
      :param tools: tools for tool calling
      :return:
      """
  ```

  参数说明见上述 `LLM 调用`。

  该接口需要根据对应`model`选择合适的`tokenizer`进行计算，如果对应模型没有提供`tokenizer`，可以使用`AIModel`基类中的`_get_num_tokens_by_gpt2(text: str)`方法进行计算。

- 获取自定义模型规则 [可选]

  ```python
  def get_customizable_model_schema(self, model: str, credentials: dict) -> Optional[AIModelEntity]:
      """
      Get customizable model schema

      :param model: model name
      :param credentials: model credentials
      :return: model schema
      """
  ```

​当供应商支持增加自定义 LLM 时，可实现此方法让自定义模型可获取模型规则，默认返回 None。

对于`OpenAI`供应商下的大部分微调模型，可以通过其微调模型名称获取到其基类模型，如`gpt-3.5-turbo-1106`，然后返回基类模型的预定义参数规则，参考[openai](https://github.com/langgenius/dify-official-plugins/blob/main/models/anthropic/models/llm/llm.py)
的具体实现

### TextEmbedding

继承 `__base.text_embedding_model.TextEmbeddingModel` 基类，实现以下接口：

- Embedding 调用

  ```python
  def _invoke(self, model: str, credentials: dict,
              texts: list[str], user: Optional[str] = None) \
          -> TextEmbeddingResult:
      """
      Invoke large language model

      :param model: model name
      :param credentials: model credentials
      :param texts: texts to embed
      :param user: unique user id
      :return: embeddings result
      """
  ```

  - 参数：

    - `model` (string) 模型名称

    - `credentials` (object) 凭据信息

      凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

    - `texts` (array[string]) 文本列表，可批量处理

    - `user` (string) [optional] 用户的唯一标识符

      可以帮助供应商监控和检测滥用行为。

  - 返回：

    [TextEmbeddingResult](#TextEmbeddingResult) 实体。

- 预计算 tokens

  ```python
  def get_num_tokens(self, model: str, credentials: dict, texts: list[str]) -> int:
      """
      Get number of tokens for given prompt messages

      :param model: model name
      :param credentials: model credentials
      :param texts: texts to embed
      :return:
      """
  ```

  参数说明见上述 `Embedding 调用`。

  同上述`LargeLanguageModel`，该接口需要根据对应`model`选择合适的`tokenizer`进行计算，如果对应模型没有提供`tokenizer`，可以使用`AIModel`基类中的`_get_num_tokens_by_gpt2(text: str)`方法进行计算。

### Rerank

继承 `__base.rerank_model.RerankModel` 基类，实现以下接口：

- rerank 调用

  ```python
  def _invoke(self, model: str, credentials: dict,
              query: str, docs: list[str], score_threshold: Optional[float] = None, top_n: Optional[int] = None,
              user: Optional[str] = None) \
          -> RerankResult:
      """
      Invoke rerank model

      :param model: model name
      :param credentials: model credentials
      :param query: search query
      :param docs: docs for reranking
      :param score_threshold: score threshold
      :param top_n: top n
      :param user: unique user id
      :return: rerank result
      """
  ```

  - 参数：

    - `model` (string) 模型名称

    - `credentials` (object) 凭据信息

      凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

    - `query` (string) 查询请求内容

    - `docs` (array[string]) 需要重排的分段列表

    - `score_threshold` (float) [optional] Score 阈值

    - `top_n` (int) [optional] 取前 n 个分段

    - `user` (string) [optional] 用户的唯一标识符

      可以帮助供应商监控和检测滥用行为。

  - 返回：

    [RerankResult](#RerankResult) 实体。

### Speech2text

继承 `__base.speech2text_model.Speech2TextModel` 基类，实现以下接口：

- Invoke 调用

  ```python
  def _invoke(self, model: str, credentials: dict,
              file: IO[bytes], user: Optional[str] = None) \
          -> str:
      """
      Invoke large language model

      :param model: model name
      :param credentials: model credentials
      :param file: audio file
      :param user: unique user id
      :return: text for given audio file
      """	
  ```

  - 参数：

    - `model` (string) 模型名称

    - `credentials` (object) 凭据信息

      凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

    - `file` (File) 文件流

    - `user` (string) [optional] 用户的唯一标识符

      可以帮助供应商监控和检测滥用行为。

  - 返回：

    语音转换后的字符串。

### Text2speech

继承 `__base.text2speech_model.Text2SpeechModel` 基类，实现以下接口：

- Invoke 调用

  ```python
  def _invoke(self, model: str, credentials: dict, content_text: str, streaming: bool, user: Optional[str] = None):
      """
      Invoke large language model

      :param model: model name
      :param credentials: model credentials
      :param content_text: text content to be translated
      :param streaming: output is streaming
      :param user: unique user id
      :return: translated audio file
      """	
  ```

  - 参数：

    - `model` (string) 模型名称

    - `credentials` (object) 凭据信息

      凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

    - `content_text` (string) 需要转换的文本内容

    - `streaming` (bool) 是否进行流式输出

    - `user` (string) [optional] 用户的唯一标识符

      可以帮助供应商监控和检测滥用行为。

  - 返回：

    文本转换后的语音流。

### Moderation

继承 `__base.moderation_model.ModerationModel` 基类，实现以下接口：

- Invoke 调用

  ```python
  def _invoke(self, model: str, credentials: dict,
              text: str, user: Optional[str] = None) \
          -> bool:
      """
      Invoke large language model

      :param model: model name
      :param credentials: model credentials
      :param text: text to moderate
      :param user: unique user id
      :return: false if text is safe, true otherwise
      """
  ```

  - 参数：

    - `model` (string) 模型名称

    - `credentials` (object) 凭据信息

      凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

    - `text` (string) 文本内容

    - `user` (string) [optional] 用户的唯一标识符

      可以帮助供应商监控和检测滥用行为。

  - 返回：

    False 代表传入的文本安全，True 则反之。

## 实体

### PromptMessageRole 

消息角色

```python
class PromptMessageRole(Enum):
    """
    Enum class for prompt message.
    """
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"
    TOOL = "tool"
```

### PromptMessageContentType

消息内容类型，分为纯文本和图片。

```python
class PromptMessageContentType(Enum):
    """
    Enum class for prompt message content type.
    """
    TEXT = 'text'
    IMAGE = 'image'
```

### PromptMessageContent

消息内容基类，仅作为参数声明用，不可初始化。

```python
class PromptMessageContent(BaseModel):
    """
    Model class for prompt message content.
    """
    type: PromptMessageContentType
    data: str  # 内容数据
```

当前支持文本和图片两种类型，可支持同时传入文本和多图。

需要分别初始化 `TextPromptMessageContent` 和 `ImagePromptMessageContent` 传入。

### TextPromptMessageContent

```python
class TextPromptMessageContent(PromptMessageContent):
    """
    Model class for text prompt message content.
    """
    type: PromptMessageContentType = PromptMessageContentType.TEXT
```

若传入图文，其中文字需要构造此实体作为 `content` 列表中的一部分。

### ImagePromptMessageContent

```python
class ImagePromptMessageContent(PromptMessageContent):
    """
    Model class for image prompt message content.
    """
    class DETAIL(Enum):
        LOW = 'low'
        HIGH = 'high'

    type: PromptMessageContentType = PromptMessageContentType.IMAGE
    detail: DETAIL = DETAIL.LOW  # 分辨率
```

若传入图文，其中图片需要构造此实体作为 `content` 列表中的一部分

`data` 可以为 `url` 或者图片 `base64` 加密后的字符串。

### PromptMessage

所有 Role 消息体的基类，仅作为参数声明用，不可初始化。

```python
class PromptMessage(ABC, BaseModel):
    """
    Model class for prompt message.
    """
    role: PromptMessageRole  # 消息角色
    content: Optional[str | list[PromptMessageContent]] = None  # 支持两种类型，字符串和内容列表，内容列表是为了满足多模态的需要，可详见 PromptMessageContent 说明。
    name: Optional[str] = None  # 名称，可选。
```

### UserPromptMessage

UserMessage 消息体，代表用户消息。

```python
class UserPromptMessage(PromptMessage):
    """
    Model class for user prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.USER
```

### AssistantPromptMessage

代表模型返回消息，通常用于 `few-shots` 或聊天历史传入。

```python
class AssistantPromptMessage(PromptMessage):
    """
    Model class for assistant prompt message.
    """
    class ToolCall(BaseModel):
        """
        Model class for assistant prompt message tool call.
        """
        class ToolCallFunction(BaseModel):
            """
            Model class for assistant prompt message tool call function.
            """
            name: str  # 工具名称
            arguments: str  # 工具参数

        id: str  # 工具 ID，仅在 OpenAI tool call 生效，为工具调用的唯一 ID，同一个工具可以调用多次
        type: str  # 默认 function
        function: ToolCallFunction  # 工具调用信息

    role: PromptMessageRole = PromptMessageRole.ASSISTANT
    tool_calls: list[ToolCall] = []  # 模型回复的工具调用结果（仅当传入 tools，并且模型认为需要调用工具时返回）
```

其中 `tool_calls` 为调用模型传入 `tools` 后，由模型返回的 `tool call` 列表。

### SystemPromptMessage

代表系统消息，通常用于设定给模型的系统指令。

```python
class SystemPromptMessage(PromptMessage):
    """
    Model class for system prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.SYSTEM
```

### ToolPromptMessage

代表工具消息，用于工具执行后将结果交给模型进行下一步计划。

```python
class ToolPromptMessage(PromptMessage):
    """
    Model class for tool prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.TOOL
    tool_call_id: str  # 工具调用 ID，若不支持 OpenAI tool call，也可传入工具名称
```

基类的 `content` 传入工具执行结果。

### PromptMessageTool

```python
class PromptMessageTool(BaseModel):
    """
    Model class for prompt message tool.
    """
    name: str  # 工具名称
    description: str  # 工具描述
    parameters: dict  # 工具参数 dict
```

---

### LLMResult

```python
class LLMResult(BaseModel):
    """
    Model class for llm result.
    """
    model: str  # 实际使用模型
    prompt_messages: list[PromptMessage]  # prompt 消息列表
    message: AssistantPromptMessage  # 回复消息
    usage: LLMUsage  # 使用的 tokens 及费用信息
    system_fingerprint: Optional[str] = None  # 请求指纹，可参考 OpenAI 该参数定义
```

### LLMResultChunkDelta

流式返回中每个迭代内部 `delta` 实体

```python
class LLMResultChunkDelta(BaseModel):
    """
    Model class for llm result chunk delta.
    """
    index: int  # 序号
    message: AssistantPromptMessage  # 回复消息
    usage: Optional[LLMUsage] = None  # 使用的 tokens 及费用信息，仅最后一条返回
    finish_reason: Optional[str] = None  # 结束原因，仅最后一条返回
```

### LLMResultChunk

流式返回中每个迭代实体

```python
class LLMResultChunk(BaseModel):
    """
    Model class for llm result chunk.
    """
    model: str  # 实际使用模型
    prompt_messages: list[PromptMessage]  # prompt 消息列表
    system_fingerprint: Optional[str] = None  # 请求指纹，可参考 OpenAI 该参数定义
    delta: LLMResultChunkDelta  # 每个迭代存在变化的内容
```

### LLMUsage

```python
class LLMUsage(ModelUsage):
    """
    Model class for llm usage.
    """
    prompt_tokens: int  # prompt 使用 tokens
    prompt_unit_price: Decimal  # prompt 单价
    prompt_price_unit: Decimal  # prompt 价格单位，即单价基于多少 tokens 
    prompt_price: Decimal  # prompt 费用
    completion_tokens: int  # 回复使用 tokens
    completion_unit_price: Decimal  # 回复单价
    completion_price_unit: Decimal  # 回复价格单位，即单价基于多少 tokens 
    completion_price: Decimal  # 回复费用
    total_tokens: int  # 总使用 token 数
    total_price: Decimal  # 总费用
    currency: str  # 货币单位
    latency: float  # 请求耗时(s)
```

---

### TextEmbeddingResult

```python
class TextEmbeddingResult(BaseModel):
    """
    Model class for text embedding result.
    """
    model: str  # 实际使用模型
    embeddings: list[list[float]]  # embedding 向量列表，对应传入的 texts 列表
    usage: EmbeddingUsage  # 使用信息
```

### EmbeddingUsage

```python
class EmbeddingUsage(ModelUsage):
    """
    Model class for embedding usage.
    """
    tokens: int  # 使用 token 数
    total_tokens: int  # 总使用 token 数
    unit_price: Decimal  # 单价
    price_unit: Decimal  # 价格单位，即单价基于多少 tokens
    total_price: Decimal  # 总费用
    currency: str  # 货币单位
    latency: float  # 请求耗时(s)
```

---

### RerankResult

```python
class RerankResult(BaseModel):
    """
    Model class for rerank result.
    """
    model: str  # 实际使用模型
    docs: list[RerankDocument]  # 重排后的分段列表	
```

### RerankDocument

```python
class RerankDocument(BaseModel):
    """
    Model class for rerank document.
    """
    index: int  # 原序号
    text: str  # 分段文本内容
    score: float  # 分数
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/model-configuration/interfaces.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 配置负载均衡
> 来源：`zh-hans/guides/model-configuration/load-balancing.mdx`

## 介绍

> **信息提示：**

负载均衡为付费特性，可通过[订阅 SaaS 付费服务或者购买企业版](https://dify.ai/zh/pricing)以启用。

通常，模型供应商会限制用户在指定时间内访问 API 服务的次数（模型速率限制），以确保服务的稳定性与合理使用。对于企业级应用，来自单一凭据的高并发请求容易触发模型速率限制，从而影响用户访问。

而负载均衡可将请求流量分配至多个模型凭据，有效避免模型速率限制和单点故障，并为所有用户提供更快的响应速度，保障业务稳定运行。

Dify 采用轮询策略的负载均衡机制，即：将模型请求按顺序依次分配给负载均衡池中的各个凭据。若某个凭据触发模型速率限制，系统将在接下来一分钟内的轮询中暂时跳过该凭据，以避免无效重试。

## 步骤

为模型配置负载均衡，按照以下步骤操作：

1. 在模型列表中找到目标模型，点击对应的 **配置**，选择 **负载均衡** 模式。

2. 在负载均衡池中，点击 **添加凭据**，从已有凭据中选择或添加新凭据。

> **信息提示：**

**默认配置** 为当前指定的默认凭据。

> **提示：**

若某个凭据的配额充足或性能更优，可重复添加该凭据以增加其在负载均衡中的权重，使其承担更大比例的请求负载。

![Add credentials for load balancing](./images/add_load_balancing_credential.png)

3. 在负载均衡池中启用至少 2 个凭据，点击 **保存**。已启用负载均衡的模型将带有特殊标识。

![Load balancing icon](./images/load_balancing_icon.png)

> **信息提示：**

从负载均衡模式切换回默认的单凭据模式时，系统将保留负载均衡配置以备后用。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/model-configuration/load-balancing.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 管理模型凭据
> 来源：`zh-hans/guides/model-configuration/manage-model-credential.mdx`

## 介绍

你可以为模型供应商的预定义模型和自定义模型添加多个凭据，并轻松进行切换、删除、修改等操作。

在以下场景中，推荐添加多个模型凭据：

- **环境隔离**：为开发、测试、生产等不同环境配置独立的模型凭据。例如，在开发环境中选择有速率限制的凭据用于功能调试，在生产环境中选择性能稳定、配额充足的付费凭据以保障服务质量。

- **成本优化**：通过添加和切换来自不同账户或模型供应商的多个凭据，最大限度地利用免费或低成本额度，降低应用开发与运营成本。

- **模型实验**：在模型微调或迭代过程中，可能会产出多个模型版本。通过添加不同模型版本的凭据，快速切换并测试其应用效果。

> **提示：**

你可以使用多个凭据为模型配置负载均衡。更多信息，请阅读 [配置负载均衡](./zh-hans/guides/model-configuration/load-balancing)。

## 步骤

    安装模型供应商并配置首个凭据后，点击供应商面板右上角的 **配置**，可进行以下操作：

    - 添加新凭据
    - 选择任一凭据作为所有预定义模型的默认凭据
    - 修改凭据
    - 删除凭据

    若默认凭据被删除，需手动指定新的默认凭据。

    ![Manage credentials for predefined models](./images/predefined_model_credential.png)

    ### 管理单个自定义模型的凭据

    安装模型供应商并添加自定义模型后，按照以下步骤操作：

    1. 在模型列表中，点击模型对应的 **配置**。

    2. 在 **指定模型凭据** 面板中，点击默认凭据以打开凭据列表，可进行以下操作：

        - 添加新凭据
        - 选择任一凭据作为该自定义模型的默认凭据
        - 修改凭据
        - 删除凭据

> **警告：**

    若删除某个自定义模型的唯一凭据，该模型将被一同删除。

    ![Manage credentials for a single custom model](./images/custom_model_credential.png)

> **信息提示：**

    添加自定义模型时，若填写的模型名称与模型类型与一个已存在的自定义模型完全相同，系统将不会创建重复的模型，而是会为已存在的模型添加一个新的凭据。

    ### 管理所有自定义模型的凭据

    你可以点击 **管理凭据**，查看、修改或删除所有自定义模型的凭据。

    ![Manage credentials for all custom models](./images/custom_model_credential_list.png)

    对于被移除的自定义模型，其所有凭据仍将保留在 **管理凭据** 列表中。当你点击 **添加模型** 时，系统将展示所有已移除但凭据尚存的自定义模型，供你快速重新添加。

    ![Removed models displayed for quick re-add](./images/removed_custom_model_re-add.png)

    若从 **管理凭据** 列表中删除某个已移除的自定义模型的所有凭据，该模型将不会在点击 **添加模型** 时出现。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/model-configuration/manage-model-credential.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 增加新供应商
> 来源：`zh-hans/guides/model-configuration/new-provider.mdx`

> **警告：**

    “模型”已全面升级为“插件”生态，模型插件的详细开发说明请参考[插件开发](./zh-hans/plugins/quick-start/develop-plugins/model-plugin/README)。以下内容已归档。

### 供应商配置方式

供应商支持三种模型配置方式：

**预定义模型（predefined-model）**

表示用户只需要配置统一的供应商凭据即可使用供应商下的预定义模型。

**自定义模型（customizable-model）**

用户需要新增每个模型的凭据配置，如 Xinference，它同时支持 LLM 和 Text Embedding，但是每个模型都有唯一的 **model\_uid**，如果想要将两者同时接入，就需要为每个模型配置一个 **model\_uid**。

**从远程获取（fetch-from-remote）**

与 `predefined-model`配置方式一致，只需要配置统一的供应商凭据即可，模型通过凭据信息从供应商获取。

如OpenAI，我们可以基于 gpt-turbo-3.5 来 Fine Tune 多个模型，而他们都位于同一个 **api\_key** 下，当配置为`fetch-from-remote`时，开发者只需要配置统一的 **api\_key** 即可让 Dify Runtime 获取到开发者所有的微调模型并接入 Dify。

这三种配置方式**支持共存**，即存在供应商支持`predefined-model` + `customizable-model` 或 `predefined-model` + `fetch-from-remote`等，也就是配置了供应商统一凭据可以使用预定义模型和从远程获取的模型，若新增了模型，则可以在此基础上额外使用自定义的模型。

### 配置说明

**名词解释**

* `module`: 一个`module`即为一个 Python Package，或者通俗一点，称为一个文件夹，里面包含了一个`__init__.py`文件，以及其他的`.py`文件。

**步骤**

新增一个供应商主要分为几步，这里简单列出，帮助大家有一个大概的认识，具体的步骤会在下面详细介绍。

* 创建供应商 yaml 文件，根据 [Provider Schema](https://github.com/langgenius/dify/blob/main/api/core/model_runtime/docs/zh_Hans/schema.md) 编写。
* 创建供应商代码，实现一个`class`。
* 根据模型类型，在供应商`module`下创建对应的模型类型 `module`，如`llm`或`text_embedding`。
* 根据模型类型，在对应的模型`module`下创建同名的代码文件，如`llm.py`，并实现一个`class`。
* 如果有预定义模型，根据模型名称创建同名的yaml文件在模型`module`下，如`claude-2.1.yaml`，根据 [AI Model Entity](https://github.com/langgenius/dify/blob/main/api/core/model_runtime/docs/zh_Hans/schema.md#aimodelentity) 编写。
* 编写测试代码，确保功能可用。

#### 开始吧

增加一个新的供应商需要先确定供应商的英文标识，如 `anthropic`，使用该标识在 `model_providers` 创建以此为名称的 `module`。

在此 `module` 下，我们需要先准备供应商的 YAML 配置。

**准备供应商 YAML**

此处以 `Anthropic` 为例，预设了供应商基础信息、支持的模型类型、配置方式、凭据规则。

```YAML
provider: anthropic  # 供应商标识
label:  # 供应商展示名称，可设置 en_US 英文、zh_Hans 中文两种语言，zh_Hans 不设置将默认使用 en_US。
  en_US: Anthropic
icon_small:  # 供应商小图标，存储在对应供应商实现目录下的 _assets 目录，中英文策略同 label
  en_US: icon_s_en.png
icon_large:  # 供应商大图标，存储在对应供应商实现目录下的 _assets 目录，中英文策略同 label
  en_US: icon_l_en.png
supported_model_types:  # 支持的模型类型，Anthropic 仅支持 LLM
- llm
configurate_methods:  # 支持的配置方式，Anthropic 仅支持预定义模型
- predefined-model
provider_credential_schema:  # 供应商凭据规则，由于 Anthropic 仅支持预定义模型，则需要定义统一供应商凭据规则
  credential_form_schemas:  # 凭据表单项列表
  - variable: anthropic_api_key  # 凭据参数变量名
    label:  # 展示名称
      en_US: API Key
    type: secret-input  # 表单类型，此处 secret-input 代表加密信息输入框，编辑时只展示屏蔽后的信息。
    required: true  # 是否必填
    placeholder:  # PlaceHolder 信息
      zh_Hans: 在此输入你的 API Key
      en_US: Enter your API Key
  - variable: anthropic_api_url
    label:
      en_US: API URL
    type: text-input  # 表单类型，此处 text-input 代表文本输入框
    required: false
    placeholder:
      zh_Hans: 在此输入你的 API URL
      en_US: Enter your API URL
```

如果接入的供应商提供自定义模型，比如`OpenAI`提供微调模型，那么我们就需要添加[`model_credential_schema`](https://github.com/langgenius/dify/blob/main/api/core/model_runtime/docs/zh_Hans/schema.md)，以`OpenAI`为例：

```yaml
model_credential_schema:
  model: # 微调模型名称
    label:
      en_US: Model Name
      zh_Hans: 模型名称
    placeholder:
      en_US: Enter your model name
      zh_Hans: 输入模型名称
  credential_form_schemas:
  - variable: openai_api_key
    label:
      en_US: API Key
    type: secret-input
    required: true
    placeholder:
      zh_Hans: 在此输入你的 API Key
      en_US: Enter your API Key
  - variable: openai_organization
    label:
        zh_Hans: 组织 ID
        en_US: Organization
    type: text-input
    required: false
    placeholder:
      zh_Hans: 在此输入你的组织 ID
      en_US: Enter your Organization ID
  - variable: openai_api_base
    label:
      zh_Hans: API Base
      en_US: API Base
    type: text-input
    required: false
    placeholder:
      zh_Hans: 在此输入你的 API Base
      en_US: Enter your API Base
```

也可以参考`model_providers`目录下其他供应商目录下的 [YAML 配置信息](https://github.com/langgenius/dify/blob/main/api/core/model_runtime/docs/zh_Hans/schema.md)。

**实现供应商代码**

我们需要在`model_providers`下创建一个同名的python文件，如`anthropic.py`，并实现一个`class`，继承`__base.provider.Provider`基类，如`AnthropicProvider`。

**自定义模型供应商**

当供应商为 Xinference 等自定义模型供应商时，可跳过该步骤，仅创建一个空的`XinferenceProvider`类即可，并实现一个空的`validate_provider_credentials`方法，该方法并不会被实际使用，仅用作避免抽象类无法实例化。

```python
class XinferenceProvider(Provider):
    def validate_provider_credentials(self, credentials: dict) -> None:
        pass
```

**预定义模型供应商**

供应商需要继承 `__base.model_provider.ModelProvider` 基类，实现 `validate_provider_credentials` 供应商统一凭据校验方法即可，可参考 [AnthropicProvider](https://github.com/langgenius/dify/blob/main/api/core/model_runtime/model_providers/anthropic/anthropic.py)。

```python
def validate_provider_credentials(self, credentials: dict) -> None:
    """
    Validate provider credentials
    You can choose any validate_credentials method of model type or implement validate method by yourself,
    such as: get model list api

    if validate failed, raise exception

    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
    """
```

当然也可以先预留 `validate_provider_credentials` 实现，在模型凭据校验方法实现后直接复用。

**增加模型**

[**增加预定义模型** ](./zh-hans/guides/model-configuration/predefined-model)**👈🏻**

对于预定义模型，我们可以通过简单定义一个 yaml，并通过实现调用代码来接入。

[**增加自定义模型**](./zh-hans/guides/model-configuration/customizable-model) **👈🏻**

对于自定义模型，我们只需要实现调用代码即可接入，但是它需要处理的参数可能会更加复杂。

***

#### 测试

为了保证接入供应商/模型的可用性，编写后的每个方法均需要在 `tests` 目录中编写对应的集成测试代码。

依旧以 `Anthropic` 为例。

在编写测试代码前，需要先在 `.env.example` 新增测试供应商所需要的凭据环境变量，如：`ANTHROPIC_API_KEY`。

在执行前需要将 `.env.example` 复制为 `.env` 再执行。

**编写测试代码**

在 `tests` 目录下创建供应商同名的 `module`: `anthropic`，继续在此模块中创建 `test_provider.py` 以及对应模型类型的 test py 文件，如下所示：

```shell
.
├── __init__.py
├── anthropic
│   ├── __init__.py
│   ├── test_llm.py       # LLM 测试
│   └── test_provider.py  # 供应商测试
```

针对上面实现的代码的各种情况进行测试代码编写，并测试通过后提交代码。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/model-configuration/new-provider.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 预定义模型接入
> 来源：`zh-hans/guides/model-configuration/predefined-model.mdx`

> **警告：**

    “模型”已全面升级为“插件”生态，模型插件的详细开发说明请参考[插件开发](./zh-hans/plugins/quick-start/develop-plugins/model-plugin/README)。以下内容已归档。

供应商集成完成后，接下来为供应商下模型的接入。

我们首先需要确定接入模型的类型，并在对应供应商的目录下创建对应模型类型的 `module`。

当前支持模型类型如下：

* `llm` 文本生成模型
* `text_embedding` 文本 Embedding 模型
* `rerank` Rerank 模型
* `speech2text` 语音转文字
* `tts` 文字转语音
* `moderation` 审查

依旧以 `Anthropic` 为例，`Anthropic` 仅支持 LLM，因此在 `model_providers.anthropic` 创建一个 `llm` 为名称的 `module`。

对于预定义的模型，我们首先需要在 `llm` `module` 下创建以模型名为文件名称的 YAML 文件，如：`claude-2.1.yaml`。

#### 准备模型 YAML

```yaml
model: claude-2.1  # 模型标识
# 模型展示名称，可设置 en_US 英文、zh_Hans 中文两种语言，zh_Hans 不设置将默认使用 en_US。
# 也可不设置 label，则使用 model 标识内容。
label:
  en_US: claude-2.1
model_type: llm  # 模型类型，claude-2.1 为 LLM
features:  # 支持功能，agent-thought 为支持 Agent 推理，vision 为支持图片理解
- agent-thought
model_properties:  # 模型属性
  mode: chat  # LLM 模式，complete 文本补全模型，chat 对话模型
  context_size: 200000  # 支持最大上下文大小
parameter_rules:  # 模型调用参数规则，仅 LLM 需要提供
- name: temperature  # 调用参数变量名
  # 默认预置了 5 种变量内容配置模板，temperature/top_p/max_tokens/presence_penalty/frequency_penalty
  # 可在 use_template 中直接设置模板变量名，将会使用 entities.defaults.PARAMETER_RULE_TEMPLATE 中的默认配置
  # 若设置了额外的配置参数，将覆盖默认配置
  use_template: temperature
- name: top_p
  use_template: top_p
- name: top_k
  label:  # 调用参数展示名称
    zh_Hans: 取样数量
    en_US: Top k
  type: int  # 参数类型，支持 float/int/string/boolean
  help:  # 帮助信息，描述参数作用
    zh_Hans: 仅从每个后续标记的前 K 个选项中采样。
    en_US: Only sample from the top K options for each subsequent token.
  required: false  # 是否必填，可不设置
- name: max_tokens_to_sample
  use_template: max_tokens
  default: 4096  # 参数默认值
  min: 1  # 参数最小值，仅 float/int 可用
  max: 4096  # 参数最大值，仅 float/int 可用
pricing:  # 价格信息
  input: '8.00'  # 输入单价，即 Prompt 单价
  output: '24.00'  # 输出单价，即返回内容单价
  unit: '0.000001'  # 价格单位，即上述价格为每 100K 的单价
  currency: USD  # 价格货币
```

建议将所有模型配置都准备完毕后再开始模型代码的实现。

同样，也可以参考 `model_providers` 目录下其他供应商对应模型类型目录下的 YAML 配置信息，完整的 YAML 规则见：Schema[^1]。

#### 实现模型调用代码

接下来需要在 `llm` `module` 下创建一个同名的 python 文件 `llm.py` 来编写代码实现。

在 `llm.py` 中创建一个 Anthropic LLM 类，我们取名为 `AnthropicLargeLanguageModel`（随意），继承 `__base.large_language_model.LargeLanguageModel` 基类，实现以下几个方法：

*   LLM 调用

    实现 LLM 调用的核心方法，可同时支持流式和同步返回。

    ```python
    def _invoke(self, model: str, credentials: dict,
                prompt_messages: list[PromptMessage], model_parameters: dict,
                tools: Optional[list[PromptMessageTool]] = None, stop: Optional[List[str]] = None,
                stream: bool = True, user: Optional[str] = None) \
            -> Union[LLMResult, Generator]:
        """
        Invoke large language model

        :param model: model name
        :param credentials: model credentials
        :param prompt_messages: prompt messages
        :param model_parameters: model parameters
        :param tools: tools for tool calling
        :param stop: stop words
        :param stream: is stream response
        :param user: unique user id
        :return: full response or stream response chunk generator result
        """
    ```

    在实现时，需要注意使用两个函数来返回数据，分别用于处理同步返回和流式返回，因为Python会将函数中包含 `yield` 关键字的函数识别为生成器函数，返回的数据类型固定为 `Generator`，因此同步和流式返回需要分别实现，就像下面这样（注意下面例子使用了简化参数，实际实现时需要按照上面的参数列表进行实现）：

    ```python
    def _invoke(self, stream: bool, **kwargs) \
            -> Union[LLMResult, Generator]:
        if stream:
              return self._handle_stream_response(**kwargs)
        return self._handle_sync_response(**kwargs)

    def _handle_stream_response(self, **kwargs) -> Generator:
        for chunk in response:
              yield chunk
    def _handle_sync_response(self, **kwargs) -> LLMResult:
        return LLMResult(**response)
    ```
*   预计算输入 tokens

    若模型未提供预计算 tokens 接口，可直接返回 0。

    ```python
    def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                       tools: Optional[list[PromptMessageTool]] = None) -> int:
        """
        Get number of tokens for given prompt messages

        :param model: model name
        :param credentials: model credentials
        :param prompt_messages: prompt messages
        :param tools: tools for tool calling
        :return:
        """
    ```
*   模型凭据校验

    与供应商凭据校验类似，这里针对单个模型进行校验。

    ```python
    def validate_credentials(self, model: str, credentials: dict) -> None:
        """
        Validate model credentials

        :param model: model name
        :param credentials: model credentials
        :return:
        """
    ```
*   调用异常错误映射表

    当模型调用异常时需要映射到 Runtime 指定的 `InvokeError` 类型，方便 Dify 针对不同错误做不同后续处理。

    Runtime Errors:

    * `InvokeConnectionError` 调用连接错误
    * `InvokeServerUnavailableError` 调用服务方不可用
    * `InvokeRateLimitError` 调用达到限额
    * `InvokeAuthorizationError` 调用鉴权失败
    * `InvokeBadRequestError` 调用传参有误

    ```python
    @property
    def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
        """
        Map model invoke error to unified error
        The key is the error type thrown to the caller
        The value is the error type thrown by the model,
        which needs to be converted into a unified error type for the caller.

        :return: Invoke error mapping
        """
    ```

接口方法说明见：[Interfaces](https://github.com/langgenius/dify/blob/main/api/core/model\_runtime/docs/zh\_Hans/interfaces)，具体实现可参考：[llm.py](https://github.com/langgenius/dify-official-plugins/blob/main/models/anthropic/models/llm/llm.py)。

[^1]: #### Provider

    * `provider` (string) 供应商标识，如：`openai`
    * `label` (object) 供应商展示名称，i18n，可设置 `en_US` 英文、`zh_Hans` 中文两种语言
      * `zh_Hans` (string) \[optional] 中文标签名，`zh_Hans` 不设置将默认使用 `en_US`。
      * `en_US` (string) 英文标签名
    * `description` (object) \[optional] 供应商描述，i18n
      * `zh_Hans` (string) \[optional] 中文描述
      * `en_US` (string) 英文描述
    * `icon_small` (string) \[optional] 供应商小 ICON，存储在对应供应商实现目录下的 `_assets` 目录，中英文策略同 `label`
      * `zh_Hans` (string) \[optional] 中文 ICON
      * `en_US` (string) 英文 ICON
    * `icon_large` (string) \[optional] 供应商大 ICON，存储在对应供应商实现目录下的 \_assets 目录，中英文策略同 label
      * `zh_Hans` (string) \[optional] 中文 ICON
      * `en_US` (string) 英文 ICON
    * `background` (string) \[optional] 背景颜色色值，例：#FFFFFF，为空则展示前端默认色值。
    * `help` (object) \[optional] 帮助信息
      * `title` (object) 帮助标题，i18n
        * `zh_Hans` (string) \[optional] 中文标题
        * `en_US` (string) 英文标题
      * `url` (object) 帮助链接，i18n
        * `zh_Hans` (string) \[optional] 中文链接
        * `en_US` (string) 英文链接
    * `supported_model_types` (array\[ModelType]) 支持的模型类型
    * `configurate_methods` (array\[ConfigurateMethod]) 配置方式
    * `provider_credential_schema` (ProviderCredentialSchema) 供应商凭据规格
    * `model_credential_schema` (ModelCredentialSchema) 模型凭据规格

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/model-configuration/predefined-model.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入大模型简介
> 来源：`zh-hans/guides/model-configuration/readme.mdx`

> **警告：**

    “模型”已全面升级为“插件”生态，模型插件的详细开发说明请参考[插件开发](./zh-hans/plugins/quick-start/develop-plugins/model-plugin/README)。以下内容已归档。

Dify 是基于大语言模型的 AI 应用开发平台，初次使用时你需要先在 Dify 的 **设置 -- 模型供应商** 页面内添加并配置所需要的模型。

![设置-模型供应商](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/model-configuration/e83d92f43b9cd8eca719b3c27ca63418.png)

Dify 目前已支持主流的模型供应商，例如 OpenAI 的 GPT 系列、Anthropic 的 Claude 系列等。不同模型的能力表现、参数类型会不一样，你可以根据不同情景的应用需求选择你喜欢的模型供应商。**你在 Dify 应用以下模型能力前，应该前往不同的模型厂商官方网站获得他们的 API key 。**

### 模型类型

在 Dify 中，我们按模型的使用场景将模型分为以下 4 类：

1.  **系统推理模型**。 在创建的应用中，用的是该类型的模型。智聊、对话名称生成、下一步问题建议用的也是推理模型。

    > 已支持的系统推理模型供应商：[OpenAI](https://platform.openai.com/account/api-keys)、[Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-services/openai-service/)、[Anthropic](https://console.anthropic.com/account/keys)、Hugging Face Hub、Replicate、Xinference、OpenLLM、[讯飞星火](https://www.xfyun.cn/solutions/xinghuoAPI)、[文心一言](https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)、[通义千问](https://dashscope.console.aliyun.com/api-key\_management?spm=a2c4g.11186623.0.0.3bbc424dxZms9k)、[Minimax](https://api.minimax.chat/user-center/basic-information/interface-key)、ZHIPU(ChatGLM)
2.  **Embedding 模型**。在知识库中，将分段过的文档做 Embedding 用的是该类型的模型。在使用了知识库的应用中，将用户的提问做 Embedding 处理也是用的该类型的模型。

    > 已支持的 Embedding 模型供应商：OpenAI、ZHIPU(ChatGLM)、Jina AI([Jina Embeddings](https://jina.ai/embeddings/))
3.  [**Rerank 模型**](./zh-hans/advanced/retrieval-augment/rerank)。**Rerank 模型用于增强检索能力，改善 LLM 的搜索结果。**

    > 已支持的 Rerank 模型供应商：Cohere、Jina AI([Jina Reranker](https://jina.ai/reranker))
4.  **语音转文字模型**。在对话型应用中，将语音转文字用的是该类型的模型。

    > 已支持的语音转文字模型供应商：OpenAI

根据技术变化和用户需求，我们将陆续支持更多 LLM 供应商。

### 托管模型试用服务

我们为 Dify 云服务的用户提供了不同模型的试用额度，请在该额度耗尽前设置你自己的模型供应商，否则将会影响应用的正常使用。

* **OpenAI 托管模型试用：** 我们提供 200 次调用次数供你试用体验，可用于 GPT3.5-turbo、GPT3.5-turbo-16k、text-davinci-003 模型。

### 设置默认模型

Dify 在需要模型时，会根据使用场景来选择设置过的默认模型。在 `设置 > 模型供应商` 中设置默认模型。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/model-configuration/c5ac5f32deb020a8aae46045d3ee9c8d.png)

系统默认推理模型(System Reasoning Model)：设置创建应用使用的默认推理模型,以及对话名称生成、下一步问题建议等功能也会使用该默认推理模型。

### 接入模型设置

在 Dify 的 `设置 > 模型供应商` 中设置要接入的模型。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/model-configuration/a8d65b27c806b0a6fabe88099023d116.png)

模型供应商分为两种：

1. 自有模型。该类型的模型供应商提供的是自己开发的模型。如 OpenAI，Anthropic 等。
2. 托管模型。该类型的模型供应商提供的是第三方模型。如 Hugging Face，Replicate 等。

在 Dify 中接入不同类型的模型供应商的方式稍有不同。

**接入自有模型的模型供应商**

接入自有模型的供应商后，Dify 会自动接入该供应商下的所有模型。

在 Dify 中设置对应模型供应商的 API key，即可接入该模型供应商。

> **信息提示：**

Dify 使用了 [PKCS1_OAEP](https://pycryptodome.readthedocs.io/en/latest/src/cipher/oaep.html) 来加密存储用户托管的 API 密钥，每个租户均使用了独立的密钥对进行加密，确保你的 API 密钥不被泄漏。

**接入托管模型的模型供应商**

托管类型的供应商上面有很多第三方模型。接入模型需要一个个的添加。具体接入方式如下：

* [Hugging Face](../../development/models-integration/hugging-face)
* [Replicate](../../development/models-integration/replicate)
* [Xinference](../../development/models-integration/xinference)
* [OpenLLM](../../development/models-integration/openllm)

### 使用模型

配置完模型后，就可以在应用中使用这些模型了：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/model-configuration/055e92f8634c0ba1bdd2c559f7d8997d.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/model-configuration/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 配置规则
> 来源：`zh-hans/guides/model-configuration/schema.mdx`

> **警告：**

    “模型”已全面升级为“插件”生态，模型插件的详细开发说明请参考[插件开发](./zh-hans/plugins/quick-start/develop-plugins/model-plugin/README)。以下内容已归档。

- 供应商规则基于 [Provider](#Provider) 实体。

- 模型规则基于 [AIModelEntity](#AIModelEntity) 实体。

> 以下所有实体均基于 `Pydantic BaseModel`，可在 `entities` 模块中找到对应实体。

### Provider

- `provider` (string) 供应商标识，如：`openai`
- `label` (object) 供应商展示名称，i18n，可设置 `en_US` 英文、`zh_Hans` 中文两种语言
  - `zh_Hans ` (string) [optional] 中文标签名，`zh_Hans` 不设置将默认使用 `en_US`。
  - `en_US` (string) 英文标签名
- `description` (object) [optional] 供应商描述，i18n
  - `zh_Hans` (string) [optional] 中文描述
  - `en_US` (string) 英文描述
- `icon_small` (string) [optional] 供应商小 ICON，存储在对应供应商实现目录下的 `_assets` 目录，中英文策略同 `label`
  - `zh_Hans` (string)  [optional] 中文 ICON
  - `en_US` (string) 英文 ICON
- `icon_large` (string) [optional] 供应商大 ICON，存储在对应供应商实现目录下的 _assets 目录，中英文策略同 label
  - `zh_Hans `(string) [optional] 中文 ICON
  - `en_US` (string) 英文 ICON
- `background` (string) [optional] 背景颜色色值，例：#FFFFFF，为空则展示前端默认色值。
- `help` (object) [optional] 帮助信息
  - `title` (object) 帮助标题，i18n
    - `zh_Hans` (string) [optional] 中文标题
    - `en_US` (string) 英文标题
  - `url` (object) 帮助链接，i18n
    - `zh_Hans` (string) [optional] 中文链接
    - `en_US` (string) 英文链接
- `supported_model_types` (array[[ModelType](#ModelType)]) 支持的模型类型
- `configurate_methods` (array[[ConfigurateMethod](#ConfigurateMethod)]) 配置方式
- `provider_credential_schema` ([ProviderCredentialSchema](#ProviderCredentialSchema)) 供应商凭据规格
- `model_credential_schema` ([ModelCredentialSchema](#ModelCredentialSchema)) 模型凭据规格

### AIModelEntity

- `model` (string) 模型标识，如：`gpt-3.5-turbo`
- `label` (object) [optional] 模型展示名称，i18n，可设置 `en_US` 英文、`zh_Hans` 中文两种语言
  - `zh_Hans `(string) [optional] 中文标签名
  - `en_US` (string) 英文标签名
- `model_type` ([ModelType](#ModelType)) 模型类型
- `features` (array[[ModelFeature](#ModelFeature)]) [optional] 支持功能列表
- `model_properties` (object) 模型属性
  - `mode` ([LLMMode](#LLMMode)) 模式 (模型类型 `llm` 可用)
  - `context_size` (int) 上下文大小 (模型类型 `llm` `text-embedding` 可用)
  - `max_chunks` (int) 最大分块数量 (模型类型 `text-embedding ` `moderation` 可用)
  - `file_upload_limit` (int) 文件最大上传限制，单位：MB。（模型类型 `speech2text` 可用）
  - `supported_file_extensions` (string)  支持文件扩展格式，如：mp3,mp4（模型类型 `speech2text` 可用）
  - `default_voice` (string)  缺省音色，必选：alloy,echo,fable,onyx,nova,shimmer（模型类型 `tts` 可用）
  - `voices` (list)  可选音色列表。
    - `mode` (string)  音色模型。（模型类型 `tts` 可用）
    - `name` (string)  音色模型显示名称。（模型类型 `tts` 可用）
    - `language` (string)  音色模型支持语言。（模型类型 `tts` 可用）
  - `word_limit` (int)  单次转换字数限制，默认按段落分段（模型类型 `tts` 可用）
  - `audio_type` (string)  支持音频文件扩展格式，如：mp3,wav（模型类型 `tts` 可用）
  - `max_workers` (int)  支持文字音频转换并发任务数（模型类型 `tts` 可用）
  - `max_characters_per_chunk` (int) 每块最大字符数 (模型类型  `moderation` 可用)
- `parameter_rules` (array[[ParameterRule](#ParameterRule)]) [optional] 模型调用参数规则
- `pricing` ([PriceConfig](#PriceConfig)) [optional] 价格信息
- `deprecated` (bool) 是否废弃。若废弃，模型列表将不再展示，但已经配置的可以继续使用，默认 False。

### ModelType

- `llm` 文本生成模型
- `text-embedding` 文本 Embedding 模型
- `rerank` Rerank 模型
- `speech2text` 语音转文字
- `tts` 文字转语音
- `moderation` 审查

### ConfigurateMethod

- `predefined-model  ` 预定义模型

  表示用户只需要配置统一的供应商凭据即可使用供应商下的预定义模型。
- `customizable-model` 自定义模型

  用户需要新增每个模型的凭据配置。

- `fetch-from-remote` 从远程获取

  与 `predefined-model` 配置方式一致，只需要配置统一的供应商凭据即可，模型通过凭据信息从供应商获取。

### ModelFeature

- `agent-thought` Agent 推理，一般超过 70B 有思维链能力。
- `vision` 视觉，即：图像理解。
- `tool-call` 工具调用
- `multi-tool-call` 多工具调用
- `stream-tool-call` 流式工具调用

### FetchFrom

- `predefined-model` 预定义模型
- `fetch-from-remote` 远程模型

### LLMMode

- `completion` 文本补全
- `chat` 对话

### ParameterRule

- `name` (string) 调用模型实际参数名

- `use_template` (string) [optional] 使用模板

  默认预置了 5 种变量内容配置模板：

  - `temperature`
  - `top_p`
  - `frequency_penalty`
  - `presence_penalty`
  - `max_tokens`

  可在 use_template 中直接设置模板变量名，将会使用 entities.defaults.PARAMETER_RULE_TEMPLATE 中的默认配置
  不用设置除 `name` 和 `use_template` 之外的所有参数，若设置了额外的配置参数，将覆盖默认配置。
  可参考 `openai/llm/gpt-3.5-turbo.yaml`。

- `label` (object) [optional] 标签，i18n

  - `zh_Hans`(string) [optional] 中文标签名
  - `en_US` (string) 英文标签名

- `type`(string) [optional] 参数类型

  - `int` 整数
  - `float` 浮点数
  - `string` 字符串
  - `boolean` 布尔型

- `help` (string) [optional] 帮助信息

  - `zh_Hans` (string) [optional] 中文帮助信息
  - `en_US` (string) 英文帮助信息

- `required` (bool) 是否必填，默认 False。

- `default`(int/float/string/bool) [optional] 默认值

- `min`(int/float) [optional] 最小值，仅数字类型适用

- `max`(int/float) [optional] 最大值，仅数字类型适用

- `precision`(int) [optional] 精度，保留小数位数，仅数字类型适用

- `options` (array[string]) [optional] 下拉选项值，仅当 `type` 为 `string` 时适用，若不设置或为 null 则不限制选项值

### PriceConfig

- `input` (float) 输入单价，即 Prompt 单价
- `output` (float) 输出单价，即返回内容单价
- `unit` (float) 价格单位，如以 1M tokens 计价，则单价对应的单位 token 数为 `0.000001`
- `currency` (string) 货币单位

### ProviderCredentialSchema

- `credential_form_schemas` (array[[CredentialFormSchema](#CredentialFormSchema)]) 凭据表单规范

### ModelCredentialSchema

- `model` (object) 模型标识，变量名默认 `model`
  - `label` (object) 模型表单项展示名称
    - `en_US` (string) 英文
    - `zh_Hans`(string) [optional] 中文
  - `placeholder` (object) 模型提示内容
    - `en_US`(string) 英文
    - `zh_Hans`(string) [optional] 中文
- `credential_form_schemas` (array[[CredentialFormSchema](#CredentialFormSchema)]) 凭据表单规范

### CredentialFormSchema

- `variable` (string) 表单项变量名
- `label` (object) 表单项标签名
  - `en_US`(string) 英文
  - `zh_Hans` (string) [optional] 中文
- `type` ([FormType](#FormType)) 表单项类型
- `required` (bool) 是否必填
- `default`(string) 默认值
- `options` (array[[FormOption](#FormOption)]) 表单项为 `select` 或 `radio` 专有属性，定义下拉内容
- `placeholder`(object) 表单项为 `text-input `专有属性，表单项 PlaceHolder
  - `en_US`(string) 英文
  - `zh_Hans` (string) [optional] 中文
- `max_length` (int) 表单项为`text-input`专有属性，定义输入最大长度，0 为不限制。
- `show_on` (array[[FormShowOnObject](#FormShowOnObject)]) 当其他表单项值符合条件时显示，为空则始终显示。

### FormType

- `text-input` 文本输入组件
- `secret-input` 密码输入组件
- `select` 单选下拉
- `radio` Radio 组件
- `switch` 开关组件，仅支持 `true` 和 `false`

### FormOption

- `label` (object) 标签
  - `en_US`(string) 英文
  - `zh_Hans`(string) [optional] 中文
- `value` (string) 下拉选项值
- `show_on` (array[[FormShowOnObject](#FormShowOnObject)]) 当其他表单项值符合条件时显示，为空则始终显示。

### FormShowOnObject

- `variable` (string) 其他表单项变量名
- `value` (string) 其他表单项变量值

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/model-configuration/schema.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 监测
> 来源：`zh-hans/guides/monitoring/README.mdx`

你可以在 **概览** 内监控、跟踪应用程序在生产环境中的性能，在数据分析仪表盘内分析生产环境中应用的使用成本、延迟、用户反馈、性能等指标，并通过持续调试、迭代不断改进你的应用程序。

![](https://assets-docs.dify.ai/2025/03/57814ba88e96305d0c92c68b1b5ea20e.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 数据分析
> 来源：`zh-hans/guides/monitoring/analysis.mdx`

你可以在 **概览** 内监控、跟踪应用程序在生产环境中的性能，在数据分析仪表盘内分析生产环境中应用的使用成本、延迟、用户反馈、性能等指标，并通过持续调试、迭代不断改进你的应用程序。

![概览—数据分析](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/83974553fee361687db31bda35198013.png)

**概览 -- 数据分析** 内显示了用量、活跃用户数和 LLM 调用消耗等，这使你可以持续改进应用运营的效果、活跃度、经济性。

***

**全部消息数（Total Messages）**

反映用户与 AI 每天的互动总次数，每回答用户一个问题即计数一次。提示词编排和调试的会话不计入。

**活跃用户数（Active Users）**

与 AI 有效互动，即有一问一答以上的唯一用户数。提示词编排和调试的会话不计入。

**平均会话互动数（Average Session Interactions）**

反映每个会话用户的持续沟通次数。如果用户与 AI 问答了 10 轮，即为 10。该指标反映了用户粘性。仅在对话型应用提供。

**Token 输出速度（Token Output Speed）**

每秒的 Token 输出数量，侧面反应模型的生成速率以及应用的使用频率。

**用户满意度（User Satisfaction Rate）**

每 1000 条消息的点赞数。反应了用户对回答十分满意的比例。

**Token 消耗（Token Usage）**

反映每日该应用请求语言模型的 Tokens 花费，用于成本控制。

**全部会话数（Total Conversations）**

反映该 AI 应用**每天**的会话总次数，发起一次新的会话即计数一次，一个会话内可能包含多条消息的往来。提示词编排和调试的消息不计入。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/analysis.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 标注回复
> 来源：`zh-hans/guides/monitoring/annotation-reply.mdx`

标注回复功能通过人工编辑标注为应用提供了可定制的高质量问答回复能力。

适用情景：

* **特定领域的定制化回答：** 在企业、政府等客服或知识库问答情景时，对于某些特定问题，服务提供方希望确保系统以明确的结果来回答问题，因此需要对在特定问题上定制化输出结果。比如定制某些问题的"标准答案"或某些问题"不可回答"。
* **POC 或 DEMO 产品快速调优：** 在快速搭建原型产品，通过标注回复实现的定制化回答可以高效提升问答结果的生成预期，提升客户满意度。

标注回复功能相当于提供了另一套检索增强系统，可以跳过 LLM 的生成环节，规避 RAG 的生成幻觉问题。

### 使用流程

1. 在开启标注回复功能之后，你可以对 LLM 对话回复内容进行标注，你可以将 LLM 回复的高质量答案直接添加为一条标注，也可以根据自己的需求编辑一条高质量答案，这些编辑的标注内容会被持久化保存；
2. 当用户再次提问相似的问题时，会将问题向量化并查询中与之相似的标注问题；
3. 如果找到匹配项，则直接返回标注中与问题相对应的答案，不再传递至 LLM 或 RAG 过程进行回复；
4. 如果没有找到匹配项，则问题继续常规流程（传递至 LLM 或 RAG）；
5. 关闭标注回复功能后，系统将一直不再继续从标注内匹配回复。

  **[图片缺失] 标注回复流程 (zh-hans/user-guide/.gitbook/assets/image (181).png)**

### 提示词编排中开启标注回复

进入"应用构建->添加功能"开启标注回复开关：

  **[图片缺失] 提示词编排中开启标注回复 (zh-hans/user-guide/.gitbook/assets/image (124).png)**

开启时需要先设置标注回复的参数，可设置参数包括：Score 阈值 和 Embedding 模型

**Score 阈值**：用于设置标注回复的匹配相似度阈值，只有高于阈值分数的标注会被召回。

**Embedding 模型**：用于对标注文本进行向量化，切换模型时会重新生成嵌入。

点击保存并启用时，该设置会立即生效，系统将对所有已保存的标注利用 Embedding 模型生成嵌入保存。

  **[图片缺失] 标注回复参数设置 (zh-hans/user-guide/.gitbook/assets/image (126).png)**

### 在会话调试页添加标注

你可以在调试与预览页面直接在模型回复信息上添加或编辑标注。

  **[图片缺失] 添加标注回复 (zh-hans/user-guide/.gitbook/assets/image (128).png)**

编辑成你需要的高质量回复并保存。

  **[图片缺失] 编辑标注回复 (zh-hans/user-guide/.gitbook/assets/image (129).png)**

再次输入同样的用户问题，系统将使用已保存的标注直接回复用户问题。

  **[图片缺失] 通过已保存的标注回复用户问题 (zh-hans/user-guide/.gitbook/assets/image (130).png)**

### 日志与标注中开启标注回复

进入"应用构建->日志与标注->标注"开启标注回复开关：

  **[图片缺失] 日志与标注中开启标注回复 (zh-hans/user-guide/.gitbook/assets/image (118).png)**

### 在标注后台设置标注回复参数

标注回复可设置的参数包括：Score 阈值 和 Embedding 模型

**Score 阈值**：用于设置标注回复的匹配相似度阈值，只有高于阈值分数的标注会被召回。

**Embedding 模型**：用于对标注文本进行向量化，切换模型时会重新生成嵌入。

  **[图片缺失] 设置标注回复参数 (zh-hans/user-guide/.gitbook/assets/image (119).png)**

### 批量导入标注问答对

在批量导入功能内，你可以下载标注导入模板，按模板格式编辑标注问答对，编辑好后在此批量导入。

  **[图片缺失] 批量导入标注问答对 (zh-hans/user-guide/.gitbook/assets/image (120).png)**

### 批量导出标注问答对

通过标注批量导出功能，你可以一次性导出系统内已保存的所有标注问答对。

  **[图片缺失] 批量导出标注问答对 (zh-hans/user-guide/.gitbook/assets/image (121).png)**

### 查看标注回复命中历史

在标注命中历史功能内，你可以查看所有命中该条标注的编辑历史、命中的用户问题、回复答案、命中来源、匹配相似分数、命中时间等信息，你可以根据这些系统信息持续改进你的标注内容。

  **[图片缺失] 查看标注回复命中历史 (zh-hans/user-guide/.gitbook/assets/image (123).png)**

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/annotation-reply.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 集成 阿里云 云监控
> 来源：`zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-aliyun.mdx`

## 什么是 阿里云云监控

阿里云提供的全托管免运维可观测平台，一键开启 Dify 应用的监控追踪和评估。

> **信息提示：**

阿里云云监控原生支持 Python/Golang/Java 应用通过 [LoongSuite](https://github.com/alibaba/loongsuite-python-agent)
探针 & 开源 OpenTelemetry 探针接入，在一键开启 Dify 大模型应用监控外，还支持通过无侵入探针对 Dify 组件及其上下游依赖的全链路可观测。
更多详情，请参考 [云监控](https://help.aliyun.com/zh/cms/cloudmonitor-2-0/user-guide/model-application)。

## 如何配置 云监控

### 1. 获取阿里云 Endpoint 和 License Key

1. 登录 [ARMS 控制台](https://arms.console.aliyun.com/)，在左侧导航栏单击 **接入中心**。
2. 在 **服务端应用** 区域单击 **OpenTelemetry** 卡片。
3. 在弹出的 **OpenTelemetry** 面板中选择数据上报方式为 **gRPC**，并依据实际部署情况选择连接方式和地域。

   ![](https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/3938280571/p976945.png)

4. 保存 **公网接入点（Endpoint）** 和 **鉴权 Token（License Key）**。
> **说明**
> Endpoint 不带端口号，例如 `http://tracing-cn-heyuan.arms.aliyuncs.com`。

### 2. 将 云监控 与 Dify 集成

> **📌 前提条件**
> Dify Cloud | 社区版本号需 ≥ v1.6.0

1. 登录 **Dify 控制台**，并进入需要监控的 Dify 应用。
2. 在左侧导航栏单击 **监测**。
3. 单击 **追踪应用性能**，然后在 **云监控** 区域单击 **配置**。

   ![](https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/9647222571/p984812.png)

4. 在弹出的对话框中输入步骤 1 获取的 **License Key** 和 **Endpoint**，并自定义 **App Name**（ARMS 控制台显示的应用名称），然后单击 **保存并启用**。

## 在 云监控 中查看监控数据

配置完成后，Dify 内应用的调试或生产数据可以在 **云监控** 中进行监控。

### 方式一：从 Dify 应用跳转 ARMS 控制台

在 Dify 控制台选择已开启应用追踪的应用，进入 **追踪配置**，在 **云监控** 区域单击 **查看**。

![](https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/9647222571/p984818.png)

### 方式二：直接在 ARMS 控制台查看

在 ARMS 控制台的 **LLM 应用监控 > 应用列表** 页面进入对应的 Dify 应用。

## 接入更多数据

云监控提供了多语言无侵入探针，支持接入Dify集群的各个组件，实现全链路追踪。

| Dify 组件      | 探针               | 详情 |
|---------------|--------------------|----------------|
| Nginx         | OpenTelemetry 探针 | [使用OpenTelemetry对Nginx进行链路追踪](https://help.aliyun.com/zh/opentelemetry/user-guide/use-opentelemetry-to-perform-tracing-analysis-on-nginx)  |
| Api           | LoongSuit-Python 探针 | [loongsuite-python-agent](https://github.com/alibaba/loongsuite-python-agent/blob/main/README.md)  |
| Sandbox       | LoongSuit-Go 探针  | [loongsuite-go-agent](https://github.com/alibaba/loongsuite-go-agent/blob/main/README.md)  |
| Worker        | OpenTelemetry 探针 | [通过OpenTelemetry上报Python应用数据](https://help.aliyun.com/zh/opentelemetry/user-guide/use-managed-service-for-opentelemetry-to-submit-the-trace-data-of-python-applications)  |
| Plugin-Daemon | LoongSuit-Go 探针  | [loongsuite-go-agent](https://github.com/alibaba/loongsuite-go-agent/blob/main/README.md)  |

## 监测数据清单

云监控支持采集Dify的Workflow/Chatflow/Chat/Agent应用，采集数据包括工作流和工作流节点的执行明细，涵盖模型调用、工具调用、知识检索和各类流程节点的执行明细数据以及会话和用户信息等元数据

### Workflow/Chatflow Trace信息

**Workflow Trace Info**

* workflow\_id - Workflow 的唯一标识
* conversation\_id - 对话 ID
* workflow\_run\_id - 此次运行的 ID
* tenant\_id - 租户 ID
* elapsed\_time - 此次运行耗时
* status - 运行状态
* version - Workflow 版本
* total\_tokens - 此次运行使用的 token 总数
* file\_list - 处理的文件列表
* triggered\_from - 触发此次运行的来源
* workflow\_run\_inputs - 此次运行的输入数据
* workflow\_run\_outputs - 此次运行的输出数据
* error - 此次运行中发生的错误
* query - 运行时使用的查询
* workflow\_app\_log\_id - Workflow 应用日志 ID
* message\_id - 关联的消息 ID
* start\_time - 运行开始时间
* end\_time - 运行结束时间
* workflow node executions - workflow 节点运行信息
* Metadata
  * workflow\_id - Workflow 的唯一标识
  * conversation\_id - 对话 ID
  * workflow\_run\_id - 此次运行的 ID
  * tenant\_id - 租户 ID
  * elapsed\_time - 此次运行耗时
  * status - 运行状态
  * version - Workflow 版本
  * total\_tokens - 此次运行使用的 token 总数
  * file\_list - 处理的文件列表
  * triggered\_from - 触发来源

### Message Trace信息

**Message Trace Info**

* message\_id - 消息 ID
* message\_data - 消息数据
* user\_session\_id - 用户的 session\_id
* conversation\_model - 对话模式
* message\_tokens - 消息中的令牌数
* answer\_tokens - 回答中的令牌数
* total\_tokens - 消息和回答中的总令牌数
* error - 错误信息
* inputs - 输入数据
* outputs - 输出数据
* file\_list - 处理的文件列表
* start\_time - 开始时间
* end\_time - 结束时间
* message\_file\_data - 消息关联的文件数据
* conversation\_mode - 对话模式
* Metadata
  * conversation\_id - 消息所属对话的 ID
  * ls\_provider - 模型提供者
  * ls\_model\_name - 模型 ID
  * status - 消息状态
  * from\_end\_user\_id - 发送用户的 ID
  * from\_account\_id - 发送账户的 ID
  * agent\_based - 是否基于代理
  * workflow\_run\_id - 工作流运行 ID
  * from\_source - 消息来源
  * message\_id - 消息 ID

### Dataset Retrieval Trace信息

**Dataset Retrieval Trace Info**

* message\_id - 消息 ID
* inputs - 输入内容
* documents - 文档数据
* start\_time - 开始时间
* end\_time - 结束时间
* message\_data - 消息数据
* Metadata
  * message\_id 消息 ID
  * ls\_provider 模型提供者
  * ls\_model\_name 模型 ID
  * status 消息状态
  * from\_end\_user\_id 发送用户的 ID
  * from\_account\_id 发送账户的 ID
  * agent\_based 是否基于代理
  * workflow\_run\_id 工作流运行 ID
  * from\_source 消息来源

### Tool Trace信息

**Tool Trace Info**

* message\_id 消息 ID
* tool\_name 工具名称
* start\_time 开始时间
* end\_time 结束时间
* tool\_inputs 工具输入
* tool\_outputs 工具输出
* message\_data 消息数据
* error 错误信息，如果存在
* inputs 消息的输入内容
* outputs 消息的回答内容
* tool\_config 工具配置
* time\_cost 时间成本
* tool\_parameters 工具参数
* file\_url 关联文件的 URL
* Metadata
  * message\_id 消息 ID
  * tool\_name 工具名称
  * tool\_inputs 工具输入
  * tool\_outputs 工具输出
  * tool\_config 工具配置
  * time\_cost 时间成本
  * error 错误信息
  * tool\_parameters 工具参数
  * message\_file\_id 消息文件 ID
  * created\_by\_role 创建者角色
  * created\_user\_id 创建者用户 ID

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-aliyun.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 集成 Arize
> 来源：`zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-arize.mdx`

### Arize 简介

企业级LLM可观测性、在线和离线评估、监控和实验平台，基于OpenTelemetry构建，专为LLM和代理驱动的应用程序设计。

> **提示：**

Arize [官网介绍](https://arize.com)

***

### 配置 Arize

本章节将指引你注册 Arize 并将其集成至 Dify 平台内。

#### 1. 注册/登录 [Arize](https://app.arize.com/auth/join)

### 2. 获取 Arize API 密钥

从右上角的用户菜单中获取 Arize API 密钥。点击 **API Key**，然后点击 API Key 进行复制：

![](https://i.ibb.co/JwBmQxnf/dify-docs-arize-api-key.png)

### 3. 集成 Arize 与 Dify

在 Dify 应用程序中配置 Arize。打开需要监控的应用程序，在侧边菜单中打开**监控**，并在页面上选择**追踪应用性能**。

![](https://i.ibb.co/v6cL6rPs/dify-docs-arize-in-use.png)

点击配置后，将在 Arize 中创建的 **API Key**, **Space ID** 和**项目名称**粘贴到配置中并保存。

![](https://i.ibb.co/m5Xww8gL/dify-docs-arize-config.png)

成功保存后，你可以在当前页面查看监控状态。

![](https://i.ibb.co/xtggVmb7/dify-docs-arize-in-service.png)

## 监控数据列表

### **工作流/对话流追踪信息**

**用于追踪工作流和对话流**

| 工作流                              | Arize 追踪                   |
| ---------------------------------- | -------------------------- |
| workflow_app_log_id/workflow_run_id | id                         |
| user_session_id                     | - 放置在元数据中            |
| `workflow_id`                      | name                       |
| start_time                          | start_time                 |
| end_time                            | end_time                   |
| inputs                              | inputs                     |
| outputs                             | outputs                    |
| Model token consumption             | usage_metadata             |
| metadata                            | metadata                   |
| error                               | error                      |
| \[workflow]                         | tags                       |
| conversation_id/none for workflow | conversation_id in metadata |

**工作流追踪信息**

- workflow_id - 工作流唯一标识符
- conversation_id - 对话 ID
- workflow_run_id - 当前运行的 ID
- tenant_id - 租户 ID
- elapsed_time - 当前运行所用时间
- status - 运行状态
- version - 工作流版本
- total_tokens - 当前运行使用的总令牌数
- file_list - 处理的文件列表
- triggered_from - 触发当前运行的来源
- workflow_run_inputs - 当前运行的输入数据
- workflow_run_outputs - 当前运行的输出数据
- error - 当前运行期间遇到的错误
- query - 运行期间使用的查询
- workflow_app_log_id - 工作流应用程序日志 ID
- message_id - 关联的消息 ID
- start_time - 运行开始时间
- end_time - 运行结束时间
- workflow node executions - 工作流节点执行信息
- 元数据
  - workflow_id - 工作流唯一标识符
  - conversation_id - 对话 ID
  - workflow_run_id - 当前运行的 ID
  - tenant_id - 租户 ID
  - elapsed_time - 当前运行所用时间
  - status - 运行状态
  - version - 工作流版本
  - total_tokens - 当前运行使用的总令牌数
  - file_list - 处理的文件列表
  - triggered_from - 触发当前运行的来源

#### **消息追踪信息**

**用于追踪 LLM 相关对话**

| 聊天                            | Arize LLM                    |
| ------------------------------- | --------------------------- |
| message_id                      | id                          |
| user_session_id                 | - 放置在元数据中             |
| "llm"                           | name                        |
| start_time                      | start_time                  |
| end_time                        | end_time                    |
| inputs                          | inputs                      |
| outputs                         | outputs                     |
| Model token consumption         | usage_metadata              |
| metadata                        | metadata                    |
| \["message", conversation_mode] | tags                        |
| conversation_id                 | conversation_id in metadata |

**消息追踪信息**

- message_id - 消息 ID
- message_data - 消息数据
- user_session_id - 用户会话 ID
- conversation_model - 对话模式
- message_tokens - 消息中的令牌数
- answer_tokens - 答案中的令牌数
- total_tokens - 消息和答案中的总令牌数
- error - 错误信息
- inputs - 输入数据
- outputs - 输出数据
- file_list - 处理的文件列表
- start_time - 开始时间
- end_time - 结束时间
- message_file_data - 与消息关联的文件数据
- conversation_mode - 对话模式
- 元数据
  - conversation_id - 对话 ID
  - ls_provider - 模型提供商
  - ls_model_name - 模型 ID
  - status - 消息状态
  - from_end_user_id - 发送用户的 ID
  - from_account_id - 发送账户的 ID
  - agent_based - 消息是否基于代理
  - workflow_run_id - 工作流运行 ID
  - from_source - 消息来源

#### **审核追踪信息**

**用于追踪对话审核**

| 审核           | Arize Tool         |
| -------------- | ----------------- |
| user_id        | - 放置在元数据中   |
| "moderation"   | name              |
| start_time     | start_time        |
| end_time       | end_time          |
| inputs         | inputs            |
| outputs        | outputs           |
| metadata       | metadata          |
| \["moderation"]| tags              |

**审核追踪信息**

- message_id - 消息 ID
- user_id - 用户 ID
- workflow_app_log_id - 工作流应用程序日志 ID
- inputs - 审核输入数据
- message_data - 消息数据
- flagged - 内容是否被标记需要注意
- action - 采取的具体行动
- preset_response - 预设响应
- start_time - 审核开始时间
- end_time - 审核结束时间
- 元数据
  - message_id - 消息 ID
  - action - 采取的具体行动
  - preset_response - 预设响应

#### **建议问题追踪信息**

**用于追踪建议问题**

| 建议问题              | Arize LLM          |
| --------------------- | ----------------- |
| user_id               | - 放置在元数据中   |
| "suggested_question"  | name              |
| start_time            | start_time        |
| end_time              | end_time          |
| inputs                | inputs            |
| outputs               | outputs           |
| metadata              | metadata          |
| \["suggested_question"]| tags             |

**消息追踪信息**

- message_id - 消息 ID
- message_data - 消息数据
- inputs - 输入内容
- outputs - 输出内容
- start_time - 开始时间
- end_time - 结束时间
- total_tokens - 令牌数量
- status - 消息状态
- error - 错误信息
- from_account_id - 发送账户的 ID
- agent_based - 是否基于代理
- from_source - 消息来源
- model_provider - 模型提供商
- model_id - 模型 ID
- suggested_question - 建议问题
- level - 状态级别
- status_message - 状态消息
- 元数据
  - message_id - 消息 ID
  - ls_provider - 模型提供商
  - ls_model_name - 模型 ID
  - status - 消息状态
  - from_end_user_id - 发送用户的 ID
  - from_account_id - 发送账户的 ID
  - workflow_run_id - 工作流运行 ID
  - from_source - 消息来源

#### **数据集检索追踪信息**

**用于追踪知识库检索**

| 数据集检索           | Arize Retriever    |
| ------------------- | ----------------- |
| user_id             | - 放置在元数据中   |
| "dataset_retrieval" | name              |
| start_time          | start_time        |
| end_time            | end_time          |
| inputs              | inputs            |
| outputs             | outputs           |
| metadata            | metadata          |
| \["dataset_retrieval"]| tags            |
| message_id          | parent_run_id     |

**数据集检索追踪信息**

- message_id - 消息 ID
- inputs - 输入内容
- documents - 文档数据
- start_time - 开始时间
- end_time - 结束时间
- message_data - 消息数据
- 元数据
  - message_id - 消息 ID
  - ls_provider - 模型提供商
  - ls_model_name - 模型 ID
  - status - 消息状态
  - from_end_user_id - 发送用户的 ID
  - from_account_id - 发送账户的 ID
  - agent_based - 是否基于代理
  - workflow_run_id - 工作流运行 ID
  - from_source - 消息来源

#### **工具追踪信息**

**用于追踪工具调用**

| 工具                  | Arize Tool         |
| -------------------- | ----------------- |
| user_id              | - 放置在元数据中   |
| tool_name            | name              |
| start_time           | start_time        |
| end_time             | end_time          |
| inputs               | inputs            |
| outputs              | outputs           |
| metadata             | metadata          |
| \["tool", tool_name] | tags              |

#### **工具追踪信息**

- message_id - 消息 ID
- tool_name - 工具名称
- start_time - 开始时间
- end_time - 结束时间
- tool_inputs - 工具输入
- tool_outputs - 工具输出
- message_data - 消息数据
- error - 错误信息（如果有）
- inputs - 消息的输入
- outputs - 消息的输出
- tool_config - 工具配置
- time_cost - 时间消耗
- tool_parameters - 工具参数
- file_url - 关联文件的 URL
- 元数据
  - message_id - 消息 ID
  - tool_name - 工具名称
  - tool_inputs - 工具输入
  - tool_outputs - 工具输出
  - tool_config - 工具配置
  - time_cost - 时间消耗
  - error - 错误信息（如果有）
  - tool_parameters - 工具参数
  - message_file_id - 消息文件 ID
  - created_by_role - 创建者角色
  - created_user_id - 创建者用户 ID

#### **生成名称追踪信息**

**用于追踪对话标题生成**

| 生成名称                      | Arize Tool         |
| ---------------------------- | ----------------- |
| user_id                      | - 放置在元数据中   |
| "generate_conversation_name" | name              |
| start_time                   | start_time        |
| end_time                     | end_time          |
| inputs                       | inputs            |
| outputs                      | outputs           |
| metadata                     | metadata          |
| \["generate_name"]           | tags              |

**生成名称追踪信息**

- conversation_id - 对话 ID
- inputs - 输入数据
- outputs - 生成的对话名称
- start_time - 开始时间
- end_time - 结束时间
- tenant_id - 租户 ID
- 元数据
  - conversation_id - 对话 ID
  - tenant_id - 租户 ID

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-arize.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 集成 Langfuse
> 来源：`zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-langfuse.mdx`

### Langfuse 简介

Langfuse 是一个开源的 LLM 工程平台，可以帮助团队协作调试、分析和迭代他们的应用程序。

> **提示：info**

Langfuse 官网介绍：[https://langfuse.com/](https://langfuse.com/)

***

### 配置 Langfuse

1. 在 [官网注册](https://langfuse.com/) 并登录 Langfuse
2. 在 Langfuse 内创建项目，登录后在主页点击 **New** ，创建一个自己的项目，**项目** 将用于与 Dify 内的 **应用** 关联进行数据监测。

  ![Langfuse 创建项目界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/75bed34765ed7d0e933a0069ecb094dd.png)

为项目编辑一个名称。

  ![Langfuse 项目命名界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/26cfbb94e312a100c39e217fdd0b4406.png)

3. 创建项目 API 凭据，在项目内左侧边栏中点击 **Settings** 打开设置

  ![Langfuse 项目设置界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/2ed72a6761f2977201c29e67e5bc634c.png)

在 Settings 内点击 **Create API Keys** 创建一个项目 API 凭据。

  ![Langfuse 创建 API 凭据界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/3c3fbd5392d37fbccf1f9ef76c54f0bc.png)

复制并保存 **Secret Key** ，**Public Key，Host**

  ![Langfuse API Key 配置界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/a2ff67951ce300082d875eae8458c8c7.png)

4. 在 Dify 内配置 Langfuse，打开需要监测的应用，在侧边菜单打开 **监测 **，在页面中选择 **配置。**

  ![Dify 监测配置界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/0eea1c32267c651ea799cbb6ad1f5052.png)

点击配置后，将在 Langfuse 内创建的 **Secret Key, Public Key, Host** 粘贴到配置内并保存。

  ![Dify Langfuse 配置界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/fe19c8989b14e80420beb3d704b518db.png)

成功保存后可以在当前页面查看到状态，显示已启动即正在监测。

  ![Dify Langfuse 配置状态界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/9caa62e2a91f1f8470b4fa13a104251c.png)

***

### 在 Langfuse 内查看监测数据

配置完成后， Dify 内应用的调试或生产数据可以在 Langfuse 查看监测数据。

  ![Dify 应用调试界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/3021f46e89ea94af506b1436891c1a56.png)

  ![Langfuse 应用数据监测界面 1](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/b5b48b5a3a1a917f137171290e1c3b0c.png)

  ![Langfuse 应用数据监测界面 2](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/de3b4e21db7fd39b4fa4cb4d54d1079e.png)

### 监测数据清单

#### Workflow /Chatflow Trace信息

**用于追踪workflow以及chatflow**

| Workflow                                 | LangFuse Trace          |
| ---------------------------------------- | ----------------------- |
| workflow\_app\_log\_id/workflow\_run\_id | id                      |
| user\_session\_id                        | user\_id                |
| workflow\_id                           | name                    |
| start\_time                              | start\_time             |
| end\_time                                | end\_time               |
| inputs                                   | input                   |
| outputs                                  | output                  |
| 模型 token 消耗相关                              | usage                   |
| metadata                                 | metadata                |
| error                                    | level                   |
| error                                    | status\_message         |
| \[workflow]                              | tags                    |
| conversation\_id/workflow 时无              | session\_id             |
| conversion\_id                           | parent\_observation\_id |

**Workflow Trace Info**

* workflow\_id - Workflow 的唯一标识
* conversation\_id - 对话 ID
* workflow\_run\_id - 此次运行的 ID
* tenant\_id - 租户 ID
* elapsed\_time - 此次运行耗时
* status - 运行状态
* version - Workflow 版本
* total\_tokens - 此次运行使用的 token 总数
* file\_list - 处理的文件列表
* triggered\_from - 触发此次运行的来源
* workflow\_run\_inputs - 此次运行的输入数据
* workflow\_run\_outputs - 此次运行的输出数据
* error - 此次运行中发生的错误
* query - 运行时使用的查询
* workflow\_app\_log\_id - Workflow 应用日志 ID
* message\_id - 关联的消息 ID
* start\_time - 运行开始时间
* end\_time - 运行结束时间
* workflow node executions - workflow 节点运行信息
* Metadata
  * workflow\_id - Workflow 的唯一标识
  * conversation\_id - 对话 ID
  * workflow\_run\_id - 此次运行的 ID
  * tenant\_id - 租户 ID
  * elapsed\_time - 此次运行耗时
  * status - 运行状态
  * version - Workflow 版本
  * total\_tokens - 此次运行使用的 token 总数
  * file\_list - 处理的文件列表
  * triggered\_from - 触发来源

#### Message Trace信息

**用于追踪llm对话相关**

| Message                          | LangFuse Generation/Trace |
| -------------------------------- | ------------------------- |
| message\_id                      | id                        |
| user\_session\_id                | user\_id                  |
| message\_id                    | name                      |
| start\_time                      | start\_time               |
| end\_time                        | end\_time                 |
| inputs                           | input                     |
| outputs                          | output                    |
| 模型 token 消耗相关                      | usage                     |
| metadata                         | metadata                  |
| error                            | level                     |
| error                            | status\_message           |
| \["message", conversation\_mode] | tags                      |
| conversation\_id                 | session\_id               |
| conversion\_id                   | parent\_observation\_id   |

**Message Trace Info**

* message\_id - 消息 ID
* message\_data - 消息数据
* user\_session\_id - 用户的 session\_id
* conversation\_model - 对话模式
* message\_tokens - 消息中的令牌数
* answer\_tokens - 回答中的令牌数
* total\_tokens - 消息和回答中的总令牌数
* error - 错误信息
* inputs - 输入数据
* outputs - 输出数据
* file\_list - 处理的文件列表
* start\_time - 开始时间
* end\_time - 结束时间
* message\_file\_data - 消息关联的文件数据
* conversation\_mode - 对话模式
* Metadata
  * conversation\_id - 消息所属对话的 ID
  * ls\_provider - 模型提供者
  * ls\_model\_name - 模型 ID
  * status - 消息状态
  * from\_end\_user\_id - 发送用户的 ID
  * from\_account\_id - 发送账户的 ID
  * agent\_based - 是否基于代理
  * workflow\_run\_id - 工作流运行 ID
  * from\_source - 消息来源
  * message\_id - 消息 ID

#### Moderation Trace信息

**用于追踪对话审查**

| Moderation    | LangFuse Generation/Trace |
| ------------- | ------------------------- |
| user\_id      | user\_id                  |
| moderation    | name                      |
| start\_time   | start\_time               |
| end\_time     | end\_time                 |
| inputs        | input                     |
| outputs       | output                    |
| metadata      | metadata                  |
| \[moderation] | tags                      |
| message\_id   | parent\_observation\_id   |

**Message Trace Info**

* message\_id - 消息 ID
* user\_id: 用户 id
* workflow\_app\_log\_id workflow\_app\_log\_id
* inputs - 审查的输入数据
* message\_data - 消息数据
* flagged - 是否被标记为需要注意的内容
* action - 执行的具体行动
* preset\_response - 预设响应
* start\_time - 审查开始时间
* end\_time - 审查结束时间
* Metadata
  * message\_id - 消息 ID
  * action - 执行的具体行动
  * preset\_response - 预设响应

#### Suggested Question Trace信息

**用于追踪建议问题**

| Suggested Question     | LangFuse Generation/Trace |
| ---------------------- | ------------------------- |
| user\_id               | user\_id                  |
| suggested\_question    | name                      |
| start\_time            | start\_time               |
| end\_time              | end\_time                 |
| inputs                 | input                     |
| outputs                | output                    |
| metadata               | metadata                  |
| \[suggested\_question] | tags                      |
| message\_id            | parent\_observation\_id   |

**Message Trace Info**

* message\_id - 消息 ID
* message\_data - 消息数据
* inputs - 输入的内容
* outputs - 输出的内容
* start\_time - 开始时间
* end\_time - 结束时间
* total\_tokens - 令牌数量
* status - 消息状态
* error - 错误信息
* from\_account\_id - 发送账户的 ID
* agent\_based - 是否基于代理
* from\_source - 消息来源
* model\_provider - 模型提供者
* model\_id - 模型 ID
* suggested\_question - 建议的问题
* level - 状态级别
* status\_message - 状态信息
* Metadata
  * message\_id - 消息 ID
  * ls\_provider - 模型提供者
  * ls\_model\_name - 模型 ID
  * status - 消息状态
  * from\_end\_user\_id - 发送用户的 ID
  * from\_account\_id - 发送账户的 ID
  * workflow\_run\_id - 工作流运行 ID
  * from\_source - 消息来源

#### Dataset Retrieval Trace信息

**用于追踪知识库检索**

| Dataset Retrieval     | LangFuse Generation/Trace |
| --------------------- | ------------------------- |
| user\_id              | user\_id                  |
| dataset\_retrieval    | name                      |
| start\_time           | start\_time               |
| end\_time             | end\_time                 |
| inputs                | input                     |
| outputs               | output                    |
| metadata              | metadata                  |
| \[dataset\_retrieval] | tags                      |
| message\_id           | parent\_observation\_id   |

**Dataset Retrieval Trace Info**

* message\_id - 消息 ID
* inputs - 输入内容
* documents - 文档数据
* start\_time - 开始时间
* end\_time - 结束时间
* message\_data - 消息数据
* Metadata
  * message\_id 消息 ID
  * ls\_provider 模型提供者
  * ls\_model\_name 模型 ID
  * status 消息状态
  * from\_end\_user\_id 发送用户的 ID
  * from\_account\_id 发送账户的 ID
  * agent\_based 是否基于代理
  * workflow\_run\_id 工作流运行 ID
  * from\_source 消息来源

#### Tool Trace信息

**用于追踪工具调用**

| Tool                  | LangFuse Generation/Trace |
| --------------------- | ------------------------- |
| user\_id              | user\_id                  |
| tool\_name            | name                      |
| start\_time           | start\_time               |
| end\_time             | end\_time                 |
| inputs                | input                     |
| outputs               | output                    |
| metadata              | metadata                  |
| \["tool", tool\_name] | tags                      |
| message\_id           | parent\_observation\_id   |

**Tool Trace Info**

* message\_id 消息 ID
* tool\_name 工具名称
* start\_time 开始时间
* end\_time 结束时间
* tool\_inputs 工具输入
* tool\_outputs 工具输出
* message\_data 消息数据
* error 错误信息，如果存在
* inputs 消息的输入内容
* outputs 消息的回答内容
* tool\_config 工具配置
* time\_cost 时间成本
* tool\_parameters 工具参数
* file\_url 关联文件的 URL
* Metadata
  * message\_id 消息 ID
  * tool\_name 工具名称
  * tool\_inputs 工具输入
  * tool\_outputs 工具输出
  * tool\_config 工具配置
  * time\_cost 时间成本
  * error 错误信息
  * tool\_parameters 工具参数
  * message\_file\_id 消息文件 ID
  * created\_by\_role 创建者角色
  * created\_user\_id 创建者用户 ID

#### Generate Name Trace信息

**用于追踪会话标题生成**

| Generate Name     | LangFuse Generation/Trace |
| ----------------- | ------------------------- |
| user\_id          | user\_id                  |
| generate\_name    | name                      |
| start\_time       | start\_time               |
| end\_time         | end\_time                 |
| inputs            | input                     |
| outputs           | output                    |
| metadata          | metadata                  |
| \[generate\_name] | tags                      |

**Generate Name Trace Info**

* conversation\_id 对话 ID
* inputs 输入数据
* outputs 生成的会话名称
* start\_time 开始时间
* end\_time 结束时间
* tenant\_id 租户 ID
* Metadata
  * conversation\_id 对话 ID
  * tenant\_id 租户 ID

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-langfuse.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 集成 LangSmith
> 来源：`zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-langsmith.mdx`

### LangSmith 简介

LangSmith 是一个用于构建生产级 LLM 应用程序的平台，它用于开发、协作、测试、部署和监控 LLM 应用程序。

> **提示：**

LangSmith [官网介绍](https://www.langchain.com/langsmith)

***

### 配置 LangSmith

本章节将指引你注册 LangSmith 并将其集成至 Dify 平台内。

#### 1. 注册/登录 [LangSmith](https://www.langchain.com/langsmith)

#### 2. 创建项目

在 LangSmith 内创建项目，登录后在主页点击 **New Project** 创建一个自己的项目，**项目**将用于与 Dify 内的**应用**关联进行数据监测。

  ![LangSmith 创建项目界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/58e20105fcc0771ca2431e8e5dcc42d3.png)

创建完成之后在 Projects 内可以查看该项目。

  ![LangSmith 项目列表界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/642c0ff7edfdfe77fba43aa22cc3fa71.png)

#### 3. 创建项目凭据

创建项目凭据，在左侧边栏内找到项目设置 **Settings**。

  ![LangSmith 项目设置界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/c49a1fc769215193928ff0d880422f89.png)

点击 **Create API Key**，创建一个项目凭据。

  ![LangSmith 创建 API Key 界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/7082286b0d12af4bc0c84d9a3acf8b1b.png)

选择 **Personal Access Token** ，用于后续的 API 身份校验。

  ![LangSmith 选择 API Key 类型界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/75a69bd4dd02f0ffc0313589ae12fb36.png)

将创建的 API key 复制保存。

  ![LangSmith API Key 复制界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/723e96a13e8f722d6df714b11ffd0bb1.png)

#### 4. 将 LangSmith 集成至 Dify 平台

在 Dify 应用内配置 LangSmith。打开需要监测的应用，在左侧边菜单内打开**监测**，点击页面内的**配置。**

  ![Dify 配置 LangSmith 入口界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/b6578e410979cdb9da901aedc94a444d.png)

点击配置后，将在 LangSmith 内创建的 **API Key** 和**项目名**粘贴到配置内并保存。

  ![Dify 配置 LangSmith 详情界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/27173b2503ca7241b084f7cbd17cdb4c.png)

> **提示：**

配置项目名需要与 LangSmith 内设置的项目一致，若项目名不一致，数据同步时 LangSmith 会自动创建一个新的项目。

成功保存后可以在当前页面查看监测状态。

  ![Dify LangSmith 配置状态界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/a4e9df6427c7914e1eef6af78d71f408.png)

### 在 LangSmith 内查看监测数据

配置完成后， Dify 内应用的调试或生产数据可以在 LangSmith 查看监测数据。

  ![Dify 应用调试界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/a0e7b21d56ecf9313f1bd48913f0a74b.png)

  ![LangSmith 应用数据监测界面1](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/2833b2ffa20927b5328e9624b065beea.png)

  ![LangSmith 应用数据监测界面2](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/monitoring/integrate-external-ops-tools/c40e522f1ffe9fc50411dd7feaf937ed.png)

### 监测数据清单

#### Workflow /Chatflow Trace信息

**用于追踪workflow以及chatflow**

| Workflow                                 | LangSmith Chain            |
| ---------------------------------------- | -------------------------- |
| workflow\_app\_log\_id/workflow\_run\_id | id                         |
| user\_session\_id                        | -放入metadata                |
| workflow\_id                           | name                       |
| start\_time                              | start\_time                |
| end\_time                                | end\_time                  |
| inputs                                   | inputs                     |
| outputs                                  | outputs                    |
| 模型token消耗相关                              | usage\_metadata            |
| metadata                                 | extra                      |
| error                                    | error                      |
| \[workflow]                              | tags                       |
| "conversation\_id/workflow时无"            | metadata中的conversation\_id |
| conversion\_id                           | parent\_run\_id            |

**Workflow Trace Info**

* workflow\_id - Workflow的唯一标识
* conversation\_id - 对话ID
* workflow\_run\_id - 此次运行的ID
* tenant\_id - 租户ID
* elapsed\_time - 此次运行耗时
* status - 运行状态
* version - Workflow版本
* total\_tokens - 此次运行使用的token总数
* file\_list - 处理的文件列表
* triggered\_from - 触发此次运行的来源
* workflow\_run\_inputs - 此次运行的输入数据
* workflow\_run\_outputs - 此次运行的输出数据
* error - 此次运行中发生的错误
* query - 运行时使用的查询
* workflow\_app\_log\_id - Workflow应用日志ID
* message\_id - 关联的消息ID
* start\_time - 运行开始时间
* end\_time - 运行结束时间
* workflow node executions - workflow节点运行信息
* Metadata
  * workflow\_id - Workflow的唯一标识
  * conversation\_id - 对话ID
  * workflow\_run\_id - 此次运行的ID
  * tenant\_id - 租户ID
  * elapsed\_time - 此次运行耗时
  * status - 运行状态
  * version - Workflow版本
  * total\_tokens - 此次运行使用的token总数
  * file\_list - 处理的文件列表
  * triggered\_from - 触发来源

#### Message Trace信息

**用于追踪llm对话相关**

| Chat                             | LangSmith LLM              |
| -------------------------------- | -------------------------- |
| message\_id                      | id                         |
| user\_session\_id                | -放入metadata                |
| “message\_id"                  | name                       |
| start\_time                      | start\_time                |
| end\_time                        | end\_time                  |
| inputs                           | inputs                     |
| outputs                          | outputs                    |
| 模型token消耗相关                      | usage\_metadata            |
| metadata                         | extra                      |
| error                            | error                      |
| \["message", conversation\_mode] | tags                       |
| conversation\_id                 | metadata中的conversation\_id |
| conversion\_id                   | parent\_run\_id            |

**Message Trace Info**

* message\_id - 消息ID
* message\_data - 消息数据
* user\_session\_id - 用户的session\_id
* conversation\_model - 对话模式
* message\_tokens - 消息中的令牌数
* answer\_tokens - 回答中的令牌数
* total\_tokens - 消息和回答中的总令牌数
* error - 错误信息
* inputs - 输入数据
* outputs - 输出数据
* file\_list - 处理的文件列表
* start\_time - 开始时间
* end\_time - 结束时间
* message\_file\_data - 消息关联的文件数据
* conversation\_mode - 对话模式
* Metadata
  * conversation\_id - 消息所属对话的ID
  * ls\_provider - 模型提供者
  * ls\_model\_name - 模型ID
  * status - 消息状态
  * from\_end\_user\_id - 发送用户的ID
  * from\_account\_id - 发送账户的ID
  * agent\_based - 是否基于代理
  * workflow\_run\_id - 工作流运行ID
  * from\_source - 消息来源
  * message\_id - 消息ID

#### Moderation Trace信息

**用于追踪对话审查**

| Moderation    | LangSmith Tool  |
| ------------- | --------------- |
| user\_id      | -放入metadata     |
| “moderation"  | name            |
| start\_time   | start\_time     |
| end\_time     | end\_time       |
| inputs        | inputs          |
| outputs       | outputs         |
| metadata      | extra           |
| \[moderation] | tags            |
| message\_id   | parent\_run\_id |

**Message Trace Info**

* message\_id - 消息ID
* user\_id: 用户id
* workflow\_app\_log\_id workflow\_app\_log\_id
* inputs - 审查的输入数据
* message\_data - 消息数据
* flagged - 是否被标记为需要注意的内容
* action - 执行的具体行动
* preset\_response - 预设响应
* start\_time - 审查开始时间
* end\_time - 审查结束时间
* Metadata
  * message\_id - 消息ID
  * action - 执行的具体行动
  * preset\_response - 预设响应

#### Suggested Question Trace信息

**用于追踪建议问题**

| Suggested Question     | LangSmith LLM   |
| ---------------------- | --------------- |
| user\_id               | -放入metadata     |
| suggested\_question    | name            |
| start\_time            | start\_time     |
| end\_time              | end\_time       |
| inputs                 | inputs          |
| outputs                | outputs         |
| metadata               | extra           |
| \[suggested\_question] | tags            |
| message\_id            | parent\_run\_id |

**Message Trace Info**

* message\_id - 消息ID
* message\_data - 消息数据
* inputs - 输入的内容
* outputs - 输出的内容
* start\_time - 开始时间
* end\_time - 结束时间
* total\_tokens - 令牌数量
* status - 消息状态
* error - 错误信息
* from\_account\_id - 发送账户的ID
* agent\_based - 是否基于代理
* from\_source - 消息来源
* model\_provider - 模型提供者
* model\_id - 模型ID
* suggested\_question - 建议的问题
* level - 状态级别
* status\_message - 状态信息
* Metadata
  * message\_id - 消息ID
  * ls\_provider - 模型提供者
  * ls\_model\_name - 模型ID
  * status - 消息状态
  * from\_end\_user\_id - 发送用户的ID
  * from\_account\_id - 发送账户的ID
  * workflow\_run\_id - 工作流运行ID
  * from\_source - 消息来源

#### Dataset Retrieval Trace信息

**用于追踪知识库检索**

| Dataset Retrieval     | LangSmith Retriever |
| --------------------- | ------------------- |
| user\_id              | -放入metadata         |
| dataset\_retrieval    | name                |
| start\_time           | start\_time         |
| end\_time             | end\_time           |
| inputs                | inputs              |
| outputs               | outputs             |
| metadata              | extra               |
| \[dataset\_retrieval] | tags                |
| message\_id           | parent\_run\_id     |

**Dataset Retrieval Trace Info**

* message\_id - 消息ID
* inputs - 输入内容
* documents - 文档数据
* start\_time - 开始时间
* end\_time - 结束时间
* message\_data - 消息数据
* Metadata
  * message\_id消息ID
  * ls\_provider模型提供者
  * ls\_model\_name模型ID
  * status消息状态
  * from\_end\_user\_id发送用户的ID
  * from\_account\_id发送账户的ID
  * agent\_based是否基于代理
  * workflow\_run\_id工作流运行ID
  * from\_source消息来源

#### Tool Trace信息

**用于追踪工具调用**

| Tool                  | LangSmith Tool  |
| --------------------- | --------------- |
| user\_id              | -放入metadata     |
| tool\_name            | name            |
| start\_time           | start\_time     |
| end\_time             | end\_time       |
| inputs                | inputs          |
| outputs               | outputs         |
| metadata              | extra           |
| \["tool", tool\_name] | tags            |
| message\_id           | parent\_run\_id |

**Tool Trace Info**

* message\_id消息ID
* tool\_name工具名称
* start\_time开始时间
* end\_time结束时间
* tool\_inputs工具输入
* tool\_outputs工具输出
* message\_data消息数据
* error错误信息，如果存在
* inputs消息的输入内容
* outputs消息的回答内容
* tool\_config工具配置
* time\_cost时间成本
* tool\_parameters工具参数
* file\_url关联文件的URL
* Metadata
  * message\_id消息ID
  * tool\_name工具名称
  * tool\_inputs工具输入
  * tool\_outputs工具输出
  * tool\_config工具配置
  * time\_cost时间成本
  * error错误信息
  * tool\_parameters工具参数
  * message\_file\_id消息文件ID
  * created\_by\_role创建者角色
  * created\_user\_id创建者用户ID

#### Generate Name Trace信息

**用于追踪会话标题生成**

| Generate Name     | LangSmith Tool |
| ----------------- | -------------- |
| user\_id          | -放入metadata    |
| generate\_name    | name           |
| start\_time       | start\_time    |
| end\_time         | end\_time      |
| inputs            | inputs         |
| outputs           | outputs        |
| metadata          | extra          |
| \[generate\_name] | tags           |

**Generate Name Trace Info**

* conversation\_id对话ID
* inputs输入数据
* outputs生成的会话名称
* start\_time开始时间
* end\_time结束时间
* tenant\_id租户ID
* Metadata
  * conversation\_id对话ID
  * tenant\_id租户ID

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-langsmith.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 集成 Opik
> 来源：`zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-opik.mdx`

## Opik 简介

Opik 是一个开源的 LLM 评估平台，用于评估、测试和监控大型语言模型（LLM）应用。它由 Comet 开发，旨在促进对基于 LLM 的应用程序进行更直观的协作、测试和监控。

> **信息提示：**

如需了解更多详情，请参考 [Opik](https://www.comet.com/site/products/opik/)。

---

## 开始配置 Opik

### 1. 注册/登录 [Opik](https://www.comet.com/signup?from=llm)

### 2. 获取 Opik API 密钥

从右上角的用户菜单中获取 Opik API 密钥。点击 **API Key**，然后点击 API Key 进行复制：

![](https://assets-docs.dify.ai/2025/01/a66603f01e4ffaa593a8b78fcf3f8204.png)

### 3. 集成 Opik 与 Dify

在 Dify 应用程序中配置 Opik。打开需要监控的应用程序，在侧边菜单中打开**监控**，并在页面上选择**追踪应用性能**。

![](https://assets-docs.dify.ai/2025/01/9d52a244e3b6cef1874ee838cd976111.png)

点击配置后，将在 Opik 中创建的 **API Key** 和**项目名称**粘贴到配置中并保存。

![](https://assets-docs.dify.ai/2025/01/7f4c436e2dc9fe94a3ed49219bb3360c.png)

成功保存后，你可以在当前页面查看监控状态。

## 查看监控数据

配置完成后，你可以照常调试或使用 Dify 应用程序。所有使用历史都可以在 Opik 中监控。

![](https://assets-docs.dify.ai/2025/01/a1c5aa80325e6d0223d48a178393baec.png)

当你切换到 Opik 时，可以在仪表板中查看 Dify 应用程序的详细操作日志。

![](https://assets-docs.dify.ai/2025/01/09601d45eaf8ed90a4dfb07c34de36ff.png)

通过 Opik 的详细 LLM 操作日志将帮助你优化 Dify 应用程序的性能。

![](https://assets-docs.dify.ai/2025/01/708533b4fc616f852b5601fe602e3ef5.png)

## 监控数据列表

### **工作流/对话流追踪信息**

**用于追踪工作流和对话流**

| 工作流                              | Opik 追踪                   |
| ---------------------------------- | -------------------------- |
| workflow_app_log_id/workflow_run_id | id                         |
| user_session_id                     | - 放置在元数据中            |
| `workflow_id`                      | name                       |
| start_time                          | start_time                 |
| end_time                            | end_time                   |
| inputs                              | inputs                     |
| outputs                             | outputs                    |
| Model token consumption             | usage_metadata             |
| metadata                            | metadata                   |
| error                               | error                      |
| \[workflow]                         | tags                       |
| conversation_id/none for workflow | conversation_id in metadata |

**工作流追踪信息**

- workflow_id - 工作流唯一标识符
- conversation_id - 对话 ID
- workflow_run_id - 当前运行的 ID
- tenant_id - 租户 ID
- elapsed_time - 当前运行所用时间
- status - 运行状态
- version - 工作流版本
- total_tokens - 当前运行使用的总令牌数
- file_list - 处理的文件列表
- triggered_from - 触发当前运行的来源
- workflow_run_inputs - 当前运行的输入数据
- workflow_run_outputs - 当前运行的输出数据
- error - 当前运行期间遇到的错误
- query - 运行期间使用的查询
- workflow_app_log_id - 工作流应用程序日志 ID
- message_id - 关联的消息 ID
- start_time - 运行开始时间
- end_time - 运行结束时间
- workflow node executions - 工作流节点执行信息
- 元数据
  - workflow_id - 工作流唯一标识符
  - conversation_id - 对话 ID
  - workflow_run_id - 当前运行的 ID
  - tenant_id - 租户 ID
  - elapsed_time - 当前运行所用时间
  - status - 运行状态
  - version - 工作流版本
  - total_tokens - 当前运行使用的总令牌数
  - file_list - 处理的文件列表
  - triggered_from - 触发当前运行的来源

#### **消息追踪信息**

**用于追踪 LLM 相关对话**

| 聊天                            | Opik LLM                    |
| ------------------------------- | --------------------------- |
| message_id                      | id                          |
| user_session_id                 | - 放置在元数据中             |
| "llm"                           | name                        |
| start_time                      | start_time                  |
| end_time                        | end_time                    |
| inputs                          | inputs                      |
| outputs                         | outputs                     |
| Model token consumption         | usage_metadata              |
| metadata                        | metadata                    |
| \["message", conversation_mode] | tags                        |
| conversation_id                 | conversation_id in metadata |

**消息追踪信息**

- message_id - 消息 ID
- message_data - 消息数据
- user_session_id - 用户会话 ID
- conversation_model - 对话模式
- message_tokens - 消息中的令牌数
- answer_tokens - 答案中的令牌数
- total_tokens - 消息和答案中的总令牌数
- error - 错误信息
- inputs - 输入数据
- outputs - 输出数据
- file_list - 处理的文件列表
- start_time - 开始时间
- end_time - 结束时间
- message_file_data - 与消息关联的文件数据
- conversation_mode - 对话模式
- 元数据
  - conversation_id - 对话 ID
  - ls_provider - 模型提供商
  - ls_model_name - 模型 ID
  - status - 消息状态
  - from_end_user_id - 发送用户的 ID
  - from_account_id - 发送账户的 ID
  - agent_based - 消息是否基于代理
  - workflow_run_id - 工作流运行 ID
  - from_source - 消息来源

#### **审核追踪信息**

**用于追踪对话审核**

| 审核           | Opik Tool         |
| -------------- | ----------------- |
| user_id        | - 放置在元数据中   |
| "moderation"   | name              |
| start_time     | start_time        |
| end_time       | end_time          |
| inputs         | inputs            |
| outputs        | outputs           |
| metadata       | metadata          |
| \["moderation"]| tags              |

**审核追踪信息**

- message_id - 消息 ID
- user_id - 用户 ID
- workflow_app_log_id - 工作流应用程序日志 ID
- inputs - 审核输入数据
- message_data - 消息数据
- flagged - 内容是否被标记需要注意
- action - 采取的具体行动
- preset_response - 预设响应
- start_time - 审核开始时间
- end_time - 审核结束时间
- 元数据
  - message_id - 消息 ID
  - action - 采取的具体行动
  - preset_response - 预设响应

#### **建议问题追踪信息**

**用于追踪建议问题**

| 建议问题              | Opik LLM          |
| --------------------- | ----------------- |
| user_id               | - 放置在元数据中   |
| "suggested_question"  | name              |
| start_time            | start_time        |
| end_time              | end_time          |
| inputs                | inputs            |
| outputs               | outputs           |
| metadata              | metadata          |
| \["suggested_question"]| tags             |

**消息追踪信息**

- message_id - 消息 ID
- message_data - 消息数据
- inputs - 输入内容
- outputs - 输出内容
- start_time - 开始时间
- end_time - 结束时间
- total_tokens - 令牌数量
- status - 消息状态
- error - 错误信息
- from_account_id - 发送账户的 ID
- agent_based - 是否基于代理
- from_source - 消息来源
- model_provider - 模型提供商
- model_id - 模型 ID
- suggested_question - 建议问题
- level - 状态级别
- status_message - 状态消息
- 元数据
  - message_id - 消息 ID
  - ls_provider - 模型提供商
  - ls_model_name - 模型 ID
  - status - 消息状态
  - from_end_user_id - 发送用户的 ID
  - from_account_id - 发送账户的 ID
  - workflow_run_id - 工作流运行 ID
  - from_source - 消息来源

#### **数据集检索追踪信息**

**用于追踪知识库检索**

| 数据集检索           | Opik Retriever    |
| ------------------- | ----------------- |
| user_id             | - 放置在元数据中   |
| "dataset_retrieval" | name              |
| start_time          | start_time        |
| end_time            | end_time          |
| inputs              | inputs            |
| outputs             | outputs           |
| metadata            | metadata          |
| \["dataset_retrieval"]| tags            |
| message_id          | parent_run_id     |

**数据集检索追踪信息**

- message_id - 消息 ID
- inputs - 输入内容
- documents - 文档数据
- start_time - 开始时间
- end_time - 结束时间
- message_data - 消息数据
- 元数据
  - message_id - 消息 ID
  - ls_provider - 模型提供商
  - ls_model_name - 模型 ID
  - status - 消息状态
  - from_end_user_id - 发送用户的 ID
  - from_account_id - 发送账户的 ID
  - agent_based - 是否基于代理
  - workflow_run_id - 工作流运行 ID
  - from_source - 消息来源

#### **工具追踪信息**

**用于追踪工具调用**

| 工具                  | Opik Tool         |
| -------------------- | ----------------- |
| user_id              | - 放置在元数据中   |
| tool_name            | name              |
| start_time           | start_time        |
| end_time             | end_time          |
| inputs               | inputs            |
| outputs              | outputs           |
| metadata             | metadata          |
| \["tool", tool_name] | tags              |

#### **工具追踪信息**

- message_id - 消息 ID
- tool_name - 工具名称
- start_time - 开始时间
- end_time - 结束时间
- tool_inputs - 工具输入
- tool_outputs - 工具输出
- message_data - 消息数据
- error - 错误信息（如果有）
- inputs - 消息的输入
- outputs - 消息的输出
- tool_config - 工具配置
- time_cost - 时间消耗
- tool_parameters - 工具参数
- file_url - 关联文件的 URL
- 元数据
  - message_id - 消息 ID
  - tool_name - 工具名称
  - tool_inputs - 工具输入
  - tool_outputs - 工具输出
  - tool_config - 工具配置
  - time_cost - 时间消耗
  - error - 错误信息（如果有）
  - tool_parameters - 工具参数
  - message_file_id - 消息文件 ID
  - created_by_role - 创建者角色
  - created_user_id - 创建者用户 ID

#### **生成名称追踪信息**

**用于追踪对话标题生成**

| 生成名称                      | Opik Tool         |
| ---------------------------- | ----------------- |
| user_id                      | - 放置在元数据中   |
| "generate_conversation_name" | name              |
| start_time                   | start_time        |
| end_time                     | end_time          |
| inputs                       | inputs            |
| outputs                      | outputs           |
| metadata                     | metadata          |
| \["generate_name"]           | tags              |

**生成名称追踪信息**

- conversation_id - 对话 ID
- inputs - 输入数据
- outputs - 生成的对话名称
- start_time - 开始时间
- end_time - 结束时间
- tenant_id - 租户 ID
- 元数据
  - conversation_id - 对话 ID
  - tenant_id - 租户 ID

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-opik.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 集成 Phoenix
> 来源：`zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-phoenix.mdx`

### Phoenix 简介

开源且基于OpenTelemetry的可观测性、评估、提示工程和实验平台，适用于您的LLM工作流程和代理。

> **提示：**

Phoenix [官网介绍](https://phoenix.arize.com)

***

### 配置 Phoenix

本章节将指引你注册 Phoenix 并将其集成至 Dify 平台内。

#### 1. 注册/登录 [Phoenix](https://app.arize.com/auth/phoenix/signup)

### 2. 获取 Phoenix API 密钥

从右上角的用户菜单中获取 Phoenix API 密钥。点击 **API Key**，然后点击 API Key 进行复制：

![](https://i.ibb.co/pB1W0pk8/dify-docs-phoenix-api-key.png)

### 3. 集成 Phoenix 与 Dify

在 Dify 应用程序中配置 Phoenix。打开需要监控的应用程序，在侧边菜单中打开**监控**，并在页面上选择**追踪应用性能**。

![](https://i.ibb.co/gMmXxfhQ/dify-docs-phoenix-in-use.png)

点击配置后，将在 Phoenix 中创建的 **API Key** 和**项目名称**粘贴到配置中并保存。

![](https://i.ibb.co/jv6QFbp7/dify-docs-phoenix-config.png)

成功保存后，你可以在当前页面查看监控状态。

![](https://i.ibb.co/HTJsj9x2/dify-docs-phoenix-in-service.png)

### 配置 Phoenix Cloud

本章节将指引你注册 Phoenix Cloud 并将其集成至 Dify 平台内。

#### 1. 注册/登录 [Phoenix Cloud](https://app.arize.com/auth/phoenix/signup)

### 2. 创建你的 Phoenix 空间

你可以在右上角的用户菜单中创建 Phoenix 空间。点击 创建空间，然后为你的空间提供一个唯一的 URL 标识符：

![](https://i.ibb.co/7JYPzZBf/dify-docs-phoenix-cloud-create-space.png)

保存成功后，你可以在概览页面查看空间的状态。

![](https://i.ibb.co/Z6RqMhhq/dify-docs-phoenix-cloud-space-overview.png)

### 3. 创建你的 Phoenix API 密钥

启动空间后，你可以在左下角的用户菜单中点击 设置 来创建 Phoenix API 密钥。点击 系统密钥，然后为你的 API 密钥命名：

![](https://i.ibb.co/SXMyX9K3/dify-docs-phoenix-cloud-api-key.png)

### 4. 集成 Phoenix Cloud 与 Dify

在 Dify 应用程序中配置 Phoenix。打开需要监控的应用程序，在侧边菜单中打开**监控**，并在页面上选择**追踪应用性能**。

![](https://i.ibb.co/gMmXxfhQ/dify-docs-phoenix-in-use.png)

点击配置后，粘贴从 Phoenix Cloud 中获取的 API 密钥、项目名称 和 空间主机名 到配置项中并保存。

![](https://i.ibb.co/jv6QFbp7/dify-docs-phoenix-config.png)

成功保存后，你可以在当前页面查看监控状态。

![](https://i.ibb.co/HTJsj9x2/dify-docs-phoenix-in-service.png)

## 监控数据列表

### **工作流/对话流追踪信息**

**用于追踪工作流和对话流**

| 工作流                              | Phoenix 追踪                   |
| ---------------------------------- | -------------------------- |
| workflow_app_log_id/workflow_run_id | id                         |
| user_session_id                     | - 放置在元数据中            |
| `workflow_id`                      | name                       |
| start_time                          | start_time                 |
| end_time                            | end_time                   |
| inputs                              | inputs                     |
| outputs                             | outputs                    |
| Model token consumption             | usage_metadata             |
| metadata                            | metadata                   |
| error                               | error                      |
| \[workflow]                         | tags                       |
| conversation_id/none for workflow | conversation_id in metadata |

**工作流追踪信息**

- workflow_id - 工作流唯一标识符
- conversation_id - 对话 ID
- workflow_run_id - 当前运行的 ID
- tenant_id - 租户 ID
- elapsed_time - 当前运行所用时间
- status - 运行状态
- version - 工作流版本
- total_tokens - 当前运行使用的总令牌数
- file_list - 处理的文件列表
- triggered_from - 触发当前运行的来源
- workflow_run_inputs - 当前运行的输入数据
- workflow_run_outputs - 当前运行的输出数据
- error - 当前运行期间遇到的错误
- query - 运行期间使用的查询
- workflow_app_log_id - 工作流应用程序日志 ID
- message_id - 关联的消息 ID
- start_time - 运行开始时间
- end_time - 运行结束时间
- workflow node executions - 工作流节点执行信息
- 元数据
  - workflow_id - 工作流唯一标识符
  - conversation_id - 对话 ID
  - workflow_run_id - 当前运行的 ID
  - tenant_id - 租户 ID
  - elapsed_time - 当前运行所用时间
  - status - 运行状态
  - version - 工作流版本
  - total_tokens - 当前运行使用的总令牌数
  - file_list - 处理的文件列表
  - triggered_from - 触发当前运行的来源

#### **消息追踪信息**

**用于追踪 LLM 相关对话**

| 聊天                            | Phoenix LLM                    |
| ------------------------------- | --------------------------- |
| message_id                      | id                          |
| user_session_id                 | - 放置在元数据中             |
| "llm"                           | name                        |
| start_time                      | start_time                  |
| end_time                        | end_time                    |
| inputs                          | inputs                      |
| outputs                         | outputs                     |
| Model token consumption         | usage_metadata              |
| metadata                        | metadata                    |
| \["message", conversation_mode] | tags                        |
| conversation_id                 | conversation_id in metadata |

**消息追踪信息**

- message_id - 消息 ID
- message_data - 消息数据
- user_session_id - 用户会话 ID
- conversation_model - 对话模式
- message_tokens - 消息中的令牌数
- answer_tokens - 答案中的令牌数
- total_tokens - 消息和答案中的总令牌数
- error - 错误信息
- inputs - 输入数据
- outputs - 输出数据
- file_list - 处理的文件列表
- start_time - 开始时间
- end_time - 结束时间
- message_file_data - 与消息关联的文件数据
- conversation_mode - 对话模式
- 元数据
  - conversation_id - 对话 ID
  - ls_provider - 模型提供商
  - ls_model_name - 模型 ID
  - status - 消息状态
  - from_end_user_id - 发送用户的 ID
  - from_account_id - 发送账户的 ID
  - agent_based - 消息是否基于代理
  - workflow_run_id - 工作流运行 ID
  - from_source - 消息来源

#### **审核追踪信息**

**用于追踪对话审核**

| 审核           | Phoenix Tool         |
| -------------- | ----------------- |
| user_id        | - 放置在元数据中   |
| "moderation"   | name              |
| start_time     | start_time        |
| end_time       | end_time          |
| inputs         | inputs            |
| outputs        | outputs           |
| metadata       | metadata          |
| \["moderation"]| tags              |

**审核追踪信息**

- message_id - 消息 ID
- user_id - 用户 ID
- workflow_app_log_id - 工作流应用程序日志 ID
- inputs - 审核输入数据
- message_data - 消息数据
- flagged - 内容是否被标记需要注意
- action - 采取的具体行动
- preset_response - 预设响应
- start_time - 审核开始时间
- end_time - 审核结束时间
- 元数据
  - message_id - 消息 ID
  - action - 采取的具体行动
  - preset_response - 预设响应

#### **建议问题追踪信息**

**用于追踪建议问题**

| 建议问题              | Phoenix LLM          |
| --------------------- | ----------------- |
| user_id               | - 放置在元数据中   |
| "suggested_question"  | name              |
| start_time            | start_time        |
| end_time              | end_time          |
| inputs                | inputs            |
| outputs               | outputs           |
| metadata              | metadata          |
| \["suggested_question"]| tags             |

**消息追踪信息**

- message_id - 消息 ID
- message_data - 消息数据
- inputs - 输入内容
- outputs - 输出内容
- start_time - 开始时间
- end_time - 结束时间
- total_tokens - 令牌数量
- status - 消息状态
- error - 错误信息
- from_account_id - 发送账户的 ID
- agent_based - 是否基于代理
- from_source - 消息来源
- model_provider - 模型提供商
- model_id - 模型 ID
- suggested_question - 建议问题
- level - 状态级别
- status_message - 状态消息
- 元数据
  - message_id - 消息 ID
  - ls_provider - 模型提供商
  - ls_model_name - 模型 ID
  - status - 消息状态
  - from_end_user_id - 发送用户的 ID
  - from_account_id - 发送账户的 ID
  - workflow_run_id - 工作流运行 ID
  - from_source - 消息来源

#### **数据集检索追踪信息**

**用于追踪知识库检索**

| 数据集检索           | Phoenix Retriever    |
| ------------------- | ----------------- |
| user_id             | - 放置在元数据中   |
| "dataset_retrieval" | name              |
| start_time          | start_time        |
| end_time            | end_time          |
| inputs              | inputs            |
| outputs             | outputs           |
| metadata            | metadata          |
| \["dataset_retrieval"]| tags            |
| message_id          | parent_run_id     |

**数据集检索追踪信息**

- message_id - 消息 ID
- inputs - 输入内容
- documents - 文档数据
- start_time - 开始时间
- end_time - 结束时间
- message_data - 消息数据
- 元数据
  - message_id - 消息 ID
  - ls_provider - 模型提供商
  - ls_model_name - 模型 ID
  - status - 消息状态
  - from_end_user_id - 发送用户的 ID
  - from_account_id - 发送账户的 ID
  - agent_based - 是否基于代理
  - workflow_run_id - 工作流运行 ID
  - from_source - 消息来源

#### **工具追踪信息**

**用于追踪工具调用**

| 工具                  | Phoenix Tool         |
| -------------------- | ----------------- |
| user_id              | - 放置在元数据中   |
| tool_name            | name              |
| start_time           | start_time        |
| end_time             | end_time          |
| inputs               | inputs            |
| outputs              | outputs           |
| metadata             | metadata          |
| \["tool", tool_name] | tags              |

#### **工具追踪信息**

- message_id - 消息 ID
- tool_name - 工具名称
- start_time - 开始时间
- end_time - 结束时间
- tool_inputs - 工具输入
- tool_outputs - 工具输出
- message_data - 消息数据
- error - 错误信息（如果有）
- inputs - 消息的输入
- outputs - 消息的输出
- tool_config - 工具配置
- time_cost - 时间消耗
- tool_parameters - 工具参数
- file_url - 关联文件的 URL
- 元数据
  - message_id - 消息 ID
  - tool_name - 工具名称
  - tool_inputs - 工具输入
  - tool_outputs - 工具输出
  - tool_config - 工具配置
  - time_cost - 时间消耗
  - error - 错误信息（如果有）
  - tool_parameters - 工具参数
  - message_file_id - 消息文件 ID
  - created_by_role - 创建者角色
  - created_user_id - 创建者用户 ID

#### **生成名称追踪信息**

**用于追踪对话标题生成**

| 生成名称                      | Phoenix Tool         |
| ---------------------------- | ----------------- |
| user_id                      | - 放置在元数据中   |
| "generate_conversation_name" | name              |
| start_time                   | start_time        |
| end_time                     | end_time          |
| inputs                       | inputs            |
| outputs                      | outputs           |
| metadata                     | metadata          |
| \["generate_name"]           | tags              |

**生成名称追踪信息**

- conversation_id - 对话 ID
- inputs - 输入数据
- outputs - 生成的对话名称
- start_time - 开始时间
- end_time - 结束时间
- tenant_id - 租户 ID
- 元数据
  - conversation_id - 对话 ID
  - tenant_id - 租户 ID

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-phoenix.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 集成 W&B Weave
> 来源：`zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-weave.mdx`
> 摘要：Dify Cloud | 社区版本号需 ≥ v1.3.1

### 什么是 W&B Weave

Weights & Biases (W&B) Weave 是一个用于跟踪、实验、评估、部署和改进基于 LLM 的应用程序的框架。Weave 专为灵活性和可扩展性而设计，支持 LLM 应用程序开发工作流的每个阶段。

> **信息提示：**

    更多详情，请参考 [Weave](https://weave-docs.wandb.ai/)。

***

### 如何配置 Weave

#### 1. 注册/登录

前往 [W&B Weave](https://wandb.ai/signup) 注册/登录。创建一个 Weights & Biases (W&B) 账户，并在[此处](https://wandb.ai/authorize)复制 API 密钥。

#### 2. 将 W&B Weave 与 Dify 集成

在 Dify 应用程序中配置 Weave。打开需要监控的应用程序，在侧边菜单中打开**监控**，在页面上选择**跟踪应用性能**。

![](https://assets-docs.dify.ai/2025/04/c33e8fda75ee9052ed23c8690e314862.png)

点击配置后，粘贴 **API 密钥**和**项目名称**，指定 **W&B 实体**(可选，默认为您的用户名)到配置中并保存。

![](https://assets-docs.dify.ai/2025/04/60bce1ae7b883825b13526d172ae0073.png)

成功保存后，您可以在当前页面查看监控状态。

![](https://assets-docs.dify.ai/2025/04/9486cee7bbb61f069842c9ea860e679c.png)

### 在 Weave 中查看监控数据

配置完成后，Dify 内应用的调试或生产数据可以在 Weave 中进行监控。

![](https://assets-docs.dify.ai/2025/04/a1c5aa80325e6d0223d48a178393baec.png)

当您切换到 Weave 时，可以在仪表板中查看 Dify 应用程序的详细操作日志。

![](https://assets-docs.dify.ai/2025/04/2cb04027c00b606029fcc26af2801bfe.png)

通过 Weave 获取的详细 LLM 操作日志将帮助您优化 Dify 应用程序的性能。

### 监控数据列表

#### **工作流/对话流追踪信息**

**用于追踪工作流和对话流**

| 工作流                                   | Weave 追踪                   |
| ---------------------------------------- | ---------------------------- |
| workflow_app_log_id/workflow_run_id | id                           |
| user_session_id                        | 放置在元数据中               |
| workflow_id                           | name                         |
| start_time                              | start_time                  |
| end_time                                | end_time                    |
| inputs                                   | inputs                       |
| outputs                                  | outputs                      |
| 模型令牌消耗                            | usage_metadata              |
| metadata                                 | extra                        |
| error                                    | error                        |
| workflow                              | tags                         |
| "conversation_id/none for workflow"     | 元数据中的 conversation_id  |
| conversion_id                           | parent_run_id              |

**工作流追踪信息**

* workflow_id - 工作流的唯一标识符
* conversation_id - 对话 ID
* workflow_run_id - 当前运行的 ID
* tenant_id - 租户 ID
* elapsed_time - 当前运行所花费的时间
* status - 运行状态
* version - 工作流版本
* total_tokens - 当前运行中使用的总令牌数
* file_list - 处理的文件列表
* triggered_from - 触发当前运行的来源
* workflow_run_inputs - 当前运行的输入数据
* workflow_run_outputs - 当前运行的输出数据
* error - 当前运行期间遇到的错误
* query - 运行期间使用的查询
* workflow_app_log_id - 工作流应用程序日志 ID
* message_id - 关联的消息 ID
* start_time - 运行的开始时间
* end_time - 运行的结束时间
* workflow node executions - 工作流节点执行的信息
* 元数据
  * workflow_id - 工作流的唯一标识符
  * conversation_id - 对话 ID
  * workflow_run_id - 当前运行的 ID
  * tenant_id - 租户 ID
  * elapsed_time - 当前运行所花费的时间
  * status - 运行状态
  * version - 工作流版本
  * total_tokens - 当前运行中使用的总令牌数
  * file_list - 处理的文件列表
  * triggered_from - 触发当前运行的来源

#### **消息追踪信息**

**用于追踪与 LLM 相关的对话**

| 聊天                             | Weave 追踪                    |
| -------------------------------- | ----------------------------- |
| message_id                      | id                            |
| user_session_id                | 放置在元数据中                |
| "message_id"                  | name                          |
| start_time                      | start_time                   |
| end_time                        | end_time                     |
| inputs                           | inputs                        |
| outputs                          | outputs                       |
| 模型令牌消耗                     | usage_metadata               |
| metadata                         | extra                         |
| error                            | error                         |
| "message", conversation_mode | tags                          |
| conversation_id                 | 元数据中的 conversation_id   |
| conversion_id                   | parent_run_id               |

**消息追踪信息**

* message_id - 消息 ID
* message_data - 消息数据
* user_session_id - 用户会话 ID
* conversation_model - 对话模式
* message_tokens - 消息中的令牌数
* answer_tokens - 回答中的令牌数
* total_tokens - 消息和回答中的总令牌数
* error - 错误信息
* inputs - 输入数据
* outputs - 输出数据
* file_list - 处理的文件列表
* start_time - 开始时间
* end_time - 结束时间
* message_file_data - 与消息关联的文件数据
* conversation_mode - 对话模式
* 元数据
  * conversation_id - 对话 ID
  * ls_provider - 模型提供商
  * ls_model_name - 模型 ID
  * status - 消息状态
  * from_end_user_id - 发送用户的 ID
  * from_account_id - 发送账户的 ID
  * agent_based - 消息是否基于代理
  * workflow_run_id - 工作流运行 ID
  * from_source - 消息来源

#### **审核追踪信息**

**用于追踪对话审核**

| 审核           | Weave 追踪             |
| ------------- | ---------------------- |
| user_id      | 放置在元数据中         |
| "moderation"  | name                   |
| start_time   | start_time            |
| end_time     | end_time              |
| inputs        | inputs                 |
| outputs       | outputs                |
| metadata      | extra                  |
| \[moderation] | tags                   |
| message_id   | parent_run_id        |

**审核追踪信息**

* message_id - 消息 ID
* user_id: 用户 ID
* workflow_app_log_id - 工作流应用程序日志 ID
* inputs - 审核输入数据
* message_data - 消息数据
* flagged - 内容是否被标记为需要注意
* action - 采取的特定操作
* preset_response - 预设响应
* start_time - 审核开始时间
* end_time - 审核结束时间
* 元数据
  * message_id - 消息 ID
  * action - 采取的特定操作
  * preset_response - 预设响应

#### **建议问题追踪信息**

**用于追踪建议的问题**

| 建议问题               | Weave 追踪             |
| ---------------------- | ---------------------- |
| user_id               | 放置在元数据中         |
| suggested_question    | name                   |
| start_time            | start_time            |
| end_time              | end_time              |
| inputs                 | inputs                 |
| outputs                | outputs                |
| metadata               | extra                  |
| suggested_question | tags                   |
| message_id            | parent_run_id        |

**消息追踪信息**

* message_id - 消息 ID
* message_data - 消息数据
* inputs - 输入内容
* outputs - 输出内容
* start_time - 开始时间
* end_time - 结束时间
* total_tokens - 令牌数
* status - 消息状态
* error - 错误信息
* from_account_id - 发送账户的 ID
* agent_based - 消息是否基于代理
* from_source - 消息来源
* model_provider - 模型提供商
* model_id - 模型 ID
* suggested_question - 建议的问题
* level - 状态级别
* status_message - 状态消息
* 元数据
  * message_id - 消息 ID
  * ls_provider - 模型提供商
  * ls_model_name - 模型 ID
  * status - 消息状态
  * from_end_user_id - 发送用户的 ID
  * from_account_id - 发送账户的 ID
  * workflow_run_id - 工作流运行 ID
  * from_source - 消息来源

#### **数据集检索追踪信息**

**用于追踪知识库检索**

| 数据集检索           | Weave 追踪             |
| --------------------- | --------------------- |
| user_id              | 放置在元数据中        |
| dataset_retrieval    | name                  |
| start_time           | start_time           |
| end_time             | end_time             |
| inputs                | inputs                |
| outputs               | outputs               |
| metadata              | extra                 |
| dataset_retrieval | tags                  |
| message_id           | parent_run_id       |

**数据集检索追踪信息**

* message_id - 消息 ID
* inputs - 输入内容
* documents - 文档数据
* start_time - 开始时间
* end_time - 结束时间
* message_data - 消息数据
* 元数据
  * message_id - 消息 ID
  * ls_provider - 模型提供商
  * ls_model_name - 模型 ID
  * status - 消息状态
  * from_end_user_id - 发送用户的 ID
  * from_account_id - 发送账户的 ID
  * agent_based - 消息是否基于代理
  * workflow_run_id - 工作流运行 ID
  * from_source - 消息来源

#### **工具追踪信息**

**用于追踪工具调用**

| 工具                   | Weave 追踪             |
| --------------------- | ----------------------- |
| user_id              | 放置在元数据中          |
| tool_name            | name                    |
| start_time           | start_time             |
| end_time             | end_time               |
| inputs                | inputs                  |
| outputs               | outputs                 |
| metadata              | extra                   |
| \["tool", tool_name] | tags                    |
| message_id           | parent_run_id         |

#### **工具追踪信息**

* message_id - 消息 ID
* tool_name - 工具名称
* start_time - 开始时间
* end_time - 结束时间
* tool_inputs - 工具输入
* tool_outputs - 工具输出
* message_data - 消息数据
* error - 错误信息（如果有）
* inputs - 消息的输入
* outputs - 消息的输出
* tool_config - 工具配置
* time_cost - 时间成本
* tool_parameters - 工具参数
* file_url - 关联文件的 URL
* 元数据
  * message_id - 消息 ID
  * tool_name - 工具名称
  * tool_inputs - 工具输入
  * tool_outputs - 工具输出
  * tool_config - 工具配置
  * time_cost - 时间成本
  * error - 错误信息（如果有）
  * tool_parameters - 工具参数
  * message_file_id - 消息文件 ID
  * created_by_role - 创建者的角色
  * created_user_id - 创建者的用户 ID

**生成名称追踪信息**

**用于追踪对话标题生成**

| 生成名称           | Weave 追踪             |
| ----------------- | ---------------------- |
| user_id          | 放置在元数据中         |
| generate_name    | name                   |
| start_time       | start_time            |
| end_time         | end_time              |
| inputs            | inputs                 |
| outputs           | outputs                |
| metadata          | extra                  |
| generate_name | tags                   |

**生成名称追踪信息**

* conversation_id - 对话 ID
* inputs - 输入数据
* outputs - 生成的对话名称
* start_time - 开始时间
* end_time - 结束时间
* tenant_id - 租户 ID
* 元数据
  * conversation_id - 对话 ID
  * tenant_id - 租户 ID

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/integrate-external-ops-tools/integrate-weave.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 集成外部 Ops 工具
> 来源：`zh-hans/guides/monitoring/integrate-external-ops-tools/readme.mdx`

### 为什么需要 LLMOps 工具

尽管 LLM 拥有出色的推理和文本生成能力，但其内部运作机制仍然难以完全理解，这给基于 LLM 的应用开发带来了挑战。例如：

* 评估输出**质量**
* 推理**成本**评估
* 模型响应**延迟**
* 链式调用、Agent 和工具引入的**调试复杂**性
* 复杂的用户意图理解

而 LangSmith、Langfuse 这类 LLMOps 工具，能够为 LLM 应用提供全面的追踪和深度评估能力，为开发者提供从应用的原型构建到生产、运营的完整生命周期支持。

* **原型阶段**

LLM 应用在原型构建阶段通常涉及提示词测试、模型选择、RAG 检索策略和其他参数组合的快速实验。快速了解模型的执行效果对于此阶段非常重要。接入 Langfuse 可以在跟踪 dify 应用执行的每个步骤，提供清晰的可见性和调试信息，从而让开发者快速定位问题并减少调试时间。

* **测试阶段**

进入测试阶段后，需要继续收集数据以改进和提高性能。 LangSmith 能够将运行作为示例添加到知识库中，从而扩展实际场景的测试覆盖范围。这是将日志系统和评估/测试系统置于同一平台中的一个关键优势。

* **生产阶段**

进入生产环境后，开发团队还需要仔细检查应用关键数据点、增加基准知识库、人工注释以及深入分析运营数据结果。尤其是在应用大规模使用中，运营和数据团队需要持续观测应用成本和性能，对模型以及应用表现进行优化。

### Dify 与 Ops 工具的集成

使用 Dify Workflow 编排 LLM 应用时，通常涵盖一系列节点和逻辑，具有较高的复杂性。

将 Dify 与外部 Ops 工具集成，有助于打破编排应用时可能面临的 LLM “黑盒”问题。开发者只需要在平台上进行简单的配置，即可追踪应用生命周期中的数据和指标，轻松评估在 Dify 上创建的 LLM 应用质量、性能和成本。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/integrate-external-ops-tools/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 日志与标注
> 来源：`zh-hans/guides/monitoring/logs.mdx`

> **提示：**

请确保您的应用在收集用户数据时遵守当地法规。通常的做法是发布隐私政策并征得用户的同意。

日志（Logs）功能用以观察与标记 Dify 应用的工作表现，Dify 为应用的全部交互过程记录了日志，无论你是通过 WebApp 或 API 调用的，如果你是 Prompt 工程师或 LLM 运营人员，它将为你提供可视化的 LLM 应用运营体验。

### 使用日志控制台

你可以在应用的左侧导航找到**日志（Logs）**，该页面通常展示了：

* 所选时间内用户与用户的交互记录
* 用户输入与 AI 输出的结果，对于对话型应用通常是一系列的消息流
* 用户、运营人员的评价，以及运营人员的改进标注

注意，如果团队中的多位协作者对同一条日志进行标注，最后标注的记录将覆盖此前的标注。

### 改进标注

> **提示：**

这些标记将在 Dify 的后续版本中供模型微调使用，以提升模型的准确性与回复风格，当前预览版仅支持标记。

  **[图片缺失] 标记日志以改进 (zh-hans/user-guide/.gitbook/assets/app-log.png)**

点击一条日志会在界面右侧打开日志详情面板，在该面板中运营人员可以对一次互动进行标注：

* 对表现较佳的消息点赞
* 对表现不佳的消息点踩
* 对改进的结果标记改进回复，这代表了你期望 AI 回复的文本

注意，如果团队中的多位管理员对同一条日志进行标注，最后标注的记录将覆盖此前的标注。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/monitoring/logs.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 高级接入工具
> 来源：`zh-hans/guides/tools/advanced-tool-integration.mdx`

在开始接入工具之前，请确保你已经阅读过[快速接入](./zh-hans/user-guide/tools/quick-tool-integration)，并对 Dify 的工具接入流程有了基本的了解。

### 工具接口

我们在`Tool`类中定义了一系列快捷方法，用于帮助开发者快速构较为复杂的工具。

#### 消息返回

Dify支持`文本` `链接` `图片` `文件BLOB` 等多种消息类型，你可以通过以下几个接口返回不同类型的消息给 LLM 和用户。

注意，在下面的接口中的部分参数将在后面的章节中介绍。

**图片URL**

只需要传递图片的URL即可，Dify会自动下载图片并返回给用户。

```python
    def create_image_message(self, image: str, save_as: str = '') -> ToolInvokeMessage:
        """
            create an image message

            :param image: the url of the image
            :return: the image message
        """
```

**链接**

如果你需要返回一个链接，可以使用以下接口。

```python
    def create_link_message(self, link: str, save_as: str = '') -> ToolInvokeMessage:
        """
            create a link message

            :param link: the url of the link
            :return: the link message
        """
```

**文本**

如果你需要返回一个文本消息，可以使用以下接口。

```python
    def create_text_message(self, text: str, save_as: str = '') -> ToolInvokeMessage:
        """
            create a text message

            :param text: the text of the message
            :return: the text message
        """
```

**文件 BLOB**

如果你需要返回文件的原始数据，如图片、音频、视频、PPT、Word、Excel 等，可以使用以下接口。

* `blob` 文件的原始数据，bytes 类型
* `meta` 文件的元数据，如果你知道该文件的类型，最好传递一个`mime_type`，否则Dify将使用`octet/stream`作为默认类型

```python
    def create_blob_message(self, blob: bytes, meta: dict = None, save_as: str = '') -> ToolInvokeMessage:
        """
            create a blob message

            :param blob: the blob
            :return: the blob message
        """
```

#### 快捷工具

在大模型应用中，我们有两种常见的需求：

* 先将很长的文本进行提前总结，然后再将总结内容传递给 LLM，以防止原文本过长导致 LLM 无法处理
* 工具获取到的内容是一个链接，需要爬取网页信息后再返回给 LLM

为了帮助开发者快速实现这两种需求，我们提供了以下两个快捷工具。

**文本总结工具**

该工具需要传入 user\_id 和需要进行总结的文本，返回一个总结后的文本，Dify 会使用当前工作空间的默认模型对长文本进行总结。

```python
    def summary(self, user_id: str, content: str) -> str:
        """
            summary the content

            :param user_id: the user id
            :param content: the content
            :return: the summary
        """
```

**网页爬取工具**

该工具需要传入需要爬取的网页链接和一个 user\_agent（可为空），返回一个包含该网页信息的字符串，其中`user_agent`是可选参数，可以用来识别工具，如果不传递，Dify将使用默认的`user_agent`。

```python
    def get_url(self, url: str, user_agent: str = None) -> str:
        """
            get url
        """ the crawled result
```

#### 变量池

我们在`Tool`中引入了一个变量池，用于存储工具运行过程中产生的变量、文件等，这些变量可以在工具运行过程中被其他工具使用。

下面，我们以`DallE3`和`Vectorizer.AI`为例，介绍如何使用变量池。

* `DallE3`是一个图片生成工具，它可以根据文本生成图片，在这里，我们将让`DallE3`生成一个咖啡厅的 Logo。
* `Vectorizer.AI`是一个矢量图转换工具，它可以将图片转换为矢量图，使得图片可以无限放大而不失真，在这里，我们将`DallE3`生成的PNG图标转换为矢量图，从而可以真正被设计师使用。

**DallE3**

首先我们使用 DallE3，在创建完图片以后，我们将图片保存到变量池中，代码如下

```python
from typing import Any, Dict, List, Union
from core.tools.entities.tool_entities import ToolInvokeMessage
from core.tools.tool.builtin_tool import BuiltinTool

from base64 import b64decode

from openai import OpenAI

class DallE3Tool(BuiltinTool):
    def _invoke(self, 
                user_id: str, 
               tool_Parameters: Dict[str, Any], 
        ) -> Union[ToolInvokeMessage, List[ToolInvokeMessage]]:
        """
            invoke tools
        """
        client = OpenAI(
            api_key=self.runtime.credentials['openai_api_key'],
        )

        # prompt
        prompt = tool_Parameters.get('prompt', '')
        if not prompt:
            return self.create_text_message('Please input prompt')

        # call openapi dalle3
        response = client.images.generate(
            prompt=prompt, model='dall-e-3',
            size='1024x1024', n=1, style='vivid', quality='standard',
            response_format='b64_json'
        )

        result = []
        for image in response.data:
            # 将所有图片通过 save_as 参数保存到变量池中，变量名为 self.VARIABLE_KEY.IMAGE.value，如果如果后续有新的图片生成，那么将会覆盖之前的图片
            result.append(self.create_blob_message(blob=b64decode(image.b64_json), 
                                                   meta= 'mime_type': 'image/png' ,
                                                    save_as=self.VARIABLE_KEY.IMAGE.value))

        return result
```

我们可以注意到这里我们使用了`self.VARIABLE_KEY.IMAGE.value`作为图片的变量名，为了便于开发者们的工具能够互相配合，我们定义了这个`KEY`，大家可以自由使用，也可以不使用这个`KEY`，传递一个自定义的KEY也是可以的。

**Vectorizer.AI**

接下来我们使用 Vectorizer.AI，将 DallE3 生成的PNG图标转换为矢量图，我们先来过一遍我们在这里定义的函数，代码如下

```python
from core.tools.tool.builtin_tool import BuiltinTool
from core.tools.entities.tool_entities import ToolInvokeMessage, ToolParameter
from core.tools.errors import ToolProviderCredentialValidationError

from typing import Any, Dict, List, Union
from httpx import post
from base64 import b64decode

class VectorizerTool(BuiltinTool):
    def _invoke(self, user_id: str, tool_Parameters: Dict[str, Any]) \
        -> Union[ToolInvokeMessage, List[ToolInvokeMessage]]:
        """
        工具调用，图片变量名需要从这里传递进来，从而我们就可以从变量池中获取到图片
        """

    def get_runtime_parameters(self) -> List[ToolParameter]:
        """
        重写工具参数列表，我们可以根据当前变量池里的实际情况来动态生成参数列表，从而 LLM 可以根据参数列表来生成表单
        """

    def is_tool_available(self) -> bool:
        """
        当前工具是否可用，如果当前变量池中没有图片，那么我们就不需要展示这个工具，这里返回 False 即可
        """     
```

接下来我们来实现这三个函数

```python
from core.tools.tool.builtin_tool import BuiltinTool
from core.tools.entities.tool_entities import ToolInvokeMessage, ToolParameter
from core.tools.errors import ToolProviderCredentialValidationError

from typing import Any, Dict, List, Union
from httpx import post
from base64 import b64decode

class VectorizerTool(BuiltinTool):
    def _invoke(self, user_id: str, tool_Parameters: Dict[str, Any]) \
        -> Union[ToolInvokeMessage, List[ToolInvokeMessage]]:
        """
            invoke tools
        """
        api_key_name = self.runtime.credentials.get('api_key_name', None)
        api_key_value = self.runtime.credentials.get('api_key_value', None)

        if not api_key_name or not api_key_value:
            raise ToolProviderCredentialValidationError('Please input api key name and value')

        # 获取 image_id，image_id 的定义可以在 get_runtime_parameters 中找到
        image_id = tool_Parameters.get('image_id', '')
        if not image_id:
            return self.create_text_message('Please input image id')

        # 从变量池中获取到之前 DallE 生成的图片
        image_binary = self.get_variable_file(self.VARIABLE_KEY.IMAGE)
        if not image_binary:
            return self.create_text_message('Image not found, please request user to generate image firstly.')

        # 生成矢量图
        response = post(
            'https://vectorizer.ai/api/v1/vectorize',
            files= 'image': image_binary ,
            data= 'mode': 'test' ,
            auth=(api_key_name, api_key_value), 
            timeout=30
        )

        if response.status_code != 200:
            raise Exception(response.text)

        return [
            self.create_text_message('the vectorized svg is saved as an image.'),
            self.create_blob_message(blob=response.content,
                                    meta='mime_type': 'image/svg+xml')
        ]

    def get_runtime_parameters(self) -> List[ToolParameter]:
        """
        override the runtime parameters
        """
        # 这里，我们重写了工具参数列表，定义了 image_id，并设置了它的选项列表为当前变量池中的所有图片，这里的配置与 yaml 中的配置是一致的
        return [
            ToolParameter.get_simple_instance(
                name='image_id',
                llm_description=f'the image id that you want to vectorize, \
                    and the image id should be specified in \
                        [i.name for i in self.list_default_image_variables()]',
                type=ToolParameter.ToolParameterType.SELECT,
                required=True,
                options=[i.name for i in self.list_default_image_variables()]
            )
        ]

    def is_tool_available(self) -> bool:
        # 只有当变量池中有图片时，LLM 才需要使用这个工具
        return len(self.list_default_image_variables()) > 0
```

可以注意到的是，我们这里其实并没有使用到`image_id`，我们已经假设了调用这个工具的时候一定有一张图片在默认的变量池中，所以直接使用了`image_binary = self.get_variable_file(self.VARIABLE_KEY.IMAGE)`来获取图片，在模型能力较弱的情况下，我们建议开发者们也这样做，可以有效提升容错率，避免模型传递错误的参数。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/advanced-tool-integration.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## AlphaVantage 股票分析
> 来源：`zh-hans/guides/tools/community/alphavantage.mdx`

> 工具作者 [@zhuhao](https://github.com/hwzhuhao)。

AlphaVantage 一个在线平台，它提供金融市场数据和API，便于个人投资者和开发者获取股票报价、技术指标和股票分析。本

## 1. 申请 AlphaVantage API Key

请在 [AlphaVantage](https://www.alphavantage.co/support/#api-key)申请 API Key。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > AlphaVantage > 去授权` 填写 API Key。

## 3. 使用工具

- **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `AlphaVantage` 工具节点。添加后，需要在节点内的 “输入变量 → 股票代码” 通过[变量](./zh-hans/user-guide/build-app/flow-app/variables)引用用户输入的查询内容。最后在 “结束” 节点内使用变量引用 `AlphaVantage` 节点输出的内容。

- **Agent 应用**

在 Agent 应用内添加 `AlphaVantage` 工具，然后在对话框内发送股票代码或大致描述，调用工具得到准确的金融数据。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/community/alphavantage.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## ComfyUI
> 来源：`zh-hans/guides/tools/community/comfyui.mdx`

[ComfyUI](https://www.comfy.org/) 是一个强大的、模块化的生成图形的平台。现在你可以在 Dify 中使用它， 传入图片的提示词， 并得到生成的图片。

## 1. 确保已能正常运行 ComfyUI 的工作流。  
请参考其[官方文档](https://docs.comfy.org/get_started/gettingstarted)，确保 ComfyUI 可以正常运行并生成图片。

## 2. 导出工作流的 API 文件。

![](./zh-hans/img/0503c5838f163b54884ca58240281f3f.png)

如图所示，在工具栏中选择 `Save(API Format)`，如果没有该选择，则需要在设置中开启 `Dev Mode`。

## 3. 在 Dify 中集成 ComfyUI

在 `工具 > ComfyUI > 去认证` 中填写访问地址，如果您使用的 docker 部署的 Dify，这个地址一般是 `http://host.docker.internal:8188`。

## 4. 在 Dify 中使用 ComfyUI

打开其 `工作流` 工具，在 `WORKFLOW JSON` 中填入刚刚导出的 API 文件中的内容，就可以正常生成了。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/community/comfyui.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## SearchApi
> 来源：`zh-hans/guides/tools/community/searchapi.mdx`

> 工具作者 @SearchApi。

SearchApi 是一个强大的实时 SERP API，可提供来自 Google 搜索、Google 招聘、YouTube、Google 新闻等搜索引擎集合的结构化数据。以下是在 Dify 中配置和使用 SearchApi 搜索工具的步骤。

## 1. 申请 Search API Key

请在 [SearchApi](https://www.searchapi.io/)申请 API Key。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > SearchApi > 去授权` 填写 API Key。

![](./zh-hans/user-guide/.gitbook/assets/zh-tool-searchapi.png)

## 3. 使用工具

你可以在以下应用类型中使用 SearchApi 工具。

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `SearchApi` 系列工具节点，提供 Google Jobs API，Google News API，Google Search API，YouTube 脚本 API 四种工具。

![](./zh-hans/user-guide/.gitbook/assets/zh-tool-searchapi-flow.png)

* **Agent 应用**

在 Agent 应用内选择需要添加的 `SearchApi` 工具，然后输入指令调用工具。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/community/searchapi.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## SearXNG
> 来源：`zh-hans/guides/tools/community/searxng.mdx`

> 工具作者 @Junytang。

SearXNG 是一个免费的互联网元搜索引擎，整合了各种搜索服务的检索结果。用户不会被跟踪，搜索行为也不会被分析。现在你可以直接在 Dify 中使用此工具。

下文将介绍如何使用 Docker 将 SearXNG 集成到 Dify。

## 1. 修改 Dify 配置文件

SearXNG 的配置文件位于 `dify/api/core/tools/provider/builtin/searxng/docker/settings.yml`， 配置文档可参考[这里](https://docs.searxng.org/admin/settings/index.html)。

你可以按需修改配置，也可直接使用默认配置。

## 2. 启动服务

在 Dify 根目录下启动 Docker 容器。

```bash
cd dify
docker run --rm -d -p 8081:8080 -v "$PWD/api/core/tools/provider/builtin/searxng/docker:/etc/searxng" searxng/searxng
```

## 3. 使用 SearXNG

在 `工具 > SearXNG > 去认证` 中填写访问地址，建立 Dify 服务与 SearXNG 服务的连接。SearXNG 的 Docker 内网地址一般是 `http://host.docker.internal:8081`。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/community/searxng.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Serper
> 来源：`zh-hans/guides/tools/community/serper.mdx`

> 工具作者 @zhuhao。

Serper 是一个强大的实时搜索引擎工具API，可提供来自 Google 搜索引擎搜索的结构化数据。以下是在 Dify 中配置和使用 Serper 搜索工具的步骤。

## 1. 申请 Serp API Key

请在 [Serper 平台](https://serper.dev/signup)申请 API Key。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > Serper > 去授权` 填写 API Key。

![](./zh-hans/user-guide/.gitbook/assets/zh-tool-serper.png)

## 3. 使用工具

你可以在以下应用类型中使用 Serper 工具。

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `Serper` 工具节点。

* **Agent 应用**

在 Agent 应用内选择需要添加的 `Serper` 工具，然后输入指令调用工具。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/community/serper.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## SiliconFlow (支持 Flux 绘图)
> 来源：`zh-hans/guides/tools/community/siliconflow.mdx`

> 工具作者 @hjlarry

SiliconCloud 基于优秀的开源基础模型，提供高性价比的 GenAI 服务。你可以通过 **SiliconFlow** 在 Dify 内调用 Flux 、Stable Diffusion 绘图模型，搭建你的专属 AI 绘图应用。以下是在 Dify 中配置 SiliconFlow 工具的步骤。

### 1. 申请 SiliconCloud API Key

请在 [SiliconCloud API 管理页面](https://cloud.siliconflow.cn/account/ak) 新建 API Key 并保证有足够余额。

### 2. 在 Dify 内填写配置

在 Dify 的工具页中点击 `SiliconCloud > 去授权` 填写 API Key。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/截屏2024-09-26 23.12.01.png)**

### 3. 使用工具

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `SiliconFlow` 工具节点。

将用户输入的内容通过[变量](../../workflow/variables)传递至 Siliconflow 工具的 Flux 或 Stable Diffusion 节点内的“提示词”“负面提示词”框中，按照需求调整内置参数，最后在“结束”节点的回复框中选中 Siliconflow 工具节点的输出内容（文本、图片等）。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/截屏2024-09-27 10.09.34.png)**

* **Agent 应用**

在 Agent 应用内添加 `Stable Diffusion` 或 `Flux` 工具，然后在对话框内发送图片描述，调用工具生成 AI 图像。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/截屏2024-09-27 10.18.54.png)**

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/截屏2024-09-27 10.23.52.png)**

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/community/siliconflow.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Bing 搜索
> 来源：`zh-hans/guides/tools/dify/bing.mdx`

> 工具作者 @Dify。

Bing 搜索工具能够帮助你在使用 LLM 应用的时候，获取联网搜索结果。以下是在 Dify 中配置和使用 Bing 搜索工具的步骤。

## 1. 申请 Bing API Key

请在 [Azure 平台](https://platform.openai.com/)申请 API Key。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > Azure > 去授权` 填写 API Key。

![](./zh-hans/img/5e8f18c29c50f14c5c83d7b45c546725.png)

## 3. 使用工具

你可以在以下应用类型中使用 Bing 工具。

- **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `Bing` 工具节点。

- **Agent 应用**

在 Agent 应用内添加 `Bing` 工具，然后输入在线搜索指令，调用此工具。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/dify/bing.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Dall·E
> 来源：`zh-hans/guides/tools/dify/dall-e.mdx`

> 工具作者 @Dify。

DALL-E 是由 OpenAI 开发的一种基于文本提示生成图像的工具。Dify 已接入 DALL-E 工具，以下是在 Dify 中配置和使用 DALL-E 绘图工具的步骤。

## 1. 申请 OpenAI 的 API Key

请在 [OpenAI Platform](https://platform.openai.com/)申请 API Key，并确保账户内有足够的 Credits。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > DALL-E > 去授权` 填写 API Key。

![](./zh-hans/user-guide/.gitbook/assets/zh-tools-dalle.png)

## 3. 使用工具

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `DALL-E 绘图` 工具节点。添加后，需要在节点内的 “输入变量 → 提示词” 内填写[变量](./zh-hans/user-guide/build-app/flow-app/variables)引用用户输入的提示词，或者是上一节点生成的内容。最后在 “结束” 节点内使用变量引用 `DALL-E 绘图` 输出的图像。

![](./zh-hans/user-guide/.gitbook/assets/zh-dalle3-node.png)

* **Agent 应用**

在 Agent 应用内添加 `DALL-E` 工具，然后在对话框内发送图片描述，调用工具生成 AI 图像。

![](./zh-hans/user-guide/.gitbook/assets/zh-agent-dalle3.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/dify/dall-e.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Google
> 来源：`zh-hans/guides/tools/dify/google.mdx`

> 工具作者 @Dify。

Google 搜索工具能够帮助你在使用 LLM 应用的时候，获取联网搜索结果。以下是在 Dify 中配置和使用 Google 搜索工具的步骤。

## 1. 申请 Serp API Key

请在 [Serp 平台](https://serpapi.com/dashboard)申请 API Key。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > Google > 去授权` 填写 API Key。

![](./zh-hans/user-guide/.gitbook/assets/zh-tools-google.png)

## 3. 使用工具

你可以在以下应用类型中使用 Google 工具。

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `Google` 工具节点。

* **Agent 应用**

在 Agent 应用内添加 `Google` 工具，然后输入在线搜索指令，调用此工具。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/dify/google.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Perplexity Search
> 来源：`zh-hans/guides/tools/dify/perplexity.mdx`

> 工具作者 @Dify。

Perplexity 是一个基于 AI 的搜索引擎，能够理解复杂的查询并提供准确、相关的实时答案。以下是在 Dify 中配置和使用 Perplexity Search 工具的步骤。

## 1. 申请 Perplexity API Key

请在 [Perplexity](https://www.perplexity.ai/settings/api)申请 API Key，并确保账户内有足够的 Credits。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > Perplexity > 去授权` 填写 API Key。

![](./zh-hans/user-guide/.gitbook/assets/zh-tools-perplexity.png)

## 3. 使用工具

你可以在以下应用类型中使用 Perplexity Search 工具。

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 Perplexity 工具节点。将用户输入的内容通过变量传递至 Perplexity 工具节点内的“查询”框中，按照需求调整 Perplexity 工具的内置参数，最后在“结束”节点的回复框中选中 Perplexity 工具节点的输出内容。

![](./zh-hans/user-guide/.gitbook/assets/zh-tools-chatflow-perplexity.png)

* **Agent 应用**

在 Agent 应用内添加 `Perplexity Search` 工具，然后输入相关指令即可调用此工具。

![](./zh-hans/user-guide/.gitbook/assets/zh-tools-agent-perplexity.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/dify/perplexity.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Stable Diffusion
> 来源：`zh-hans/guides/tools/dify/stable-diffusion.mdx`

> 工具作者 @Dify。

Stable Diffusion 是一种基于文本提示生成图像的工具，Dify 已经实现了访问 Stable Diffusion WebUI API 的接口，因此你可以直接在 Dify 中使用它。以下是在 Dify 中集成 Stable Diffusion 的步骤。

## 1. 初始化本地环境

推荐使用装有较强 GPU 的机器来安装和驱动 Stable Diffusion，但这并不是必须的，你也可以使用 CPU 来生成图像，但速度可能会很慢。

## 2. 安装并启动 Stable Diffusion WebUI

1. 从[官方仓库](https://github.com/AUTOMATIC1111/stable-diffusion-webui)克隆 Stable Diffusion WebUI 仓库

```bash
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
```

2. 运行命令启动 Stable Diffusion WebUI。

克隆仓库后，切换到仓库目录。根据系统的不同，可能需要使用不同的命令来启动 WebUI。

#### Windows

```bash
cd stable-diffusion-webui
./webui.bat --api --listen
```

#### Linux
```bash
cd stable-diffusion-webui
./webui.sh --api --listen
```

3. 准备模型

现在你可以根据终端中显示的地址在浏览器中访问 Stable Diffusion WebUI，但模型还不可用。你需要从 HuggingFace 或其他来源下载模型，并将其放在 Stable Diffusion WebUI 的 `models` 目录中。

例如，我们使用 [pastel-mix](https://huggingface.co/JamesFlare/pastel-mix) 作为模型，使用 `git lfs` 下载模型并将其放在 `stable-diffusion-webui` 的 `models` 目录中。

```bash
git clone https://huggingface.co/JamesFlare/pastel-mix
```

4. 获取模型名称

现在你可以在模型列表中看到 `pastel-mix`，但我们仍然需要获取模型名称，访问 `http://your_id:port/sdapi/v1/sd-models`，你将看到如下的模型名称。

```json
[

        "title": "pastel-mix/pastelmix-better-vae-fp32.ckpt [943a810f75]",
        "model_name": "pastel-mix_pastelmix-better-vae-fp32",
        "hash": "943a810f75",
        "sha256": "943a810f7538b32f9d81dc5adea3792c07219964c8a8734565931fcec90d762d",
        "filename": "/home/takatost/stable-diffusion-webui/models/Stable-diffusion/pastel-mix/pastelmix-better-vae-fp32.ckpt",
        "config": null
    ,
]
```

`model_name` 就是我们需要的，这个例子中是 `pastel-mix_pastelmix-better-vae-fp32`。

## 3. 在 Dify 集成 Stable Diffusion

在 `工具 > StableDiffusion > 去认证` 中填写你在之前步骤中获取的认证信息和模型配置。

## 4. 完成

- **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `Stable Diffusion` 工具节点。添加后，需要在节点内的 “输入变量 → 提示词” 内填写[变量](./zh-hans/user-guide/build-app/flow-app/variables)引用用户输入的提示词，或者是上一节点生成的内容。最后在 “结束” 节点内使用变量引用 `Stable Diffusion` 输出的图像。

- **Agent 应用**

在 Agent 应用内添加 `Stable Diffusion` 工具，然后在对话框内发送图片描述，调用工具生成 AI 图像。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/dify/stable-diffusion.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 扩展
> 来源：`zh-hans/guides/tools/extensions/README.mdx`

在创造 AI 应用的过程中，开发者面临着不断变化的业务需求和复杂的技术挑战。有效地利用扩展能力不仅可以提高应用的灵活性和功能性，还可以确保企业数据的安全性和合规性。

Dify 提供了以下两种扩展方式：

* API 扩展
* 代码扩展

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/extensions/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## API 扩展
> 来源：`zh-hans/guides/tools/extensions/api-based/api-based-extension.mdx`

开发者可通过 API 扩展模块能力，当前支持以下模块扩展：

* `moderation` 敏感内容审计
* `external_data_tool` 外部数据工具

在扩展模块能力之前，您需要准备一个 API 和用于鉴权的 API Key（也可由 Dify 自动生成，可选）。

除了需要开发对应的模块能力，还需要遵照以下规范，以便 Dify 正确调用 API。

![基于 API 扩展](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/extension/api-based-extension/10f17984eae28c7854983e7112738fa8.png)

### API 规范 <a href="#usercontentapi-gui-fan" id="usercontentapi-gui-fan"></a>

Dify 将会以以下规范调用您的接口：

```
POST Your-API-Endpoint
```

#### Header <a href="#user-content-header" id="user-content-header"></a>

| Header          | Value             | Desc                                                                  |
| --------------- | ----------------- | --------------------------------------------------------------------- |
| `Content-Type`  | application/json  | 请求内容为 JSON 格式。                                                        |
| `Authorization` | Bearer api_key | API Key 以 Token 令牌的方式传输，您需要解析该 `api_key` 并确认是否和提供的 API Key 一致，保证接口安全。 |

#### Request Body <a href="#user-content-request-body" id="user-content-request-body"></a>

```
{
    "point":  string, //  扩展点，不同模块可能包含多个扩展点
    "params": {
        ...  // 各模块扩展点传入参数
    }
}
```

#### API 返回 <a href="#usercontentapi-fan-hui" id="usercontentapi-fan-hui"></a>

```

    ...  // API 返回的内容，不同扩展点返回见不同模块的规范设计

```

### 校验 <a href="#usercontent-xiao-yan" id="usercontent-xiao-yan"></a>

在 Dify 配置 API-based Extension 时，Dify 将会发送一个请求至 API Endpoint，以检验 API 的可用性。

当 API Endpoint 接收到 `point=ping` 时，接口应返回 `result=pong`，具体如下：

#### Header <a href="#user-content-header-1" id="user-content-header-1"></a>

```
Content-Type: application/json
Authorization: Bearer api_key
```

#### Request Body <a href="#user-content-request-body-1" id="user-content-request-body-1"></a>

```

    "point": "ping"

```

#### API 期望返回 <a href="#usercontentapi-qi-wang-fan-hui" id="usercontentapi-qi-wang-fan-hui"></a>

```

    "result": "pong"

```

### 范例 <a href="#usercontent-fan-li" id="usercontent-fan-li"></a>

此处以外部数据工具为例，场景为根据地区获取外部天气信息作为上下文。

#### API 范例 <a href="#usercontentapi-fan-li" id="usercontentapi-fan-li"></a>

```
POST https://fake-domain.com/api/dify/receive
```

**Header**

```
Content-Type: application/json
Authorization: Bearer 123456
```

**Request Body**

```
{
    "point": "app.external_data_tool.query",
    "params": {
        "app_id": "61248ab4-1125-45be-ae32-0ce91334d021",
        "tool_variable": "weather_retrieve",
        "inputs": {
            "location": "London"
        },
        "query": "How's the weather today?"
    }
}
```

**API 返回**

```

    "result": "City: London\nTemperature: 10°C\nRealFeel®: 8°C\nAir Quality: Poor\nWind Direction: ENE\nWind Speed: 8 km/h\nWind Gusts: 14 km/h\nPrecipitation: Light rain"

```

#### 代码范例 <a href="#usercontent-dai-ma-fan-li" id="usercontent-dai-ma-fan-li"></a>

代码基于 Python FastAPI 框架。

1.  安装依赖

    ```
    pip install fastapi[all] uvicorn
    ```
2.  按照接口规范编写代码

    ```
    from fastapi import FastAPI, Body, HTTPException, Header
    from pydantic import BaseModel

    app = FastAPI()

    class InputData(BaseModel):
        point: str
        params: dict = {}

    @app.post("/api/dify/receive")
    async def dify_receive(data: InputData = Body(...), authorization: str = Header(None)):
        """
        Receive API query data from Dify.
        """
        expected_api_key = "123456"  # TODO Your API key of this API
        auth_scheme, _, api_key = authorization.partition(' ')

        if auth_scheme.lower() != "bearer" or api_key != expected_api_key:
            raise HTTPException(status_code=401, detail="Unauthorized")

        point = data.point

        # for debug
        print(f"point: point")

        if point == "ping":
            return 
                "result": "pong"

        if point == "app.external_data_tool.query":
            return handle_app_external_data_tool_query(params=data.params)
        # elif point == "point name":
            # TODO other point implementation here

        raise HTTPException(status_code=400, detail="Not implemented")

    def handle_app_external_data_tool_query(params: dict):
        app_id = params.get("app_id")
        tool_variable = params.get("tool_variable")
        inputs = params.get("inputs")
        query = params.get("query")

        # for debug
        print(f"app_id: app_id")
        print(f"tool_variable: tool_variable")
        print(f"inputs: inputs")
        print(f"query: query")

        # TODO your external data tool query implementation here, 
        #  return must be a dict with key "result", and the value is the query result
        if inputs.get("location") == "London":
            return 
                "result": "City: London\nTemperature: 10°C\nRealFeel®: 8°C\nAir Quality: Poor\nWind Direction: ENE\nWind "
                          "Speed: 8 km/h\nWind Gusts: 14 km/h\nPrecipitation: Light rain"

        else:
            return "result": "Unknown city"
    ```
3.  启动 API 服务，默认端口为 8000，API 完整地址为：`http://127.0.0.1:8000/api/dify/receive`，配置的 API Key 为 `123456`。

    ```
    uvicorn main:app --reload --host 0.0.0.0
    ```
4. 在 Dify 配置该 API。

  ![配置 API](https://github.com/langgenius/dify-docs/raw/main/zh_CN/.gitbook/assets/api_based_01.png)

5. 在 App 中选择该 API 扩展。

  ![选择扩展](https://github.com/langgenius/dify-docs/raw/main/zh_CN/.gitbook/assets/api_based_02.png)

App 调试时，Dify 将请求配置的 API，并发送以下内容（范例）：

```
{
    "point": "app.external_data_tool.query",
    "params": {
        "app_id": "61248ab4-1125-45be-ae32-0ce91334d021",
        "tool_variable": "weather_retrieve",
        "inputs": {
            "location": "London"
        },
        "query": "How's the weather today?"
    }
}
```

API 返回为：

```

    "result": "City: London\nTemperature: 10°C\nRealFeel®: 8°C\nAir Quality: Poor\nWind Direction: ENE\nWind Speed: 8 km/h\nWind Gusts: 14 km/h\nPrecipitation: Light rain"

```

### 本地调试

由于 Dify 云端版无法访问内网 API 服务，为了方便本地调试 API 服务，可以使用 [Ngrok](https://ngrok.com) 将 API 服务的端点暴露到公网，实现云端调试本地代码。操作步骤：

1.  进入 [https://ngrok.com](https://ngrok.com) 官网，注册并下载 Ngrok 文件。

![Download](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/extension/api-based-extension/c44d6cc5425508daac8d31bc4af113df.png)

2. 下载完成后，进入下载目录，根据下方说明解压压缩包，并执行说明中的初始化脚本。
   * ```Shell
     $ unzip /path/to/ngrok.zip
     $ ./ngrok config add-authtoken 你的Token
     ```
3. 查看本地 API 服务的端口：

![查看端口](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/extension/api-based-extension/7ac8ee0f0955f36255e0261b36499db7.png)

并运行以下命令启动：

*   ```Shell
    $ ./ngrok http 端口号
    ```

    启动成功的样例如下：

![Ngrok 启动](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/extension/api-based-extension/2b4adbe0bb1ff203da521ea6eea401f8.png)

4. 我们找到 Forwarding 中，如上图：`https://177e-159-223-41-52.ngrok-free.app`（此为示例域名，请替换为自己的）即为公网域名。

* 按照上述的范例，我们把本地已经启动的服务端点暴露出去，将代码范例接口：`http://127.0.0.1:8000/api/dify/receive` 替换为 `https://177e-159-223-41-52.ngrok-free.app/api/dify/receive`

此 API 端点即可公网访问。至此，我们即可在 Dify 配置该 API 端点进行本地调试代码，配置步骤请参考 [外部数据工具](./external-data-tool)。

### 使用 Cloudflare Workers 部署 API 扩展

我们推荐你使用 Cloudflare Workers 来部署你的 API 扩展，因为 Cloudflare Workers 可以方便的提供一个公网地址，而且可以免费使用。

详细说明请参考 [使用 Cloudflare Workers 部署 API Tools](./zh-hans/user-guide/tools/extensions/api-based/cloudflare-workers)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/extensions/api-based/api-based-extension.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 使用 Cloudflare Workers 部署 API Tools
> 来源：`zh-hans/guides/tools/extensions/api-based/cloudflare-workers.mdx`

## 开始

因为 Dify API Extension 需要使用可以访问的公网地址作为 API Endpoint，所以我们需要将 API 扩展部署到一个公网地址上。这里我们使用 Cloudflare Workers 来部署我们的 API 扩展。

我们 Clone [Example GitHub Repository](https://github.com/crazywoola/dify-extension-workers)，这个仓库包含了一个简单的 API 扩展，我们可以在这个基础上进行修改。

```bash
git clone https://github.com/crazywoola/dify-extension-workers.git
cp wrangler.toml.example wrangler.toml
```

打开 `wrangler.toml` 文件，修改 `name` 和 `compatibility_date` 为你的应用名称和兼容日期。

这里我们我们需要注意的配置就是 `vars` 里面的 `TOKEN`，在 Dify 添加 API 扩展的时候，我们需要填写这个 Token。出于安全考虑，我们建议你使用一个随机的字符串作为 Token，你不应该在源代码中直接写入 Token，而是使用环境变量的方式来传递 Token。所以请不要把 wrangler.toml 提交到你的代码仓库中。

```toml
name = "dify-extension-example"
compatibility_date = "2023-01-01"

[vars]
TOKEN = "bananaiscool"
```

这个 API 扩展会返回一个随机的 Breaking Bad 名言。你可以在 `src/index.ts` 中修改这个 API 扩展的逻辑。这个例子展示了与第三方 API 进行交互的方式。

```typescript
// ⬇️ implement your logic here ⬇️
// point === "app.external_data_tool.query"
// https://api.breakingbadquotes.xyz/v1/quotes
const count = params?.inputs?.count ?? 1;
const url = `https://api.breakingbadquotes.xyz/v1/quotes/$count`;
const result = await fetch(url).then(res => res.text())
// ⬆️ implement your logic here ⬆️
```

这个仓库简化了除了业务逻辑之外所有的配置，你可以直接使用 `npm` 命令来部署你的 API 扩展。

```bash
npm install
npm run deploy
```

部署成功之后，你会得到一个公网地址，你可以在 Dify 中添加这个地址作为 API Endpoint。请注意不要遗漏 `endpoint` 这个路径，此路径的具体定义在 `src/index.ts` 中可以查看。

![在 Dify 中添加 API Endpoint](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/extension/api-based-extension/9433a486a441713ade6270e9dc6c0544.png)

![在 App 编辑页面中添加上 API Tool](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/extension/api-based-extension/72c285e58ec136a1a9a66f61b4b41ca1.png)

另外，也可以直接使用 `npm run dev` 命令来部署到本地进行测试。

```bash
npm install
npm run dev
```

相关输出：

```bash
$ npm run dev
> dev
> wrangler dev src/index.ts

 ⛅️ wrangler 3.99.0
-------------------

Your worker has access to the following bindings:
- Vars:
  - TOKEN: "ban****ool"
⎔ Starting local server...
[wrangler:inf] Ready on http://localhost:58445
```

之后就可以使用 Postman 等工具进行本地接口调试。

## 其他逻辑

### 关于 Bearer Auth

```typescript

(c, next) => {
    const auth = bearerAuth({ token: c.env.TOKEN });
    return auth(c, next);
},
```

我们的 Bearer 校验逻辑在如上代码中，我们使用了 `hono/bearer-auth` 这个包来实现 Bearer 校验。你可以在 `src/index.ts` 中使用 `c.env.TOKEN` 来获取 Token。

### 关于参数验证

```typescript

const schema = z.object({
  point: z.union([
    z.literal("ping"),
    z.literal("app.external_data_tool.query"),
  ]), // Restricts 'point' to two specific values
  params: z
    .object({
      app_id: z.string().optional(),
      tool_variable: z.string().optional(),
      inputs: z.record(z.any()).optional(),
      query: z.any().optional(),  // string or null
    })
    .optional(),
});

```

我们这里使用了 `zod` 来定义参数的类型，你可以在 `src/index.ts` 中使用 `zValidator` 来校验参数。通过 `const  point, params  = c.req.valid("json");` 来获取校验后的参数。 我们这里的 point 只有两个值，所以我们使用了 `z.union` 来定义。 params 是一个可选的参数，所以我们使用了 `z.optional` 来定义。 其中会有一个 `inputs` 的参数，这个参数是一个 `Record<string, any>` 类型，这个类型表示一个 key 为 string，value 为 any 的对象。这个类型可以表示任意的对象，你可以在 `src/index.ts` 中使用 `params?.inputs?.count` 来获取 `count` 参数。

### 获取 Cloudflare Workers 的日志

```bash
wrangler tail
```

## 参考内容

* [Cloudflare Workers](https://workers.cloudflare.com/)
* [Cloudflare Workers CLI](https://developers.cloudflare.com/workers/cli-wrangler/install-update)
* [Example GitHub Repository](https://github.com/crazywoola/dify-extension-workers)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/extensions/api-based/cloudflare-workers.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 外部数据工具
> 来源：`zh-hans/guides/tools/extensions/api-based/external-data-tool.mdx`

在创建 AI 应用时，开发者可以通过 API 扩展的方式实现使用外部工具获取额外数据组装至 Prompt 中作为 LLM 额外信息。具体的实操过程可以参考 [API 扩展](./zh-hans/user-guide/tools/extensions/api-based/api-based-extension)。

### 前置条件

请先阅读 [API 扩展](./zh-hans/user-guide/tools/extensions/api-based/api-based-extension) 完成 API 服务基础能力的开发和接入。

### 扩展点

`app.external_data_tool.query` 应用外部数据工具查询扩展点。

该扩展点将终端用户传入的应用变量内容和对话输入内容（对话型应用固定参数）作为参数，传给 API。

开发者需要实现对应工具的查询逻辑，并返回字符串类型的查询结果。

#### Request Body <a href="#user-content-request-body" id="user-content-request-body"></a>

```
{
    "point": "app.external_data_tool.query", // 扩展点类型，此处固定为 app.external_data_tool.query
    "params": {
        "app_id": string,  // 应用 ID
        "tool_variable": string,  // 外部数据工具变量名称，表示对应变量工具调用来源
        "inputs": {  // 终端用户传入变量值，key 为变量名，value 为变量值
            "var_1": "value_1",
            "var_2": "value_2",
            ...
        },
        "query": string | null  // 终端用户当前对话输入内容，对话型应用固定参数。
    }
}
```

* Example
  * ```
    {
        "point": "app.external_data_tool.query",
        "params": {
            "app_id": "61248ab4-1125-45be-ae32-0ce91334d021",
            "tool_variable": "weather_retrieve",
            "inputs": {
                "location": "London"
            },
            "query": "How's the weather today?"
        }
    }
    ```

#### API 返回 <a href="#usercontentapi-fan-hui" id="usercontentapi-fan-hui"></a>

```

    "result": string

```

* Example
  * ```

        "result": "City: London\nTemperature: 10°C\nRealFeel®: 8°C\nAir Quality: Poor\nWind Direction: ENE\nWind Speed: 8 km/h\nWind Gusts: 14 km/h\nPrecipitation: Light rain"

    ```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/extensions/api-based/external-data-tool.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 敏感内容审查
> 来源：`zh-hans/guides/tools/extensions/api-based/moderation.mdx`

该模块用于审查应用中终端用户输入的内容和 LLM 输出的内容，分为两个扩展点类型。

### 扩展点 <a href="#usercontent-kuo-zhan-dian" id="usercontent-kuo-zhan-dian"></a>

* `app.moderation.input` 终端用户输入的内容审查扩展点
  * 用于审查终端用户传入的变量内容以及对话型应用中对话的输入内容。
* `app.moderation.output`LLM 输出的内容审查扩展点
  * 用于审查 LLM 输出的内容，
  * 当 LLM 输出为流式时，输出的内容将分 100 字为一个分段进行请求 API，尽可能避免输出内容较长时，审查不及时的问题。

### app.moderation.input 扩展点 <a href="#usercontentappmoderationinput-kuo-zhan-dian" id="usercontentappmoderationinput-kuo-zhan-dian"></a>

当在 Chatflow、Agent、聊天助手等应用下开启**内容审查>审查输入内容**时，Dify 会给相应的 API 扩展发送下列 HTTP POST 请求：

#### Request Body <a href="#user-content-request-body" id="user-content-request-body"></a>

```
{
    "point": "app.moderation.input", // 扩展点类型，此处固定为 app.moderation.input
    "params": {
        "app_id": string,  // 应用 ID
        "inputs": {  // 终端用户传入变量值，key 为变量名，value 为变量值
            "var_1": "value_1",
            "var_2": "value_2",
            ...
        },
        "query": string | null  // 终端用户当前对话输入内容，对话型应用固定参数。
    }
}
```

* Example
  * ```
    {
        "point": "app.moderation.input",
        "params": {
            "app_id": "61248ab4-1125-45be-ae32-0ce91334d021",
            "inputs": {
                "var_1": "I will kill you.",
                "var_2": "I will fuck you."
            },
            "query": "Happy everydays."
        }
    }
    ```

#### API 返回规范 <a href="#usercontentapi-fan-hui" id="usercontentapi-fan-hui"></a>

```
{
    "flagged": bool,  // 是否违反校验规则
    "action": string, // 动作，direct_output 直接输出预设回答; overridden 覆写传入变量值
    "preset_response": string,  // 预设回答（仅当 action=direct_output 返回）
    "inputs": {  // 终端用户传入变量值，key 为变量名，value 为变量值（仅当 action=overridden 返回）
        "var_1": "value_1",
        "var_2": "value_2",
        ...
    },
    "query": string | null  // 覆写的终端用户当前对话输入内容，对话型应用固定参数。（仅当 action=overridden 返回）
}
```

* Example
  * `action=direct_output`
    * ```

          "flagged": true,
          "action": "direct_output",
          "preset_response": "Your content violates our usage policy."

      ```
  * `action=overridden`
    * ```
      {
          "flagged": true,
          "action": "overridden",
          "inputs": {
              "var_1": "I will *** you.",
              "var_2": "I will *** you."
          },
          "query": "Happy everydays."
      }
      ```

### app.moderation.output 扩展点 <a href="#usercontentappmoderationoutput-kuo-zhan-dian" id="usercontentappmoderationoutput-kuo-zhan-dian"></a>

当在 Chatflow、Agent、聊天助手等应用下开启**内容审查>审查输出内容**时，Dify 会给相应的 API 扩展发送下列 HTTP POST 请求：

#### Request Body <a href="#user-content-request-body-1" id="user-content-request-body-1"></a>

```
{
    "point": "app.moderation.output", // 扩展点类型，此处固定为 app.moderation.output
    "params": {
        "app_id": string,  // 应用 ID
        "text": string  // LLM 回答内容。当 LLM 输出为流式时，此处为 100 字为一个分段的内容。
    }
}
```

* Example
  * ```
    {
        "point": "app.moderation.output",
        "params": {
            "app_id": "61248ab4-1125-45be-ae32-0ce91334d021",
            "text": "I will kill you."
        }
    }
    ```

#### API 返回 <a href="#usercontentapi-fan-hui-1" id="usercontentapi-fan-hui-1"></a>

```

    "flagged": bool,  // 是否违反校验规则
    "action": string, // 动作，direct_output 直接输出预设回答; overridden 覆写传入变量值
    "preset_response": string,  // 预设回答（仅当 action=direct_output 返回）
    "text": string  // 覆写的 LLM 回答内容。（仅当 action=overridden 返回）

```

* Example
  * `action=direct_output`
    * ```

          "flagged": true,
          "action": "direct_output",
          "preset_response": "Your content violates our usage policy."

      ```
  * `action=overridden`
    * ```

          "flagged": true,
          "action": "overridden",
          "text": "I will *** you."

      ```

## 代码示例
下面展示一段可部署在 Cloudflare 的 `src/index.ts` 代码。（Cloudflare 完整的使用方法参见[此文档](https://docs.dify.ai/zh-hans/guides/extension/api-based-extension/cloudflare-workers)）

代码工作原理是进行关键词匹配，实现对 Input （用户输入的内容）以及输出（大模型返回的内容）进行过滤。用户可以按照需求自行修改匹配逻辑。
```

type Bindings = 
  TOKEN: string;
;

const app = new Hono< Bindings: Bindings >();

// API 格式校验 ⬇️
const schema = z.object({
  point: z.union([
    z.literal("ping"),
    z.literal("app.external_data_tool.query"),
    z.literal("app.moderation.input"),
    z.literal("app.moderation.output"),
  ]), // Restricts 'point' to two specific values
  params: z
    .object({
      app_id: z.string().optional(),
      tool_variable: z.string().optional(),
      inputs: z.record(z.any()).optional(),
      query: z.any(),
      text: z.any()
    })
    .optional(),
});

// Generate OpenAPI schema
app.get("/", (c) => 
  return c.json(generateSchema(schema));
);

app.post(
  "/",
  (c, next) => {
    const auth = bearerAuth({ token: c.env.TOKEN });
    return auth(c, next);
  },
  zValidator("json", schema),
  async (c) => {
    const { point, params } = c.req.valid("json");
    if (point === "ping") {
      return c.json({
        result: "pong",
      });
    }
    // ⬇️ impliment your logic here ⬇️
    // point === "app.external_data_tool.query"
    else if (point === "app.moderation.input"){
    // 输入检查 ⬇️
    const inputkeywords = ["输入过滤测试1", "输入过滤测试2", "输入过滤测试3"];

    if (inputkeywords.some(keyword => params.query.includes(keyword))) 
      {
      return c.json({
        "flagged": true,
        "action": "direct_output",
        "preset_response": "输入存在违法内容，请换个问题再试！"
      });
    } else {
      return c.json({
        "flagged": false,
        "action": "direct_output",
        "preset_response": "输入无异常"
      });
    }
    // 输入检查完毕 
    }

    else {
      // 输出检查 ⬇️
      const outputkeywords = ["输出过滤测试1", "输出过滤测试2", "输出过滤测试3"]; 

  if (outputkeywords.some(keyword => params.text.includes(keyword))) 
    {
      return c.json({
        "flagged": true,
        "action": "direct_output",
        "preset_response": "输出存在敏感内容，已被系统过滤，请换个问题再问！"
      });
    }

  else {
    return c.json({
      "flagged": false,
      "action": "direct_output",
      "preset_response": "输出无异常"
    });
  };
    }
    // 输出检查完毕 
  }
);

```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/extensions/api-based/moderation.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 代码扩展简介
> 来源：`zh-hans/guides/tools/extensions/code-based/README.mdx`

对于在本地部署 Dify 的开发人员来说，代码扩展可以在不重写 API 服务的情况下实现功能的扩展。你可以在不破坏 Dify 原始代码逻辑的情况下，以代码形式扩展或增强程序的功能（即插件功能）。它遵循一定的接口或规范，以实现与主程序的兼容性和即插即用功能。目前，Dify 提供两种代码扩展：

* [外部数据工具](./external-data-tool)
* [敏感内容审核](./moderation)

基于上述功能，你可以按照代码级接口规范实现横向扩展。如果你愿意为我们贡献你的扩展功能，我们非常欢迎你为 Dify 提交 PR。

## 前端组件规范定义

代码扩展的前端样式通过 `schema.json` 进行定义：

* label: 自定义类型名称，支持系统语言切换
* form_schema: 表单内容列表
  * type: 组件类型
    * select: 下拉选项
    * text-input: 文本
    * paragraph: 段落
  * label: 组件名称，支持系统语言切换
  * variable: 变量名
  * required: 是否为必填
  * default：默认值
  * placeholder: 组件提示内容
  * options: 组件的专属属性，定义下拉内容
    * label：下拉菜单名称，支持系统语言切换
    * value：下拉选项值
  * max_length：专属属性

### 模板示例

```json
{
    "label": {
        "en-US": "Cloud Service",
        "zh-Hans": "云服务"
    },
    "form_schema": [
        {
            "type": "select",
            "label": {
                "en-US": "Cloud Provider",
                "zh-Hans": "云厂商"
            },
            "variable": "cloud_provider",
            "required": true,
            "options": [
                {
                    "label": {
                        "en-US": "AWS",
                        "zh-Hans": "亚马逊"
                    },
                    "value": "AWS"
                },
                {
                    "label": {
                        "en-US": "Google Cloud",
                        "zh-Hans": "谷歌云"
                    },
                    "value": "GoogleCloud"
                },
                {
                    "label": {
                        "en-US": "Azure Cloud",
                        "zh-Hans": "微软云"
                    },
                    "value": "Azure"
                }
            ],
            "default": "GoogleCloud",
            "placeholder": ""
        },
        {
            "type": "text-input",
            "label": {
                "en-US": "API Endpoint",
                "zh-Hans": "API Endpoint"
            },
            "variable": "api_endpoint",
            "required": true,
            "max_length": 100,
            "default": "",
            "placeholder": "https://api.example.com"
        },
        {
            "type": "paragraph",
            "label": {
                "en-US": "API Key",
                "zh-Hans": "API Key"
            },
            "variable": "api_keys",
            "required": true,
            "default": "",
            "placeholder": "Paste your API key here"
        }
    ]
}
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/extensions/code-based/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 外部数据工具
> 来源：`zh-hans/guides/tools/extensions/code-based/external-data-tool.mdx`

外部数据工具用于在终端用户提交数据后，利用外部工具获取额外数据组装至提示词中作为 LLM 额外上下文信息。Dify 默认提供了外部 API 调用的工具，具体参见 [基于 API 的扩展](./zh-hans/guides/tools/extensions/api-based/api-based-extension)。

而对于本地部署 Dify 的开发者，为了满足更加定制化的需求，或者不希望额外开发一个 API Server，可以直接在 Dify 服务的基础上，以插件的形式插入定制的外部数据工具实现逻辑。扩展自定义工具后，将会在工具类型的下拉列表中增加你的自定义工具选项，团队成员即可使用自定义的工具来获取外部数据。

## 快速开始

这里以一个 `天气查询` 外部数据工具扩展为例，步骤如下：

1. 初始化目录
2. 添加前端表单规范
3. 添加实现类
4. 预览前端界面
5. 调试扩展

### 1. **初始化目录**

新增自定义类型 `Weather Search` ，需要在 `api/core/external_data_tool` 目录下新建相关的目录和文件。

```python
.
└── api
    └── core
        └── external_data_tool
            └── weather_search
                ├── __init__.py
                ├── weather_search.py
                └── schema.json
```

### 2. **添加前端组件规范**

* `schema.json`，定义前端组件，详细请参考[基于代码的扩展](./zh-hans/guides/tools/extensions/code-based/external-data-tool)

```json
{
    "label": {
        "en-US": "Weather Search",
        "zh-Hans": "天气查询"
    },
    "form_schema": [
        {
            "type": "select",
            "label": {
                "en-US": "Temperature Unit",
                "zh-Hans": "温度单位"
            },
            "variable": "temperature_unit",
            "required": true,
            "options": [
                {
                    "label": {
                        "en-US": "Fahrenheit",
                        "zh-Hans": "华氏度"
                    },
                    "value": "fahrenheit"
                },
                {
                    "label": {
                        "en-US": "Centigrade",
                        "zh-Hans": "摄氏度"
                    },
                    "value": "centigrade"
                }
            ],
            "default": "centigrade",
            "placeholder": "Please select temperature unit"
        }
    ]
}
```

### 3. 添加实现类

`weather_search.py` 代码模板，你可以在这里实现具体的业务逻辑。

> **提示：warning**

注意：类变量 name 为自定义类型名称，需要跟目录和文件名保持一致，而且唯一。

```python
from typing import Optional

from core.external_data_tool.base import ExternalDataTool

class WeatherSearch(ExternalDataTool):
    """
    The name of custom type must be unique, keep the same with directory and file name.
    """
    name: str = "weather_search"

    @classmethod
    def validate_config(cls, tenant_id: str, config: dict) -> None:
        """
        schema.json validation. It will be called when user save the config.

        Example:
            .. code-block:: python
                config = 
                    "temperature_unit": "centigrade"

        :param tenant_id: the id of workspace
        :param config: the variables of form config
        :return:
        """

        if not config.get('temperature_unit'):
            raise ValueError('temperature unit is required')

    def query(self, inputs: dict, query: Optional[str] = None) -> str:
        """
        Query the external data tool.

        :param inputs: user inputs
        :param query: the query of chat app
        :return: the tool query result
        """
        city = inputs.get('city')
        temperature_unit = self.config.get('temperature_unit')

        if temperature_unit == 'fahrenheit':
            return f'Weather in city is 32°F'
        else:
            return f'Weather in city is 0°C'
```

### 4. **调试扩展**

至此，即可在 Dify 应用编排界面选择自定义的 `Weather Search` 外部数据工具扩展类型进行调试。

## 实现类模板

```python
from typing import Optional

from core.external_data_tool.base import ExternalDataTool

class WeatherSearch(ExternalDataTool):
    """
    The name of custom type must be unique, keep the same with directory and file name.
    """
    name: str = "weather_search"

    @classmethod
    def validate_config(cls, tenant_id: str, config: dict) -> None:
        """
        schema.json validation. It will be called when user save the config.

        :param tenant_id: the id of workspace
        :param config: the variables of form config
        :return:
        """

        # implement your own logic here

    def query(self, inputs: dict, query: Optional[str] = None) -> str:
        """
        Query the external data tool.

        :param inputs: user inputs
        :param query: the query of chat app
        :return: the tool query result
        """

        # implement your own logic here
        return "your own data."
```

### 实现类开发详细介绍

### def validate\_config

`schema.json` 表单校验方法，当用户点击「发布」保存配置时调用

* `config` 表单参数
  * `{{variable}}` 表单自定义变量

### def query

用户自定义数据查询实现，返回的结果将会被替换到指定的变量。

* `inputs` ：终端用户传入变量值
* `query` ：终端用户当前对话输入内容，对话型应用固定参数。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/extensions/code-based/external-data-tool.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 敏感内容审查
> 来源：`zh-hans/guides/tools/extensions/code-based/moderation.mdx`

除了系统内置的内容审查类型，Dify 也支持用户扩展自定义的内容审查规则，该方法适用于私有部署的开发者定制开发。比如企业内部客服，规定用户在查询的时候以及客服回复的时候，除了不可以输入暴力，性和非法行为等相关词语，也不能出现企业自己规定的禁词或违反内部制定的审查逻辑，那么开发者可以在私有部署的 Dify 代码层扩展自定义内容审查规则。

## 快速开始

这里以一个 `Cloud Service` 内容审查扩展为例，步骤如下：

1. 初始化目录
2. 添加前端组件定义文件
3. 添加实现类
4. 预览前端界面
5. 调试扩展

### 1. 初始化目录

新增自定义类型 `Cloud Service`，需要在 `api/core/moderation` 目录下新建相关的目录和文件。

```Plain
.
└── api
    └── core
        └── moderation
            └── cloud_service
                ├── __init__.py
                ├── cloud_service.py
                └── schema.json
```

### 2.添加前端组件规范

* `schema.json`，这里定义了前端组件规范，详细见 [Broken link](./zh-hans/guides/extension/code-based-extension) 。

```json
{
    "label": {
        "en-US": "Cloud Service",
        "zh-Hans": "云服务"
    },
    "form_schema": [
        {
            "type": "select",
            "label": {
                "en-US": "Cloud Provider",
                "zh-Hans": "云厂商"
            },
            "variable": "cloud_provider",
            "required": true,
            "options": [
                {
                    "label": {
                        "en-US": "AWS",
                        "zh-Hans": "亚马逊"
                    },
                    "value": "AWS"
                },
                {
                    "label": {
                        "en-US": "Google Cloud",
                        "zh-Hans": "谷歌云"
                    },
                    "value": "GoogleCloud"
                },
                {
                    "label": {
                        "en-US": "Azure Cloud",
                        "zh-Hans": "微软云"
                    },
                    "value": "Azure"
                }
            ],
            "default": "GoogleCloud",
            "placeholder": ""
        },
        {
            "type": "text-input",
            "label": {
                "en-US": "API Endpoint",
                "zh-Hans": "API Endpoint"
            },
            "variable": "api_endpoint",
            "required": true,
            "max_length": 100,
            "default": "",
            "placeholder": "https://api.example.com"
        },
        {
            "type": "paragraph",
            "label": {
                "en-US": "API Key",
                "zh-Hans": "API Key"
            },
            "variable": "api_keys",
            "required": true,
            "default": "",
            "placeholder": "Paste your API key here"
        }
    ]
}
```

### 3. 添加实现类

`cloud_service.py` 代码模板，你可以在这里实现具体的业务逻辑。

> **提示：**

注意：类变量 name 为自定义类型名称，需要跟目录和文件名保持一致，而且唯一。

```python
from core.moderation.base import Moderation, ModerationAction, ModerationInputsResult, ModerationOutputsResult

class CloudServiceModeration(Moderation):
    """
    The name of custom type must be unique, keep the same with directory and file name.
    """
    name: str = "cloud_service"

    @classmethod
    def validate_config(cls, tenant_id: str, config: dict) -> None:
        """
        schema.json validation. It will be called when user save the config.

        Example:
            .. code-block:: python
                config = {
                    "cloud_provider": "GoogleCloud",
                    "api_endpoint": "https://api.example.com",
                    "api_keys": "123456",
                    "inputs_config": {
                        "enabled": True,
                        "preset_response": "Your content violates our usage policy. Please revise and try again."
                    },
                    "outputs_config": 
                        "enabled": True,
                        "preset_response": "Your content violates our usage policy. Please revise and try again."

                }

        :param tenant_id: the id of workspace
        :param config: the variables of form config
        :return:
        """

        cls._validate_inputs_and_outputs_config(config, True)

        if not config.get("cloud_provider"):
            raise ValueError("cloud_provider is required")

        if not config.get("api_endpoint"):
            raise ValueError("api_endpoint is required")

        if not config.get("api_keys"):
            raise ValueError("api_keys is required")

    def moderation_for_inputs(self, inputs: dict, query: str = "") -> ModerationInputsResult:
        """
        Moderation for inputs.

        :param inputs: user inputs
        :param query: the query of chat app, there is empty if is completion app
        :return: the moderation result
        """
        flagged = False
        preset_response = ""

        if self.config['inputs_config']['enabled']:
            preset_response = self.config['inputs_config']['preset_response']

            if query:
                inputs['query__'] = query
            flagged = self._is_violated(inputs)

        # return ModerationInputsResult(flagged=flagged, action=ModerationAction.overridden, inputs=inputs, query=query)
        return ModerationInputsResult(flagged=flagged, action=ModerationAction.DIRECT_OUTPUT, preset_response=preset_response)

    def moderation_for_outputs(self, text: str) -> ModerationOutputsResult:
        """
        Moderation for outputs.

        :param text: the text of LLM response
        :return: the moderation result
        """
        flagged = False
        preset_response = ""

        if self.config['outputs_config']['enabled']:
            preset_response = self.config['outputs_config']['preset_response']

            flagged = self._is_violated('text': text)

        # return ModerationOutputsResult(flagged=flagged, action=ModerationAction.overridden, text=text)
        return ModerationOutputsResult(flagged=flagged, action=ModerationAction.DIRECT_OUTPUT, preset_response=preset_response)

    def _is_violated(self, inputs: dict):
        """
        The main logic of moderation.

        :param inputs:
        :return: the moderation result
        """
        return False
```

### 4. 调试扩展

至此，即可在 Dify 应用编排界面选择自定义的 `Cloud Service` 内容审查扩展类型进行调试。

## 实现类模板

```python
from core.moderation.base import Moderation, ModerationAction, ModerationInputsResult, ModerationOutputsResult

class CloudServiceModeration(Moderation):
    """
    The name of custom type must be unique, keep the same with directory and file name.
    """
    name: str = "cloud_service"

    @classmethod
    def validate_config(cls, tenant_id: str, config: dict) -> None:
        """
        schema.json validation. It will be called when user save the config.

        :param tenant_id: the id of workspace
        :param config: the variables of form config
        :return:
        """
        cls._validate_inputs_and_outputs_config(config, True)

        # implement your own logic here

    def moderation_for_inputs(self, inputs: dict, query: str = "") -> ModerationInputsResult:
        """
        Moderation for inputs.

        :param inputs: user inputs
        :param query: the query of chat app, there is empty if is completion app
        :return: the moderation result
        """
        flagged = False
        preset_response = ""

        # implement your own logic here

        # return ModerationInputsResult(flagged=flagged, action=ModerationAction.overridden, inputs=inputs, query=query)
        return ModerationInputsResult(flagged=flagged, action=ModerationAction.DIRECT_OUTPUT, preset_response=preset_response)

    def moderation_for_outputs(self, text: str) -> ModerationOutputsResult:
        """
        Moderation for outputs.

        :param text: the text of LLM response
        :return: the moderation result
        """
        flagged = False
        preset_response = ""

        # implement your own logic here

        # return ModerationOutputsResult(flagged=flagged, action=ModerationAction.overridden, text=text)
        return ModerationOutputsResult(flagged=flagged, action=ModerationAction.DIRECT_OUTPUT, preset_response=preset_response)
```

## 实现类开发详细介绍

### def validate\_config

`schema.json` 表单校验方法，当用户点击「发布」保存配置时调用

* `config` 表单参数
  * `{{variable}}` 表单自定义变量
  * `inputs_config` 输入审查预设回复
    * `enabled` 是否开启
    * `preset_response` 输入预设回复
  * `outputs_config`输出审查预设回复
    * `enabled` 是否开启
    * `preset_response` 输出预设回复

### def moderation\_for\_inputs

输入校验函数

* `inputs` ：终端用户传入变量值
* `query` ：终端用户当前对话输入内容，对话型应用固定参数。
* `ModerationInputsResult`
  * `flagged` 是否违反校验规则
  * `action` 执行动作
    * `direct_output` 直接输出预设回复
    * `overridden` 覆写传入变量值
  * `preset_response` 预设回复（仅当 action=direct\_output 返回）
  * `inputs` 终端用户传入变量值，key 为变量名，value 为变量值（仅当 action=overridden 返回）
  * `query` 覆写的终端用户当前对话输入内容，对话型应用固定参数。（仅当 action=overridden 返回）

### def moderation\_for\_outputs

输出校验函数

* `text` ：模型输出内容
* `moderation_for_outputs` ：输出校验函数
  * `text` ：LLM 回答内容。当 LLM 输出为流式时，此处为 100 字为一个分段的内容。
  * `ModerationOutputsResult`
    * `flagged` 是否违反校验规则
    * `action` 执行动作
      * `direct_output`直接输出预设回复
      * `overridden`覆写传入变量值
    * `preset_response` 预设回复（仅当 action=direct\_output 返回）
    * `text` 覆写的 LLM 回答内容（仅当 action=overridden 返回）。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/extensions/code-based/moderation.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 工具说明
> 来源：`zh-hans/guides/tools/introduction.mdx`

### 工具定义

工具可以扩展 LLM 的能力，比如联网搜索、科学计算或绘制图片，赋予并增强了 LLM 连接外部世界的能力。Dify 提供了两种工具类型：**第一方工具**和**自定义工具**。

你可以直接使用 Dify 生态提供的第一方内置工具，或者轻松导入自定义的 API 工具（目前支持 OpenAPI / Swagger 和 OpenAI Plugin 规范）。

#### 工具的作用：

1. 工具使用户可以在 Dify 上创建更强大的 AI 应用，如你可以为智能助理型应用（Agent）编排合适的工具，它可以通过任务推理、步骤拆解、调用工具完成复杂任务。
2. 方便将你的应用与其他系统或服务连接，与外部环境交互，如代码执行、对专属信息源的访问等。

### 如何配置第一方工具

  **[图片缺失] 第一方工具列表 (zh-hans/user-guide/.gitbook/assets/image (182).png)**

Dify 目前已支持：

<table><thead><tr><th width="154">工具</th><th>工具描述</th></tr></thead><tbody><tr><td>谷歌搜索</td><td>用于执行 Google SERP 搜索并提取片段和网页的工具，输入应该是一个搜索查询</td></tr><tr><td>维基百科</td><td>用于执行维基百科搜索并提取片段和网页的工具</td></tr><tr><td>DALL-E 绘画</td><td>用于通过自然语言输入生成高质量图片</td></tr><tr><td>网页抓取</td><td>用于爬取网页数据的工具</td></tr><tr><td>WolframAlpha</td><td>一个强大的计算知识引擎，能根据问题直接给出标准化答案，同时具有强大的数学计算功能</td></tr><tr><td>图表生成</td><td>用于生成可视化图表的工具，你可以通过它来生成柱状图、折线图、饼图等各类图表</td></tr><tr><td>当前时间</td><td>用于查询当前时间的工具</td></tr><tr><td>雅虎财经</td><td>获取并整理出最新的新闻、股票报价等一切你想要的财经信息</td></tr><tr><td>Stable Diffusion</td><td>一个可以在本地部署的图片生成的工具，您可以使用 stable-diffusion-webui 来部署它</td></tr><tr><td>Vectorizer</td><td>一个将 PNG 和 JPG 图像快速轻松地转换为 SVG 矢量图的工具</td></tr><tr><td>YouTube</td><td>一个用于获取油管频道视频统计数据的工具</td></tr></tbody></table>

> **提示：**

欢迎您为 Dify 贡献自己开发的工具，关于如何贡献的具体方法请查看 [Dify 开发贡献文档](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md)，您的任何支持对我们都是极为宝贵的。

#### 第一方工具授权

若你需要直接使用 Dify 生态提供的第一方内置工具，你需要在使用前配置相应的凭据。

  **[图片缺失] 配置第一方工具凭据 (zh-hans/user-guide/.gitbook/assets/image (185).png)**

凭据校验成功后工具会显示"已授权"状态。配置凭据后，工作区中的所有成员都可以在编排应用程序时使用此工具。

  **[图片缺失] 第一方工具已授权 (zh-hans/user-guide/.gitbook/assets/image (187).png)**

### 如何创建自定义工具

你可以在"工具-自定义工具"内导入自定义的 API 工具，目前支持 OpenAPI / Swagger 和 ChatGPT Plugin 规范。你可以将 OpenAPI schema 内容直接粘贴或从 URL 内导入。关于 OpenAPI / Swagger 规范您可以查看[官方文档说明](https://swagger.io/specification/)。

工具目前支持两种鉴权方式：无鉴权 和 API Key。

  **[图片缺失] 创建自定义工具 (zh-hans/user-guide/.gitbook/assets/image (198).png)**

在导入 Schema 内容后系统会主动解析文件内的参数，并可预览工具具体的参数、 方法、路径。您也可以在此对工具参数进行测试。

  **[图片缺失] 自定义工具参数测试 (zh-hans/user-guide/.gitbook/assets/image (199).png)**

完成自定义工具创建之后，工作区中的所有成员都可以在"工作室"内编排应用程序时使用此工具。

  **[图片缺失] 已添加自定义工具 (zh-hans/user-guide/.gitbook/assets/image (201).png)**

#### Cloudflare Workers

您也可以使用 [dify-tools-worker](https://github.com/crazywoola/dify-tools-worker) 来快速部署自定义工具。该工具提供了：

* 可以导入 Dify 的路由 `https://difytoolsworker.yourname.workers.dev/doc`, 提供了 OpenAPI 兼容的接口文档
* API 的实现代码，可以直接部署到 Cloudflare Workers

### 如何在应用内使用工具

目前，您可以在"工作室"中创建**智能助手型应用**时，将已配置好凭据的工具在其中使用。

  **[图片缺失] 创建智能助手型应用时添加工具 (zh-hans/user-guide/.gitbook/assets/image (190).png)**

以下图为例，在财务分析应用内添加工具后，智能助手将在需要时自主调用工具，从工具中查询财务报告数据，并将数据分析后完成与用户之间的对话。

  **[图片缺失] 智能助手在对话中完成工具调用回复问题 (zh-hans/user-guide/.gitbook/assets/image (195).png)**

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/introduction.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 集成 MCP 工具
> 来源：`zh-hans/guides/tools/mcp.mdx`

你可以在 Dify 的 Agent 和 Workflow 应用中，直接集成来自外部 [MCP](https://modelcontextprotocol.io/introduction) 服务器的[工具](https://modelcontextprotocol.io/docs/concepts/tools)。除了使用 Dify 内置插件外，还可以接入 MCP [生态系统](https://mcpservers.org/)中的第三方服务，持续扩展你的应用功能。

  本文介绍了如何在 Dify 内集成和使用 MCP 工具。如果你希望将自己的 Dify 应用发布为 MCP 服务器，请参考此[链接](./zh-hans/guides/application-publishing/publish-mcp)。

> **信息提示：**

  目前仅支持接入使用 HTTP 传输协议的 [MCP 服务器](https://modelcontextprotocol.io/docs/concepts/architecture#transport-layer) 。

## MCP 服务器管理界面

登录 Dify 后，在左侧导航栏中依次点击 **工具** → **MCP**，即可进入外部 MCP 服务器的管理页面。在这里，你可以统一管理所有为自身应用配置的 MCP 服务器。

![6cef1436fcc13a65ccedb54bcf5ab77eb87b8faba1098a85951839fb1907f2d2.png](./images/6cef1436fcc13a65ccedb54bcf5ab77eb87b8faba1098a85951839fb1907f2d2.png)

## 添加 MCP 服务器

![b5429131836c1caae84f4ce8b3b806221e39636723644961ce2f2a97d5421f16.png](images/b5429131836c1caae84f4ce8b3b806221e39636723644961ce2f2a97d5421f16.png)

点击 **添加 MCP 服务器（HTTP）**，即可集成新的外部工具服务。需要填写如下信息：

* **服务器 URL**：MCP 服务器的 HTTP 接口地址，例如集成 Notion 时为 `https://api.notion.com/mcp`。

* **名称与图标**：自定义服务器名称，建议选择能清晰体现工具用途的名字。Dify 会自动尝试获取服务器域名的图标，你也可以手动上传。

* **服务器标识符**：Dify 用于区分服务器的唯一 ID。规则：小写字母、数字、下划线或连字符，最多 24 个字符。

> **警告：**

  服务器 ID 一旦创建即无法更改。如果更改服务器 ID，所有依赖该服务器工具的 Agent 或 Workflow 都会失效。这一设计对于[应用迁移](##application-portability)尤为重要。

## 授权与工具发现

添加服务器后，Dify 会自动执行如下操作：

1. **检测可用工具**：自动识别该服务器能提供哪些工具功能。
2. **处理授权流程**：如服务器需要身份验证，则自动发起 OAuth 授权流程。
3. **获取工具定义**：下载各工具的接口定义（schema）。
4. **同步工具列表**：将识别到的工具加入 Agent 或Workflow应用的构建页面。

当 Dify 成功获取到至少一个可用工具后，会在页面中显示该服务器的信息卡片：

![fcef5ecad1deca82a1d8988c4bcb7cec745a0cd47945ff05fca588502cfaafbc.png](./images/fcef5ecad1deca82a1d8988c4bcb7cec745a0cd47945ff05fca588502cfaafbc.png)

## 管理已连接服务器

点击对应服务器卡片，可进行以下操作：

* **更新工具**：重新从服务器获取最新工具信息，适用于服务方新增或调整功能后更新。

  ![7b526a64ff34b10a357511b2cd3e42f251a6786210eac71c58ca7bfccdf63f0c.png](images/7b526a64ff34b10a357511b2cd3e42f251a6786210eac71c58ca7bfccdf63f0c.png)

* **重新授权**：点击授权状态，更新服务器的访问权限（如令牌失效需重新授权）。

* **编辑配置**：可修改服务器信息。

> **警告：**

  更改服务器 URL 会触发重新授权，修改服务器 ID 会让已有应用失效！

![CleanShot 2025-07-07 at 07.28.04@2x.png](images/CleanShot2025-07-07at07.28.04@2x.png)

* **移除服务器**：断开服务器连接。此后所有依赖该服务器工具的应用都会报错，直到你重新连接或删除相关工具。

## 在应用中使用 MCP 工具

当服务器配置完成后，其下的工具会出现在应用构建时的工具选择区：

### Agent 应用

- 在 Agent 配置界面，与内置工具并列显示 MCP 工具。
- 工具按服务器分组，例如："Notion MCP » 创建页面"、"Linear MCP » 创建任务"等。
- 可一键"添加全部"，快速启用该服务器下的所有工具。

### Workflow 应用

- 构建 Workflow 时，MCP 工具以可选节点类型出现。
- 每个工具节点都会指明归属服务器，便于定位和排查问题。
- 参数较为复杂的工具会自动生成 JSON 格式的结构化输入界面。

### Workflows 中的 Agent 节点

在 Workflow 的 Agent 节点中，也可灵活选择 MCP 工具进行配置，使用方式与独立 Agent 一致。

## 按需定制 MCP 工具

将 MCP 工具添加到Agent节点或 Agent 应用中后，你可以根据实际需求灵活定制：

![CleanShot 2025-07-07 at 07.41.33@2x.png](images/CleanShot2025-07-07at07.41.33@2x.png)

### 工具说明

可自定义工具的显示描述，调整为更贴合业务场景的说明信息，替换原 MCP 服务器自带描述。

### 参数配置（Reasoning Config）

每个工具参数可灵活选择两种模式：

* **自动（Auto）**：让 AI 根据上下文智能决定该参数值（默认）。

* **固定值（Fixed Value）**：设定为某个确定的值（支持静态文本或变量表达式），AI 不再推理此参数。

使用示例：

* 统一配置项，例如将搜索工具的 `numResults` 固定为 10。
* 预填写不应更改的参数，如特定的 API 地址、返回格式等。
* 通过减少 AI 需要处理的参数数量，简化工具调用逻辑。

例如，配置 Web 搜索工具时：

* 将 `query` 设置为"自动"，由 AI 动态生成搜索内容。
* 将 `numResults` 固定为 5，控制每次返回结果数量。
* 其他如过滤条件参数也可固定，以保证结果一致性。

## 应用迁移

当你导出包含 MCP 工具的 Dify 应用时：

* **DSL 导出**：导出的 DSL 文件会引用所用 MCP 服务器的唯一标识符（ID）。
* **环境迁移**：迁移应用到其他环境时，需在目标环境添加相同 ID 的 MCP 服务器。这样可以确保工具引用关系保持不变。
* **应用共享**：建议在文档中明确标注依赖的 MCP 服务器（包括 URL 和 ID），以便团队协作和环境同步。

## 常见问题排查

**"未配置的服务器"**: 授权失败或未获取到工具。请检查服务器 URL 并重新授权。

**应用内工具缺失**: 点击"更新工具" - 有可能外部服务更改了工具列表。

**服务器变动导致应用失效**: 如果修改服务器 ID 或移除服务器，应用会报错。需用原 ID 重新添加服务器，以恢复功能。

## 最佳实践

**服务器 ID 保持一致性**: 使用具备描述性的 ID 名，例如 `github-mcp` 或者 `salesforce-api`。ID 一旦被应用引用，请勿更改。

**多环境一致性**: 开发、测试、生产等环境的 MCP 服务器配置应保持一致。

**工具定制**: 主动设置固定参数值，保证工具行为稳定、简化 AI 推理，仅将动态输入交由 AI 处理。

**工具文档**: 明确记录应用中用到的外部工具、定制内容及其用途，方便团队后续运维与协作。

**逐步升级**: 外部服务升级或变更 MCP 服务器时，应先在开发环境测试通过后，再同步到生产环境。

**应急方案**: 提前规划好关键外部 MCP 服务器不可用时的应用应对策略。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/mcp.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 快速接入工具
> 来源：`zh-hans/guides/tools/quick-tool-integration.mdx`

这里我们以 GoogleSearch 为例，介绍如何快速接入一个工具。

### 1. 准备工具供应商 yaml

#### 介绍

这个 yaml 将包含工具供应商的信息，包括供应商名称、图标、作者等详细信息，以帮助前端灵活展示。

#### 示例

我们需要在 `core/tools/provider/builtin`下创建一个`google`模块（文件夹），并创建`google.yaml`，名称必须与模块名称一致。

后续，我们关于这个工具的所有操作都将在这个模块下进行。

```yaml
identity: # 工具供应商的基本信息
  author: Dify # 作者
  name: google # 名称，唯一，不允许和其他供应商重名
  label: # 标签，用于前端展示
    en_US: Google # 英文标签
    zh_Hans: Google # 中文标签
  description: # 描述，用于前端展示
    en_US: Google # 英文描述
    zh_Hans: Google # 中文描述
  icon: icon.svg # 图标，需要放置在当前模块的_assets文件夹下

```

* `identity` 字段是必须的，它包含了工具供应商的基本信息，包括作者、名称、标签、描述、图标等
  *   图标需要放置在当前模块的`_assets`文件夹下，可以参考这里：api/core/tools/provider/builtin/google/\_assets/icon.svg

      ```xml
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="25" viewBox="0 0 24 25" fill="none">
        <path d="M22.501 12.7332C22.501 11.8699 22.4296 11.2399 22.2748 10.5865H12.2153V14.4832H18.12C18.001 15.4515 17.3582 16.9099 15.9296 17.8898L15.9096 18.0203L19.0902 20.435L19.3106 20.4565C21.3343 18.6249 22.501 15.9298 22.501 12.7332Z" fill="#4285F4"/>
        <path d="M12.214 23C15.1068 23 17.5353 22.0666 19.3092 20.4567L15.9282 17.8899C15.0235 18.5083 13.8092 18.9399 12.214 18.9399C9.38069 18.9399 6.97596 17.1083 6.11874 14.5766L5.99309 14.5871L2.68583 17.0954L2.64258 17.2132C4.40446 20.6433 8.0235 23 12.214 23Z" fill="#34A853"/>
        <path d="M6.12046 14.5766C5.89428 13.9233 5.76337 13.2233 5.76337 12.5C5.76337 11.7766 5.89428 11.0766 6.10856 10.4233L6.10257 10.2841L2.75386 7.7355L2.64429 7.78658C1.91814 9.20993 1.50146 10.8083 1.50146 12.5C1.50146 14.1916 1.91814 15.7899 2.64429 17.2132L6.12046 14.5766Z" fill="#FBBC05"/>
        <path d="M12.2141 6.05997C14.2259 6.05997 15.583 6.91163 16.3569 7.62335L19.3807 4.73C17.5236 3.03834 15.1069 2 12.2141 2C8.02353 2 4.40447 4.35665 2.64258 7.78662L6.10686 10.4233C6.97598 7.89166 9.38073 6.05997 12.2141 6.05997Z" fill="#EB4335"/>
      </svg>
      ```

### 2. 准备供应商凭据

Google 作为一个第三方工具，使用了 SerpApi 提供的 API，而 SerpApi 需要一个 API Key 才能使用，那么就意味着这个工具需要一个凭据才可以使用，而像`wikipedia`这样的工具，就不需要填写凭据字段，可以参考这里：api/core/tools/provider/builtin/wikipedia/wikipedia.yaml

```yaml
identity:
  author: Dify
  name: wikipedia
  label:
    en_US: Wikipedia
    zh_Hans: 维基百科
    pt_BR: Wikipedia
  description:
    en_US: Wikipedia is a free online encyclopedia, created and edited by volunteers around the world.
    zh_Hans: 维基百科是一个由全世界的志愿者创建和编辑的免费在线百科全书。
    pt_BR: Wikipedia is a free online encyclopedia, created and edited by volunteers around the world.
  icon: icon.svg
credentials_for_provider:
```

配置好凭据字段后效果如下：

```yaml
identity:
  author: Dify
  name: google
  label:
    en_US: Google
    zh_Hans: Google
  description:
    en_US: Google
    zh_Hans: Google
  icon: icon.svg
credentials_for_provider: # 凭据字段
  serpapi_api_key: # 凭据字段名称
    type: secret-input # 凭据字段类型
    required: true # 是否必填
    label: # 凭据字段标签
      en_US: SerpApi API key # 英文标签
      zh_Hans: SerpApi API key # 中文标签
    placeholder: # 凭据字段占位符
      en_US: Please input your SerpApi API key # 英文占位符
      zh_Hans: 请输入你的 SerpApi API key # 中文占位符
    help: # 凭据字段帮助文本
      en_US: Get your SerpApi API key from SerpApi # 英文帮助文本
      zh_Hans: 从 SerpApi 获取您的 SerpApi API key # 中文帮助文本
    url: https://serpapi.com/manage-api-key # 凭据字段帮助链接

```

* `type`：凭据字段类型，目前支持`secret-input`、`text-input`、`select` 三种类型，分别对应密码输入框、文本输入框、下拉框，如果为`secret-input`，则会在前端隐藏输入内容，并且后端会对输入内容进行加密。

### 3. 准备工具 yaml

一个供应商底下可以有多个工具，每个工具都需要一个 yaml 文件来描述，这个文件包含了工具的基本信息、参数、输出等。

仍然以 GoogleSearch 为例，我们需要在`google`模块下创建一个`tools`模块，并创建`tools/google_search.yaml`，内容如下。

```yaml
identity: # 工具的基本信息
  name: google_search # 工具名称，唯一，不允许和其他工具重名
  author: Dify # 作者
  label: # 标签，用于前端展示
    en_US: GoogleSearch # 英文标签
    zh_Hans: 谷歌搜索 # 中文标签
description: # 描述，用于前端展示
  human: # 用于前端展示的介绍，支持多语言
    en_US: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.
    zh_Hans: 一个用于执行 Google SERP 搜索并提取片段和网页的工具。输入应该是一个搜索查询。
  llm: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query. # 传递给 LLM 的介绍，为了使得LLM更好理解这个工具，我们建议在这里写上关于这个工具尽可能详细的信息，让 LLM 能够理解并使用这个工具
parameters: # 参数列表
  - name: query # 参数名称
    type: string # 参数类型
    required: true # 是否必填
    label: # 参数标签
      en_US: Query string # 英文标签
      zh_Hans: 查询语句 # 中文标签
    human_description: # 用于前端展示的介绍，支持多语言
      en_US: used for searching
      zh_Hans: 用于搜索网页内容
    llm_description: key words for searching # 传递给LLM的介绍，同上，为了使得LLM更好理解这个参数，我们建议在这里写上关于这个参数尽可能详细的信息，让LLM能够理解这个参数
    form: llm # 表单类型，llm表示这个参数需要由Agent自行推理出来，前端将不会展示这个参数
  - name: result_type
    type: select # 参数类型
    required: true
    options: # 下拉框选项
      - value: text
        label:
          en_US: text
          zh_Hans: 文本
      - value: link
        label:
          en_US: link
          zh_Hans: 链接
    default: link
    label:
      en_US: Result type
      zh_Hans: 结果类型
    human_description:
      en_US: used for selecting the result type, text or link
      zh_Hans: 用于选择结果类型，使用文本还是链接进行展示
    form: form # 表单类型，form表示这个参数需要由用户在对话开始前在前端填写

```

* `identity` 字段是必须的，它包含了工具的基本信息，包括名称、作者、标签、描述等
* `parameters` 参数列表
  * `name` 参数名称，唯一，不允许和其他参数重名
  * `type` 参数类型，目前支持`string`、`number`、`boolean`、`select` 四种类型，分别对应字符串、数字、布尔值、下拉框
  * `required` 是否必填
    * 在`llm`模式下，如果参数为必填，则会要求 Agent 必须要推理出这个参数
    * 在`form`模式下，如果参数为必填，则会要求用户在对话开始前在前端填写这个参数
  * `options` 参数选项
    * 在`llm`模式下，Dify 会将所有选项传递给 LLM，LLM 可以根据这些选项进行推理
    * 在`form`模式下，`type`为`select`时，前端会展示这些选项
  * `default` 默认值
  * `label` 参数标签，用于前端展示
  * `human_description` 用于前端展示的介绍，支持多语言
  * `llm_description` 传递给 LLM 的介绍，为了使得 LLM 更好理解这个参数，我们建议在这里写上关于这个参数尽可能详细的信息，让 LLM 能够理解这个参数
  * `form` 表单类型，目前支持`llm`、`form`两种类型，分别对应 Agent 自行推理和前端填写

### 4. 准备工具代码

当完成工具的配置以后，我们就可以开始编写工具代码了，主要用于实现工具的逻辑。

在`google/tools`模块下创建`google_search.py`，内容如下。

```python
from core.tools.tool.builtin_tool import BuiltinTool
from core.tools.entities.tool_entities import ToolInvokeMessage

from typing import Any, Dict, List, Union

class GoogleSearchTool(BuiltinTool):
    def _invoke(self, 
                user_id: str,
               tool_Parameters: Dict[str, Any], 
        ) -> Union[ToolInvokeMessage, List[ToolInvokeMessage]]:
        """
            invoke tools
        """
        query = tool_Parameters['query']
        result_type = tool_Parameters['result_type']
        api_key = self.runtime.credentials['serpapi_api_key']
        # TODO: search with serpapi
        result = SerpAPI(api_key).run(query, result_type=result_type)

        if result_type == 'text':
            return self.create_text_message(text=result)
        return self.create_link_message(link=result)
```

#### 参数

工具的整体逻辑都在`_invoke`方法中，这个方法接收两个参数：`user_id`和`tool_Parameters`，分别表示用户 ID 和工具参数

#### 返回数据

在工具返回时，你可以选择返回一个消息或者多个消息，这里我们返回一个消息，使用`create_text_message`和`create_link_message`可以创建一个文本消息或者一个链接消息。

### 5. 准备供应商代码

最后，我们需要在供应商模块下创建一个供应商类，用于实现供应商的凭据验证逻辑，如果凭据验证失败，将会抛出`ToolProviderCredentialValidationError`异常。

在`google`模块下创建`google.py`，内容如下。

```python
from core.tools.entities.tool_entities import ToolInvokeMessage, ToolProviderType
from core.tools.tool.tool import Tool
from core.tools.provider.builtin_tool_provider import BuiltinToolProviderController
from core.tools.errors import ToolProviderCredentialValidationError

from core.tools.provider.builtin.google.tools.google_search import GoogleSearchTool

from typing import Any, Dict

class GoogleProvider(BuiltinToolProviderController):
    def _validate_credentials(self, credentials: Dict[str, Any]) -> None:
        try:
            # 1. 此处需要使用 GoogleSearchTool()实例化一个 GoogleSearchTool，它会自动加载 GoogleSearchTool 的 yaml 配置，但是此时它内部没有凭据信息
            # 2. 随后需要使用 fork_tool_runtime 方法，将当前的凭据信息传递给 GoogleSearchTool
            # 3. 最后 invoke 即可，参数需要根据 GoogleSearchTool 的 yaml 中配置的参数规则进行传递
            GoogleSearchTool().fork_tool_runtime(
                meta=
                    "credentials": credentials,

            ).invoke(
                user_id='',
                tool_Parameters=
                    "query": "test",
                    "result_type": "link"
                ,
            )
        except Exception as e:
            raise ToolProviderCredentialValidationError(str(e))
```

### 完成

当上述步骤完成以后，我们就可以在前端看到这个工具了，并且可以在 Agent 中使用这个工具。

当然，因为 google\_search 需要一个凭据，在使用之前，还需要在前端配置它的凭据。

  ![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/tools/c99fed3e1bbe5d724810fd6118012071.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/quick-tool-integration.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 工具
> 来源：`zh-hans/guides/tools/readme.mdx`

> **警告：**

“工具”已全面升级为“插件”生态，详细的使用说明请参考[插件开发](https://docs.dify.ai/zh-hans/plugins/quick-start/install-plugins)。以下内容已归档。

### 工具定义

工具可以扩展 LLM 的能力，比如联网搜索、科学计算或绘制图片，赋予并增强了 LLM 连接外部世界的能力。Dify 提供了两种工具类型：**第一方工具**和**自定义工具**。

你可以直接使用 Dify 生态提供的第一方内置工具，或者轻松导入自定义的 API 工具（目前支持 OpenAPI / Swagger 和 OpenAI Plugin 规范）。

#### 工具的作用：

1. 工具使用户可以在 Dify 上创建更强大的 AI 应用，如你可以为智能助理型应用（Agent）编排合适的工具，它可以通过任务推理、步骤拆解、调用工具完成复杂任务。
2. 方便将你的应用与其他系统或服务连接，与外部环境交互，如代码执行、对专属信息源的访问等。

### 如何配置第一方工具

![](https://assets-docs.dify.ai/2025/04/a432b5067adff5513e49d9302e1e4e05.png)

Dify 目前已支持：

| 工具           | 工具描述                                                                             |
|----------------|--------------------------------------------------------------------------------------|
| 谷歌搜索       | 用于执行 Google SERP 搜索并提取片段和网页的工具。输入应该是一个搜索查询             |
| 维基百科       | 用于执行维基百科搜索并提取片段和网页的工具。                                         |
| DALL-E 绘画    | 用于通过自然语言输入生成高质量图片                                                   |
| 网页抓取       | 用于爬取网页数据的工具                                                               |
| WolframAlpha   | 一个强大的计算知识引擎，能根据问题直接给出标准化答案，同时具有强大的数学计算功能     |
| 图表生成       | 用于生成可视化图表的工具，你可以通过它来生成柱状图、折线图、饼图等各类图表          |
| 当前时间       | 用于查询当前时间的工具                                                               |
| 雅虎财经       | 获取并整理出最新的新闻、股票报价等一切你想要的财经信息。                             |
| Stable Diffusion | 一个可以在本地部署的图片生成的工具，你可以使用 stable-diffusion-webui 来部署它     |
| Vectorizer     | 一个将 PNG 和 JPG 图像快速轻松地转换为 SVG 矢量图的工具。                           |
| YouTube        | 一个用于获取油管频道视频统计数据的工具                                               |

> **信息提示：**

欢迎你为 Dify 贡献自己开发的工具，关于如何贡献的具体方法请查看 [Dify 开发贡献文档](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md)，你的任何支持对我们都是极为宝贵的。

#### 第一方工具授权

若你需要直接使用 Dify 生态提供的第一方内置工具，你需要在使用前配置相应的凭据。

![](https://assets-docs.dify.ai/2025/04/a784c7ee71d45f4a987210d0938a779f.png)

凭据校验成功后工具会显示“已授权”状态。配置凭据后，工作区中的所有成员都可以在编排应用程序时使用此工具。

![](https://assets-docs.dify.ai/2025/04/e4dd64a7b49c11db81fb11eaefa2f6c1.png)

### 如何创建自定义工具

你可以在“工具-自定义工具”内导入自定义的 API 工具，目前支持 OpenAPI / Swagger 和 ChatGPT Plugin 规范。你可以将 OpenAPI schema 内容直接粘贴或从 URL 内导入。关于 OpenAPI / Swagger 规范你可以查看[官方文档说明](https://swagger.io/specification/)。

工具目前支持两种鉴权方式：无鉴权 和 API Key。

![](https://assets-docs.dify.ai/2025/04/0caedfe38c05ad2c225ccc5dcdef12dc.png)

在导入 Schema 内容后系统会主动解析文件内的参数，并可预览工具具体的参数、 方法、路径。你也可以在此对工具参数进行测试。

![](https://assets-docs.dify.ai/2025/04/4f343dcfaff5cf6b63d9422c29359a6f.png)

完成自定义工具创建之后，工作区中的所有成员都可以在“工作室”内编排应用程序时使用此工具。

![](https://assets-docs.dify.ai/2025/04/969c49092f61529829c50cc03e7fa9e9.png)

#### Cloudflare Workers

你也可以使用 [dify-tools-worker](https://github.com/crazywoola/dify-tools-worker) 来快速部署自定义工具。该工具提供了：

* 可以导入 Dify 的路由 `https://difytoolsworker.yourname.workers.dev/doc`, 提供了 OpenAPI 兼容的接口文档
* API 的实现代码，可以直接部署到 Cloudflare Workers

### 如何在应用内使用工具

目前，你可以在“工作室”中创建**智能助手型应用**时，将已配置好凭据的工具在其中使用。

![](https://assets-docs.dify.ai/2025/04/70c01de59cce8fce27b62040ab729e78.png)

以下图为例，在财务分析应用内添加工具后，智能助手将在需要时自主调用工具，从工具中查询财务报告数据，并将数据分析后完成与用户之间的对话。

![](https://assets-docs.dify.ai/2025/04/cbeb1e1435fa56c43c3be957aac1c5f2.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## AlphaVantage 股票分析
> 来源：`zh-hans/guides/tools/tool-configuration/alphavantage.mdx`

> 工具作者 [@zhuhao](https://github.com/hwzhuhao)。

AlphaVantage 一个在线平台，它提供金融市场数据和API，便于个人投资者和开发者获取股票报价、技术指标和股票分析。本

## 1. 申请 AlphaVantage API Key

请在 [AlphaVantage](https://www.alphavantage.co/support/#api-key)申请 API Key。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > AlphaVantage > 去授权` 填写 API Key。

## 3. 使用工具

- **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `AlphaVantage` 工具节点。添加后，需要在节点内的 “输入变量 → 股票代码” 通过[变量](./zh-hans/user-guide/build-app/flow-app/variables)引用用户输入的查询内容。最后在 “结束” 节点内使用变量引用 `AlphaVantage` 节点输出的内容。

- **Agent 应用**

在 Agent 应用内添加 `AlphaVantage` 工具，然后在对话框内发送股票代码或大致描述，调用工具得到准确的金融数据。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/alphavantage.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Bing 搜索
> 来源：`zh-hans/guides/tools/tool-configuration/bing.mdx`

> 工具作者 @Dify。

Bing 搜索工具能够帮助你在使用 LLM 应用的时候，获取联网搜索结果。以下是在 Dify 中配置和使用 Bing 搜索工具的步骤。

## 1. 申请 Bing API Key

请在 [Azure 平台](https://platform.openai.com/)申请 API Key。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > Azure > 去授权` 填写 API Key。

![](./zh-hans/img/5e8f18c29c50f14c5c83d7b45c546725.png)

## 3. 使用工具

你可以在以下应用类型中使用 Bing 工具。

- **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `Bing` 工具节点。

- **Agent 应用**

在 Agent 应用内添加 `Bing` 工具，然后输入在线搜索指令，调用此工具。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/bing.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## ComfyUI
> 来源：`zh-hans/guides/tools/tool-configuration/comfyui.mdx`

[ComfyUI](https://www.comfy.org/) 是一个强大的、模块化的生成图形的平台。现在你可以在 Dify 中使用它， 传入图片的提示词， 并得到生成的图片。

## 1. 确保已能正常运行 ComfyUI 的工作流。  
请参考其[官方文档](https://docs.comfy.org/get_started/gettingstarted)，确保 ComfyUI 可以正常运行并生成图片。

## 2. 导出工作流的 API 文件。

![](./zh-hans/img/0503c5838f163b54884ca58240281f3f.png)

如图所示，在工具栏中选择 `Save(API Format)`，如果没有该选择，则需要在设置中开启 `Dev Mode`。

## 3. 在 Dify 中集成 ComfyUI

在 `工具 > ComfyUI > 去认证` 中填写访问地址，如果您使用的 docker 部署的 Dify，这个地址一般是 `http://host.docker.internal:8188`。

## 4. 在 Dify 中使用 ComfyUI

打开其 `工作流` 工具，在 `WORKFLOW JSON` 中填入刚刚导出的 API 文件中的内容，就可以正常生成了。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/comfyui.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Dall·E
> 来源：`zh-hans/guides/tools/tool-configuration/dall-e.mdx`

> 工具作者 @Dify。

DALL-E 是由 OpenAI 开发的一种基于文本提示生成图像的工具。Dify 已接入 DALL-E 工具，以下是在 Dify 中配置和使用 DALL-E 绘图工具的步骤。

## 1. 申请 OpenAI 的 API Key

请在 [OpenAI Platform](https://platform.openai.com/)申请 API Key，并确保账户内有足够的 Credits。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > DALL-E > 去授权` 填写 API Key。

![](./zh-hans/user-guide/.gitbook/assets/zh-tools-dalle.png)

## 3. 使用工具

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `DALL-E 绘图` 工具节点。添加后，需要在节点内的 “输入变量 → 提示词” 内填写[变量](./zh-hans/user-guide/build-app/flow-app/variables)引用用户输入的提示词，或者是上一节点生成的内容。最后在 “结束” 节点内使用变量引用 `DALL-E 绘图` 输出的图像。

![](./zh-hans/user-guide/.gitbook/assets/zh-dalle3-node.png)

* **Agent 应用**

在 Agent 应用内添加 `DALL-E` 工具，然后在对话框内发送图片描述，调用工具生成 AI 图像。

![](./zh-hans/user-guide/.gitbook/assets/zh-agent-dalle3.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/dall-e.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Google
> 来源：`zh-hans/guides/tools/tool-configuration/google.mdx`

> 工具作者 @Dify。

Google 搜索工具能够帮助你在使用 LLM 应用的时候，获取联网搜索结果。以下是在 Dify 中配置和使用 Google 搜索工具的步骤。

## 1. 申请 Serp API Key

请在 [Serp 平台](https://serpapi.com/dashboard)申请 API Key。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > Google > 去授权` 填写 API Key。

![](./zh-hans/user-guide/.gitbook/assets/zh-tools-google.png)

## 3. 使用工具

你可以在以下应用类型中使用 Google 工具。

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `Google` 工具节点。

* **Agent 应用**

在 Agent 应用内添加 `Google` 工具，然后输入在线搜索指令，调用此工具。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/google.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Perplexity Search
> 来源：`zh-hans/guides/tools/tool-configuration/perplexity.mdx`

> 工具作者 @Dify。

Perplexity 是一个基于 AI 的搜索引擎，能够理解复杂的查询并提供准确、相关的实时答案。以下是在 Dify 中配置和使用 Perplexity Search 工具的步骤。

## 1. 申请 Perplexity API Key

请在 [Perplexity](https://www.perplexity.ai/settings/api)申请 API Key，并确保账户内有足够的 Credits。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > Perplexity > 去授权` 填写 API Key。

![](./zh-hans/user-guide/.gitbook/assets/zh-tools-perplexity.png)

## 3. 使用工具

你可以在以下应用类型中使用 Perplexity Search 工具。

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 Perplexity 工具节点。将用户输入的内容通过变量传递至 Perplexity 工具节点内的“查询”框中，按照需求调整 Perplexity 工具的内置参数，最后在“结束”节点的回复框中选中 Perplexity 工具节点的输出内容。

![](./zh-hans/user-guide/.gitbook/assets/zh-tools-chatflow-perplexity.png)

* **Agent 应用**

在 Agent 应用内添加 `Perplexity Search` 工具，然后输入相关指令即可调用此工具。

![](./zh-hans/user-guide/.gitbook/assets/zh-tools-agent-perplexity.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/perplexity.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 工具配置
> 来源：`zh-hans/guides/tools/tool-configuration/readme.mdx`

> **警告：**

    “工具”已全面升级为“插件”生态，详细的使用说明请参考[插件开发](./zh-hans/plugins/quick-start/install-plugins)。以下内容已归档。

Dify 支持各种工具来增强应用的功能。每个工具都有独特的功能和参数，因此选择适合应用需求的工具。**在 Dify 中使用之前，请从工具提供商的官方网站获取 API 密钥。**

> 在部分工具内配置凭据后，工作区中的所有成员都可以使用此工具，请注意对应 Key 背后的服务额度消耗。

## 工具集成指南

- [StableDiffusion](./stable-diffusion)：一种基于文本提示生成图像的工具。
- [SearXNG](./searxng)：一个免费的互联网元搜索引擎，整合了各种搜索服务的结果。用户不会被跟踪，也不会被分析。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## SearchApi
> 来源：`zh-hans/guides/tools/tool-configuration/searchapi.mdx`

> 工具作者 @SearchApi。

SearchApi 是一个强大的实时 SERP API，可提供来自 Google 搜索、Google 招聘、YouTube、Google 新闻等搜索引擎集合的结构化数据。以下是在 Dify 中配置和使用 SearchApi 搜索工具的步骤。

## 1. 申请 Search API Key

请在 [SearchApi](https://www.searchapi.io/)申请 API Key。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > SearchApi > 去授权` 填写 API Key。

![](./zh-hans/user-guide/.gitbook/assets/zh-tool-searchapi.png)

## 3. 使用工具

你可以在以下应用类型中使用 SearchApi 工具。

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `SearchApi` 系列工具节点，提供 Google Jobs API，Google News API，Google Search API，YouTube 脚本 API 四种工具。

![](./zh-hans/user-guide/.gitbook/assets/zh-tool-searchapi-flow.png)

* **Agent 应用**

在 Agent 应用内选择需要添加的 `SearchApi` 工具，然后输入指令调用工具。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/searchapi.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## SearXNG
> 来源：`zh-hans/guides/tools/tool-configuration/searxng.mdx`

> 工具作者 @Junytang。

SearXNG 是一个免费的互联网元搜索引擎，整合了各种搜索服务的检索结果。用户不会被跟踪，搜索行为也不会被分析。现在你可以直接在 Dify 中使用此工具。

下文将介绍如何使用 Docker 将 SearXNG 集成到 Dify。

## 1. 修改 Dify 配置文件

SearXNG 的配置文件位于 `dify/api/core/tools/provider/builtin/searxng/docker/settings.yml`， 配置文档可参考[这里](https://docs.searxng.org/admin/settings/index.html)。

你可以按需修改配置，也可直接使用默认配置。

## 2. 启动服务

在 Dify 根目录下启动 Docker 容器。

```bash
cd dify
docker run --rm -d -p 8081:8080 -v "$PWD/api/core/tools/provider/builtin/searxng/docker:/etc/searxng" searxng/searxng
```

## 3. 使用 SearXNG

在 `工具 > SearXNG > 去认证` 中填写访问地址，建立 Dify 服务与 SearXNG 服务的连接。SearXNG 的 Docker 内网地址一般是 `http://host.docker.internal:8081`。

确保你的防火墙已开放 `8081` 端口。

---

# 4. 将 SearXNG 与 Dify 集成

一旦你的 SearXNG 实例在 Linux VM 上运行，你可以将其与 Dify 进行连接。

### 4.1 配置 Dify

1. 在 Dify 平台的 **工具 > SearXNG > 去认证** 页面中，输入你的自建 SearXNG 服务的 **Base URL**，格式为：

```text
http://<your-linux-vm-ip>:8081
```

2. 保存配置后，Dify 将能够连接到你的 SearXNG 实例。

---

## 5. 测试 SearXNG 集成

你可以通过 `curl` 命令测试 SearXNG 服务是否正常工作：

```bash
curl "http://<your-linux-vm-ip>:8081/search?q=apple&format=json&categories=general"
```

如果一切正常，你应该收到包含 "apple" 搜索结果的 JSON 响应。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/searxng.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Serper
> 来源：`zh-hans/guides/tools/tool-configuration/serper.mdx`

> 工具作者 @zhuhao。

Serper 是一个强大的实时搜索引擎工具API，可提供来自 Google 搜索引擎搜索的结构化数据。以下是在 Dify 中配置和使用 Serper 搜索工具的步骤。

## 1. 申请 Serp API Key

请在 [Serper 平台](https://serper.dev/signup)申请 API Key。

## 2. 在 Dify 内填写配置

在 Dify 导航页内轻点 `工具 > Serper > 去授权` 填写 API Key。

![](./zh-hans/user-guide/.gitbook/assets/zh-tool-serper.png)

## 3. 使用工具

你可以在以下应用类型中使用 Serper 工具。

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `Serper` 工具节点。

* **Agent 应用**

在 Agent 应用内选择需要添加的 `Serper` 工具，然后输入指令调用工具。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/serper.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## SiliconFlow (支持 Flux 绘图)
> 来源：`zh-hans/guides/tools/tool-configuration/siliconflow.mdx`

> 工具作者 @hjlarry

SiliconCloud 基于优秀的开源基础模型，提供高性价比的 GenAI 服务。你可以通过 **SiliconFlow** 在 Dify 内调用 Flux 、Stable Diffusion 绘图模型，搭建你的专属 AI 绘图应用。以下是在 Dify 中配置 SiliconFlow 工具的步骤。

### 1. 申请 SiliconCloud API Key

请在 [SiliconCloud API 管理页面](https://cloud.siliconflow.cn/account/ak) 新建 API Key 并保证有足够余额。

### 2. 在 Dify 内填写配置

在 Dify 的工具页中点击 `SiliconCloud > 去授权` 填写 API Key。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/截屏2024-09-26 23.12.01.png)**

### 3. 使用工具

* **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `SiliconFlow` 工具节点。

将用户输入的内容通过[变量](../../workflow/variables)传递至 Siliconflow 工具的 Flux 或 Stable Diffusion 节点内的“提示词”“负面提示词”框中，按照需求调整内置参数，最后在“结束”节点的回复框中选中 Siliconflow 工具节点的输出内容（文本、图片等）。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/截屏2024-09-27 10.09.34.png)**

* **Agent 应用**

在 Agent 应用内添加 `Stable Diffusion` 或 `Flux` 工具，然后在对话框内发送图片描述，调用工具生成 AI 图像。

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/截屏2024-09-27 10.18.54.png)**

  **[图片缺失] 未命名插图 (zh-hans/user-guide/.gitbook/assets/截屏2024-09-27 10.23.52.png)**

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/siliconflow.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Stable Diffusion
> 来源：`zh-hans/guides/tools/tool-configuration/stable-diffusion.mdx`

> 工具作者 @Dify。

Stable Diffusion 是一种基于文本提示生成图像的工具，Dify 已经实现了访问 Stable Diffusion WebUI API 的接口，因此你可以直接在 Dify 中使用它。以下是在 Dify 中集成 Stable Diffusion 的步骤。

## 1. 初始化本地环境

推荐使用装有较强 GPU 的机器来安装和驱动 Stable Diffusion，但这并不是必须的，你也可以使用 CPU 来生成图像，但速度可能会很慢。

## 2. 安装并启动 Stable Diffusion WebUI

1. 从[官方仓库](https://github.com/AUTOMATIC1111/stable-diffusion-webui)克隆 Stable Diffusion WebUI 仓库

```bash
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
```

2. 运行命令启动 Stable Diffusion WebUI。

克隆仓库后，切换到仓库目录。根据系统的不同，可能需要使用不同的命令来启动 WebUI。

#### Windows

```bash
cd stable-diffusion-webui
./webui.bat --api --listen
```

#### Linux
```bash
cd stable-diffusion-webui
./webui.sh --api --listen
```

3. 准备模型

现在你可以根据终端中显示的地址在浏览器中访问 Stable Diffusion WebUI，但模型还不可用。你需要从 HuggingFace 或其他来源下载模型，并将其放在 Stable Diffusion WebUI 的 `models` 目录中。

例如，我们使用 [pastel-mix](https://huggingface.co/JamesFlare/pastel-mix) 作为模型，使用 `git lfs` 下载模型并将其放在 `stable-diffusion-webui` 的 `models` 目录中。

```bash
git clone https://huggingface.co/JamesFlare/pastel-mix
```

4. 获取模型名称

现在你可以在模型列表中看到 `pastel-mix`，但我们仍然需要获取模型名称，访问 `http://your_id:port/sdapi/v1/sd-models`，你将看到如下的模型名称。

```json
[

        "title": "pastel-mix/pastelmix-better-vae-fp32.ckpt [943a810f75]",
        "model_name": "pastel-mix_pastelmix-better-vae-fp32",
        "hash": "943a810f75",
        "sha256": "943a810f7538b32f9d81dc5adea3792c07219964c8a8734565931fcec90d762d",
        "filename": "/home/takatost/stable-diffusion-webui/models/Stable-diffusion/pastel-mix/pastelmix-better-vae-fp32.ckpt",
        "config": null
    ,
]
```

`model_name` 就是我们需要的，这个例子中是 `pastel-mix_pastelmix-better-vae-fp32`。

## 3. 在 Dify 集成 Stable Diffusion

在 `工具 > StableDiffusion > 去认证` 中填写你在之前步骤中获取的认证信息和模型配置。

## 4. 完成

- **Chatflow / Workflow 应用**

Chatflow 和 Workflow 应用均支持添加 `Stable Diffusion` 工具节点。添加后，需要在节点内的 “输入变量 → 提示词” 内填写[变量](./zh-hans/user-guide/build-app/flow-app/variables)引用用户输入的提示词，或者是上一节点生成的内容。最后在 “结束” 节点内使用变量引用 `Stable Diffusion` 输出的图像。

- **Agent 应用**

在 Agent 应用内添加 `Stable Diffusion` 工具，然后在对话框内发送图片描述，调用工具生成 AI 图像。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/tools/tool-configuration/stable-diffusion.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 附加功能
> 来源：`zh-hans/guides/workflow/additional-feature.mdx`

Workflow 和 Chatflow 应用均支持开启附加功能以增强使用者的交互体验。例如添加文件上传入口、给 LLM 应用添加一段自我介绍或使用欢迎语，让应用使用者获得更加丰富的交互体验。

点击应用右上角的 **"功能"** 按钮即可为应用添加更多功能。

<iframe
  src="https://www.motionshot.app/walkthrough/6772b3cb721a6ff7774e7fa1/embed?fullscreen=1&hideAsSteps=1&hideCopy=1&hideDownload=1&hideSteps=1"
  frameborder="0"
  width="70%"
  height="300px"
  allowfullscreen
></iframe>

## Workflow

> **信息提示：**

不再推荐使用该方法为 Workflow 应用添加文件上传功能。建议应用开发者改用自定义文件变量为 Workflow 应用添加文件上传功能。

Workflow 类型应用仅支持 **"图片上传"** 功能。开启后，Workflow 应用的使用页将出现图片上传入口。

<iframe
  src="https://www.motionshot.app/walkthrough/6772b489721a6ff7774e7fa2/embed?fullscreen=1&hideAsSteps=1&hideCopy=1&hideDownload=1&hideSteps=1"
  frameborder="0"
  width="70%"
  height="300px"
  allowfullscreen
></iframe>

**用法：**

**对于应用使用者而言：** 已开启图片上传功能的应用的使用页将出现上传按钮，点击按钮或粘贴文件链接即可完成图片上传，你将会收到 LLM 对于图片的回答。

**对于应用开发者而言：** 开启文件图片上传功能后，使用者所上传的图片文件将存储在 `sys.files` 变量内。接下来添加 LLM 节点，选中具备视觉能力的大模型并在其中开启 VISION 功能，选择 `sys.files` 变量，使得 LLM 能够读取该图片文件。

最后在 END 节点内选择 LLM 节点的输出变量即可完成设置。

![开启视觉分析能力](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/98c281d4c2ba2de27d030c05c1fa94d0.png)

## Chatflow

Chatflow 类型应用支持以下功能：

* **对话开场白**

  让 AI 主动发送一段话，可以是欢迎语或 AI 的自我介绍，以拉近与使用者的距离。

* **下一步问题建议**

  在对话完成后，自动添加下一步问题建议，以提升对话的话题深度与频率。

* **文字转语音**

  在问答文字框中添加一个音频播放按钮，使用 TTS 服务（需在[模型供应商](../../getting-started/readme/model-providers)内置）并朗读其中的文字。

* **文件上传**

  支持以下文件类型：文档、图片、音频、视频以及其它文件类型。开启此功能后，应用使用者可以在应用对话的过程中随时上传并更新文件。最多支持同时上传 10 个文件，每个文件的大小上限为 15MB。

  ![文件上传功能](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/dbe0090f61852d9f64311d8537942f94.png)

* **引用和归属**

  常用于配合["知识检索"](node/knowledge-retrieval)节点共同使用，显示 LLM 给出答复的参考源文档及归属部分。

* **内容审查**

  支持使用审查 API 维护敏感词库，确保 LLM 能够回应和输出安全内容，详细说明请参考[敏感内容审查](../application-orchestrate/app-toolkits/moderation-tool)。

**用法：**

除了 **文件上传** 功能以外，Chatflow 应用内的其它功能用法较为简单，开启后可以在应用交互页直观使用。

本章节将主要介绍 **文件上传** 功能的具体用法：

**对于应用使用者而言：** 已开启文件上传功能的 Chatflow 应用将会在对话框右侧出现 "回形针" 标识，点击后即可上传文件并与 LLM 交互。

![使用文件上传](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/56d4c6b4accedbae07ef102fb9a7fba4.png)

**对于应用开发者而言：**

开启文件上传功能后，使用者发送的文件将上传至 `sys.files` 变量内。用户在同一场对话发送新的消息后，该变量将更新。

根据上传的文件差异，不同类型的文件对应不同的应用编排方式。

* **文档文件**

LLM 并不具备直接读取文档文件的能力，因此需要使用 [文档提取器](node/doc-extractor) 节点预处理 `sys.files` 变量内的文件。编排步骤如下：

1. 开启 Features 功能，并在文件类型中仅勾选 "文档"。
2. 在[文档提取器](node/doc-extractor)节点的输入变量中选中 `sys.files` 变量。
3. 添加 LLM 节点，在系统提示词中选中文档提取器节点的输出变量。
4. 在末尾添加 "直接回复" 节点，填写 LLM 节点的输出变量。

使用此方法搭建出的 Chatflow 应用无法记忆已上传的文件内容。应用使用者每次对话时都需要在聊天框中上传文档文件。如果你希望应用能够记忆已上传的文件，请参考 [《文件上传：在开始节点添加变量》](file-upload#fang-fa-er-zai-tian-jia-wen-jian-bian-liang)。

![文档文件编排](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/8f47afd4090475e9cacd8af47155a90d.png)

* **图片文件**

部分 LLMs 支持直接获取图片中的信息，因此无需添加额外节点处理图片。

编排步骤如下：

1. 开启 Features 功能，并在文件类型中仅勾选 "图片"。
2. 添加 LLM 节点，启 VISION 功能并选择 `sys.files` 变量。
3. 在末尾添加 "直接回复" 节点，填写 LLM 节点的输出变量。

![开启视觉分析能力](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/643585382e7c97cd4d0b726d2679df75.png)

* **混合文件类型**

若希望应用具备同时处理文档文件 + 图片文件的能力，需要用到 [列表操作](node/list-operator) 节点预处理 `sys.files` 变量内的文件，提取更加精细的变量后发送至对应的处理节点。编排步骤如下：

1. 开启 Features 功能，并在文件类型中勾选 "图片" + "文档文件" 类型。 
2. 添加两个列表操作节点，在 "过滤" 条件中提取图片与文档变量。
3. 提取文档文件变量，传递至 "文档提取器" 节点；提取图片文件变量，传递至 "LLM" 节点。
4. 在末尾添加 "直接回复" 节点，填写 LLM 节点的输出变量。

应用使用者同时上传文档文件和图片后，文档文件自动分流至文档提取器节点，图片文件自动分流至 LLM 节点以实现对于文件的共同处理。

![混合文件处理](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/eb8274c2cd9938c0edd89caf60a9b14a.png)

* **音视频文件**

LLM 尚未支持直接读取音视频文件，Dify 平台也尚未内置相关文件处理工具。应用开发者可以参考 [外部数据工具](../extension/api-based-extension/external-data-tool) 接入工具自行处理文件信息。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/additional-feature.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 变更公告：图片上传被替换为文件上传
> 来源：`zh-hans/guides/workflow/bulletin.mdx`

图片上传功能已被纳入至更加综合的[文件上传](file-upload)功能中，为了避免出现功能重复，我们决定对 Workflow 和 Chatflow 应用的“[附加功能](./additional-feature)”进行升级和调整：

* 移除 Chatflow 应用“功能”中的图片上传选项，取而代之的是新的“文件上传”功能。你可以在“文件上传”功能内选择图片文件类型。同时，应用对话框中的图片上传 icon 也被替换为文件上传 icon。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/90c0e2d9ac9c16b493bb4793b90df548.png)

* 将在未来**停用 Workflow 应用“功能”中的图片上传选项**以及移除 `sys.files` [变量](variables)，目前这两项功能已被标记为 `LEGACY`，建议应用开发者改用自定义文件变量为 Workflow 应用添加文件上传功能。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/befa0580cd0b7ab312c2fe85f6fc2ac7.png)

### 为什么要替换“图片上传”功能？

Dify 此前仅支持上传图片文件。而在最新的版本中，已提供更加全面的文件上传能力，支持文档、图片、音视频文件或自定义文件格式，**图片上传能力已被更大的“文件上传”功能所包含。**应用开发者添加文件上传功能后，仅勾选“图片”类型文件即可开启图片上传能力。

为了避免功能重复所造成体验上的困扰，我们决定替换 Chatflow 应用内单独的图片上传功能，转而提供更加全面的文件上传能力；同时不再建议继续为 Workflow 应用开启图片上传功能。

### 更加全面的功能：文件上传

为了让应用具备更加强大的信息处理能力，本次更新我们新增了“文件上传”能力。相较于聊天文本，文档文件能够承载大量的信息，例如学术报告、法律合同。

* 文件上传功能允许将文件以 File variables 的形式在工作流应用中上传、解析、引用、和下载。
* 开发者现可轻松构建能理解和处理图片、音频、视频复杂工作的应用。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/f137939601f9d95112e27ad27cb2aa3a.png)

因此不再建议使用单独的“图片上传”功能，而是改用更为综合全面的“文件上传”功能以增强应用体验。

### 你需要做什么？

#### **对于 Dify Cloud 用户：**

* **Chatflow 应用**

如果你已创建 Chatflow 应用并启用了“图片上传”功能，并在 LLM 节点中开启 Vision 功能，系统将自动完成功能切换，不会影响到应用的图片上传能力。如果需要更新并重新发布应用，需要在 LLM 节点中的 Vision 变量选择框指定文件变量后清除 checklist 中的 item，重新发布应用。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/93f533be37a1f936879379fcaabc2b45.png)

如果你希望在 Chatflow 应用中添加“图片上传”功能，请在功能中开启“文件上传”，仅勾选“图片”类型。然后在 LLM 节点中启用 Vision 功能，并在其中填写 `sys.files` 变量。此时输入框将出现“回形针”的上传入口，详细说明请参考 [附加功能](./additional-feature)。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/e64569e7d240bf453308e86ec0573178.png)

* **Workflow 应用**

如果你已创建 Workflow 应用并启用了“图片上传”功能，并在 LLM 节点中开启 Vision 功能，此次变动当下不会产生任何影响但你需要做正式下线前完成手动迁移。

如果希望为 Workflow 应用开启“图片上传”功能，请在[开始](node/start)节点中添加文件变量。然后在后续的节点中引用该文件变量，不再继续使用 `sys.files` 变量。

#### 对于Dify 社区版或本地部署的企业版用户：

升级到 v0.10.0 版本后你将看到 “文件上传” 功能。

* **Chatflow 应用**

已启用“图片上传”功能的 Chatflow 应用将自动完成切换，无需变更。

如果你希望在 Chatflow 应用中添加“图片上传”功能，详细说明请参考[附加功能](./additional-feature)。

* Workflow 应用

已创建的 Workflow 应用不会产生任何影响，但是请在正式下线前完成手动迁移。

如果希望为 Workflow 应用开启“图片上传”功能，请在[开始](node/start)节点中添加文件变量。然后在后续的节点中引用该文件变量，不再继续使用 `sys.files` 变量。

### 常见问题

1. **这次更新会影响我现有的应用吗？**

* 已创建的 Chatflow 应用将自动迁移，图片上传功无感切换至文件上传功能。仍然会默认使用 sys.file 作为模型 vision 输入框的变量。应用使用页的图片上传入口会被替换为文件上传入口。
* 现有 Workflow 应用暂时不会受到影响。`sys.file` 和图片上传功能会被标记为 `Legacy` ，但仍然可以使用。被标记为 `Legacy` 的功能将在未来下线，届时需要手动更新应用。

2. **我需要立即更新我的应用吗？**

* 对于 Chatflow 应用,系统会自动迁移，无需手动更新。
* 对于 Workflow 应用，虽然不需要立即更新，但建议你尽早熟悉新的文件上传功能，为未来的迁移做准备。

3. **如何确保我的应用兼容新的文件上传功能？**

对于 Chatflow 应用:

* 检查 features 配置中的文件上传选项是否已开启。
* 确保使用带有视觉能力的 LLM，并打开 Vision 功能开关。
* 验证 `sys.files` 是否被正确选中作 Vision 框中的输入项。

对于 Workflow 应用:

* 在“开始节点”创建文件类型的变量。
* 在后续的节点中引用这个文件变量，而不是使用已被标记为 `Legacy` 的 `sys.files`。

4. **历史发布的 Chatflow 应用内，原有的图片上传图标消失，如何处理？**

建议重新发布应用，应用聊天框将出现文件上传图标。

### 我们期待你的反馈

作为 Dify 社区的重要成员，你的使用体验和反馈对我们至关重要。我们诚挚地邀请你：

1. 尝试新的文件上传功能，体验其便捷性和灵活性。
2. 通过以下渠道分享你的想法和建议：
   * [GitHub](https://github.com/langgenius/dify)
   * [Discord 频道](https://discord.gg/FngNHpbcY7)

你的每一条反馈都将帮助我们不断完善产品，为整个社区带来更好的体验。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/bulletin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 创建应用
> 来源：`zh-hans/guides/workflow/create-flow-app.mdx`

## Chatflow

**适用场景：**

面向对话类情景，包括客户服务、语义搜索、以及其他需要在构建响应时进行多步逻辑的对话式应用程序。该类型应用的特点在于支持对生成的结果进行多轮对话交互，调整生成的结果。

常见的交互路径：给出指令 → 生成内容 → 就内容进行多次讨论 → 重新生成结果 → 结束。

在 "工作室" 页，轻点左侧 “创建空白应用”，然后选择 “聊天助手” 中的 “工作流编排”。

![](./zh-hans/img/8eb5a12939c298bc7cb9a778d10d42db.png)

## Workflow

**适用场景：**

面向自动化和批处理情景，适合高质量翻译、数据分析、内容生成、电子邮件自动化等应用程序。该类型应用无法对生成的结果进行多轮对话交互。

常见的交互路径：给出指令 → 生成内容 → 结束

在 "工作室" 页，轻点左侧 “创建空白应用”，然后选择 “工作流” 完成创建。

![](./zh-hans/user-guide/.gitbook/assets/workflow.png)

## 两者之间的差异

**应用类型差异**

1. End 节点属于 Workflow 的结束节点，仅可在流程结束时选择。
2. Answer 节点属于 Chatflow ，用于流式输出文本内容，并支持在流程中间步骤输出。
3. Chatflow 内置聊天记忆（Memory），用于存储和传递多轮对话的历史消息，可在 LLM 、问题分类等节点内开启，Workflow 无 Memory 相关配置，无法开启。
4. Chatflow 的开始节点内置变量包括：`sys.query`，`sys.files`，`sys.conversation_id`，`sys.user_id`。Workflow 的开始节点内置变量包括：`sys.files`，`sys.user_id`

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/create-flow-app.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 调试节点
> 来源：`zh-hans/guides/workflow/debug-and-preview/debug-node.mdx`

Workflow / Chatflow 类型应用通常包含多个节点，每个节点互有关联。若要确保应用整体运行正常，需要确认每个节点的输入输出符合预期。调试节点功能可以帮助开发者检测应用是否按照设计预期提供服务，提前发现并解决潜在问题，避免在生产环境中出现错误。

你可以通过以下两种模式调试节点。

## 单步调试

单步调试允许你对工作流内的特定节点进行独立测试，无需执行整个工作流。它可以帮助开发者在应用内添加新节点时验证其功能、排查特定节点的错误以及测试节点对不同输入的响应。

### 操作步骤

1. 在工作流编辑界面选择需要调试的节点
2. 点击节点右上角的 **run step** 按钮
3. 在弹出的调试面板中填写该节点的输入变量
4. 点击执行按钮触发节点运行
5. 查看节点的输出结果及运行状态

例如，在工作流内添加了一个 HTTP 节点，为验证该节点能否正确获取并处理 API 响应，你可以使用单步调试功能模拟节点的实际工作状态，而不会影响下游节点。

![](https://assets-docs.dify.ai/2025/04/376c9de6f92cb7a5f97a6661c5e0e9eb.png)

调试完成后，你可以看到当前节点的运行状态、输入/输出、元数据信息。如遇报错，可通过报错信息快速排查错误，避免节点异常导致的应用整体运行失败。

> **警告：**

    回答、结束节点不支持单步调试。

## 逐步执行

逐步执行适用于测试多个相互依赖的节点组合，特别是当节点的输入依赖于上游节点的输出时。与单步调试不同，逐步执行会从起始节点开始，按照工作流路径依次执行到指定节点。

### 操作步骤

1. 在工作流编辑界面选择需要作为终点的目标节点
2. 点击该节点右上角的 **run to** 按钮激活逐步执行功能
3. 系统将从起始节点开始，按照工作流路径依次执行至目标节点
4. 执行完成后，可查看每个节点的运行状态和输出结果

假设你有一个包含数据获取(A节点)→数据处理(B节点)→结果展示(C节点)的工作流，B节点的功能完全依赖于A节点的输出。使用逐步执行功能，你可以选择B节点并点击"run to"，系统将先执行A节点再执行B节点，让你能够验证两个节点之间的数据传递是否正常。

逐步执行过程中，你可以观察局部工作流的运行情况，基于结果及时调整节点的配置、数据流向和处理逻辑，确保工作流的效率和准确性。

![](https://assets-docs.dify.ai/2025/04/5bb7e8c6e2f0af38d272d2f4bfa3e90a.png)

> **警告：**

    对于问题分类节点、条件节点等存在多分支处理情况，不支持逐步执行功能。

## 查看节点运行记录

每个节点运行完成后都会生成操作日志，你可以点击节点详情页中的 Last run 查看运行历史。

![](https://assets-docs.dify.ai/2025/04/5ee92e6406979f5101d21865f95a86e5.png)

如需查看应用整体的运行历史，详细说明请参考[运行历史](./zh-hans/guides/workflow/debug-and-preview/history-and-logs)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/debug-and-preview/debug-node.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 调试历史
> 来源：`zh-hans/guides/workflow/debug-and-preview/history-and-logs.mdx`

调试 Chatflow / Workflow 应用时将生成详细的历史记录，包括整个应用的执行日志和应用内各个节点的运行详情。开发者可以查看不同维度的历史记录以快速定位问题、分析应用的性能表现并优化工作流配置。

> **信息提示：**

    如需查看发布应用后用户所产生的应用使用记录，请参考[日志与标注](./zh-hans/guides/annotation/logs)。

应用的运行记录分为以下两个维度。

## 应用调试历史

运行应用后将产生**运行历史（Run History）**，每次运行节点时将产生一次版本记录。每个版本包含当前应用的**对话记录（Conversation Log）**，以及当前版本记录内各个节点的**追踪日志（TRACING）**。这些记录按时间顺序排列，显示应用内每次对话交互的基本信息，包括运行时间、执行状态、输入输出参数概要等。你可以通过该列表快速找到过往的应用运行详情。

![](https://assets-docs.dify.ai/2025/04/08a885858cfa6e8863faac891a5be319.png)

点击任意一条运行记录查看该次执行的详细信息。每次版本运行包含三个主要部分：

### 运行结果（RESULT）

> **警告：**

    运行结果仅面向 Workflow 应用类型。

显示工作流的最终输出结果，即用户最终看到的内容。如果工作流执行失败，此处会显示错误信息和失败原因。

![](https://assets-docs.dify.ai/2025/06/22856751d278ffad99d0533d2d96e125.png)

### 运行详情（DETAIL）

包含每次应用运行/对话时的完整输入参数、系统元数据和配置信息。你可以在这里查看：

- 用户输入的原始数据
- 工作流应用的输出数据
- 系统自动生成的元数据

![](https://assets-docs.dify.ai/2025/06/882b783cd843ab666f5bc3c06f78521d.png)

### 追踪（TRACING）

在这个视图内你可以查看以下信息：

- **节点执行顺序**：工作流中各个节点的实际执行顺序。
- **数据流转过程**：数据在节点间的传递和转换情况。你也可以通过[变量检查](./zh-hans/guides/workflow/debug-and-preview/variable-inspect)进行查看。
- **执行时间分析**：每个节点的运行时长，帮助识别性能瓶颈。
- **资源消耗统计**：Token 使用量、API 调用次数等成本信息。
- **错误定位**：快速找到执行失败的具体节点和原因。

![](https://assets-docs.dify.ai/2025/06/9e614ac01b1f6e0aeadda78c91ce93b7.png)

通过节点追踪视图，你可以深入了解工作流的内部运行机制，这对于调试复杂工作流和优化性能表现非常有价值。特别是当工作流包含多个分支或循环逻辑时，追踪视图能够清晰地展示实际的执行路径。

## 节点运行记录

除了查看应用整体的运行历史，你还可以在工作流编辑界面中查看单个节点在最后一次调试过程时产生的记录。点击任意节点内节点配置面板中的 **上次运行**，查看节点的输入输出记录。

![](https://assets-docs.dify.ai/2025/06/9c6e57236d85f426a930424863042d7d.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/debug-and-preview/history-and-logs.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 功能简介
> 来源：`zh-hans/guides/workflow/debug-and-preview/preview-and-run.mdx`

创建工作流后，开发者可在发布应用前调试应用以确保各个节点正常运行、验证变量内的数据是否能够正确流转。Dify 提供了完整的调试工具，帮助你快速定位问题、检查变量传递和查看详细日志。

本文介绍工作流应用调试的完整流程，包括单节点调试、变量检查、运行历史查看以及整体测试方法。

![](https://assets-docs.dify.ai/2025/06/8e7933b45a69241a9861a09fa47d5c62.png)

## 调试工作流应用

### 单节点调试

当工作流中某个节点出现问题导致工作流应用无法正常运行时，单独调试该节点以快速定位问题。

点击节点右上角的调试按钮，输入测试数据并查看输出结果。在调试过程中，建议从简单的测试数据开始，逐步增加数据复杂度，确保节点在各种输入情况下都能正常工作。

关于详细的单节点调试方法，请参考[调试节点](./zh-hans/guides/workflow/debug-and-preview/step-run)。

![](https://assets-docs.dify.ai/2025/06/44decb6644b140e46ed2e1e9246f48f7.png)

### 逐步调试节点

逐步调试节点指的是基于上游节点的变量，检查下游节点是否正确处理变量内的数据并输出预期处理结果。

详细使用方法请参考[变量检查](./zh-hans/guides/workflow/debug-and-preview/variable-inspect)。

![](https://assets-docs.dify.ai/2025/06/887630764b180a60becb6a4fcee2c622.png)

### 查看节点运行记录

执行节点后将生成详细的运行记录，帮助开发者排查问题。点击节点详情页中的“上次运行”查看执行日志，包括输入参数、输出结果、执行时间和错误信息。详细说明请参考[调试历史 - 节点运行记录](./zh-hans/guides/workflow/debug-and-preview/history-and-logs#节点运行记录)。

![](https://assets-docs.dify.ai/2025/06/a6011d5966c78a4d1705f2af44ed8af1.png)

### 调试整体流程

完成所有节点的调试工作后，接下来运行整个工作流来验证端到端的执行效果。

使用预览功能体验应用的最终用户界面，该模式将完整展示包括输入框、输出展示和交互流程。主要用于验证用户体验是否符合预期。系统在预览时会进行自动检查，确保所有节点配置正确且连接完整。

![](https://assets-docs.dify.ai/2025/06/de00849b363ec9356e5764b88b4331fb.png)

#### 检查清单

系统会自动检查工作流配置，如果发现节点连接错误、必填参数缺失等问题，会在界面右上角进行提示，解决所有问题后方可运行应用。

![](https://assets-docs.dify.ai/2025/06/85bafda1f786549c22404cd5ec711d0f.png)

运行工作流时，在右侧面板查看每个节点的执行状态，包括输入参数、输出结果和执行日志。通过节点上的状态指示器（绿色表示成功）快速识别流程在哪个节点处异常而造成中断。

建议在正式发布前进行多轮测试，使用不同类型和复杂度的数据来验证工作流的稳定性。

![](https://assets-docs.dify.ai/2025/06/c09f788f77b5f8ebdd635ddba66a1b99.png)

## 查看应用的运行日志

发布应用后，开发者可以通过应用的**日志和监测功能**查看用户使用该应用的对话记录和性能数据。这些历史记录有助于查看用户的行为路径、分析应用性能变化和复盘问题原因。

![](https://assets-docs.dify.ai/2025/06/6dd8e8a7186089a390679b6de4bb97b9.png)

详细说明请参考以下文档：

- [运行历史](./zh-hans/guides/workflow/debug-and-preview/history-and-logs)
- [监测](./zh-hans/guides/monitoring/README)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/debug-and-preview/preview-and-run.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 调试节点
> 来源：`zh-hans/guides/workflow/debug-and-preview/step-run.mdx`

Workflow / Chatflow 类型应用通常包含多个节点，每个节点互有关联。若要确保应用整体运行正常，需要确认每个节点的输入输出符合预期。

调试节点功能可以帮助开发者检测应用是否按照设计预期提供服务，提前发现并解决潜在问题，避免在生产环境中出现错误。

调试节点分为单步调试和逐步执行两种方法。

## 单步调试

### 方法简介

单步调试允许你对工作流内的特定节点进行独立测试，无需执行整个工作流。它可以帮助开发者在应用内添加新节点时验证其功能、排查特定节点的错误以及测试节点对不同输入的响应。

### 操作步骤

1. 在工作流编辑界面选择需要调试的节点
2. 在节点的设置页内填写输入变量
3. 点击执行按钮触发节点运行
4. 查看节点的输出结果及运行状态

### 示例

在工作流内添加 HTTP 节点，为验证该节点能否正确获取并处理 API 响应，你可以使用单步调试功能模拟节点的实际工作状态，确保能够正确向下游节点传递数据。

![](https://assets-docs.dify.ai/2025/04/376c9de6f92cb7a5f97a6661c5e0e9eb.png)

调试完成后，你可以“上次运行”页查看当前节点的运行状态、查看输入/输出、元数据信息。如遇报错，可通过报错信息快速排查错误，避免单个节点运行异常而导致整体运行失败。

> **警告：**

    回答、结束节点不支持单步调试。

## 逐步执行

### 方法简介

工作流的运行依赖于数据能够正确地从一个节点流转到下一个节点。若工作流较为复杂，该过程容易出错，常见问题包括：

- 数据格式不匹配（如文本传给了需要数字的节点）
- 变量配置错误
- JSON 数据解析失败
- 变量路径引用错误

逐步执行节点的调试方法能够帮助开发者在复杂的工作流应用内快速排查错误。

调试节点时，节点的输出变量将会被缓存至[变量检查](./zh-hans/guides/workflow/debug-and-preview/variable-inspect)内。开发者可以直接在“变量检查”内修改变量，快速修改上游变量内的数据，验证不同数值对于下游节点的影响。

该方法适用于测试多个相互依赖的节点组合。

![](https://assets-docs.dify.ai/2025/06/f8656d8deeeaefeab0a8d9169f0ed2d3.png)

运行节点后，系统会自动将输出数据保存到"变量检查"视图中。你可以使用以下方法排除潜在问题：

1. **查看实际数据**：对比节点输出的数据是否符合预期
2. **修改测试数据**：直接在视图内修改变量值，测试对后续节点的影响
3. **验证数据流转**：确认数据能正确传递到下游节点

### 操作步骤

1. 在调试模式中运行应用
2. 点击应用底部的变量检查，查看变量缓存
3. 定位需要调试的节点，查看它引用了哪个变量
4. 在变量检查内修改该变量的值，重新运行节点
5. 比对运行效果

### 示例

假设存在一个工作流：数据获取(A 节点) → 数据处理(B 节点) → 结果展示(C 节点)。

B 节点的功能完全依赖于 A 节点的输出数据，并且不同的数据将影响 B 节点的运行情况。

运行 A 节点后的输出变量值将保存至“变量检查”内。开发者可以修改“变量检查”内的数据，验证对于 B 节点的影响而无需手动再次运行 A 节点。

逐步执行过程中，你可以观察局部工作流的运行情况，基于结果及时调整节点的配置、数据流向和处理逻辑，确保工作流的效率和准确性。

## 查看节点运行记录

每个节点运行完成后都会生成操作记录，点击节点详情页中的 Last run 进行查看。

![](https://assets-docs.dify.ai/2025/04/5ee92e6406979f5101d21865f95a86e5.png)

如需查看应用整体的运行历史，详细说明请参考[运行历史](./zh-hans/guides/workflow/debug-and-preview/history-and-logs)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/debug-and-preview/step-run.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 变量检查
> 来源：`zh-hans/guides/workflow/debug-and-preview/variable-inspect.mdx`

变量检查（Variable Inspect）是一个位于工作流应用底部的看板，记录各个节点在执行任务后的输入输出数据，帮助开发者快速定位问题和验证数据流转。 

## 功能价值

[变量](./zh-hans/guides/workflow/variables)是连接节点之间的重要桥梁，也是实现动态流程控制的基础。在工作流应用中，变量记录了用户输入的数据，以及各节点内的输出数据，例如大模型输出，工具调用结果、对话历史上下文及环境配置参数等。

变量检查视图将在节点运行后，自动缓存每个节点所接受的输入参数，以及执行任务后各节点输出变量内的数据。提供以下核心功能：

- **实时变量监控**：自动捕获并显示节点执行后产生的所有变量值，记录工作流的输入和输出数据。
- **缓存变量值编辑**：允许开发者手动修改大多数类型变量的值，而无需重新运行上游节点，便于模拟不同场景。
- **异常数据追踪**：展示变量的实际值及其类型，便于识别格式不符、缺字段、类型错误等问题。
- **全局状态管理**：在单一界面集中展示变量信息，包括系统变量、环境变量和节点内的自定义变量等。

通过变量检查，开发者可以直观地观察上次运行时各个节点的输出变量，同时可以在其中直接进行修改，观察新数据对于后续节点的影响，更快地定位问题并验证数据，提升应用的调试效率。

## 使用方法

变量检查位于画布底部，随着工作流运行实时更新变量值。

当某个节点运行后，其输出变量将自动出现在变量检查中，便于开发者查找。该功能可以帮助开发者管理当前工作流应用内所涉及的所有变量所对应的数据，它展示工作流中所有已创建变量及其当前值。

![](https://assets-docs.dify.ai/2025/06/38f26d7339f64abfdfb6955b1c34f4ae.png)

下文将以一个“查询外部数据库”应用作为案例，演示变量视图的操作方法。该应用的流程是查询外部数据库的应用。LLM 节点在接受自然语言后，自动转译为 SQL 语法，向外部数据库发送请求并接受数据。

> 点击[此处](https://assets-docs.dify.ai/2025/06/ac4da5ed5506f8a34aae7f0b88323f37.yml)下载 DSL 应用文件。

### 查看

节点运行后，输出变量会自动显示在变量检查视图内，点击变量查看详细内容。

![](https://assets-docs.dify.ai/2025/06/94a4741c25204db5fd1281ec475093d9.png)

### 编辑

点击变量值修改内容。修改后，下游节点可以使用新的变量值。

> **信息提示：**

    编辑变量值后，不影响当前节点在“上次运行”内已有的存储记录。    

**用法示例：**

> **步骤：**

    用户输入“查询所有用户数据”命令，LLM 节点自动生成了 `SELECT * FROM users;` 命令，数据库正确返回了所有数据。
    ![](https://assets-docs.dify.ai/2025/06/dcf4b0048bf1ed802369ab10731a4848.png)

    用户在变量面板中手动将 SQL 修改为 `SELECT username FROM users;`，随后仅重新运行数据库节点，系统将返回用户名列表。

    手动修改变量值后，手动运行下游的数据库节点即可重新查询新的数据，而无需重新运行整个工作流。
    ![](https://assets-docs.dify.ai/2025/06/fb8c49fc0c8c63866f1a9379e8752d9e.png)

### 回退

点击编辑框右上角的回退按钮，恢复该变量的原始值。

![](https://assets-docs.dify.ai/2025/06/b713290543a0feb95ecab65336e97483.png)

### 重置所有变量

点击左上角 Reset all 按钮，清空所有变量缓存。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/debug-and-preview/variable-inspect.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 错误类型
> 来源：`zh-hans/guides/workflow/error-handling/error-type.mdx`

本文总结了不同类型节点可能发生的异常和对应的错误类型。

### 通用错误

*   系统错误（System Error）

    通常由系统问题引起，例如沙盒服务未开启、网络连接异常等。
*   操作错误（Operational Error）

    应用开发者无法正常配置或运行节点时发生的错误。

### 代码节点

[代码节点](https://docs.dify.ai/guides/workflow/node/code) 支持运行 Python 和 JavaScript 代码，用于在工作流或聊天流中对数据进行改造。以下是常见的 4 种运行错误：

1.  **代码节点错误（CodeNodeError）**

    此错误是由于开发者编写代码中的异常引起的，例如：缺少变量、计算逻辑错误、将字符串数组输入作为字符串变量处理等。你可以通过错误信息和精确的行号定位问题。

    ![代码错误](https://assets-docs.dify.ai/2024/12/c86b11af7f92368180ea1bac38d77083.png)
2.  **沙盒网络问题（System Error）**\
    此错误常见于网络流量或连接异常时，例如沙盒服务未开启，代理服务中断了网络。你可以通过以下方式解决：

    1. 检查网络服务质量
    2. 开启沙盒服务
    3. 验证代理设置

    ![沙盒网络问题](https://assets-docs.dify.ai/2024/12/d95007adf67c4f232e46ec455c348e2c.PNG)
3.  **深度限制错误（DepthLimitError）**

    当前节点的默认配置最多仅支持 5 层嵌套结构。如果超过 5 层，则会报错。

    ![OutputValidationError](https://assets-docs.dify.ai/2024/12/5649d52a6e80ddd4180b336266701f7b.png)

4.  **输出验证错误（OutputValidationError）**

    如果实际输出变量类型与所选输出变量类型不一致将报错。开发者需要更改所选的输出变量类型规避此问题。

    ![](https://assets-docs.dify.ai/2024/12/ab8cae01a590b037017dfe9ea4dbbb8b.png)

### LLM 节点

[LLM 节点](https://docs.dify.ai/guides/workflow/node/llm)是 Chatflow 和 Workflow 的核心组件，利用大语言模型的对话、生成、分类和处理能力，基于使用者输入的指令完成各种任务。

以下是运行时常见的 6 种错误：

1.  **未找到对应变量（VariableNotFoundError）**

    如果 LLM 找不到系统提示词或在上下文中设置的变量，则会出现此错误。应用开发者可以通过替换异常变量来解决此问题。

    ![VariableNotFoundError](https://assets-docs.dify.ai/2024/12/f20c5fbde345144de6183374ab277662.png)
2.  **上下文结构无效（InvalidContextStructureError）**

    LLM 节点内的 [上下文](https://docs.dify.ai/guides/workflow/node/llm#explanation-of-special-variables) 接收到非法数据结构（如 `array[object]`）时会报错。

    > 上下文仅支持字符串（String）数据结构。

    ![InvalidContextStructureError](https://assets-docs.dify.ai/2024/12/f20c5fbde345144de6183374ab277662.png)
3.  **错误的参数类型（InvalidVariableTypeError）**

    系统提示词的类型不为常规的 Prompt 文本或 Jinja 语法格式，则出现此错误。
4.  **模型不存在（ModelNotExistError）**

    每个 LLM 节点都需要配置一个模型，如果未选中模型将出现此错误。
5.  **LLM 需授权（LLMModeRequiredError）**

    LLM 节点所选中的模型未配置 API Key，你可以阅读 [此文档](https://docs.dify.ai/guides/tools/tool-configuration) 授权模型。
6.  **未找到提示词（NoPromptFoundError）**

    LLM 节点的提示词不能为空，否则异常。

    ![NoPromptFoundError](https://assets-docs.dify.ai/2024/12/9882f7a5ee544508ba11b51fb469a911.png)

### HTTP

[HTTP 节点](https://docs.dify.ai/guides/workflow/node/http-request)允许通过发送 HTTP 请求获取数据、触发Webhook、生成图像或下载文件，从而通过可定制的请求与外部服务无缝集成。以下是该节点常见的 5 种错误：

1.  **授权配置错误（AuthorizationConfigError）**

    未配置认证信息（Auth）时出现此报错。
2.  **文件获取错误（FileFetchError）**

    无法获取文件变量时出现此报错。
3.  **无效的 HTTP 请求方法（InvalidHttpMethodError）**

    请求头非以下方法：GET、HEAD、POST、PUT、PATCH 或 DELETE，出现报错。
4.  **响应大小超限（ResponseSizeError）**

    HTTP 返回的响应大小限制为 10MB，如果响应超出限制，出现报错。
5.  **HTTP 响应代码错误（HTTPResponseCodeError）**

    当请求响应返回非 2 开头的代码时（例如 200, 201）将报错。如果开启了异常处理，当返回的状态码为 400、404、500 时将报错，否则不会报错。

### 工具

运行时常见以下 3 种错误：

1.  **工具执行异常（ToolNodeError）**

    工具本身执行的异常报错，例如达到了目标 API 的请求限制。

![](https://assets-docs.dify.ai/2024/12/84af0831b7cb23e64159dfbba80e9b28.jpg)

2.  **工具参数异常（ToolParameterError）**

    所配置的工具节点参数存在异常，传入了不符合工具节点所定义的参数。
3.  **工具文件处理异常（ToolFileError）**

    工具节点未找到所需的文件，出现报错。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/error-handling/error-type.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 预定义异常处理逻辑
> 来源：`zh-hans/guides/workflow/error-handling/predefined-nodes-failure-logic.mdx`

以下四种类型的节点提供应对异常情况的预处理逻辑编排能力：

* [LLM](../node/llm)
* [HTTP](../node/http-request)
* [代码](../node/code)
* [工具](../node/tools)

异常处理机制提供以下三种预定义编排逻辑选项：

• **无**：不处理异常，直接抛出节点的报错信息并中断整体流程。

• **默认值**：允许开发者预定义异常信息。异常发生后，使用预定义的值替代原节点内置的异常输出信息。

• **异常分支**：发生异常后，执行预编排的异常分支。

![Error handling](https://assets-docs.dify.ai/2024/12/6e2655949889d4d162945d840d698649.png)

### 处理逻辑：无

节点异常处理机制的默认选项。如果当前节点的运行状态超时或遇到错误，则直接抛出节点内置的报错信息，中断所有流程，工作流应用记录为运行失败。

### 处理逻辑：默认值

允许开发者通过默认值编辑器自定义节点的报错输出信息，类似编程中常见的单步调试方法，为应用的调试过程提供更加清晰的说明。

例如：

* 对于 `object` 和 `array` 类型，系统提供直观的 `JSON` 编辑器
* 对于 `number` 和 `string` 类型，则提供对应的类型编辑器。

当节点运行失败时，流程会自动使用开发者预设的默认值替代原节点输出的异常信息，确保流程不中断。更加清晰的报错信息能够提升故障的处理效率，让开发者能够专注于优化应用的流程设计。

> 预设默认值的数据结构类型与节点的输出变量相一致。例如在代码节点中，设置节点的输出变量为 `array[number]` 数据类型，则默认值的数据类型也同样为 `array[number]` 数据类型。

![Error handling: default value](https://assets-docs.dify.ai/2024/12/e9e5e757090679243e0c9976093c7e6c.png)

### 处理逻辑：异常分支

如果当前节点运行异常，则触发预设的下游分支。选择该处理逻辑后，将为当前节点提供新的连线位，开发者可以在画布上继续编排接下来的运行流程，或点击节点详情右下角添加下游节点。例如连接邮件工具节点发送异常信息。

> 异常分支以橙色线条高亮显示。

![](https://assets-docs.dify.ai/2024/12/e5ea1af947818bd9e27cab3042c1c4f3.png)

一个常见的编排策略是在异常分支内引入应对错误情况的处理节点，将修正后的内容通过变量聚合节点链接至原分支，汇总输出结果。

#### 异常变量

在节点的异常处理机制中选择**默认值**或**异常分支**逻辑选项后，当前节点在遇到异常情况时将通过 `error_type` 和 `error_message` 异常变量将报错信息传递给下游节点。

| 变量名称            | 功能描述                                                                                                          |
| --------------- | ------------------------------------------------------------------------------------------------------------- |
| `error_type`    | 错误类型。不同类型的节点有着不同的[错误类型](./error-type)，开发者可以根据不同的错误标识编排对应方案。 |
| `error_message` | 错误信息，异常节点输出的具体故障信息。开发者可以传递给下游的 LLM 节点进行修复，或连接邮箱工具推送信息。                                                        |

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/error-handling/predefined-nodes-failure-logic.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 异常处理
> 来源：`zh-hans/guides/workflow/error-handling/readme.mdx`

工作流应用通常包含多个节点。如果因为某个节点的异常（例如 API 请求异常或 LLM 输出异常）而造成整个流程的运行失败，会迫使应用开发者不得不花费大量的精力排查故障并修复，这在复杂的工作流应用中尤为困难。

**异常处理机制**提供多样化的节点错误处理策略，能够在发生局部节点错误时抛出故障信息而不中断主流程。你可以设置出现异常时重新执行节点，或通过备用路径继续任务。为关键节点**添加异常处理机制将极大地增强应用整体的灵活性与稳健性。**

> 同时开启**错误重试**和**异常处理**功能时，将优先重试运行节点。若重试后仍然失败，再启用异常处理机制。

开发者无需在节点内编排复杂的逻辑代码或额外的节点应对错误情况。异常处理机制将简化工作流的设计复杂度，以多样的预设策略编排工作流的执行逻辑。

## 应用场景

**1. 网络异常处理**

示例：在某个工作流中需要通过三个 API 服务（例如天气服务、新闻摘要和社交媒体分析）获取数据并汇总。然而，其中一个服务因请求限制无法响应，导致数据获取失败。通过异常处理功能，主流程将继续处理其它两个成功的数据源，同时记录失败的 API 调用错误日志，供开发者稍后分析并优化服务调用策略。

**2. 工作流备用设计**

示例：某个 LLM 节点执行生成详细文档摘要任务，但因输入的篇幅过长而触发超出 Token 限制的异常。在节点中配置异常错误机制后，出现此类错误时，可以使用备用路径中的代码节点协助将内容切分为多个小段并重新调用 LLM 节点，避免流程中断。

**3. 异常信息预定义**

示例：运行工作流时可能会遇到某个节点返回模糊的错误信息（例如简单的“调用失败”），难以快速定位问题。开发者可以通过异常处理机制内编写预定义报错信息，为后续的应用调试提供更加清晰、准确的错误信息。

## 异常处理机制

以下四个类型的节点新增异常处理机制，点击标题即可阅读详细文档：

* [LLM](../node/llm)
* [HTTP](../node/http-request)
* [代码](../node/code)
* [工具](../node/tools)

**异常重试**

部分异常可以通过重新运行节点解决，此时可以在节点内开启 **“异常重试”** 功能，设置尝试次数与重试间隔时间。

![](https://assets-docs.dify.ai/2024/12/18097e4c94b67a79150b967fc50f9f43.png)

如果尝试重试运行节点后依然报错，将按照异常处理机制中的预设策略运行接下来的流程。

**异常处理**

异常处理机制提供以下三种选项：

• **无**：不处理异常，直接抛出节点的报错信息并中断整体流程。

• **默认值**：允许开发者预定义异常信息。异常发生后，使用预定义的值替代原节点内置的异常输出信息。

• **异常分支**：发生异常后，执行预编排的异常分支

如需了解各个策略的说明和配置方法，请参考[预定义异常处理逻辑](predefined-nodes-failure-logic)。

![Error handling](https://assets-docs.dify.ai/2024/12/6e2655949889d4d162945d840d698649.png)

## 快速开始

### 场景：为工作流应用添加应对错误输出代码的处理机制

下文将以一个简单的示例应用，演示如何在工作流应用内增设异常处理机制，以备用分支应对节点异常。

![](https://assets-docs.dify.ai/2024/12/958326384d3b60a98246e9ff565c7ed3.png)

**应用逻辑**： LLM 节点根据输入的指令，生成正确或错误格式的 JSON 代码内容，然后通过 A 代码节点执行代码并输出结果。如果 A 代码节点接收到了错误格式的 JSON 内容，则按照预设的异常处理机制，执行备用路径而继续主流程。

> **步骤：**

    新建 Workflow 应用，并添加 LLM 节点和代码节点。通过 Prompt 让 LLM 根据指令生成正确或错误格式的 JSON 内容，然后通过 A 代码节点验证。

    **LLM 节点内的 Prompt 参考：**

    ```text
    You are a teaching assistant. According to the user's requirements, you only output a correct or incorrect sample code in json format.
    ```

    **代码节点中的 JSON 验证代码：**

    ```python
    def main(json_str: str) -> dict:
        obj = json.loads(json_str)
        return 'result': obj
    ```

    A 代码节点是验证 JSON 内容的节点，如果接收到的 JSON 内容格式错误，需要通过异常处理机制运行备用路径，让下一个 LLM 节点修复错误内容并重新验证 JSON 从而继续主流程。在 A 代码节点的"异常处理"选项卡中，选择"异常分支"并新建 LLM 节点。

    在新的 LLM 节点中，填写 Prompt 并通过变量引用 A 代码节点的异常输出内容，并进行修复。添加 B 代码节点对 JSON 内容进行二次验证。

    添加变量聚合节点，汇总正确和错误分支的处理结果并输出至结束节点内，完成整体流程。

    ![错误处理流程图](https://assets-docs.dify.ai/2024/12/059b5a814514cd9abe10f1f4077ed17f.png)

> Demo 应用 DSL 文件[下载地址](https://assets-docs.dify.ai/2024/12/087861aa20e06bb4f8a2bef7e7ae0522.yml)。

## 状态描述

状态指的是节点状态与流程状态。清晰的状态说明有助于开发者判断当前工作流应用的运行现状，协助进行问题排查，快速了解信息并做出对应决策。引入异常处理机制后，节点状态和流程存在以下状态：

### **节点状态**

*   **成功**

    节点正常执行，并正确输出信息。
*   **失败**

    未启用异常处理，节点执行失败，输出报错信息。
*   **异常**

    在异常处理机制中启用了**默认值**或**异常分支**选项。节点执行时遇到了错误，但启用异常机制应对错误。

### 工作流状态

*   **成功**

    流程中的所有节点正常执行，结束节点能够正确输出信息，状态被标记为 Success。
*   **失败**

    因出现节点异常，整体流程被中断，状态被标记为 Failed。
*   **局部成功**

    节点出现异常，但启用了异常处理机制，整体流程最终运行正常。状态将会被标记为 Partial success。

## 常见问题

### 1. 启用异常处理机制前后的区别是什么？

**没有错误处理机制时：**

* **节点错误中断流程**：当 LLM 调用失败、网络出现问题或工具出错时，整个工作流程会立即中断，应用开发者需要手动查找并修复错误后重新运行流程。
* **缺乏灵活性**：开发者无法对不同错误类型或节点定义特定的处理逻辑。例如，无法在错误发生时继续后续流程或选择替代路径。
* **手动添加冗余节点**：避免错误影响全局需要额外设计大量节点来捕获和处理错误，增加了工作流程的复杂性和开发成本。
* **日志信息有限**：错误日志通常简单或不足，无法快速诊断问题。

**启用异常处理机制后：**

* **流程不中断**：即使某个节点发生错误，工作流程可以根据用户定义的规则继续运行，减少因单点失败导致的全局影响。
* **灵活自定义错误处理**：应用开发者可以为每个节点指定错误处理策略，如继续流程、记录日志，或切换到替代路径。
* **简化工作流程设计**：通用错误处理器减少了用户手动设计冗余节点的需求，流程更清晰简洁。
* **详细错误日志支持**：提供错误信息的自定义编排机制，便于开发者快速排查问题和优化流程。

***

### 2. 如何调试替代路径的执行情况？

你可以通过工作流程的运行日志检查条件判断和路径选择情况。异常分支的运行路线以黄色高亮显示，帮助开发者验证替代路径是否按预期执行。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/error-handling/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 文件上传
> 来源：`zh-hans/guides/workflow/file-upload.mdx`

相较于聊天文本，文档文件能够承载大量的信息，例如学术报告、法律合同。受限于 LLM 自身仅能够支持文件或图片，难以获取文件内更加丰富的上下文信息，应用的使用者不得不手动复制粘贴大量信息与 LLM 对话，增加了许多不必要的使用成本。

文件上传功能允许将文件以 File variables 的形式在工作流应用中上传、解析、引用、和下载。**开发者现可轻松构建能理解和处理图片、音频、视频的复杂工作。**

### 应用场景

1. **文档分析**: 上传学术研究报告文件，LLM 可以快速总结要点，根据文件内容回答相关问题。
2. **代码审查**: 开发者上传代码文件，获得优化建议与 bug 检测。
3. **学习辅导**: 学生上传作业或学习资料，获得个性化的解释和指导。
4. **法律援助**: 上传完整的合同文本，由 LLM 协助审查条款，指出潜在风险。

### 文件上传与知识库的区别

文件上传和知识库都是为 LLM 提供额外上下文信息的方式，但它们在使用场景和功能上有明显区别：

1. **信息来源**：
   * 文件上传：允许终端用户在对话过程中动态上传文件，提供即时的、个性化的上下文信息。
   * 知识库：由应用开发者预先设置和管理，包含相对固定的信息集合。
2. **使用灵活性**：
   * 文件上传：更加灵活，用户可以根据具体需求上传不同类型的文件。
   * 知识库：内容相对固定，但可以被多个会话重复利用。
3. **信息处理**：
   * 文件上传：需要通过文档提取器或其他工具将文件内容转换为 LLM 可理解的文本。
   * 知识库：通常已经过预处理和索引，可以直接进行检索。
4. **应用场景**：
   * 文件上传：适用于需要处理用户特定文档的场景，如文档分析、个性化学习辅导等。
   * 知识库：适用于需要访问大量预设信息的场景，如客户服务、产品咨询等。
5. **数据持久性**：
   * 文件上传：通常为临时使用，不会长期存储在系统中。
   * 知识库：作为应用的一部分长期存在，可以持续更新和维护。

### 快速开始

Dify 支持在 [ChatFlow](./zh-hans/guides/workflow/key-concepts#chatflow-和-workflow) 和 [WorkFlow](./zh-hans/guides/workflow/concepts#chatflow-和-workflow) 类型应用中上传文件，并通过[变量](./zh-hans/guides/workflow/variables)交由 LLM 处理。应用开发者可以参考以下方法为应用开启文件上传功能：

* 在 Workflow 应用中：
  * 在 ["开始节点"](./zh-hans/guides/workflow/node/start) 添加文件变量
* 在 ChatFlow 应用中：
  * 在 ["附加功能"](./zh-hans/guides/workflow/additional-feature) 中开启文件上传，允许在聊天窗中直接上传文件
  * 在 ["开始节点"](./zh-hans/guides/workflow/node/start) 添加文件变量
  * 注意：这两种方法可以同时配置，它们是彼此独立的。附加功能中的文件上传设置（包括上传方式和数量限制）不会影响开始节点中的文件变量。例如只想通过开始节点创建文件变量，则无需开启附加功能中的文件上传功能。

这两种方法为应用提供了灵活的文件上传选项，以满足不同场景的需求。

#### File Types

file variables 和 array[file] variables 支持以下文件类型与格式：

| 文件类型 | 支持格式 |
|---------|---------|
| 文档 | TXT, MARKDOWN, PDF, HTML, XLSX, XLS, DOCX, CSV, EML, MSG, PPTX, PPT, XML, EPUB. |
| 图片 | JPG, JPEG, PNG, GIF, WEBP, SVG. |
| 音频 | MP3, M4A, WAV, WEBM, AMR. |
| 视频 | MP4, MOV, MPEG, MPGA. |
| 其他 | 自定义后缀名支持 |

#### 方法一：使用具备文件处理能力的 LLM

部分 LLMs（例如 [Claude 3.5 Sonnet](https://docs.anthropic.com/en/docs/build-with-claude/pdf-support)）已支持直接处理并分析文件内容，因此 LLM 节点的提示词已允许输入文件变量。

> 为了避免潜在异常，应用开发者在使用该文件变量前需前往 LLM 官网确认 LLM 支持何种文件类型。

1. 点击创建 Chatflow / Workflow 应用。
2. 添加 LLM 节点，选择具备文件分析能力的 LLM。
3. 在开始节点添加文件变量
4. 在 LLM 的系统提示词内输入文件变量。
5. 完成创建。

  ![使用具备识别文件的 LLM 配置示意图](https://assets-docs.dify.ai/2024/11/a7154e8966d979dcba13eac0a172ef89.png)

#### 方法二：在应用聊天框中开启文件上传（仅适用于 Chatflow）

1. 点击 Chatflow 应用右上角的 **"功能"** 按钮即可为应用添加更多功能。

   开启此功能后，应用使用者可以在应用对话的过程中随时上传并更新文件。最多支持同时上传 10 个文件，每个文件的大小上限为 15MB。

  ![Chatflow应用中文件上传功能的设置界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/20784cfa167417654a69c10e42e8271b.png)

开启该功能并不意味着赋予 LLM 直接读取文件的能力，还需要配备[**文档提取器**](./zh-hans/guides/workflow/node/doc-extractor)将文档解析为文本供 LLM 理解。

* 对于音频文件，可以使用 `gpt-4o-audio-preview` 等支持多模态输入的模型直接处理音频，无需额外的提取器。
* 对于视频和其他文件类型，暂无对应的提取器，需要应用开发者接入[外部工具](./zh-hans/guides/tools/extensions/api-based/api-based-extension)进行处理

2. 添加[文档提取器](./zh-hans/guides/workflow/node/doc-extractor)节点，在输入变量中选中 `sys.files` 变量。
3. 添加 LLM 节点，在系统提示词中选中文档提取器节点的输出变量。
4. 在末尾添加 "直接回复" 节点，填写 LLM 节点的输出变量。

  ![包含文件上传的工作流示意图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/bc7faa1f2ec9d26d3257f7bacc4b85d9.png)

开启后，用户可以在对话框中上传文件并进行对话。但通过此方式， LLM 应用并不具备记忆文件内容的能力，每次对话时需要上传文件。

  ![对话框中上传文件的界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/b18af11da3f339c496193d9732906849.png)

若希望 LLM 能够在对话中记忆文件内容，请参考下文。

#### 方法三：通过添加文件变量开启文件上传功能

#### 1. 在"开始"节点添加文件变量

在应用的["开始"](./zh-hans/guides/workflow/node/start)节点内添加输入字段，选择 **"单文件"** 或 **"文件列表"** 字段类型的变量。

<iframe
  src="https://www.motionshot.app/walkthrough/6772ae35d65f37064a5d28d3/embed?fullscreen=1&hideAsSteps=1&hideCopy=1&hideDownload=1&hideSteps=1"
  width="70%"
  height="300px"
  frameborder="0"
  allowfullscreen
></iframe>

*   **单文件**

    仅允许应用使用者上传单个文件。
*   **文件列表**

    允许应用使用者单词批量上传多个文件。

> 为了便于操作，将使用单文件变量作为示例。

#### 文件解析

文件变量的使用方式主要分为两种：

1. 使用工具节点转换文件内容：
   * 对于文档类型的文件，可以使用"文档提取器"节点将文件内容转换为文本形式。
   * 这种方法适用于需要将文件内容解析为模型可理解的格式（如 string、array[string] 等）的情况。
2. 直接在 LLM 节点中使用文件变量：
   * 对于某些特定类型的文件（如图片），可以在 LLM 节点中直接使用文件变量。
   * 例如，对于图片类型的 file variables，可以在 LLM 节点中启用 vision 功能，然后在变量选择器中直接引用对应的文件变量。

选择哪种方式取决于文件类型和您的具体需求。接下来，我们将详细介绍这两种方法的具体操作步骤。

#### 2. 添加文档提取器节点

上传文件后将存储至单文件变量内，LLM 暂不支持直接读取变量中的文件。因此需要先添加 [**"文档提取器"**](./zh-hans/guides/workflow/node/doc-extractor)节点，从已上传的文档文件内提取内容并发送至 LLM 节点完成信息处理。

将"开始"节点内的文件变量作为 **"文档提取器"** 节点的输入变量。

  ![文档提取器节点添加输入变量的界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/a42d183fa7ba38fa9c9d3bc772c79c29.png)

将"文档提取器"节点的输出变量填写至 LLM 节点的系统提示词内。

  ![LLM节点中粘贴系统提示词的界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/f6ea094b30b240c999a4248d1fc21a1c.png)

完成上述设置后，应用的使用者可以在 WebApp 内粘贴文件 URL 或上传本地文件，然后就文档内容与 LLM 展开互动。应用使用者可以在对话过程中随时替换文件，LLM 将获取最新的文件内容。

  ![WebApp中粘贴URL进行对话的界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/f4d9056c2df7f94ce41d4f281b45a94e.png)

**在 LLM 节点中引用文件变量**

对于某些特定类型的文件（如图片），可以在 LLM 节点中直接使用文件变量。这种方法特别适用于需要视觉分析的场景。以下是具体步骤：

1. 在 LLM 节点中，启用 vision 功能。这允许模型处理图像输入（模型需要支持 vision）。
2. 在 LLM 节点的变量选择器中，直接引用之前创建的文件变量如果是通过附加功能开启的文件上传，则选择 `sys.files` 变量。
3. 在系统提示词中，指导模型如何处理图像输入。例如，你可以要求模型描述图像内容或回答关于图像的问题。

下面是一个示例配置：

![](https://assets-docs.dify.ai/2025/04/ec247f5de4f59d4fb0c4ac25ce2fd96c.png)

需要注意的是，直接在 LLM 节点中使用文件变量时，我们需要确保文件变量仅包含图片文件，否则可能会导致错误。如果用户可能上传不同类型的文件，我们需要使用列表操作来进行过滤。

#### 文件下载

将文件变量放置到 answer 节点或者 end 节点中，当应用运行到该节点都时候将会在会话框中提供文件下载卡片。点击卡片即可下载文件。

![](https://assets-docs.dify.ai/2025/04/2ffc81675dee89d477cc461385501ddd.png)

### 进阶使用

若希望应用能够支持上传多种文件，例如允许用户同时上传文档文件、图片和音视频文件，此时需要在 "开始节点" 中添加 "文件列表" 变量，并通过"列表操作"节点针对不同的文件类型进行处理。详细说明请参考[列表操作](./zh-hans/guides/workflow/node/list-operator)节点。

  ![处理多种文件类型的工作流示意图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/812d1b2f167065e17df8392b2cb3cc8a.png)

如需查看更多使用案例，请参考：[动手实验室 - 使用文件上传搭建文章理解助手](./zh-hans/workshop/intermediate/article-reader)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/file-upload.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 关键概念
> 来源：`zh-hans/guides/workflow/key-concept.mdx`

### 节点

**节点是工作流的关键构成**，通过连接不同功能的节点，执行工作流的一系列操作。

工作流的核心节点请从[节点说明 - 开始节点](./node/start)起阅读。

***

### 变量

**变量用于串联工作流内前后节点的输入与输出**，实现流程中的复杂处理逻辑，包含系统变量、环境变量和会话变量。详细说明请参考 [变量](./variables)。

***

### Chatflow

**适用场景：**

面向对话类情景，包括客户服务、语义搜索、以及其他需要在构建响应时进行多步逻辑的对话式应用程序。该类型应用的特点在于支持对生成的结果进行多轮对话交互，调整生成的结果。

常见的交互路径：给出指令 → 生成内容 → 就内容进行多次讨论 → 重新生成结果 → 结束

![Chatflow 入口](https://assets-docs.dify.ai/2024/12/224b6bcd750ff0b83e3a5dac5cf24d7d.png)

### 工作流（Workflow）

**适用场景：**

面向自动化和批处理情景，适合高质量翻译、数据分析、内容生成、电子邮件自动化等应用程序。该类型应用无法对生成的结果进行多轮对话交互。

常见的交互路径：给出指令 → 生成内容 → 结束

![](https://assets-docs.dify.ai/2024/12/26a9fc809854fe51d946c148587fc1cf.png)

**应用类型差异**

1. [End 节点](node/end)属于 Workflow 的结束节点，仅可在流程结束时选择。
2. [Answer 节点](node/answer)属于 Chatflow ，用于流式输出文本内容，并支持在流程中间步骤输出。
3. Chatflow 内置聊天记忆（Memory），用于存储和传递多轮对话的历史消息，可在 [LLM](node/llm) 、[问题分类](node/question-classifier)等节点内开启，Workflow 无 Memory 相关配置，无法开启。
4. Chatflow 的开始节点内置变量包括：`sys.query`，`sys.files`，`sys.conversation_id`，`sys.user_id`。Workflow 的开始节点内置变量包括：`sys.files`，`sys.user_id` ，详见[变量](./zh-hans/guides/workflow/variables)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/key-concept.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## README
> 来源：`zh-hans/guides/workflow/node/README.mdx`

# 节点说明

**节点是工作流中的关键构成**，通过连接不同功能的节点，执行工作流的一系列操作。

### 核心节点

<table data-view="cards"><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td><a href="start"><strong>开始（Start）</strong></a></td><td>定义一个 workflow 流程启动的初始参数。</td><td></td></tr><tr><td><a href="end"><strong>结束（End）</strong></a></td><td>定义一个 workflow 流程结束的最终输出内容。</td><td></td></tr><tr><td><a href="answer"><strong>回复（Answer）</strong></a></td><td>定义一个 Chatflow 流程中的回复内容。</td><td></td></tr><tr><td><a href="llm"><strong>大语言模型（LLM）</strong></a></td><td>调用大语言模型回答问题或者对自然语言进行处理。</td><td></td></tr><tr><td><a href="knowledge-retrieval"><strong>知识检索（Knowledge Retrieval）</strong></a></td><td>从知识库中检索与用户问题相关的文本内容，可作为下游 LLM 节点的上下文。</td><td></td></tr><tr><td><a href="question-classifier"><strong>问题分类（Question Classifier）</strong></a></td><td>通过定义分类描述，LLM 能够根据用户输入选择与之相匹配的分类。</td><td></td></tr><tr><td><a href="ifelse"><strong>条件分支（IF/ELSE）</strong></a></td><td>允许你根据 if/else 条件将 workflow 拆分成两个分支。</td><td></td></tr><tr><td><a href="code"><strong>代码执行（Code）</strong></a></td><td>运行 Python / NodeJS 代码以在工作流程中执行数据转换等自定义逻辑。</td><td></td></tr><tr><td><a href="template"><strong>模板转换（Template）</strong></a></td><td>允许借助 Jinja2 的 Python 模板语言灵活地进行数据转换、文本处理等。</td><td></td></tr><tr><td><a href="variable-assigner"><strong>变量聚合（Variable Aggregator）</strong></a></td><td>将多路分支的变量聚合为一个变量，以实现下游节点统一配置。</td><td></td></tr><tr><td><a href="parameter-extractor"><strong>参数提取器（Parameter Extractor）</strong></a></td><td>利用 LLM 从自然语言推理并提取结构化参数，用于后置的工具调用或 HTTP 请求。</td><td></td></tr><tr><td><a href="iteration"><strong>迭代（Iteration）</strong></a></td><td>对列表对象执行多次步骤直至输出所有结果。</td><td></td></tr><tr><td><a href="http-request"><strong>HTTP 请求（HTTP Request）</strong></a></td><td>允许通过 HTTP 协议发送服务器请求，适用于获取外部检索结果、webhook、生成图片等情景。</td><td></td></tr><tr><td><a href="tools"><strong>工具（Tools）</strong></a></td><td>允许在工作流内调用 Dify 内置工具、自定义工具、子工作流等。</td><td></td></tr><tr><td><a href="variable-assignment"><strong>变量赋值（Variable Assigner）</strong></a></td><td>变量赋值节点用于向可写入变量（例如会话变量）进行变量赋值。</td><td></td></tr></tbody></table>

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Agent
> 来源：`zh-hans/guides/workflow/node/agent.mdx`

## 定义

Agent 节点是 Dify Chatflow/Workflow 中用于实现自主工具调用的组件。它通过集成不同的 Agent 推理策略，使大语言模型能够在运行时动态选择并执行工具，从而实现多步推理。

## 配置步骤

### 添加节点

在 Dify Chatflow/Workflow 编辑器中，从组件栏拖拽 Agent 节点至画布。

![](https://assets-docs.dify.ai/2025/04/7200e6f466a9da21fd8282afa392b348.png)

### 选择 Agent 策略

在节点配置面板中，点击 **Agent 策略**。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/2a6897e97b7ad534afdbe74bd7272426.png)

从下拉菜单选择所需的 Agent 推理策略。Dify 内置了 **Function Calling 和 ReAct** 两种策略，可在 **Marketplace** → **Agent 策略**分类中安装使用。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/41a147e0bfa027b801c09668adec7d19.png)

#### 1. Function Calling

通过将用户指令映射到预定义函数或工具，LLM 先识别用户意图，再决定调用哪个函数并提取所需参数。它的核心是调用外部函数或工具，属于一种明确的工具调用机制。

**优点:**

* **精确:** 对于明确的任务，可以直接调用相应的工具，无需复杂的推理过程。
* **易于集成外部功能:** 可以将各种外部 API 或工具封装成函数供模型调用。
* **结构化输出:** 模型输出的是结构化的函数调用信息，方便下游节点处理。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/312b854ad40f88a079f4ddaf7f99d0ee.png)

2. **ReAct (Reason + Act)**

ReAct 策略使 Agent 交替进行思考和行动：LLM 首先思考当前状态和目标，然后选择并调用合适的工具，工具的输出结果又将引导 LLM 进行下一步的思考和行动，如此循环，直到问题解决。

**优点:**

* **有效利用外部信息:** 能够有效地利用外部工具获取信息，解决仅靠模型自身无法完成的任务。
* **可解释性较好:** 思考和行动的过程是交织的，可以一定程度上追踪 Agent 的推理路径。
* **适用范围广:** 适用于需要外部知识或需要执行特定操作的场景，例如问答、信息检索、任务执行等。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/9196af3b81d8b02a8dcd21ac917825a6.png)

开发者可以向[公开仓库](https://github.com/langgenius/dify-plugins)贡献 Agent 策略插件，经过审核后将在 Marketplace 上架，供其他用户安装使用。

### **配置节点参数**

选择 Agent 策略后，配置面板会显示对应的配置项。Dify 官方内置的 Function Calling 和 ReAct 策略的配置项包括：

1. **模型：** 选择驱动 Agent 的大语言模型。
2. **工具：** 工具的使用方式由 Agent 策略定义，点击 "+" 添加并配置 Agent 可调用的工具。
   * **搜索：** 在下拉框中选择已安装的工具插件。
   * **授权：** 填写 API 密钥等授权信息后启用工具。
   * **工具描述和参数设置：** 提供工具描述，帮助 LLM 理解工具用途并选择调用，同时设置工具的功能参数。
3. **指令：** 定义 Agent 的任务目标和上下文。支持使用 Jinja 语法引用上游节点变量。
4. **查询：** 接收用户输入。
5. **最大迭代次数：** 设定 Agent 的最大执行步数。
6. **输出变量：** 提示节点输出的数据结构。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/d028e9dc111eca4fe4f7f0b25e75c4b0.png)

## **查看日志**

Agent 节点执行过程中将生成详细日志。显示节点执行的总体信息，包括输入和输出、token 开销、耗时和状态。点击 "详情" 查看 Agent 策略执行的每一轮输出信息。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/2dff44986829dfd100ee03c8eb89f94a.png)

## 记忆

启用记忆开关可以为 Agent 提供对话上下文记忆能力。通过调整记忆窗口滑块，你可以控制 Agent 能够“记住”的对话历史消息数量。这使 Agent 能够理解和引用先前的交流内容，从而提供连贯且上下文相关的回答，大幅提升多轮对话体验。

例如，当用户在后续消息中使用代词（如“它”、“这个”或“他们”）时，启用了记忆功能的 Agent 能够理解这些代词所指代的前文实体，无需用户重复提及完整信息。

<video controls src="https://assets-docs.dify.ai/2025/04/1801b96763eb8f22f1e2158645897885.mp4" width="100%"></video>

## 按需定制工具

将工具添加到Agent节点或 Agent 应用中后，你可以根据实际需求灵活定制：

![CleanShot 2025-07-07 at 07.41.33@2x.png](images/CleanShot2025-07-07at07.41.33@2x.png)

### 工具说明

可自定义工具的显示描述，调整为更贴合业务场景的说明信息，替换原 MCP 服务器自带描述。

### 参数配置（Reasoning Config）

每个工具参数可灵活选择两种模式：

* **自动（Auto）**：让 AI 根据上下文智能决定该参数值（默认）。

* **固定值（Fixed Value）**：设定为某个确定的值（支持静态文本或变量表达式），AI 不再推理此参数。

使用示例：

* 统一配置项，例如将搜索工具的 `numResults` 固定为 10。
* 预填写不应更改的参数，如特定的 API 地址、返回格式等。
* 通过减少 AI 需要处理的参数数量，简化工具调用逻辑。

例如，配置 Web 搜索工具时：

* 将 `query` 设置为"自动"，由 AI 动态生成搜索内容。
* 将 `numResults` 固定为 5，控制每次返回结果数量。
* 其他如过滤条件参数也可固定，以保证结果一致性。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/agent.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 直接回复
> 来源：`zh-hans/guides/workflow/node/answer.mdx`

### 定义

定义一个 Chatflow 流程中的回复内容。

你可以在文本编辑器中自由定义回复格式，包括自定义一段固定的文本内容、使用前置步骤中的输出变量作为回复内容、或者将自定义文本与变量组合后回复。

可随时加入节点将内容流式输出至对话回复，支持所见即所得配置模式并支持图文混排，如：

1. 输出 LLM 节点回复内容
2. 输出生成图片
3. 输出纯文本

**示例1：** 输出纯文本

![](https://assets-docs.dify.ai/2025/04/42bb6bdef101bf79f959f4fc56a50ff3.png)

**示例2：** 输出图片+LLM回复

![](https://assets-docs.dify.ai/2025/04/d2c901e821029756ebf95f4e099d833f.png)

![](https://assets-docs.dify.ai/2025/04/5a70a5e568dded3975e54cfa84085c93.png)

> **信息提示：**

直接回复节点可以不作为最终的输出节点，作为流程过程节点时，可以在中间步骤流式输出结果。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/answer.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 代码执行
> 来源：`zh-hans/guides/workflow/node/code.mdx`

## 目录

- [介绍](#介绍)
- [使用场景](#使用场景)
- [本地部署](#本地部署)
- [安全策略](#安全策略)

## 介绍

代码节点支持运行 Python / NodeJS 代码以在工作流程中执行数据转换。它可以简化你的工作流程，适用于Arithmetic、JSON transform、文本处理等情景。

该节点极大地增强了开发人员的灵活性，使他们能够在工作流程中嵌入自定义的 Python 或 Javascript 脚本，并以预设节点无法达到的方式操作变量。通过配置选项，你可以指明所需的输入和输出变量，并撰写相应的执行代码：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/9969aa1bc1912aebe366f5d8f5dde296.png)

## 配置

如果你需要在代码节点中使用其他节点的变量，你需要在`输入变量`中定义变量名，并引用这些变量，可以参考[变量引用](../key-concepts#变量)。

## 使用场景

使用代码节点，你可以完成以下常见的操作：

### 结构化数据处理

在工作流中，经常要面对非结构化的数据处理，如 JSON 字符串的解析、提取、转换等。最典型的例子就是 HTTP 节点的数据处理，在常见的 API 返回结构中，数据可能会被嵌套在多层 JSON 对象中，而我们需要提取其中的某些字段。代码节点可以帮助你完成这些操作，下面是一个简单的例子，它从 HTTP 节点返回的 JSON 字符串中提取了`data.name`字段：

```python
def main(http_response: str) -> dict:

    data = json.loads(http_response)
    return 
        # 注意在输出变量中声明result
        'result': data['data']['name'] 

```

### 数学计算

当工作流中需要进行一些复杂的数学计算时，也可以使用代码节点。例如，计算一个复杂的数学公式，或者对数据进行一些统计分析。下面是一个简单的例子，它计算了一个数组的平方差：

```python
def main(x: list) -> dict:
    return 
        # 注意在输出变量中声明result
        'result' : sum([(i - sum(x) / len(x)) ** 2 for i in x]) / len(x)

```

### 拼接数据

有时，也许你需要拼接多个数据源，如多个知识检索、数据搜索、API调用等，代码节点可以帮助你将这些数据源整合在一起。下面是一个简单的例子，它将两个知识库的数据合并在一起：

```python
def main(knowledge1: list, knowledge2: list) -> dict:
    return 
        # 注意在输出变量中声明result
        'result': knowledge1 + knowledge2

```

## 本地部署

如果你是本地部署的用户，你需要启动一个沙盒服务，它会确保恶意代码不会被执行，同时，启动该服务需要使用Docker服务，你可以在[这里](https://github.com/langgenius/dify/tree/main/docker/docker-compose.middleware.yaml)找到Sandbox服务的具体信息，你也可以直接通过`docker-compose`启动服务：

```bash
docker-compose -f docker-compose.middleware.yaml up -d
```

> 如果你的系统安装了 Docker Compose V2 而不是 V1，请使用 `docker compose` 而不是 `docker-compose`。通过`$ docker compose version`检查这是否为情况。在[这里](https://docs.docker.com/compose/#compose-v2-and-the-new-docker-compose-command)阅读更多信息。

## 安全策略

无论是 Python3 还是 Javascript 代码执行器，它们的执行环境都被严格隔离（沙箱化），以确保安全性。这意味着开发者不能使用那些消耗大量系统资源或可能引发安全问题的功能，例如直接访问文件系统、进行网络请求或执行操作系统级别的命令。这些限制保证了代码的安全执行，同时避免了对系统资源的过度消耗。

### 高级功能

**错误重试**

针对节点发生的部分异常情况，通常情况下再次重试运行节点即可解决。开启错误重试功能后，节点将在发生错误的时候按照预设策略进行自动重试。你可以调整最大重试次数和每次重试间隔以设置重试策略。

- 最大重试次数为 10 次
- 最大重试间隔时间为 5000 ms

![](https://assets-docs.dify.ai/2024/12/9fdd5525a91dc925b79b89272893becf.png)

**异常处理**

代码节点处理信息时有可能会遇到代码执行异常的情况。应用开发者可以参考以下步骤配置异常分支，在节点出现异常时启用应对方案，而避免中断整个流程。

1. 在代码节点启用 “异常处理”
2. 选择异常处理方案并进行配置

![Code Error handling](https://assets-docs.dify.ai/2024/12/58f392734ce44b22cd8c160faf28cd14.png)

需了解更多应对异常的处理办法，请参考[异常处理](../error-handling/readme)。

### 常见问题

**在代码节点内填写代码后为什么无法保存？**

请检查代码是否包含危险行为。例如：

```python
def main() -> dict:
    return 
        "result": open("/etc/passwd").read(),

```

这段代码包含以下问题：

- **未经授权的文件访问：** 代码试图读取 "/etc/passwd" 文件，这是 Unix/Linux 系统中存储用户账户信息的关键系统文件。
- **敏感信息泄露：** "/etc/passwd" 文件包含系统用户的重要信息，如用户名、用户 ID、组 ID、home 目录路径等。直接访问可能会导致信息泄露。

危险代码将会被 Cloudflare WAF 自动拦截，你可以通过 “网页调试工具” 中的 “网络” 查看是否被拦截。

![Cloudflare WAF](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/d1fe121991c51b26b66d42a55b18fb57.png)

## 代码修复

此功能通过利用上次运行`current_codeerror_message`变量实现自动代码纠正。

当代码节点运行失败时：

- 系统会捕获代码和错误信息。
- 这些信息会作为上下文变量传递到提示中。
- 系统会生成一个新版本的代码供审查和重试。

**配置：**

1. **编写修复提示：**

你可以自定义一个提示，例如：

在提示编辑器中，使用变量插入菜单（`/`或`{`）插入变量。

`根据以下错误信息修复代码：
代码：
{{current_code}}
错误：
{{error_message}}`

![Codefix PN](./images/codefix.PNG)

2. **使用上下文变量（如果在工作流程后续需要）**

要启用自动代码修复，请在提示中引用以下上下文变量：

- `{{current_code}}`：此节点上次运行的代码。
- `{{error_message}}`：如果上次运行失败，则为错误消息。

你还可以引用任何前置节点的输出变量。

当代码节点运行时，这些变量会自动可用，并允许模型使用先前的运行信息进行迭代修正。

3. **版本管理**

- 每次修正尝试都会保存为一个单独的版本（例如，版本1、版本2）。
- 用户可以通过结果显示区域的下拉菜单在不同版本间切换。

**注意事项：**

- 如果上次运行成功，error_message为空。
- last_run可用于引用先前的输入/输出。

这减少了手动复制粘贴操作，并允许在工作流程中直接进行迭代调试。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/code.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 文档提取器
> 来源：`zh-hans/guides/workflow/node/doc-extractor.mdx`

### 定义

LLM 自身无法直接读取或解释文档的内容。因此需要将用户上传的文档，通过文档提取器节点解析并读取文档文件中的信息，转化文本之后再将内容传给 LLM 以实现对于文件内容的处理。

### 应用场景

* 构建能够与文件进行互动的 LLM 应用，例如 ChatPDF 或 ChatWord；
* 分析并检查用户上传的文件内容；

### 节点功能

文档提取器节点可以理解为一个信息处理中心，通过识别并读取输入变量中的文件，提取信息后并转化为 string 类型输出变量，供下游节点调用。

![文档提取器节点](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/c5d46ad8a0d315dbd097824d3d9cc88a.png)

文档提取器节点结构分为输入变量、输出变量。

#### 输入变量

文档提取器仅接受以下数据结构的变量：

* `File`，单独一个文件
* `Array[File]`，多个文件

文档提取器仅能够提取文档类型文件中的信息，例如 TXT、Markdown、PDF、HTML、DOCX 格式文件的内容，无法处理图片、音频、视频等格式文件。

#### 输出变量

输出变量固定命名为 text。输出的变量类型取决于输入变量：

* 输入变量为 `File`，输出变量为 `string`
* 输入变量为 `Array[File]`，输出变量为 `array[string]`

> Array 数组变量一般需配合列表操作节点使用，详细说明请参考 [列表操作](./list-operator)。

### 配置示例

在一个典型的文件交互问答场景中，文档提取器可以作为 LLM 节点的前置步骤，提取应用的文件信息并传递至下游的 LLM 节点，回答用户关于文件的问题。

本章节将通过一个典型的 ChatPDF 示例工作流模板，介绍文档提取器节点的使用方法。

![ChatPDF 工作流](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/65f6abbf733b9e3f51c5425637dbec9a.png)

**配置流程：**

1. 为应用开启文件上传功能。在 ["开始"](start) 节点中添加**单文件变量**并命名为 `pdf`。
2. 添加文档提取节点，并在输入变量内选中 `pdf` 变量。
3. 添加 LLM 节点，在系统提示词内选中文档提取器节点的输出变量。LLM 可以通过该输出变量读取文件中的内容。

![填写文档提取器的输出变量](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/d17113e0b6601d18686cdfde7ca2f666.png)

4\. 配置结束节点，在结束节点中选择 LLM 节点的输出变量。

配置完成后，应用将具备文件上传功能，使用者可以上传 PDF 文件并展开对话。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/92211d8c7cdf4e00393e97c158ebe5ad.png)

> **提示：**

如需了解如何在聊天对话中上传文件并与 LLM 互动，请参考 [附加功能](./zh-hans/guides/workflow/additional-feature)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/doc-extractor.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 结束
> 来源：`zh-hans/guides/workflow/node/end.mdx`

### 定义

定义一个工作流程结束的最终输出内容。每一个工作流在完整执行后都需要至少一个结束节点，用于输出完整执行的最终结果。

结束节点为流程终止节点，后面无法再添加其他节点，工作流应用中只有运行到结束节点才会输出执行结果。若流程中出现条件分叉，则需要定义多个结束节点。

结束节点需要声明一个或多个输出变量，声明时可以引用任意上游节点的输出变量。

> **信息提示：**

Chatflow 内不支持结束节点。

***

### 场景

在以下[长故事生成工作流](./zh-hans/guides/workflow/node/iteration#示例-2：长文章迭代生成器（另一种编排方式）)中，结束节点声明的变量 `Output` 为上游代码节点的输出，即该工作流会在 Code3 节点执行完成之后结束，并输出 Code3 的执行结果。

![结束节点-长故事生成示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/50152cf67089446181819755a5fa2dcb.png)

**单路执行示例：**

![单路执行示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/04cddaa15398cd7c905275234494ead7.png)

**多路执行示例：**

![多路执行示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/3cb3f5fea376265bede0a4ac5bcc1ddc.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/end.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## HTTP 请求
> 来源：`zh-hans/guides/workflow/node/http-request.mdx`

### 定义

允许通过 HTTP 协议发送服务器请求，适用于获取外部数据、webhook、生成图片、下载文件等情景。它让你能够向指定的网络地址发送定制化的 HTTP 请求，实现与各种外部服务的互联互通。

该节点支持常见的 HTTP 请求方法：

* **GET**，用于请求服务器发送某个资源。
* **POST**，用于向服务器提交数据，通常用于提交表单或上传文件。
* **HEAD**，类似于 GET 请求，但服务器不返回请求的资源主体，只返回响应头。
* **PATCH**，用于在请求-响应链上的每个节点获取传输路径。
* **PUT**，用于向服务器上传资源，通常用于更新已存在的资源或创建新的资源。
* **DELETE**，用于请求服务器删除指定的资源。

你可以通过配置 HTTP 请求的包括 URL、请求头、查询参数、请求体内容以及认证信息等。

![HTTP 请求配置](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/bf2a990493bf60a0278fea7147900fc6.png)

***

### 场景

这个节点的一个实用特性是能够根据场景需要，在请求的不同部分动态插入变量。比如在处理客户评价请求时，你可以将用户名或客户ID、评价内容等变量嵌入到请求中，以定制化自动回复信息或获取特定客户信息并发送相关资源至特定的服务器。

![客户评价分类](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/39c7ad0816891caefed1e9446be541bf.png)

HTTP 请求的返回值包括响应体、状态码、响应头和文件。值得注意的是，如果响应中包含了文件，这个节点能够自动保存文件，供流程后续步骤使用。这样不仅能提高处理效率，也可以更加简单直接地处理带有文件的响应。

* **发送文件**

你可以使用 HTTP PUT 请求将应用内的文件发送至其它 API 服务。在请求的 Body 中，可以在 `binary` 内选中文件变量。这种方式常用于文件传输、文档存储或媒体处理等场景。

示例： 假设你正在开发一个文档管理应用，需要将用户上传的 PDF 文件同步发送第三方服务，可以通过 HTTP 请求节点通过文件变量进行传递。

配置示例如下：

![通过 HTTP 节点发送文件](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/7519496a273655476305f26b2fa2321d.png)

### 高级功能

**错误重试**

针对节点发生的部分异常情况，通常情况下再次重试运行节点即可解决。开启错误重试功能后，节点将在发生错误的时候按照预设策略进行自动重试。你可以调整最大重试次数和每次重试间隔以设置重试策略。

- 最大重试次数为 10 次
- 最大重试间隔时间为 5000 ms

![错误重试配置](https://assets-docs.dify.ai/2024/12/2e7c6080c0875e31a074c2a9a4543797.png)

**异常处理**

HTTP 节点处理信息时有可能会遇到网络请求超时、请求限制等异常情况。应用开发者可以参考以下步骤配置异常分支，在节点出现异常时启用应对方案，而避免中断整个流程。

1. 在 HTTP 节点启用 “异常处理”
2. 选择异常处理方案并进行配置

需了解更多应对异常的处理办法，请参考[异常处理](./zh-hans/guides/workflow/error-handling/readme)。

![异常处理配置](https://assets-docs.dify.ai/2024/12/91daa86d9770390ab2a41d6d0b6ed1e7.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/http-request.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 条件分支
> 来源：`zh-hans/guides/workflow/node/ifelse.mdx`

### 定义

根据 If/else/elif 条件将 Chatflow / Workflow 流程拆分成多个分支。

### 节点功能

条件分支的运行机制包含以下六个路径：

* IF 条件：选择变量，设置条件和满足条件的值；
* IF 条件判断为 `True`，执行 IF 路径；
* IF 条件判断为 `False`，执行 ELSE 路径；
* ELIF 条件判断为 `True`，执行 ELIF 路径；
* ELIF 条件判断为 `False`，继续判断下一个 ELIF 路径或执行最后的 ELSE 路径；

**条件类型**

支持的条件类型取决于变量的数据类型：

**字符串/数字/对象变量：**
* 包含（Contains）
* 不包含（Not contains）
* 开始是（Start with）
* 结束是（End with）
* 是（Is）
* 不是（Is not）
* 为空（Is empty）
* 不为空（Is not empty）

**布尔值变量：**
* 是（Is）- 真/假
* 不是（Is not）- 真/假

**布尔值数组变量：**
* 包含（Contains）- 真/假
* 不包含（Not contains）- 真/假
* 为空（Is empty）
* 不为空（Is not empty）

***

### 场景

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/c9655478c988a816a99485f50467049e.png)

以**文本总结工作流**作为示例说明各个条件：

* IF 条件： 选择开始节点中的 `summarystyle` 变量，条件为**包含** `技术`；
* IF 条件判断为 `True`，执行 IF 路径，通过知识检索节点查询技术相关知识再到 LLM 节点回复（图中上半部分）；
* IF 条件判断为 `False`，但添加了 `ELIF` 条件，即 `summarystyle` 变量输入**不包含**`技术`，但 `ELIF` 条件内包含 `科技`，会检查 `ELIF` 内的条件是否为 `True`，然后执行路径内定义的步骤；
* `ELIF` 内的条件为 `False`，即输入变量既不不包含 `技术`，也不包含 `科技`，继续判断下一个 ELIF 路径或执行最后的 ELSE 路径；
* IF 条件判断为 `False`，即 `summarystyle` 变量输入**不包含** `技术`，执行 ELSE 路径，通过 LLM2 节点进行回复（图中下半部分）；

**多重条件判断**

涉及复杂的条件判断时，可以设置多重条件判断，在条件之间设置 **AND** 或者 **OR**，即在条件之间取**交集**或者**并集**。

![多重条件判断](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/c3bf3ebe6bc8709f5bc5099eb1242845.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/ifelse.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 迭代
> 来源：`zh-hans/guides/workflow/node/iteration.mdx`

### 定义

对数组中的元素依次执行相同的操作步骤，直至输出所有结果，可以理解为任务批处理器。迭代节点通常配合数组变量使用。

例如在长文翻译迭代节点内，如果将所有内容输入至 LLM 节点，有可能会达到单次对话限制。上游节点可以先将长文拆分为了多个片段，配合迭代节点对各个片段执行批量翻译，以避免达到 LLM 单次对话的消息限制。

***

### 功能简介

使用迭代的条件是确保输入值已格式化为列表对象；迭代节点将依次处理迭代开始节点数组变量内的所有元素，每个元素遵循相同的处理步骤，每轮处理被称为一个迭代，最终输出处理结果。

迭代节点的结构通常包含**输入变量**、**迭代工作流**、**输出变量**三个功能单元。

**输入变量：** 仅接受 Array 数组变量类型数据。如果你不了解什么是数组变量，请阅读 [扩展阅读：数组](../../../learn-more/extended-reading/what-is-array-variable)。

**迭代工作流：** 你可以在迭代节点中使用多个工作流节点，编排不同的任务步骤。

**输出变量：** 仅支持输出数组变量 `Array[List]`。如果你想要输出其它变量格式，请阅读 [扩展阅读：如何将数组转换为文本](#如何将数组转换为文本)。

![迭代节点原理图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/2b26dc5f5b088304b65190e14f58423a.png)

### 场景

#### **示例1：长文章迭代生成器**

![长故事生成器](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/91091e9c5297944edb57f509a7294714.png)

1. 在 **开始节点** 内添加输入故事标题、大纲变量，提示用户手动输入初始信息
2. 使用 **LLM 节点** 基于用户输入的故事标题和大纲，让 LLM 开始编写内容
3. 使用 **参数提取节点** 将 LLM 输出的完整内容转换成数组格式
4. 通过 **迭代节点** 包裹的 **LLM 节点** 循环多次生成各章节内容
5. 将 **直接回复** 节点添加在迭代节点内部，实现在每轮迭代生成之后流式输出

**具体配置步骤**

1. 在 **开始节点** 配置故事标题（title）和大纲（outline）；

![开始节点配置](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/1b371ec3fc8a97831745e530fe8ad50f.png)

2. 选择 **LLM 节点** 基于用户输入的故事标题和大纲，让 LLM 开始编写文本；

![模板节点](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/55e2b509c4a7b271a71156dc677e6fb8.png)

3. 选择 **参数提取节点**，将故事文本转换成为数组（Array）结构。提取参数为 `sections` ，参数类型为 `Array[Object]`

![参数提取](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/89419f8b96db401014ca399e931e61d0.png)

> **信息提示：**

参数提取效果受模型推理能力和指令影响，使用推理能力更强的模型，在**指令**内增加示例可以提高参数提取的效果。

4. 将数组格式的故事大纲作为迭代节点的输入，在迭代节点内部使用 **LLM 节点** 进行处理

![配置迭代节点](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/eb7735d04b1cb6a6ebde76fe7f0da701.png)

在 LLM 节点内配置输入变量 `GenerateOverallOutline/output` 和 `Iteration/item`

![配置 LLM 节点](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/fe17ddf24ec1689be1ab72200804ed0c.png)

> **信息提示：**

迭代的内置变量：`items[object]` 和 `index[number]`

`items[object] 代表以每轮迭代的输入条目；`

`index[number] 代表当前迭代的轮次；`

5. 在迭代节点内部配置 **直接回复节点** ，可以实现在每轮迭代生成之后流式输出。

![配置 Answer 节点](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/17fe8533d1649d541e47390db2d1cf92.png)

6. 完整调试和预览

![按故事章节多轮迭代生成](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/a032a01e49387e7bdc2e0038aa3650b3.png)

#### **示例 2：长文章迭代生成器（另一种编排方式）**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/6378e5eb85ce9760d7ef642ea555b268.png)

* 在 **开始节点** 内输入故事标题和大纲
* 使用 **LLM 节点** 生成文章小标题，以及小标题对应的内容
* 使用 **代码节点** 将完整内容转换成数组格式
* 通过 **迭代节点** 包裹的 **LLM 节点** 循环多次生成各章节内容
* 使用 **模板转换** 节点将迭代节点输出的字符串数组转换为字符串
* 在最后添加 **直接回复节点** 将转换后的字符串直接输出

***

### 高级功能

**并行模式**

迭代节点支持并行模式，开启后将有效提升迭代节点的整体运行效率。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/d412f5048cd544b90b829662f64f9593.png)

下图是迭代节点开启或关闭并行模式的运行效果对比。

![顺序与并行执行原理图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/adbc49bfb14e0de6d1a72ccccc30cdd0.png)

并行模式下的最高并行轮数为 10，这意味着单位时间内最多可以同时运行 10 个任务。如果需要处理超过  10 个任务，前 10 个元素将率先同时运行，前排任务处理完成后将继续处理剩余任务。

> **信息提示：**

开启并行模式后，不再建议在迭代节点内放置直接回答、变量赋值和工具节点。此举可能会造成异常情况。

* **错误响应方法**

迭代节点通常需要处理大量任务，有时会在处理某个元素时发生错误。为了避免某个元素异常而中断所有任务，你可以在**错误响应方法**中设置异常的应对方法：

* 错误时终止。如果发现异常输出，终止迭代节点，输出错误信息。
* 忽略错误并继续。忽略异常信息，继续处理剩余元素。输出的信息中包含正确信息，异常信息为空值。
* 移除错误输出。忽略异常信息，继续处理剩余元素。输出的信息中仅包含正确信息。

迭代节点的输入变量与输出变量相对应。例如输入变量为 \[1,2,3] ，则输出变量同样为 \[result-1, result-2, result-3]。

如果选择了**忽略错误并继续，** 异常情况的输出值为 null 值，例如 \[result-1, null, result-3]；

如果选择了**移除错误输出，** 将不会输出异常变量，例如 \[result-1, result-3]。

### 扩展阅读

[**什么是数组变量？**](../../../learn-more/extended-reading/what-is-array-variable)

***

#### 如何生成数组变量？

你可以通过以下节点生成数组变量，用以充当迭代节点的输入变量：

*   [代码节点](code)

    ![code 节点输出 array](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/2faff6c41d45191307296a52a406b776.png)
*   [参数提取](parameter-extractor)

    ![参数提取节点输出 array](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/66ec57db7558ca372fe847834e201a52.png)
* [知识库检索](knowledge-retrieval)
* [迭代](iteration)
* [工具](tools)
* [HTTP 请求](http-request)

***

#### 如何将数组转换为文本

迭代节点的输出变量为数组格式，无法直接输出 String 字符串内容。你可以使用一个简单的步骤将数组转换回文本。

**使用代码节点转换**

![代码节点转换](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/d6a2ca50f2484eedea2ff7ca5efb2bb5.png)

代码示例：

```python
def main(articleSections: list):
    data = articleSections
    return 
        "result": "\n".join(data)

```

**使用模板节点转换**

![模板节点转换](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/ebc414466340c323d2eb1b6c7056360d.png)

代码示例：

```django
{{ articleSections | join("\n") }}
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/iteration.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 知识检索
> 来源：`zh-hans/guides/workflow/node/knowledge-retrieval.mdx`

### 定义

从知识库中检索与用户问题相关的文本内容，可作为下游 LLM 节点的上下文来使用。

***

### 应用场景

常见情景：构建基于外部数据/知识的 AI 问答系统（RAG）。了解更多关于 RAG 的[基本概念](../../../learn-more/extended-reading/retrieval-augment/)。

下图为一个最基础的知识库问答应用示例，该流程的执行逻辑为：知识库检索作为 LLM 节点的前置步骤，在用户问题传递至 LLM 节点之前，先在知识检索节点内将匹配用户问题最相关的文本内容并召回，随后在 LLM 节点内将用户问题与检索到的上下文一同作为输入，让 LLM 根据检索内容来回复问题。

![知识库问答应用示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/34eefebfe8737186d89cc3cf2662a99c.png)

***

### 配置指引

**配置流程：**

1. 选择查询变量。查询变量通常代表用户输入的问题，该变量可以作为输入项并检索知识库中的相关文本分段。在常见的对话类应用中一般将开始节点的 `sys.query` 作为查询变量，知识库所能接受的最大查询内容为 200 字符；
2. 选择需要查询的知识库，可选知识库需要在 Dify 知识库内预先[创建](../../knowledge-base/create-knowledge-and-upload-documents/)；
3. 在 元数据筛选 板块中配置元数据的筛选条件，使用元数据功能筛选知识库内的文档。详情请参阅[在应用内集成知识库](./zh-hans/guides/knowledge-base/integrate-knowledge-within-application)中的 **使用元数据筛选知识** 章节。
4. 指定[召回模式](../../../learn-more/extended-reading/retrieval-augment/retrieval)。自 9 月 1 日后，知识库的召回模式将自动切换为多路召回，不再建议使用 N 选 1 召回模式；
5. 连接并配置下游节点，一般为 LLM 节点；

![知识检索配置](https://assets-docs.dify.ai/2025/03/f33b9a3ff1c9468fb5d7c1de4c1e02d6.png)

**输出变量**

![输出变量](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/ca3d688cb8644b6e0e1f7ce54256ee34.png)

知识检索的输出变量 `result` 为从知识库中检索到的相关文本分段。其变量数据结构中包含了分段内容、标题、链接、图标、元数据信息。

**配置下游节点**

在常见的对话类应用中，知识库检索的下游节点一般为 LLM 节点，知识检索的**输出变量** `result` 需要配置在 LLM 节点中的 **上下文变量** 内关联赋值。关联后你可以在提示词的合适位置插入 **上下文变量**。

> **信息提示：**

上下文变量是 LLM 节点内定义的特殊变量类型，用于在提示词内插入外部检索的文本内容。

当用户提问时，若在知识检索中召回了相关文本，文本内容会作为上下文变量中的值填入提示词，提供 LLM 回复问题；若未在知识库检索中召回相关的文本，上下文变量值为空，LLM 则会直接回复用户问题。

![配置下游 LLM 节点](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/a9cb49ad4b8e0dee1f8bb20f49d1fe79.png)

该变量除了可以作为 LLM 回复问题时的提示词上下文作为外部知识参考引用，另外由于其数据结构中包含了分段引用信息，同时可以支持应用端的 [**引用与归属**](./zh-hans/guides/knowledge-base/retrieval-test-and-citation) 功能。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/knowledge-retrieval.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 列表操作
> 来源：`zh-hans/guides/workflow/node/list-operator.mdx`

文件列表变量支持同时上传文档文件、图片、音频与视频文件等多种文件。应用使用者在上传文件时，所有文件都存储在同一个 `Array[File]` 数组类型变量内，**不利于后续单独处理文件。** 列表操作节点可以在数组变量内提取单独的元素，便于后续节点处理。

> `Array`数据类型意味着该变量的实际值可能为 \[1.mp3, 2.png, 3.doc]，大语言模型（LLM）仅支持读取图片文件或文本内容等单一值作为输入变量，无法直接读取数组变量，通常需要配合列表操作节点一起使用。

### 节点功能

列表操作节点可以对文件的格式类型、文件名、大小等属性进行过滤与提取，将不同格式的文件传递给对应的处理节点，以实现对不同文件处理流的精确控制。

例如在一个应用中，允许用户同时上传文档文件和图片文件两种不同类型的文件。需要使用**列表操作节点**进行分拣，将不同的文件类型交由不同流程处理。

![分流不同的文件类型](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/522a0c932aab93d4f3970168412f759e.png)

列表操作节点一般用于提取数组变量中的信息，通过设置条件将其转化为能够被下游节点所接受的变量类型。它的结构分为**输入变量**、**过滤条件**、**排序（可选）**、**取前 N 项（可选）**、**输出变量**。

![列表操作节点](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/8c1be5a1270203aeb694872c316cd61e.png)

#### 输入变量

列表操作节点仅接受以下数据结构变量：

* Array\[string]
* Array\[number]
* Array\[file]

#### 过滤条件

处理输入变量中的数组，添加过滤条件。从数组中分拣所有满足条件的数组变量，可以理解为对变量的属性进行过滤。

举例：文件中可能包含多重维度的属性，例如文件名、文件类型、文件大小等属性。过滤条件允许设置筛选条件，选择并提取数组变量中的特定文件。

支持提取以下变量：

* type 文件类别，包含图片，文档，音频和视频类型
* size 文件大小
* name 文件名
* url 指的是应用使用者通过 URL 上传的文件，可填写完整 URL 进行筛选
* extension 文件拓展名
*   mime\_type

    [MIME 类型](https://datatracker.ietf.org/doc/html/rfc2046)是用来标识文件内容类型的标准化字符串。示例: "text/html" 表示 HTML 文档。
*   transfer\_method

    文件上传方式，分为本地上传或通过 URL 上传

#### 排序

提供对于输入变量中数组的排序能力，支持根据文件属性进行排序。

*   升序排列

    默认排序选项，按照从小到大排序。对于字母和文本，按字母表顺序排列（A - Z）
*   降序排列

    由大到小排序，对于字母和文本，按字母表倒序排列（Z - A）

该选项常用于配合输出变量中的 first\_record 及 last\_record 使用。

#### 取前 N 项

可以在 1-20 中选值，用途是为了选中数组变量的前 n 项。

#### 输出变量

满足各项过滤条件的数组元素。过滤条件、排序和限制可以单独开启。如果同时开启，则返回符合所有条件的数组元素。

* Result，过滤结果，数据类型为数组变量。若数组中仅包含 1 个文件，则输出变量仅包含 1 个数组元素；
* first\_record，筛选完的数组的首元素，即 result\[0]；
* last\_record，筛选完的数组的尾元素，即 result\[array.length-1]。

***

### 配置案例

在文件交互问答场景中，应用使用者可能会同时上传文档文件或图片文件。LLM 仅支持识别图片文件的能力，不支持读取文档文件。此时需要用到 [列表操作](list-operator) 节点预处理文件变量的数组，将不同的文件类型并发送至对应的处理节点。编排步骤如下：

1. 开启 [Features](../additional-feature) 功能，并在文件类型中勾选 "图片" + "文档文件" 类型。
2. 添加两个列表操作节点，在 "过滤" 条件中分别设置提取图片与文档变量。
3. 提取文档文件变量，传递至 "文档提取器" 节点；提取图片文件变量，传递至 "LLM" 节点。
4. 在末尾添加 "直接回复" 节点，填写 LLM 节点的输出变量。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/ca60c2a982f7a9902c178e4e5503db50.png)

应用使用者同时上传文档文件和图片后，文档文件自动分流至文档提取器节点，图片文件自动分流至 LLM 节点以实现对于混合文件的共同处理。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/list-operator.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## LLM
> 来源：`zh-hans/guides/workflow/node/llm.mdx`

### 定义

调用大语言模型的能力，处理用户在 "开始" 节点中输入的信息（自然语言、上传的文件或图片），给出有效的回应信息。

  ![LLM 节点](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/0356bf3a8c46660181707da6f736386f.png)

---

### 应用场景

LLM 节点是 Chatflow/Workflow 的核心节点。该节点能够利用大语言模型的对话/生成/分类/处理等能力，根据给定的提示词处理广泛的任务类型，并能够在工作流的不同环节使用。

- **意图识别**，在客服对话情景中，对用户问题进行意图识别和分类，导向下游不同的流程。
- **文本生成**，在文章生成情景中，作为内容生成的节点，根据主题、关键词生成符合的文本内容。
- **内容分类**，在邮件批处理情景中，对邮件的类型进行自动化分类，如咨询/投诉/垃圾邮件。
- **文本转换**，在文本翻译情景中，将用户提供的文本内容翻译成指定语言。
- **代码生成**，在辅助编程情景中，根据用户的要求生成指定的业务代码，编写测试用例。
- **RAG**，在知识库问答情景中，将检索到的相关知识和用户问题重新组织回复问题。
- **图片理解**，使用 vision 能力的多模态模型，能对图像内的信息进行理解和问答。

选择合适的模型，编写提示词，你可以在 Chatflow/Workflow 中构建出强大、可靠的解决方案。

---

### 配置示例

在应用编辑页中，点击鼠标右键或轻点上一节点末尾的 \+ 号，添加节点并选择 LLM。

  ![LLM 节点配置-选择模型](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/778b40e25d203a5da9dddd9d8d7063a1.png)

**配置步骤：**

1. **选择模型**，Dify 提供了全球主流模型的[支持](./zh-hans/getting-started/readme/model-providers)，包括 OpenAI 的 GPT 系列、Anthropic 的 Claude 系列、Google 的 Gemini 系列等，选择一个模型取决于其推理能力、成本、响应速度、上下文窗口等因素，你需要根据场景需求和任务类型选择合适的模型。

> 如果你是初次使用 Dify ，在 LLM 节点选择模型之前，需要在 **系统设置—模型供应商** 内提前完成[模型配置](../../model-configuration/)。

2. **配置模型参数**，模型参数用于控制模型的生成结果，例如温度、TopP，最大标记、回复格式等，为了方便选择系统同时提供了 3 套预设参数：创意，平衡和精确。如果你对以上参数并不熟悉，建议选择默认设置。若希望应用具备图片分析能力，请选择具备视觉能力的模型。
3. **填写上下文（可选）**，上下文可以理解为向 LLM 提供的背景信息，常用于填写[知识检索](knowledge-retrieval)的输出变量。
4. **编写提示词**，LLM 节点提供了一个易用的提示词编排页面，选择聊天模型或补全模型，会显示不同的提示词编排结构。如果选择聊天模型（Chat model），你可以自定义系统提示词（SYSTEM）/用户（USER）/ 助手（ASSISTANT）三部分内容。

![描述文字](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/a986b3bb34a57a9440bcbf7a54c2467e.png)

如果在编写系统提示词（SYSTEM）时没有好的思路，也可以使用提示生成器功能，借助 AI 能力快速生成适合实际业务场景的提示词。

  ![提示生成器](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/727e40ef04a4df13d3bef82ad02e73f1.png)

在提示词编辑器中，你可以通过输入 **"/"** 呼出 **变量插入菜单**，将 **特殊变量块** 或者 **上游节点变量** 插入到提示词中作为上下文内容。

  ![呼出变量插入菜单](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/cc96ca72400fb81aca6936908d667478.png)

5. **高级设置**，可以开关记忆功能并设置记忆窗口、开关 Vision 功能或者使用 Jinja-2 模板语言来进行更复杂的提示词等。

---

### 特殊变量说明

**上下文变量**

上下文变量是一种特殊变量类型，用于向 LLM 提供背景信息，常用于在知识检索场景下使用。详细说明请参考[知识检索节点](knowledge-retrieval)。

**文件变量**

部分 LLMs（例如 [Claude 3.5 Sonnet](https://docs.anthropic.com/en/docs/build-with-claude/pdf-support)）已支持直接处理并分析文件内容，因此系统提示词已允许输入文件变量。为了避免潜在异常，应用开发者在使用该文件变量前需前往 LLM 官网确认 LLM 支持何种文件类型。

![](https://assets-docs.dify.ai/2024/11/05b3d4a78038bc7afbb157078e3b2b26.png)

> 阅读[文件上传](https://docs.dify.ai/zh-hans/guides/workflow/file-upload)了解如何搭建具备文件上传功能的 Chatflow/Workflow 应用。

**会话历史**

为了在文本补全类模型（例如 gpt-3.5-turbo-Instruct）内实现聊天型应用的对话记忆，Dify 在原[提示词专家模式（已下线）](user-guide/learn-more/extended-reading/prompt-engineering/prompt-engineering-1/)内设计了会话历史变量，该变量沿用至 Chatflow 的 LLM 节点内，用于在提示词中插入 AI 与用户之间的聊天历史，帮助 LLM 理解对话上文。

> 会话历史变量应用并不广泛，仅在 Chatflow 中选择文本补全类模型时可以插入使用。

  ![插入会话历史变量](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/b8642f8c6e3f562fceeefae83628fd68.png)

**模型参数**

模型的参数会影响模型的输出效果。不同模型的参数会有所区别。下图为`gpt-4`的参数列表。

  ![模型参数列表](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/74a93d9b4982a8ad4d046dc9fb290b2d.png)

主要的参数名词解释如下：

- **温度：** 通常是0-1的一个值，控制随机性。温度越接近0，结果越确定和重复，温度越接近1，结果越随机。
- **Top P：** 控制结果的多样性。模型根据概率从候选词中选择，确保累积概率不超过预设的阈值P。
- **存在惩罚：** 用于减少重复生成同一实体或信息，通过对已经生成的内容施加惩罚，使模型倾向于生成新的或不同的内容。参数值增加时，对于已经生成过的内容，模型在后续生成中被施加更大的惩罚，生成重复内容的可能性越低。
- **频率惩罚：** 对过于频繁出现的词或短语施加惩罚，通过降低这些词的生成概率。随着参数值的增加，对频繁出现的词或短语施加更大的惩罚。较高的参数值会减少这些词的出现频率，从而增加文本的词汇多样性。

如果你不理解这些参数是什么，可以选择**加载预设**，从创意、平衡、精确三种预设中选择。

  ![加载预设参数](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/a117606125cbc65573f201738cd0af6e.png)

---

### 高级功能

**记忆：** 开启记忆后问题分类器的每次输入将包含对话中的聊天历史，以帮助 LLM 理解上文，提高对话交互中的问题理解能力。

**记忆窗口：** 记忆窗口关闭时，系统会根据模型上下文窗口动态过滤聊天历史的传递数量；打开时用户可以精确控制聊天历史的传递数量（对数）。

**对话角色名设置：** 由于模型在训练阶段的差异，不同模型对于角色名的指令遵循程度不同，如 Human/Assistant，Human/AI，人类/助手等等。为适配多模型的提示响应效果，系统提供了对话角色名的设置，修改对话角色名将会修改会话历史的角色前缀。

**Jinja-2 模板：** LLM 的提示词编辑器内支持 Jinja-2 模板语言，允许你借助 Jinja2 这一强大的 Python 模板语言，实现轻量级数据转换和逻辑处理，参考[官方文档](https://jinja.palletsprojects.com/en/3.1.x/templates/)。

**错误重试**：针对节点发生的部分异常情况，通常情况下再次重试运行节点即可解决。开启错误重试功能后，节点将在发生错误的时候按照预设策略进行自动重试。你可以调整最大重试次数和每次重试间隔以设置重试策略。

- 最大重试次数为 10 次
- 最大重试间隔时间为 5000 ms

![高质量](https://assets-docs.dify.ai/2024/12/dfb43c1cbbf02cdd36f7d20973a5529b.png)

**异常处理**：提供多样化的节点错误处理策略，能够在当前节点发生错误时抛出故障信息而不中断主流程；或通过备用路径继续完成任务。详细说明请参考[异常处理](https://docs.dify.ai/guides/workflow/error-handling)。

**结构化输出**：确保 LLM 返回的数据格式可用、稳定、可预测，减少错误处理和格式转换的工作。

  LLM 节点中的 **JSON Schema 编辑器** 让你能够定义 LLM 返回的数据结构，确保输出可解析、可复用、可控。你可以使用**可视化编辑模式**直观编辑，或通过**代码编辑模式**精细调整，适配不同复杂度的需求。

> **信息提示：**

    作为节点级能力，JSON Schema 适用于所有模型的结构化输出定义和约束。

    - **原生支持结构化输出的模型**：可直接使用 JSON Schema 定义结构化变量。
    - **不支持结构化输出的模型**：系统会将 JSON Schema 以提示词方式输入。你可以尝试引导模型按结构生成内容，但这并不保证一定可以正确解析输出。

  **JSON Schema 编辑器入口**

  点击 **LLM 节点 \> 输出变量**，打开 **结构化开关 \> 配置**，即可进入 **JSON Schema 编辑器** 界面。JSON Schema 编辑器分为可视化编辑窗口与代码编辑窗口，两者可无缝切换。

  ![JSON Schema Editor](https://assets-docs.dify.ai/2025/04/646805384efa3cd85869d23a4d9735ad.png)

      **适用场景**

      - **你只需要定义几个简单的字段**，例如 `name`、`email`、`age` 等，并不涉及嵌套结构。
      - **你不熟悉 JSON Schema 语法**，希望不写代码，而是用直观的界面拖拽、添加字段。
      - **你希望快速迭代字段结构**，而不是每次修改都需要更新 JSON 代码。

      ![Visual Editor](https://assets-docs.dify.ai/2025/04/a9d6a34a7903f81e4d57c7f1d8d0712b.png)

      **添加字段**

      在 **结构化输出** 框中点击 **添加子字段** 按钮，并配置字段参数：

      - _（必填）_ **字段名**
      - _（必填）_ **字段类型**：支持 string、number、object、array 等字段类型等。

        > 对象（object）或数组（array）字段可添加子字段。
      - **描述**：帮助 LLM 理解字段含义，提高输出准确性。
      - **必填**：开启后，LLM 将强制返回该字段值。
      - **枚举值**：用于限制字段值的可选范围，使模型仅能从预设的枚举值中返回值。例如，若只允许 `red`、`green`、`blue`：

      ```json

        "type": "string",
        "enum": ["red", "green", "blue"]

      ```

      > 该规则要求输入值只能是 `red`、`green` 或 `blue`。

      **删改字段**

      - 编辑字段：鼠标悬停至字段卡片，点击 **编辑** 图标，修改字段类型、描述、默认值等参数。
      - 删除字段：鼠标悬停至字段卡片，点击 **删除** 图标，字段将从列表中删除。

        > 删除对象（object）或数组（array）字段时，其所有子字段也会被删除。

      **导入现有 JSON 示例**

      1. 点击 **从 JSON 导入** 按钮，在弹出的对话框中粘贴或上传 JSON 示例，例如：

      ```json

       "comment": "This is great!",
       "rating": 5

      ```

      2. 点击 **提交** 按钮，系统会自动解析 JSON 示例，并转换为 JSON Schema 如下：

      ![JSON Schema Editor](https://assets-docs.dify.ai/2025/04/646805384efa3cd85869d23a4d9735ad.png)

      **使用 AI 生成 JSON Schema**

      1. 点击 **AI 生成** 图标，选择模型（如 GPT-4o）。在输入框中描述你的 JSON Schema，例如：

      > “我需要一个包含用户名（string）、年龄（number）和兴趣爱好（array）的 JSON Schema。”

      2. 点击 **生成** ，系统将自动生成 JSON Schema 如下：

      ```json
      {
        "type": "object",
        "properties": {
          "username": {
            "type": "string"
          },
          "age": 
            "type": "number"
          ,
          "interests": {
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "username",
          "age",
          "interests"
        ]
      }
      ```

      **适用场景**

      - **你的数据结构复杂，需要支持嵌套对象或数组**，例如 `订单详情`、`产品列表` 等。
      - **你已经有一个 JSON Schema（或者 API 响应示例）**，希望直接粘贴并手动调整。
      - **你希望使用高级 Schema 特性**，如 `pattern`（正则表达式匹配）或 `oneOf`（多种类型支持）。
      - 你使用 LLM 生成了初步 Schema，但**希望修改某些字段的类型或结构**，使其更符合业务需求。

      ![JSON Schema](https://assets-docs.dify.ai/2025/04/669af808dd9d0d8521a36e14db731cec.png)

      **添加字段**

      1. 进入 JSON Schema 代码编辑器。
      2. 点击 **从 JSON 导入**， 输入字段。例如：

      ```json

        "name": "username",
        "type": "string",
        "description": "user's name",
        "required": true

      ```

      3. 点击 **保存**，系统会自动校验 JSON Schema 并保存。

      **删改字段**：在 JSON 代码框直接删改字段类型、描述、默认值等参数，并点击 **保存**。

      **导入现有 JSON 示例**

      1. 点击 **从 JSON 导入** 按钮，在弹出的对话框中粘贴或上传 JSON 示例，例如：

      ```json

       "comment": "This is great!",
       "rating": 5

      ```

      2. 点击 **提交** 按钮，系统会自动解析 JSON 示例，并转换为 JSON Schema 如下：

      ```json
      {
        "type": "object",
        "properties": {
          "comment": {
            "type": "string"
          },
          "rating": 
            "type": "number"

        },
        "required": [
          "comment",
          "rating"
        ],
        "additionalProperties": false
      }
      ```

      **使用 AI 生成 JSON Schema**

      1. 点击 **AI 生成** 图标，选择模型（如 GPT-4o）。在输入框中描述你的 JSON Schema，例如：

      > “我需要一个包含用户名（string）、年龄（number）和兴趣爱好（array）的 JSON Schema。”

      2. 点击 **生成** ，系统将自动生成 JSON Schema 如下：

      ```json
      {
        "type": "object",
        "properties": {
          "username": {
            "type": "string"
          },
          "age": 
            "type": "number"
          ,
          "interests": {
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "username",
          "age",
          "interests"
        ]
      }
      ```

---

### 使用案例

- **读取知识库内容**

想要让工作流应用具备读取 [“知识库”](../../knowledge-base/) 内容的能力，例如搭建智能客服应用，请参考以下步骤：

1. 在 LLM 节点上游添加知识库检索节点；
2. 将知识检索节点的 **输出变量** `result` 填写至 LLM 节点中的 **上下文变量** 内；
3. 将 **上下文变量** 插入至应用提示词内，赋予 LLM 读取知识库内的文本能力。

![](https://assets-docs.dify.ai/2025/04/8ec79d64b90bd4c690ab5a9af8de1cc4.png)

[知识检索节点](knowledge-retrieval)输出的变量 `result` 还包含了分段引用信息，你可以通过 [**引用与归属**](../../knowledge-base/retrieval-test-and-citation#id-2-yin-yong-yu-gui-shu) 功能查看信息来源。

> **信息提示：**

  上游节点的普通变量同样可以填写至上下文变量内，例如开始节点的字符串类型变量，但 **引用与归属** 功能将会失效。

- **读取文档文件**

想要让工作流应用具备读取读取文档内容的能力，例如搭建 ChatPDF 应用，可以参考以下步骤：

- 在 “开始” 节点内添加文件变量；
- 在 LLM 节点上游添加文档提取器节点，将文件变量作为输入变量；
- 将文档提取器节点的 **输出变量** `text` 填写至 LLM 节点中的提示词内。

如需了解更多，请参考[文件上传](../file-upload)。

![](https://assets-docs.dify.ai/2025/04/c74cf0c58aaf1f35e515044deec2a88c.png)

- **异常处理**

LLM 节点处理信息时有可能会遇到输入文本超过 Token 限制，未填写关键参数等错误。应用开发者可以参考以下步骤配置异常分支，在节点出现异常时启用应对方案，而避免中断整个流程。

1. 在 LLM 节点启用 “异常处理”
2. 选择异常处理方案并进行配置

如需了解更多应对异常的处理办法，请参考[异常处理](https://docs.dify.ai/guides/workflow/error-handling)。

![Error handling](https://assets-docs.dify.ai/2024/12/48c666959a491aa87c2232c444794dc5.png)

- **结构化输出**

**案例：客户信息采集表单**

你可以通过以下视频，了解如何使用结构化输出功能采集客户信息：

<iframe width="560" height="315" src="https://www.youtube.com/embed/u8NQFxrsaW0" title="Customer Information Intake Form Demo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

## 提示优化

提示优化功能可根据不尽人意的输出对提示进行迭代改进。它允许用户直接参考上一次运行的结果来完善其指令，从而在提示编写、模型输出和反馈之间形成闭环。

### 目的

此前，大语言模型（LLM）节点是无状态的——如果提示效果不佳，用户必须自行猜测如何改进。借助此功能，您现在可以：

- 使用上下文变量引用上一次输出
- 定义一个理想输出用于比较
- 使用提示生成器用户界面重新生成优化后的提示

### 原理

在大语言模型（LLM）节点中执行提示后：

- 系统会捕获原始提示及其最后输出。
- 这些将作为上下文变量公开：
  - `current_prompt`：此节点中的当前提示。
  - `last_run`：此节点的上一次输入和输出。

这些变量可以使用 `/` 或 `{}` 直接插入到提示编辑器中，为模型提供迭代改进所需的上下文。

---

### 步骤

打开提示生成器

点击魔杖图标启动提示生成器，它会预先填充一条修复指令，例如：

![Llm PN](./images/llm.PNG)

1. 自定义指令

在左侧的提示编辑器中编辑指令，以反映应该做出哪些改变或改进。这可能涉及语气、结构、格式、真实性等方面。

2. 使用理想输出框

点击展开理想输出区域，并编写几个示例或期望的响应格式。这将在提示重新生成期间作为模型的参考。

注意：你不能在理想输出框中插入变量。它仅用于静态示例。

例如，如果你的任务是重写提示，以便模型以恰好三个项目符号点输出新闻文章的简洁摘要，一个理想的输出可能是：

![Llm2 PN](./images/llm2.PNG)

3. 生成优化提示

点击“生成”，让系统根据你的指令和参考输出重写提示。你可以立即测试新版本。

---

### 版本管理

每次提示词重新生成都会保存为一个新版本：

- 输出区域包含一个下拉菜单，标签为“版本1”、“版本2”等。
- 你可以在不同版本之间切换以比较结果。
- 当只有一个版本时，下拉菜单将隐藏。

---

### 备注

- last_run包含此大语言模型节点特定的上一次输入/输出。
- 这与代码节点的当前代码或错误消息不同。
- 此功能在不破坏工作流程连续性的情况下改进提示迭代。

提示优化可帮助开发人员和低代码用户根据上下文微调提示——通过有指导的迭代减少猜测并提高结果。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/llm.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 循环
> 来源：`zh-hans/guides/workflow/node/loop.mdx`

## 简介

循环（Loop）节点用于执行依赖前一轮结果的重复任务，直到满足退出条件或达到最大循环次数。

## 循环节点与迭代节点有什么区别？

循环节点和迭代节点在任务处理上的定位不同：

<table>
  <thead>
    <tr>
      <th>类型</th>
      <th>特点</th>
      <th>适用场景</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>循环</strong>（Loop）</td>
      <td>轮次之间存在依赖关系的优化型任务。即任务的每一轮执行都依赖上一轮的结果。</td>
      <td>需要前一轮的计算结果。</td>
    </tr>
    <tr>
      <td><strong>迭代</strong>（Iteration）</td>
      <td>轮次之间无依赖关系的批处理任务。即每一轮任务可以独立运行，无需依赖前一轮。</td>
      <td>每轮独立执行。</td>
    </tr>
  </tbody>
</table>

## 如何配置循环节点？

循环节点包含以下三个关键配置项和一个子节点：

<table>
  <thead>
    <tr>
      <th>配置项/子节点</th>
      <th>作用</th>
      <th>示例</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>循环终止条件</strong>（Loop Termination Condition）</td>
      <td>设置循环何时停止。</td>
      <td>例：当变量 <code>x < 50</code> 时，停止循环。</td>
    </tr>
    <tr>
      <td><strong>最大循环次数</strong>（Maximum Loop Count）</td>
      <td>限制最多执行的轮次，避免无限循环。</td>
      <td>例：最多执行 10 轮，不管是否满足退出条件。</td>
    </tr>
    <tr>
      <td><strong>循环变量</strong>（Loop Variables）</td>
      <td>用于在循环的不同轮次间传递数据，并在循环结束后继续供下游节点使用。</td>
      <td>例：变量 <code>x < 50</code> 在每轮循环中递增 1，循环体内部可以基于 <code>x < 50</code> 进行计算，循环结束后，<code>x < 50</code> 的最终值可用于后续流程。</td>
    </tr>
    <tr>
      <td><strong>退出循环节点</strong>（Exit Loop）</td>
      <td>当循环体内运行到此节点后，循环终止。</td>
      <td>例：最多执行 10 轮，不管是否满足退出条件。</td>
    </tr>
  </tbody>
</table>

> **信息提示：**

**退出循环节点** 与 **循环终止条件** 均可作为循环的终止触发点，满足任意一个条件时，循环都会提前退出。

如果未配置任何退出条件，则循环将持续运行（相当于 while (true)），直到达到 **最大循环次数**。

## 示例一：如何使用循环节点？

**需求：生成 1-100 的随机数，直到随机数小于 50 时停止。**

**实现步骤**：

1. 在 **循环** 节点中，配置 **循环终止条件**，为 **模板转换** 节点输出 `done`。

2. 使用 **代码执行** 节点生成 `1-100` 的随机数。

3. 使用 **条件分支** 节点判断随机数是否大于 `50`：

  - 如果大于或等于 50，输出 `当前数字` 并继续循环，生成新的随机数。

  - 如果小于 50，输出 `最终输出数字`，并经由 **模板转换** 节点输出 `done`，结束循环。

4. 循环将在随机数小于 `50` 时自动停止。

![Basic loop workflow](https://assets-docs.dify.ai/2025/04/282013c48b46d3cc4ebf99323da10a31.png)

![Steps](https://assets-docs.dify.ai/2025/04/9d9fb4db7093521000ac735a26f86962.png)

## 示例二：如何使用循环变量与退出循环节点？

**需求：通过一个循环工作流生成并逐步重写一首诗，每次输出都基于上一轮的结果。循环执行 4 次后自动停止。**

**实现步骤：**

1. 在 **循环** 节点中，配置 **循环变量**，用于在每次迭代中传递数据：

  - num（循环次数）：初始值为 0，每次循环 +1。

  - verse（诗歌内容）：初始值 `I haven’t started creating yet`，后续每次循环更新。

2. 使用 **条件分支** 节点判断循环次数是否大于 `3`：

  - 如果大于 3，则进入 **退出循环** 节点，结束循环。

  - 如果小于或等于 3，则进入 **LLM** 节点继续循环。

3. 使用 **LLM** 节点，要求模型根据用户的输入和过往的创作输出诗歌内容。

> **信息提示：**

参考 Prompt：

- 使用用户的输出 `sys.query` 作为灵感，创作一首欧洲长诗。

- 参考你上一次的创作 `verse`，尝试在新的诗句中展现进步和创新。

- 确保你的诗句符合欧洲文学的风格和传统，注重诗歌的韵律和意境。

在第一次循环时，verse 为 `I haven’t started creating yet`，之后每次循环根据上一轮的输出更新诗歌。每次模型生成的新诗歌都会覆盖 verse 变量，供下一次循环使用。

4. 使用 **变量赋值** 节点，在每次循环后更新循环中的变量：

  - 更新 num 变量，每次循环 +1。

  - 更新 verse 变量为模型新生成的诗歌内容，直接覆盖前一轮循环的诗歌内容。

5. 输入你的诗歌灵感，模型将输出四个版本的诗歌，每一篇诗歌都以前一篇为基础而产生。

<video controls src="https://assets-docs.dify.ai/2025/04/7ecfc04458aa38e721baaa5f6355486c.mp4" width="100%"></video>

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/loop.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 参数提取
> 来源：`zh-hans/guides/workflow/node/parameter-extractor.mdx`

### 定义

利用 LLM 从自然语言推理并提取结构化参数，用于后置的工具调用或 HTTP 请求。

Dify 工作流内提供了丰富的[工具](https://docs.dify.ai/v/zh-hans/guides/tools)选择，其中大多数工具的输入为结构化参数，参数提取器可以将用户的自然语言转换为工具可识别的参数，方便工具调用。

工作流内的部分节点有特定的数据格式传入要求，如[迭代](./zh-hans/guides/workflow/node/iteration)节点的输入要求为数组格式，参数提取器可以方便的实现结构化参数的转换。

***

### 场景

1. **从自然语言中提供工具所需的关键参数提取**，如构建一个简单的对话式 Arxiv 论文检索应用。

在该示例中：Arxiv 论文检索工具的输入参数要求为 **论文作者** 或 **论文编号**，参数提取器从问题"这篇论文中讲了什么内容：2405.10739"中提取出论文编号 **2405.10739**，并作为工具参数进行精确查询。

![Arxiv 论文检索工具](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/9119e3f40d71ac845ad1e14f7401ee1f.png)

2. **将文本转换为结构化数据**，如长故事迭代生成应用中，作为[迭代节点](./zh-hans/guides/workflow/node/iteration)的前置步骤，将文本格式的章节内容转换为数组格式，方便迭代节点进行多轮生成处理。

![长故事迭代生成应用流程图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/342d37bfa31c1d9ab26cd8212be7ee7d.png)

3. **提取结构化数据并使用** [**HTTP 请求**](./zh-hans/guides/workflow/node/http-request) ，可请求任意可访问的 URL ，适用于获取外部检索结果、webhook、生成图片等情景。

***

### 如何配置

![参数提取配置界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/2171232dfe8a907ebad05cef8b789c9a.png)

**配置步骤**

1. 选择输入变量，一般为用于提取参数的变量输入。输入变量支持 file
2. 选择模型，参数提取器的提取依靠的是 LLM 的推理和结构化生成能力
3. 定义提取参数，可以手动添加需要提取的参数，也可以**从已有工具中快捷导入**
4. 编写指令，在提取复杂的参数时，编写示例可以帮助 LLM 提升生成的效果和稳定性

**高级设置**

**推理模式**

部分模型同时支持两种推理模式，通过函数/工具调用或是纯提示词的方式实现参数提取，在指令遵循能力上有所差别。例如某些模型在函数调用效果欠佳的情况下可以切换成提示词推理。

* Function Call/Tool Call
* Prompt

**记忆**

开启记忆后问题分类器的每次输入将包含对话中的聊天历史，以帮助 LLM 理解上文，提高对话交互中的问题理解能力。

**图片**

开启图片

**输出变量**

* 提取定义的变量
* 节点内置变量

`__is_success Number 提取是否成功` 成功时值为 1，失败时值为 0。

`__reason String` 提取错误原因

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/parameter-extractor.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 问题分类
> 来源：`zh-hans/guides/workflow/node/question-classifier.mdx`

### **定义**

通过定义分类描述，问题分类器能够根据用户输入，使用 LLM 推理与之相匹配的分类并输出分类结果，向下游节点提供更加精确的信息。

***

### **场景**

常见的使用情景包括**客服对话意图分类、产品评价分类、邮件批量分类**等。

在一个典型的产品客服问答场景中，问题分类器可以作为知识库检索的前置步骤，对用户输入问题意图进行分类处理，分类后导向下游不同的知识库查询相关的内容，以精确回复用户的问题。

下图为产品客服场景的示例工作流模板：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/465d730a4b7eaa2005e7268a086bdd1a.png)

在该场景中我们设置了 3 个分类标签/描述：

* 分类 1 ：**与售后相关的问题**
* 分类 2：**与产品操作使用相关的问题**
* 分类 3 ：**其他问题**

当用户输入不同的问题时，问题分类器会根据已设置的分类标签 / 描述自动完成分类：

* "**iPhone 14 如何设置通讯录联系人？**" —> "**与产品操作使用相关的问题**"
* "**保修期限是多久？**" —> "**与售后相关的问题**"
* "**今天天气怎么样？**" —> "**其他问题**"

***

### 如何配置

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/923c4cbc6956fe8925895b812802a24b.png)

**配置步骤：**

1. **选择输入变量**，指用于分类的输入内容，支持输入[文件变量](./zh-hans/guides/workflow/variables)。客服问答场景下一般为用户输入的问题 `sys.query`;
2. **选择推理模型**，问题分类器基于大语言模型的自然语言分类和推理能力，选择合适的模型将有助于提升分类效果；
3. **编写分类标签/描述**，你可以手动添加多个分类，通过编写分类的关键词或者描述语句，让大语言模型更好的理解分类依据。
4. **选择分类对应的下游节点，** 问题分类节点完成分类之后，可以根据分类与下游节点的关系选择后续的流程路径。

#### **高级设置：**

**指令：** 你可以在 **高级设置-指令** 里补充附加指令，比如更丰富的分类依据，以增强问题分类器的分类能力。

**记忆：** 开启记忆后问题分类器的每次输入将包含对话中的聊天历史，以帮助 LLM 理解上文，提高对话交互中的问题理解能力。

**图片分析：** 仅适用于具备图片识别能力的 LLM，允许输入图片变量。

**记忆窗口：** 记忆窗口关闭时，系统会根据模型上下文窗口动态过滤聊天历史的传递数量；打开时用户可以精确控制聊天历史的传递数量（对数）。

**输出变量：**

`class_name` 存储了分类模型的预测结果。当分类完成后，这个变量会包含具体的类别标签，你可以在后续的处理节点中引用这个分类结果来执行相应的逻辑。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/question-classifier.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 开始
> 来源：`zh-hans/guides/workflow/node/start.mdx`

## 定义

**"开始"** 节点是每个工作流应用（Chatflow / Workflow）必备的预设节点，为后续工作流节点以及应用的正常流转提供必要的初始信息，例如应用使用者所输入的内容、以及[上传的文件](./zh-hans/guides/workflow/file-upload)等。

### 配置节点

在开始节点的设置页，你可以看到两部分设置，分别是 **"输入字段"** 和预设的[**系统变量**](./zh-hans/guides/workflow/variables#系统变量)。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/c4a9bb46f636807f0b59710724fddc40.png)

### 输入字段

输入字段功能由应用开发者设置，通常用于让应用使用者主动补全更多信息。例如在周报应用中要求使用者按照格式预先提供更多背景信息，如姓名、工作日期区间、工作详情等。这些前置信息将有助于 LLM 生成质量更高的答复。

支持以下八种类型输入变量，所有变量均可设置为必填项：

* **文本**：短文本，由应用使用者自行填写内容，最大长度 256 字符。
* **段落**：长文本，允许应用使用者输入较长字符。
* **下拉选项**：由应用开发者固定选项，应用使用者仅能选择预设选项，无法自行填写内容。
* **数字**：仅允许用户输入数字。
* **复选框**：布尔值输入，以复选框形式呈现，允许用户选择真/假值。
* **对象**：结构化 JSON 输入，允许用户提供复杂的数据对象。仅在工作流/聊天流应用中可用。
* **单文件**：允许应用使用者单独上传文件，支持文档类型文件、图片、音频、视频和其它文件类型。支持通过本地上传文件或粘贴文件 URL。详细用法请参考[文件上传](./zh-hans/guides/workflow/file-upload)。
* **文件列表**：允许应用使用者批量上传文件，支持文档类型文件、图片、音频、视频和其它文件类型。支持通过本地上传文件或粘贴文件 URL。详细用法请参考[文件上传](./zh-hans/guides/workflow/file-upload)。

> **信息提示：**

Dify 内置的文档提取器节点只能够处理部分格式的文档文件。如需处理图片、音频或视频类型文件，请参考[外部数据工具](./zh-hans/guides/tools/extensions/code-based/external-data-tool)搭建对应文件的处理节点。

配置完成后，用户在使用应用前将按照输入项指引，向 LLM 提供必要信息。更多的信息将有助于 LLM 提升问答效率。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/400679ae5cbbcd5dc0f84ec5861efc85.png)

### 系统变量

系统变量指的是在 Chatflow / Workflow 应用内预设的系统级参数，可以被应用内的其它节点全局读取。通常用于进阶开发场景，例如搭建多轮次对话应用、收集应用日志与监控、记录不同应用和用户的使用行为等。

**Workflow**

Workflow 类型应用提供以下系统变量：

| 变量名称 | 数据类型 | 说明 | 备注 |
|---------|--------|------|------|
| `sys.files` [LEGACY] | Array[File] | 文件参数，存储用户初始使用应用时上传的图片 | 图片上传功能需在应用编排页右上角的 "功能" 处开启 |
| `sys.user_id` | String | 用户 ID，每个用户在使用工作流应用时，系统会自动向用户分配唯一标识符，用以区分不同的对话用户 | |
| `sys.app_id` | String | 应用 ID，系统会向每个 Workflow 应用分配一个唯一的标识符，用以区分不同的应用，并通过此参数记录当前应用的基本信息 | 面向具备开发能力的用户，通过此参数区分并定位不同的 Workflow 应用 |
| `sys.workflow_id` | String | Workflow ID，用于记录当前 Workflow 应用内所包含的所有节点信息 | 面向具备开发能力的用户，可以通过此参数追踪并记录 Workflow 内的包含节点信息 |
| `sys.workflow_run_id` | String | Workflow 应用运行 ID，用于记录 Workflow 应用中的运行情况 | 面向具备开发能力的用户，可以通过此参数追踪应用的历次运行情况 |

![](https://assets-docs.dify.ai/2025/04/cb39be409f0037549d45f4b7d05aa9ce.png)

**Chatflow**

Chatflow 类型应用提供以下系统变量：

| 变量名称 | 数据类型 | 说明 | 备注 |
|---------|--------|------|------|
| `sys.query` | String | 用户在对话框中初始输入的内容 | |
| `sys.files` | Array[File] | 用户在对话框内上传的文件 | 文件上传功能需在应用编排页右上角的 "功能" 处开启 |
| `sys.dialogue_count` | Number | 用户在与 Chatflow 类型应用交互时的对话轮数。每轮对话后自动计数增加 1，可以和 if-else 节点搭配出丰富的分支逻辑。例如到第 X 轮对话时，回顾历史对话并给出分析 | |
| `sys.conversation_id` | String | 对话框交互会话的唯一标识符，将所有相关的消息分组到同一个对话中，确保 LLM 针对同一个主题和上下文持续对话 | |
| `sys.user_id` | String | 分配给每个应用用户的唯一标识符，用以区分不同的对话用户 | |
| `sys.app_id` | String | 应用 ID，系统会向每个 Workflow 应用分配一个唯一的标识符，用以区分不同的应用，并通过此参数记录当前应用的基本信息 | 面向具备开发能力的用户，通过此参数区分并定位不同的 Workflow 应用 |
| `sys.workflow_id` | String | Workflow ID，用于记录当前 Workflow 应用内所包含的所有节点信息 | 面向具备开发能力的用户，可以通过此参数追踪并记录 Workflow 内的包含节点信息 |
| `sys.workflow_run_id` | String | Workflow 应用运行 ID，用于记录 Workflow 应用中的运行情况 | 面向具备开发能力的用户，可以通过此参数追踪应用的历次运行情况 |

![](https://assets-docs.dify.ai/2025/04/233efef6802ae700489f3ab3478bca6b.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/start.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 模板转换
> 来源：`zh-hans/guides/workflow/node/template.mdx`

### 定义

允许借助 Jinja2 的 Python 模板语言灵活地进行数据转换、文本处理等。

### 什么是 Jinja？

> [Jinja](https://jinja.palletsprojects.com/en/3.1.x/) 是一个快速、表达力强、可扩展的模板引擎。

### 场景

模板节点允许你借助 Jinja2 这一强大的 Python 模板语言，在工作流内实现轻量、灵活的数据转换，适用于文本处理、JSON 转换等情景。例如灵活地格式化并合并来自前面步骤的变量，创建出单一的文本输出。这非常适合于将多个数据源的信息汇总成一个特定格式，满足后续步骤的需求。

**示例1：** 将多个输入（文章标题、介绍、内容）拼接为完整文本

  ![拼接文本示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/549bd41e839ba2689d7ff286f77f7489.png)

**示例2：** 将知识检索节点获取的信息及其相关的元数据，整理成一个结构化的 Markdown 格式

```Plain
% for item in chunks %
### Chunk {{ loop.index }}. 
### Similarity: {{ item.metadata.score | default('N/A') }}

#### {{ item.title }}

##### Content
{{ item.content | replace('\n', '\n\n') }}

---
% endfor %
```

  ![知识检索节点输出转换为 Markdown示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/51f80c553d979e947a9749a9f820b6ab.png)

你可以参考 Jinja 的[官方文档](https://jinja.palletsprojects.com/en/3.1.x/templates/)，创建更为复杂的模板来执行各种任务。

**示例 3：** 支持渲染 HTML 的表单
```html
<form data-format="json"> // Default to text
  <label for="username">Username:</label>
  <input type="text" name="username" />
  <label for="password">Password:</label>
  <input type="password" name="password" />
  <label for="content">Content:</label>
  <textarea name="content"></textarea>
  <label for="date">Date:</label>
  <input type="date" name="date" />
  <label for="time">Time:</label>
  <input type="time" name="time" />
  <label for="datetime">Datetime:</label>
  <input type="datetime" name="datetime" />
  <label for="select">Select:</label>
  <input type="select" name="select" data-options='["hello","world"]'/>
  <input type="checkbox" name="check" data-tip="By checking this means you agreed"/>
  <button data-size="small" data-variant="primary">Login</button>
</form>
```

![metadata_field](https://assets-docs.dify.ai/2025/04/9d24e9cfa3cdde00e4eee15bd4bbea76.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/template.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 工具
> 来源：`zh-hans/guides/workflow/node/tools.mdx`

"工具"节点可以为工作流提供强大的第三方能力支持，分为以下三种类型：

* **内置工具**，Dify 第一方提供的工具，使用该工具前可能需要先给工具进行 **授权**。
* **自定义工具**，通过 [OpenAPI/Swagger 标准格式](https://swagger.io/specification/)导入或配置的工具。如果内置工具无法满足使用需求，你可以在 **Dify 菜单导航 --工具** 内创建自定义工具。
* **工作流**，你可以编排一个更复杂的工作流，并将其发布为工具。详细说明请参考[工具配置说明](./zh-hans/guides/tools/extensions/api-based/api-based-extension)。

### 添加并使用工具节点

添加节点时，选择右侧的 "工具" tab 页。配置工具节点一般分为两个步骤：

1. 对工具授权/创建自定义工具/将工作流发布为工具
2. 配置工具输入和参数

  ![工具选择](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/736875fbb1b73f0b027d9f2b9063db32.png)

工具节点可以连接其它节点，通过[变量](./zh-hans/guides/workflow/variables)处理和传递数据。

  ![配置 Google 搜索工具检索外部知识](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/84a6ab75de95d2362d88cda8995c2d45.png)

### 高级功能

**错误重试**

针对节点发生的部分异常情况，通常情况下再次重试运行节点即可解决。开启错误重试功能后，节点将在发生错误的时候按照预设策略进行自动重试。你可以调整最大重试次数和每次重试间隔以设置重试策略。

- 最大重试次数为 10 次
- 最大重试间隔时间为 5000 ms

  ![错误重试配置](https://assets-docs.dify.ai/2024/12/34867b2d910d74d2671cd40287200480.png)

**异常处理**

工具节点处理信息时有可能会遇到异常情况，导致流程中断。应用开发者可以参考以下步骤配置异常分支，在节点出现异常时启用应对方案，而避免中断整个流程。

1. 在工具节点启用 "异常处理"
2. 选择异常处理方案并进行配置

  ![异常处理配置](https://assets-docs.dify.ai/2024/12/39dc3b5881d9a5fe35b877971f70d3a6.png)

需了解更多应对异常的处理办法，请参考[异常处理](./zh-hans/guides/workflow/error-handling/readme)。

### 将工作流应用发布为工具

工作流应用可以被发布为工具，并被其它工作流内的节点所应用。关于如何创建自定义工具和配置工具，请参考[工具配置说明](./zh-hans/guides/tools/extensions/api-based/api-based-extension)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/tools.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 变量聚合
> 来源：`zh-hans/guides/workflow/node/variable-aggregator.mdx`

### 定义

将多路分支的变量聚合为一个变量，以实现下游节点统一配置。

变量聚合节点（原变量赋值节点）是工作流程中的一个关键节点，它负责整合不同分支的输出结果，确保无论哪个分支被执行，其结果都能通过一个统一的变量来引用和访问。这在多分支的情况下非常有用，可将不同分支下相同作用的变量映射为一个输出变量，避免下游节点重复定义。

***

### 场景

通过变量聚合，可以将诸如问题分类或条件分支等多路输出聚合为单路，供流程下游的节点使用和操作，简化了数据流的管理。

**问题分类后的多路聚合**

未添加变量聚合，分类1 和 分类 2 分支经不同的知识库检索后需要重复定义下游的 LLM 和直接回复节点。

  ![问题分类无变量聚合的流程图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/7a7c91663c3799ce9d056b013d5df29c.png)

添加变量聚合，可以将两个知识检索节点的输出聚合为一个变量。

  ![问题分类后添加变量聚合的流程图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/78e088e16a409cc18552b21bec98bc01.png)

**IF/ELSE 条件分支后的多路聚合**

*图：IF/ELSE 条件分支后的多路聚合*

  ![IF/ELSE 条件分支后添加变量聚合的流程图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/da33064c784fc44c19b532a6d873cfaf.png)

### 格式要求

变量聚合器支持聚合多种数据类型，包括字符串（`String`）、数字（`Number`）、文件（`File`）对象（`Object`）以及数组（`Array`）

**变量聚合器只能聚合同一种数据类型的变量**。若第一个添加至变量聚合节点内的变量数据格式为 `String`，后续连线时会自动过滤可添加变量为 `String` 类型。

**聚合分组**

开启聚合分组后，变量聚合器可以聚合多组变量，各组内聚合时要求同一种数据类型。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/variable-aggregator.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 变量赋值
> 来源：`zh-hans/guides/workflow/node/variable-assigner.mdx`

### 定义

变量赋值节点用于向可写入变量进行变量赋值，已支持以下可写入变量：

* [会话变量](../variables#会话变量)
* [循环变量](./zh-hans/guides/workflow/node/loop)

用法：通过变量赋值节点，你可以将工作流内的变量赋值到会话变量中用于临时存储，并可以在后续对话中持续引用。

  ![会话变量示例图](https://assets-docs.dify.ai/2024/11/83d0b9ef4c1fad947b124398d472d656.png)

***

### 使用场景示例

通过变量赋值节点，你可以将会话过程中的**上下文、上传至对话框的文件（即将上线）、用户所输入的偏好信息**等写入至会话变量，并在后续对话中引用已存储的信息导向不同的处理流程或者进行回复。

**场景 1**

**自动判断提取并存储对话中的信息**，在会话内通过会话变量数组记录用户输入的重要信息，并在后续对话中让 LLM 基于会话变量中存储的历史信息进行个性化回复。

示例：开始对话后，LLM 会自动判断用户输入是否包含需要记住的事实、偏好或历史记录。如果有，LLM 会先提取并存储这些信息，然后再用这些信息作为上下文来回答。如果没有新的信息需要保存，LLM 会直接使用自身的相关记忆知识来回答问题。

  ![自动判断提取并存储对话中的信息流程图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/f687e6837515fda2be3e18f656bd2a67.jpeg)

**配置流程：**

1. **设置会话变量**：首先设置一个会话变量数组 `memories`，类型为 array\[object]，用于存储用户的事实、偏好和历史记录。
2. **判断和提取记忆**：
   * 添加一个条件判断节点，使用 LLM 来判断用户输入是否包含需要记住的新信息。
   * 如果有新信息，走上分支，使用 LLM 节点提取这些信息。
   * 如果没有新信息，走下分支，直接使用现有记忆回答。
3. **变量赋值/写入**：
   * 在上分支中，使用变量赋值节点，将提取出的新信息追加（append）到 `memories` 数组中。
   * 使用转义功能将 LLM 输出的文本字符串转换为适合存储在 array\[object] 中的格式。
4. **变量读取和使用**：
   * 在后续的 LLM 节点中，将 `memories` 数组中的内容转换为字符串，并插入到 LLM 的提示词 Prompts 中作为上下文。
   * LLM 使用这些历史信息来生成个性化回复。

图中的 code 节点代码如下：

1. 将字符串转义为 object

```python

def main(arg1: str) -> object:
    try:
        # Parse the input JSON string
        input_data = json.loads(arg1)

        # Extract the memory object
        memory = input_data.get("memory", {})

        # Construct the return object
        result = 
            "facts": memory.get("facts", []),
            "preferences": memory.get("preferences", []),
            "memories": memory.get("memories", [])

        return 
            "mem": result

    except json.JSONDecodeError:
        return 
            "result": "Error: Invalid JSON string"

    except Exception as e:
        return {
            "result": f"Error: {str(e)}"
        }
```

2. 将 object 转义为字符串

```python

def main(arg1: list) -> str:
    try:
        # Assume arg1[0] is the dictionary we need to process
        context = arg1[0] if arg1 else {}

        # Construct the memory object
        memory = "memory": context

        # Convert the object to a JSON string
        json_str = json.dumps(memory, ensure_ascii=False, indent=2)

        # Wrap the JSON string in <answer> tags
        result = f"<answer>json_str</answer>"

        return 
            "result": result

    except Exception as e:
        return {
            "result": f"<answer>Error: {str(e)}</answer>"
        }
```

**场景 2**

**记录用户的初始偏好信息**，在会话内记住用户输入的语言偏好，在后续对话中持续使用该语言类型进行回复。

示例：用户在对话开始前，在 `language` 输入框内指定了 "中文"，该语言将会被写入会话变量，LLM 在后续进行答复时会参考会话变量中的信息，在后续对话中持续使用"中文"进行回复。

  ![记录用户的初始偏好信息流程图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/8ce622d50bd947d829fff85f36bbfa45.png)

**配置流程：**

**设置会话变量**：首先设置一个会话变量 `language`，在会话流程开始时添加一个条件判断节点，用来判断 `language` 变量的值是否为空。

**变量写入/赋值**：首轮对话开始时，若 `language` 变量值为空，则使用 LLM 节点来提取用户输入的语言，再通过变量赋值节点将该语言类型写入到会话变量 `language` 中。

**变量读取**：在后续对话轮次中 `language` 变量已存储用户语言偏好。在后续对话中，LLM 节点通过引用 language 变量，使用用户的偏好语言类型进行回复。

**场景 3**

**辅助 Checklist 检查**，在会话内通过会话变量记录用户的输入项，更新 Checklist 中的内容，并在后续对话中检查遗漏项。

示例：开始对话后，LLM 会要求用户在对话框内输入 Checklist 所涉及的事项，用户一旦提及了 Checklist 中的内容，将会更新并存储至会话变量内。LLM 会在每轮对话后提醒用户继续补充遗漏项。

  ![辅助 Checklist 检查流程图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/node/c4362b01298b12e7d6fcd9e798f3165a.png)

**配置流程：**

* **设置会话变量：** 首先设置一个会话变量 `ai_checklist`，在 LLM 内引用该变量作为上下文进行检查。
* **变量赋值/写入：** 每一轮对话时，在 LLM 节点内检查 `ai_checklist` 内的值并比对用户输入，若用户提供了新的信息，则更新 Checklist 并将输出内容通过变量赋值节点写入到 `ai_checklist` 内。
* **变量读取：** 每一轮对话读取 `ai_cheklist` 内的值并比对用户输入直至所有 checklist 完成。

***

### 使用变量赋值节点

点击节点右侧 ＋ 号，选择"变量赋值"节点，填写"赋值的变量"和"设置变量"。

  ![变量赋值节点设置界面](https://assets-docs.dify.ai/2024/11/ee15dee864107ba5a93b459ebdfc32cf.png)

**设置变量：**

赋值的变量：选择被赋值变量，即指定需要被赋值的目标会话变量。

设置变量：选择需要赋值的变量，即指定需要被转换的源变量。

以上图赋值逻辑为例：将上一个节点的文本输出项 `Language Recognition/text` 赋值到会话变量 `language` 内。

### 指定变量的写入模式

目标变量的数据类型将影响变量的写入模式。以下是不同变量间的写入模式：

1. 目标变量的数据类型为 `String`。

  * **覆盖**，将源变量直接覆盖至目标变量
  * **清空**，清空所选中变量中的内容
  * **设置**，手动指定一个值，无需设置源变量

2. 目标变量的数据类型为 `Number`。

  * **覆盖**，将源变量直接覆盖至目标变量
  * **清空**，清空所选中变量中的内容
  * **设置**，手动指定一个值，无需设置源变量
  * **数字处理**，对目标变量进行`加减乘除`操作

3. 目标变量的数据类型为 `Object`。

  * **覆盖**，将源变量的内容直接覆盖至目标变量
  * **清空**，清空所选中变量中的内容
  * **设置**，手动指定一个值，无需设置源变量

4. 目标变量的数据类型为 `Array`。

  * **覆盖**，将源变量的内容直接覆盖至目标变量
  * **清空**，清空所选中变量中的内容
  * **追加**，在目标的数组变量中添加一个新的元素
  * **扩展**，在目标的数组变量中添加新的数组，即一次性添加多个元素
  * **移除**，从数组中移除元素，可选择从头部移除（First）或尾部移除（Last），默认为“头部移除”

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/node/variable-assigner.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 编排节点
> 来源：`zh-hans/guides/workflow/orchestrate-node.mdx`

Chatflow 和 Workflow 类型应用内的节点均可以通过可视化拖拉拽的形式进行编排，支持**串行**和**并行**两种编排设计模式。

  ![串行和并行节点流对比图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/3a087683b42b421d73bf4f4ed224df9c.png)

## 串行设计

该结构要求节点按照预设顺序依次执行，每个节点需等待前一个节点完成并输出结果后才能开始工作，有助于**确保任务按照逻辑顺序执行。**

例如，在一个采用串行结构设计的"小说生成" AI 应用内，用户输入小说风格、节奏和角色后，LLM 按照顺序补全小说大纲、小说剧情和结尾；每个节点都基于前一个节点的输出结果展开工作，确保小说的风格一致性。

### 设计串行结构

点击两个节点中间连线的 + 号即可在中间添加一个串行节点；按照顺序将节点依次串线连接，最后将线收拢至 **"结束"节点**（Workflow）/ **"直接回复"节点**（Chatflow）完成设计。

  ![串行结构设计示意图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/4fbde8db25205e6532550e4da688a839.png)

### 查看串行结构应用日志

串行结构应用内的日志将按照顺序展示各个节点的运行情况。点击对话框右上角的 「查看日志-追踪」，查看工作流完整运行过程各节点的输入 / 输出、Token 消耗、运行时长等。

  ![串行结构应用日志界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/46478beb414087e7ce030017d8cb1fbe.png)

## 并行设计

该设计模式允许多个节点在同一时间内共同执行，前置节点可以同时触发位于并行结构内的多个节点。并行结构内的节点不存在依赖关系，能够同时执行任务，更好地提升**节点的任务执行效率。**

例如，在某个并行设计的翻译工作流应用内，用户输入源文本触发工作流后，位于并行结构内的节点将共同收到前置节点的流转指令，同时开展多语言的翻译任务，缩短任务的处理耗时。

  ![并行设计示意图](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/2cd6bb97c75cc3bdaa4a95dd35e637b9.png)

### 新建并行结构

你可以参考以下四种方式，通过新建节点或拖拽的方式创建并行结构。

**方式 1**

将鼠标 Hover 至某个节点，显示 `+` 按钮，支持新建多个节点，创建后自动形成并行结构。

  ![新建并行结构方式1](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/7ec551351c6483ce8fcd93d4d4c6991f.png)

**方式 2**

拖拽节点末尾的 `+` 按钮，拉出连线形成并行结构。

  ![新建并行结构方式2](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/18009cb97167f3efe3e51829b6cec159.png)

**方式 3**

如果画布存在多个节点，通过可视化拖拽的方式组成并行结构。

  ![新建并行结构方式3](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/ff447ce4bc20f6b51b3497887ad10cf3.png)

**方式 4**

除了在画布中通过直接添加并行节点或可视化拖拽方式组成并行结构，你也可以在节点右侧清单的"下一步"中添加并行节点，自动生成并行结构。

  ![新建并行结构方式4](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/e799c7692999cf2b3659777e43e2c85d.png)

**Tips：**

* 画布上的"线"可以被删除；
* 并行结构的下游节点可以是任意节点；
* 在 Workflow 类型应用内需确定唯一的 "end" 节点；
* Chatflow 类型应用支持添加多个 **"直接回复"** 节点，该类型应用内的所有并行结构在末尾处均需要配置 **"直接回复"** 节点才能正常输出各个并行结构里的内容；
* 所有的并行结构都会同时运行；并行结构内的节点处理完任务后即输出结果，**输出结果时不存在顺序关系**。并行结构越简单，输出结果的速度越快。

  ![Chatflow 应用中的并行结构示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/b1744a307c6da7f43cf7f5abb0c2c161.png)

### 设计并行结构应用

下文将展示四种常见的并行节点设计思路。

1. **普通并行**

普通并行指的是 `开始 | 并行结构 | 结束` 三层关系也是并行结构的最小单元。这种结构较为直观，用户输入内容后，工作流能同时执行多条任务。

> 并行分支的上限数为 10 个。

  ![普通并行结构示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/799ea5b376f0392fbc16ade2740fffa8.png)

2. **嵌套并行**

嵌套并行指的是 `开始 | 多个并行结构 | 结束`多层关系，它适用于内部较为复杂的工作流，例如需要在某个节点内请求外部 API，将返回的结果同时交给下游节点处理。

一个工作流内最多支持 3 层嵌套关系。

  ![嵌套并行结构示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/c15a7deb3fc119dfa6e4d91f1dd9c9f2.png)

3. **条件分支 + 并行**

并行结构也可以和条件分支共同使用。

  ![条件分支和并行结构结合示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/3a5e12d185efd55f2b84a09da0a61434.png)

4. **迭代分支 + 并行**

迭代分支内同样支持编排并行结构，加速迭代内各节点的执行效率。

  ![迭代分支和并行结构结合示例](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/5f659f26df129bbeac87e788b62e4f02.png)

### 查看并行结构应用日志

包含并行结构的应用的运行日志支持以树状结构进行展示，你可以折叠并行节点组以更好地查看各个节点的运行日志。

  ![并行结构应用日志界面](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workflow/ad6acb838b58d2e0c8f99669b24aa20d.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/orchestrate-node.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 应用发布
> 来源：`zh-hans/guides/workflow/publish.mdx`

调试完成之后点击右上角的「发布」可以将该工作流保存并快速发布成为不同类型的应用。

![](https://assets-docs.dify.ai/2025/03/6cd7d2105cb5a9e4f25601efbda4ffb0.png)

对话型应用支持发布为：

* 直接运行
* 嵌入网站
* 访问 API

工作流应用支持发布为：

* 直接运行
* 批处理
* 访问 API
* 发布为工具

> **信息提示：**

如需管理多个版本的 聊天流/工作流，请参阅 [版本管理](https://docs.dify.ai/zh-hans/guides/management/version-control)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/publish.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 工作流
> 来源：`zh-hans/guides/workflow/readme.mdx`

### 基本介绍

工作流通过将复杂的任务分解成较小的步骤（节点）降低系统复杂度，减少了对提示词技术和模型推理能力的依赖，提高了 LLM 应用面向复杂任务的性能，提升了系统的可解释性、稳定性和容错性。

Dify 工作流分为两种类型：

* **Chatflow**：面向对话类情景，包括客户服务、语义搜索、以及其他需要在构建响应时进行多步逻辑的对话式应用程序。
* **Workflow**：面向自动化和批处理情景，适合高质量翻译、数据分析、内容生成、电子邮件自动化等应用程序。

![](https://assets-docs.dify.ai/2025/03/cbf76f9ce2a81573ea80e135dce42615.png)

为解决自然语言输入中用户意图识别的复杂性，Chatflow 提供了问题理解类节点。相对于 Workflow 增加了 Chatbot 特性的支持，如：对话历史（Memory）、标注回复、Answer 节点等。

为解决自动化和批处理情景中复杂业务逻辑，工作流提供了丰富的逻辑节点，如代码节点、IF/ELSE 节点、模板转换、迭代节点等，除此之外也将提供定时和事件触发的能力，方便构建自动化流程。

### 常见案例

* 客户服务

通过将 LLM 集成到你的客户服务系统中，你可以自动化回答常见问题，减轻支持团队的工作负担。 LLM 可以理解客户查询的上下文和意图，并实时生成有帮助且准确的回答。

* 内容生成

无论你需要创建博客文章、产品描述还是营销材料，LLM 都可以通过生成高质量内容来帮助你。只需提供一个大纲或主题，LLM将利用其广泛的知识库来制作引人入胜、信息丰富且结构良好的内容。

* 任务自动化

可以与各种任务管理系统集成，如 Trello、Slack、Lark、以自动化项目和任务管理。通过使用自然语言处理，LLM 可以理解和解释用户输入，创建任务，更新状态和分配优先级，无需手动干预。

* 数据分析和报告

可以用于分析大型知识库并生成报告或摘要。通过提供相关信息给 LLM，它可以识别趋势、模式和洞察力，将原始数据转化为可操作的智能。对于希望做出数据驱动决策的企业来说，这尤其有价值。

* 邮件自动化处理

LLM 可以用于起草电子邮件、社交媒体更新和其他形式的沟通。通过提供简要的大纲或关键要点，LLM 可以生成一个结构良好、连贯且与上下文相关的信息。这样可以节省大量时间，并确保你的回复清晰和专业。

### 如何开始

* 从一个空白的工作流开始构建或者使用系统模板帮助你开始；
* 熟悉基础操作，包括在画布上创建节点、连接和配置节点、调试工作流、查看运行历史等；
* 保存并发布一个工作流；
* 在已发布应用中运行或者通过 API 调用工作流；

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 快捷键
> 来源：`zh-hans/guides/workflow/shortcut-key.mdx`

Chatflow / Workflow 应用编排页支持以下快捷键，帮助你提升编排节点的效率。

| Windows          | macOS               | 说明            |
| ---------------- | ------------------- | ------------- |
| Ctrl + C         | Command + C         | 复制节点          |
| Ctrl + V         | Command + V         | 粘贴节点          |
| Ctrl + D         | Command + D         | 复制并新建节点       |
| Ctrl + O         | Command + O         | 整理节点          |
| Ctrl + Z         | Command + Z         | 撤销            |
| Ctrl + Y         | Command + Y         | 重做            |
| Ctrl + Shift + Z | Command + Shift + Z | 重做            |
| Ctrl + 1         | Command + 1         | 画布适合视图        |
| Ctrl + (-)       | Command + (-)       | 画布缩小          |
| Ctrl + (=)       | Command + (=)       | 画布放大          |
| Shift + 1        | Shift + 1           | 将画布视图重置为 100% |
| Shift + 5        | Shift + 5           | 将画布缩放至 50%    |
| H                | H                   | 画布切换至手动模式     |
| V                | V                   | 画布切换至指针模式     |
| Delete/Backspace | Delete/Backspace    | 删除选定节点        |
| Alt + R          | Option + R          | 工作流开始运行       |

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/shortcut-key.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 结构化输出
> 来源：`zh-hans/guides/workflow/structured-outputs.mdx`

## 简介

作为 LLM 工具链平台，Dify 支持 JSON 结构化输出功能。结构化输出功能可以确保 LLM 返回的数据格式可用、稳定、可预测，减少错误处理和格式转换的工作。

## 价值

-   **确保数据格式一致**：即使由 LLM 生成内容，也必须符合预设格式，避免数据混乱。

-   **方便后续节点处理**：数据库、API 或前端可以直接解析 JSON Schema，而无需额外数据清洗。

-   **提升低代码开发体验**：开发者无需手写复杂数据校验逻辑，直接使用 JSON Schema 约束输出。

## 如何实现结构化输出？

在 Dify 的操作界面中，可以通过以下两种方式实现结构化输出：

-   **方式一：直接定义工具参数**

-   **方式二：使用 LLM 节点中的 JSON Schema 编辑器**

### 方式一：直接定义工具参数

请参阅 **[Tool](https://docs.dify.ai/zh-hans/plugins/schema-definition/tool) > 数据结构 > 返回变量定义**。

### 方式二：使用 LLM 节点中的 JSON Schema 编辑器

请参阅 **[LLM](https://docs.dify.ai/zh-hans/guides/workflow/node/llm) > 高级功能 > 结构化输出** 与 **[LLM](https://docs.dify.ai/zh-hans/guides/workflow/node/llm) > 使用案例 > 结构化输出**。

## 异常处理方案

**异常情况**

在使用 JSON Schema 编辑器进行结构化输出时，可能会遇到以下限制和异常情况：

-   **模型能力限制**：部分 LLM（尤其是 70B 以下的模型或 GPT-3.5 Turbo 级别模型）在指令遵循性上较弱，可能导致 JSON Schema 解析失败。

-   **格式兼容性**：部分 LLM 仅支持 **JSON mode** 而非 **JSON Schema**，导致严格的 Schema 解析失败。

-   **错误信息**：出现错误 `Failed to parse structured output: output is not a valid json str`。此类错误主要源于模型生成 JSON 失败。

**推荐处理方案**

1.  **优先使用支持 JSON Schema 的模型**。推荐列表如下：
    - Gemini 2.0 Flash/Flash-Lite
    - Gemini 1.5 Flash 8B (0827/0924)
    - Gemini-1.5 pro
    - GPT-4o
    - GPT-4o-mini
    - o1-mini/o3-mini 系列

2.  **适当调整系统提示词以增强指令遵循性，尽可能确保 LLM 输出符合 Schema 规范**。假如 JSON Schema 设计用于结构化数学公式的输入与输出，而系统提示词却要求模型进行法律条文解析，这种不匹配可能会导致模型无法正确理解任务，影响生成结果的准确性。

3.  **配置异常处理策略**。你可以在解析失败时考虑采取以下措施：

    1.  **配置失败时重试**：在节点内开启 **失败时重试** 功能并配置最大重试次数与重试间隔，以减少解析错误的影响。

    2.  **配置异常分支**：在节点内的 **异常处理** 中配置 **失败分支**。当节点发生异常时，将自动执行失败分支。

详情请参阅[异常处理](https://docs.dify.ai/zh-hans/guides/workflow/error-handling)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/structured-outputs.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 变量
> 来源：`zh-hans/guides/workflow/variables.mdx`

Workflow 和 Chatflow 类型应用由独立节点相构成。大部分节点设有输入和输出项，但每个节点的输入信息不一致，各个节点所输出的答复也不尽相同。

如何用一种固定的符号**指代动态变化的内容？** 变量作为一种动态数据容器，能够存储和传递不固定的内容，在不同的节点内被相互引用，实现信息在节点间的灵活通信。

## 变量类型

### **系统变量**

系统变量指的是在 Chatflow / Workflow 应用内预设的系统级参数，可以被其它节点全局读取。系统级变量均以 `sys` 开头。

**Workflow**

Workflow 类型应用提供以下系统变量：

<table>
  <thead>
    <tr>
      <th width="193">变量名称</th>
      <th width="116">数据类型</th>
      <th width="278">说明</th>
      <th>备注</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><p><code>sys.files</code></p><p><code>[LEGACY]</code></p></td>
      <td>Array[File]</td>
      <td>文件参数，存储用户初始使用应用时上传的图片</td>
      <td>图片上传功能需在应用编排页右上角的 "功能" 处开启</td>
    </tr>
    <tr>
      <td><code>sys.user_id</code></td>
      <td>String</td>
      <td>用户 ID，每个用户在使用工作流应用时，系统会自动向用户分配唯一标识符，用以区分不同的对话用户</td>
      <td></td>
    </tr>
    <tr>
      <td><code>sys.app_id</code></td>
      <td>String</td>
      <td>应用 ID，系统会向每个 Workflow 应用分配一个唯一的标识符，用以区分不同的应用，并通过此参数记录当前应用的基本信息</td>
      <td>面向具备开发能力的用户，通过此参数区分并定位不同的 Workflow 应用</td>
    </tr>
    <tr>
      <td><code>sys.workflow_id</code></td>
      <td>String</td>
      <td>Workflow ID，用于记录当前 Workflow 应用内所包含的所有节点信息</td>
      <td>面向具备开发能力的用户，可以通过此参数追踪并记录 Workflow 内的包含节点信息</td>
    </tr>
    <tr>
      <td><code>sys.workflow_run_id</code></td>
      <td>String</td>
      <td>Workflow 应用运行 ID，用于记录 Workflow 应用中的运行情况</td>
      <td>面向具备开发能力的用户，可以通过此参数追踪应用的历次运行情况</td>
    </tr>
  </tbody>
</table>

![](https://assets-docs.dify.ai/2025/04/c405efa31fd5708542fdc3bd7c0cb708.png)

**Chatflow**

Chatflow 类型应用提供以下系统变量：

<table>
  <thead>
    <tr>
      <th>变量名称</th>
      <th width="127">数据类型</th>
      <th width="283">说明</th>
      <th>备注</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>sys.query</code></td>
      <td>String</td>
      <td>用户在对话框中初始输入的内容</td>
      <td></td>
    </tr>
    <tr>
      <td><code>sys.files</code></td>
      <td>Array[File]</td>
      <td>用户在对话框内上传的图片</td>
      <td>图片上传功能需在应用编排页右上角的 "功能" 处开启</td>
    </tr>
    <tr>
      <td><code>sys.dialogue_count</code></td>
      <td>Number</td>
      <td><p>用户在与 Chatflow 类型应用交互时的对话轮数。每轮对话后自动计数增加 1，可以和 if-else 节点搭配出丰富的分支逻辑。</p><p>例如到第 X 轮对话时，回顾历史对话并给出分析</p></td>
      <td></td>
    </tr>
    <tr>
      <td><code>sys.conversation_id</code></td>
      <td>String</td>
      <td>对话框交互会话的唯一标识符，将所有相关的消息分组到同一个对话中，确保 LLM 针对同一个主题和上下文持续对话</td>
      <td></td>
    </tr>
    <tr>
      <td><code>sys.user_id</code></td>
      <td>String</td>
      <td>分配给每个应用用户的唯一标识符，用以区分不同的对话用户  

<strong>注意</strong>：Service API 不共享 WebApp 创建的对话。这意味着具有相同 ID 的用户在 API 和 WebApp 界面之间会有独立的对话历史。</td>
      <td></td>
    </tr>
    <tr>
      <td><code>sys.app_id</code></td>
      <td>String</td>
      <td>应用 ID，系统会向每个 Workflow 应用分配一个唯一的标识符，用以区分不同的应用，并通过此参数记录当前应用的基本信息</td>
      <td>面向具备开发能力的用户，通过此参数区分并定位不同的 Workflow 应用</td>
    </tr>
    <tr>
      <td><code>sys.workflow_id</code></td>
      <td>String</td>
      <td>Workflow ID，用于记录当前 Workflow 应用内所包含的所有节点信息</td>
      <td>面向具备开发能力的用户，可以通过此参数追踪并记录 Workflow 内的包含节点信息</td>
    </tr>
    <tr>
      <td><code>sys.workflow_run_id</code></td>
      <td>String</td>
      <td>Workflow 应用运行 ID，用于记录 Workflow 应用中的运行情况</td>
      <td>面向具备开发能力的用户，可以通过此参数追踪应用的历次运行情况</td>
    </tr>
  </tbody>
</table>

![Chatflow 类型应用系统变量](https://assets-docs.dify.ai/2025/04/c79ca2cbce49a61b1fb94d5bd7a53274.png)

### 环境变量

**环境变量用于保护工作流内所涉及的敏感信息**，例如运行工作流时所涉及的 API 密钥、数据库密码等。它们被存储在工作流程中，而不是代码中，以便在不同环境中共享。

![](https://assets-docs.dify.ai/2025/06/7b920ddf7e3b4fd26954fb518ad6754e.png)

支持以下三种数据类型：

* String 字符串
* Number 数字
* Secret 密钥

环境变量拥有以下特性：

* 环境变量可在大部分节点内全局引用；
* 环境变量命名不可重复；
* 环境变量为只读变量，不可写入；

![](https://assets-docs.dify.ai/2025/06/8d9342615b3623ef4ce526a583a8de76.png)

### 会话变量

> 会话变量面向多轮对话场景，而 Workflow 类型应用的交互是线性而独立的，不存在多次对话交互的情况，因此会话变量仅适用于 **Chatflow 类型**应用。

**会话变量允许应用开发者在同一个 Chatflow 会话内，指定需要被临时存储的特定信息，并确保在当前工作流内的多轮对话内都能够引用该信息**，如上下文、上传至对话框的文件（即将上线）、 用户在对话过程中所输入的偏好信息等。好比为 LLM 提供一个可以被随时查看的"备忘录"，避免因 LLM 记忆出错而导致的信息偏差。

例如你可以将用户在首轮对话时输入的语言偏好存储至会话变量中，LLM 在回答时将参考会话变量中的信息，并在后续的对话中使用指定的语言回复用户。

![](https://assets-docs.dify.ai/2025/04/338f93f401142fea4936a67a615eba32.png)

**会话变量**支持以下八种数据类型：

* String 字符串
* Number 数值
* Object 对象
* Boolean 布尔值
* Array\[string] 字符串数组
* Array\[number] 数值数组
* Array\[object] 对象数组
* Array\[boolean] 布尔值数组

**会话变量**具有以下特性：

* 会话变量可在大部分节点内全局引用；
* 会话变量的写入需要使用[变量赋值](./node/variable-assigner)节点；
* 会话变量为可读写变量；

关于如何将会话变量与变量赋值节点配合使用，请参考[变量赋值](./node/variable-assigner)节点说明。

## 注意事项

* 为避免变量名重复，节点命名不可重复。
* 执行节点后，输出变量内的值将会被保存至[变量检查](./zh-hans/guides/workflow/debug-and-preview/variable-inspect)视图内。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workflow/variables.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 发现
> 来源：`zh-hans/guides/workspace/app.mdx`

## 模板应用

在**发现**中，提供了一些常用的模板应用。这些应用涵盖了人力资源，助手，翻译，编程和写作。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workspace/37573570e27ed988331fee18a7a30ce1.png)

如果要使用某个模板应用，点击模板的“添加到工作区”按钮。在左侧的工作区中，可以使用该应用。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workspace/3688257e46ca0ec4e9c23dbe19653d20.png)

如果要修改某个模板来创建一个新的应用，点击模板的“自定义”按钮。

## 工作区

工作区是应用的导航。点击工作区里的应用，可以直接使用该应用。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/guides/workspace/aa95de9ca884480c7c52a6ee7239de1d.jpeg)

工作区中的应用包括：自己的应用和其他团队添加到工作区中的应用。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workspace/app.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 全局搜索
> 来源：`zh-hans/guides/workspace/goto-anything.mdx`

**全局搜索（Go to Anything）** 允许你在 Dify 的任意页面快速跳转到应用、插件、知识库或当前工作流中的节点。

### 打开方式

在 macOS 上按 `⌘ + K`，在 Windows/Linux 上按 `Ctrl + K` 即可打开或关闭搜索面板；按 `Esc` 也可以关闭。

### 搜索与筛选

输入关键词即可搜索所有支持的资源，结果按类别展示。
使用以下命令可以限定搜索范围：

- `@app`：搜索应用
- `@plugin`：搜索已安装插件
- `@kb` 或 `@knowledge`：搜索知识库
- `@node`：在当前工作流中搜索节点（仅在查看工作流时可用）

使用上下箭头选择结果，按 `Enter` 跳转到对应页面。

### 示例

试试以下命令来快速定位到目标：

- `@app analytics`：打开名称包含 "analytics" 的应用
- `@plugin slack`：进入 Slack 插件
- `@kb company handbook`：查找名为 "company handbook" 的知识库
- `@node summary`：在当前工作流中找到名为 "summary" 的节点

### 提示

如果某些搜索服务暂时不可用，面板会提示稍后再试。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workspace/goto-anything.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 邀请与管理成员
> 来源：`zh-hans/guides/workspace/invite-and-manage-members.mdx`

工作空间的成员可由负责人和管理员邀请和管理，登录后在 Dify 的用户头像下拉中找到设置，在该界面中的左侧打开成员管理界面。

### 成员邀请

提供被邀请者的 Email，系统将即时批准对方访问工作空间，被邀请人同时将收到一份邮件。

系统将自动新成员创建 Dify 账号。

### 成员删除

成员被移出团队后将不再能访问当前工作空间，但这不影响该用户访问其它已加入的工作空间。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workspace/invite-and-manage-members.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 协同
> 来源：`zh-hans/guides/workspace/readme.mdx`

Dify 是一个多用户平台，工作空间（Workspace）是团队的基本协作单元。工作空间的成员可创建和编辑应用、知识库，也可以直接在[发现](app)区域直接使用团队其它成员创建的公共应用。

### 登录方式

需要注意，目前 Dify 的云服务、社区版、企业版支持的登录方式有所区别，参见下表。

|                      | 社区版 | 云服务 | 企业版 |
|----------------------|:------:|:------:|:------:|
| Email 登录           |  支持  |   -    |  支持  |
| 使用 GitHub 账号登录 |   -    |  支持  |   -    |
| 使用 Google 账号登录 |   -    |  支持  |   -    |
| SSO 登录             |   -    |   -    |  支持  |

### 创建账号

如果你使用的是云服务，当你首次登录后将为你自动创建一个工作空间，你将成为管理员。

在社区版中，安装时将提示你设置管理员 Email 与密码。社区版不支持开通多个工作空间。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/guides/workspace/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 产品简介
> 来源：`zh-hans/introduction.mdx`

**Dify** 是一款开源的大语言模型（LLM）应用开发平台。它融合了后端即服务（Backend as Service）和 [LLMOps](learn-more/extended-reading/what-is-llmops) 的理念，使开发者可以快速搭建生产级的生成式 AI 应用。即使你是非技术人员，也能参与到 AI 应用的定义和数据运营过程中。

由于 Dify 内置了构建 LLM 应用所需的关键技术栈，包括对数百个模型的支持、直观的 Prompt 编排界面、高质量的 RAG 引擎、稳健的 Agent 框架、灵活的工作流，并同时提供了一套易用的界面和 API。这为开发者节省了许多重复造轮子的时间，使其可以专注在创新和业务需求上。

### 为什么使用 Dify？

你或许可以把 LangChain 这类的开发库（Library）想象为有着锤子、钉子的工具箱。与之相比，Dify 提供了更接近生产需要的完整方案，Dify 好比是一套脚手架，并且经过了精良的工程设计和软件测试。

重要的是，Dify 是**开源**的，它由一个专业的全职团队和社区共同打造。你可以基于任何模型自部署类似 Assistants API 和 GPTs 的能力，在灵活和安全的基础上，同时保持对数据的完全控制。

> 我们的社区用户对 Dify 的产品评价可以归结为简单、克制、迭代迅速。
> ——路宇，Dify.AI CEO

希望以上信息和这份指南可以帮助你了解这款产品，我们相信 Dify 是为你而做的（Do It For You）。

### Dify 能做什么？

> **信息提示：**

Dify 一词源自 Define + Modify，意指定义并且持续的改进你的 AI 应用，它是为你而做的（Do it for you）。

* **创业**，快速的将你的 AI 应用创意变成现实，无论成功和失败都需要加速。在真实世界，已经有几十个团队通过 Dify 构建 MVP（最小可用产品）获得投资，或通过 POC（概念验证）赢得了客户的订单。
* **将 LLM 集成至已有业务**，通过引入 LLM 增强现有应用的能力，接入 Dify 的 RESTful API 从而实现 Prompt 与业务代码的解耦，在 Dify 的管理界面是跟踪数据、成本和用量，持续改进应用效果。
* **作为企业级 LLM 基础设施**，一些银行和大型互联网公司正在将 Dify 部署为企业内的 LLM 网关，加速 GenAI 技术在企业内的推广，并实现中心化的监管。
* **探索 LLM 的能力边界**，即使你是一个技术爱好者，通过 Dify 也可以轻松的实践 Prompt 工程和 Agent 技术，在 GPTs 推出以前就已经有超过 60,000 开发者在 Dify 上创建了自己的第一个应用。

### 下一步行动

* 阅读[**快速开始**](./zh-hans/guides/application-orchestrate/creating-an-application)，速览 Dify 的应用构建流程
* 了解如何[**自部署 Dify 到服务器**](./zh-hans/getting-started/install-self-hosted/docker-compose)上，并[**接入开源模型**](./zh-hans/guides/model-configuration/)
* 了解 Dify 的[**特性规格**](./zh-hans/getting-started/readme/features-and-specifications/)和 **Roadmap**
* 在 [**GitHub**](https://github.com/langgenius/dify) 上为我们点亮一颗星，并阅读我们的[**贡献指南**](./zh-hans/community/contribution)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/introduction.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 扩展阅读/指南
> 来源：`zh-hans/learn-more/extended-reading/README.mdx`

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 部署 Dify Docs MCP 服务，与文档进行对话
> 来源：`zh-hans/learn-more/extended-reading/dify-docs-mcp.mdx`
> 摘要：学习如何部署本地文档 MCP 服务器，并通过 AI 与文档进行对话。

Model Context Protocol (MCP) 是由 Anthropic 开发的开放标准协议，为 AI 与外部工具和数据源提供标准化交互接口。AI 通过此协议访问软件工具和数据资源。

本文介绍如何基于 [dify-docs 仓库](https://github.com/langgenius/dify-docs) 部署本地 MCP 服务器，实现 LLM 与文档的自然对话。

> **信息提示：**

    详细了解 MCP 协议，请参考 [Model Context Protocol](https://docs.anthropic.com/en/docs/agents-and-tools/mcp)。

**1. 分析问题**

接收到问题后，AI 会先分析其中涉及的概念和技术细节，判断是否需要查阅 Dify 的官方文档。

**2. 生成查询关键词**

如果需要文档支持，AI 会根据问题的核心内容，自动生成搜索关键词和查询策略。比如询问“如何在 Dify 中集成 OpenAI GPT-4 模型”，AI 可能会生成“模型配置”、“API 集成”、“GPT-4 设置”等关键词，用于精准搜索。

**3. 检索文档内容**

MCP 服务器接收到这些查询后，会在 Dify 的文档库中进行搜索，并返回最相关的内容。

**4. 整合生成答案**

AI 将检索到的信息进行整理和分析，最终生成一个准确、详细的回答。

**5. 多轮搜索优化**

如果初次搜索结果不够完整，AI 会根据结果自动调整搜索策略，进行进一步查询，直到获取更完整的答案。

## 前置准备

- Node ≥ 16.0
- Git
- MCP 客户端（如 Claude Desktop、VS Code 等）

## 安装步骤

### 1. 拉取仓库

克隆 Dify 文档仓库到本地：

```bash
git clone https://github.com/langgenius/dify-docs.git
```

该仓库包含 Dify 完整文档，作为 MCP 服务器的数据源。

### 2. 初始化 MCP 服务器

进入文档目录，安装并配置 MCP 服务器：

```bash
cd dify-docs
npx mint-mcp add dify-6c0370d8
```

此命令完成以下操作：
- 创建本地 MCP 服务器实例
- 分析和索引文档内容
- 配置必要依赖项

安装过程约需几分钟，时间取决于网络状况。

### 3. 配置 MCP 服务器

> **信息提示：**

    **MCP 客户端和服务器关系：**

    MCP 服务器提供知识和工具，处理查询请求、管理数据资源、执行特定功能。客户端为用户交互界面，通常是 AI 应用或聊天工具，接收用户问题，转发查询至相应 MCP 服务器，整合信息后返回用户。

安装过程中选择 MCP 客户端。**以 Claude Desktop 为例**，工具生成相应配置信息。

![](https://assets-docs.dify.ai/2025/05/722c689b1c27d86c183c09dfda7a6a39.png)

完成安装后，在 Claude Desktop 设置中添加 MCP 服务器。进入设置页面，在 MCP 服务器配置部分添加服务器地址和端口，保存配置并重启应用。

![](https://assets-docs.dify.ai/2025/05/a332247103fb9a7dcf5b1a891979ce86.png)

## 与文档对话

配置完成后即可与 Dify 文档进行对话。该方式支持自然语言查询，无需逐页搜索或精确匹配关键词。

例如询问”我想创建一个客服聊天机器人，应该选择 Workflow 还是 Chatflow？“，系统解释两种应用类型区别，并结合客服场景给出具体建议。

![](https://assets-docs.dify.ai/2025/05/90eab3ce20dfeac2e98770adc75fb8b2.png)

对于技术问题如“如何修改 Dify 端口号”，AI 提供具体操作步骤：

![](https://assets-docs.dify.ai/2025/05/c836ed0ebab0b66c07d505049b72ea5f.png)

MCP 方式允许用自然语言描述问题，即使不确定具体技术术语，只需描述期望效果即可获取相关信息。

## 该方案与 RAG 方法对比

| 特性 | RAG (检索增强生成) | MCP (Model Context Protocol) |
|------|-------------------|----------------------------|
| 工作原理 | 预先将文档分割成文本块，使用向量嵌入建立索引。用户提问时，系统计算问题与文本块相似度，选择相关块作为上下文生成答案。 | AI 根据问题需求主动生成查询策略，支持多轮交互查询，根据初次结果调整后续搜索。 |
| 优势 | 处理速度快，适合大规模静态文档集合。 | - 可访问完整文档内容，支持跨章节复杂查询  
- 文档更新后无需再次进行繁琐处理，重新生成 MCP 服务即可提供查询服务  
- 提供连贯完整的答案 |
| 局限性 | - 静态文档分割可能分散相关信息  
- 基于向量相似度检索可能遗漏语义相关但词汇不同的内容  
- 上下文窗口限制，仅基于特定片段生成答案 | - 需要消耗大量 Tokens，成本较高  
- 依赖 LLM 的查询策略生成能力，可能影响检索准确性  
- 多轮交互查询可能导致响应时间较长  
- 需要额外的 MCP 服务器部署和维护成本 |

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/dify-docs-mcp.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 如何使用 JSON Schema 让 LLM 输出遵循结构化格式的内容？
> 来源：`zh-hans/learn-more/extended-reading/how-to-use-json-schema-in-dify.mdx`

JSON Schema 是一种用于描述 JSON 数据结构的规范，开发者可以通过定义 JSON Schema 结构，指定 LLM 输出严格遵循定义内的数据或内容，例如按照指定内容格式输出文档或代码结构。

## 支持 JSON Schema 功能的模型

* `gpt-4o-mini-2024-07-18` and later
* `gpt-4o-2024-08-06` and later

> 如需了解更多关于 OpenAI 系列模型的结构化输出能力，请参考 [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs/introduction)。

## 结构化输出用法

以下是指定 LLM 结构化输出的用法路径：

1. 将 LLM 连接到系统中的工具、函数、数据等；在函数定义中设置 `strict: true`，当打开它时，结构化输出（Structured-outputs）功能可确保 LLM 为函数调用生成的参数与你在函数定义中提供的 JSON 架构完全匹配。
2. LLM 回答用户时，按照 JSON Schema 中的定义，以结构化内容格式输出。

下文将简要介绍如何在 Dify 开启并使用 JSON Schema 功能。

### 1. 开启 JSON Schema

将应用中的 LLM 切换至上述支持 JSON Schema 输出的模型，然后在设置表单开启 `JSON Schema` 并填写 JSON Schema 模板；同时开启 `response_format` 栏并切换至 `json_schema` 格式。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/899b0a46e438e50bef731fa45d3e7837.png)

LLM 生成的内容支持以下格式输出：

* **Text:** 以文本格式输出

### 2. 定义 JSON Schema 模板

你可以参考以下 JSON Schema 格式并定义模板内容：

```json
{
    "name": "template_schema",
    "description": "A generic template for JSON Schema",
    "strict": true,
    "schema": {
        "type": "object",
        "properties": {
            "field1": {
                "type": "string",
                "description": "Description of field1"
            },
            "field2": 
                "type": "number",
                "description": "Description of field2"
            ,
            "field3": {
                "type": "array",
                "description": "Description of field3",
                "items": {
                    "type": "string"
                }
            },
            "field4": {
                "type": "object",
                "description": "Description of field4",
                "properties": {
                    "subfield1": {
                        "type": "string",
                        "description": "Description of subfield1"
                    }
                },
                "required": ["subfield1"],
                "additionalProperties": false
            }
        },
        "required": ["field1", "field2", "field3", "field4"],
        "additionalProperties": false
    }
}
```

步骤指导：

1. 定义基本信息：

* 设置 `name`：为你的 schema 起一个描述性的名称。
* 添加 `description`：简要说明 schema 的用途。
* 设置 `strict`: true：确保严格模式。

2. 创建 `schema` 对象：

* 设置 `type: "object"`：指定根级别为对象类型。
* 添加 `properties` 对象：用于定义所有字段。

3. 定义字段：

* 为每个字段创建一个对象，包含 `type` 和 `description`。
* 常见类型：`string`, `number`, `boolean`, `array`, `object`。
* 对于数组，使用 `items` 定义元素类型。
* 对于对象，递归定义 `properties`。

4. 设置约束：

* 在每个级别添加 `required` 数组，列出所有必需字段。
* 在每个对象级别设置 `additionalProperties: false`。

5. 特殊字段处理：

* 使用 `enum` 限制可选值。
* 使用 `$ref` 实现递归结构。

## 示例

### 1. 推理链（常规）

**JSON Schema 文件示例**

```json
{
    "name": "math_reasoning",
    "description": "Records steps and final answer for mathematical reasoning",
    "strict": true,
    "schema": {
        "type": "object",
        "properties": {
            "steps": {
                "type": "array",
                "description": "Array of reasoning steps",
                "items": {
                    "type": "object",
                    "properties": {
                        "explanation": {
                            "type": "string",
                            "description": "Explanation of the reasoning step"
                        },
                        "output": 
                            "type": "string",
                            "description": "Output of the reasoning step"

                    },
                    "required": ["explanation", "output"],
                    "additionalProperties": false
                }
            },
            "final_answer": 
                "type": "string",
                "description": "The final answer to the mathematical problem"

        },
        "additionalProperties": false,
        "required": ["steps", "final_answer"]
    }
}
```

**提示词参考**

```
You are a helpful math tutor. You will be provided with a math problem,
and your goal will be to output a step by step solution, along with a final answer.
For each step, just provide the output as an equation use the explanation field to detail the reasoning.
```

### UI 生成器（根递归模式）

```json
{
        "name": "ui",
        "description": "Dynamically generated UI",
        "strict": true,
        "schema": {
            "type": "object",
            "properties": {
                "type": {
                    "type": "string",
                    "description": "The type of the UI component",
                    "enum": ["div", "button", "header", "section", "field", "form"]
                },
                "label": 
                    "type": "string",
                    "description": "The label of the UI component, used for buttons or form fields"
                ,
                "children": {
                    "type": "array",
                    "description": "Nested UI components",
                    "items": {
                        "$ref": "#"
                    }
                },
                "attributes": {
                    "type": "array",
                    "description": "Arbitrary attributes for the UI component, suitable for any element",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {
                                "type": "string",
                                "description": "The name of the attribute, for example onClick or className"
                            },
                            "value": 
                                "type": "string",
                                "description": "The value of the attribute"

                        },
                      "additionalProperties": false,
                      "required": ["name", "value"]
                    }
                }
            },
            "required": ["type", "label", "children", "attributes"],
            "additionalProperties": false
        }
    }
```

**提示词参考：**

```
You are a UI generator AI. Convert the user input into a UI.
```

**效果示例：**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/03c1132f714cbd5920f5b0f80287a07d.png)

## 提示

* 请确保应用提示词内包含如何处理用户输入无法产生有效响应的情况说明。
* 模型将始终尝试遵循提供的模式，如果输入的内容与指定的模式完全无关，则可能会导致 LLM 产生幻觉。
* 如果 LLM 检测到输入与任务不兼容，你可以在提示中包含语言，以指定返回空参数或特定句子。
* 所有字段必须为 `required`，详情请参考[此处](https://platform.openai.com/docs/guides/structured-outputs/supported-schemas)。
* [additionalProperties：false](https://platform.openai.com/docs/guides/structured-outputs/additionalproperties-false-must-always-be-set-in-objects) 必须始终在对象中设置
* 模式的根级别对象必须是一个对象

## 参考阅读

* [Introduction to Structured Outputs](https://cookbook.openai.com/examples/structured\_outputs\_intro)
* [Structured Output](https://platform.openai.com/docs/guides/structured-outputs/json-mode?context=without\_parse)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/how-to-use-json-schema-in-dify.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 设计提示词&编排应用
> 来源：`zh-hans/learn-more/extended-reading/prompt-engineering/README.mdx`
> 摘要：掌握如何使用 Dify 编排应用和实践 Prompt Engineering，通过内置的两种应用类型，搭建出高价值的 AI 应用。

Dify 的核心理念是可声明式的定义 AI 应用，包括 Prompt、上下文和插件等等的一切都可以通过一个 YAML 文件描述（这也是为什么称之为 Dify ）。最终呈现的是单一 API 或开箱即用的 WebApp。

与此同时，Dify 提供了一个易用的 Prompt 编排界面，开发者能以 Prompt 为基础所见即所得的编排出各种应用特性。听上去是不是很简单？

无论简单或是复杂的 AI 应用，好的 Prompt 可以有效提高模型输出的质量，降低错误率，并满足特定场景的需求。Dify 已提供对话型和文本生成型两种常见的应用形态，这个章节会带你以可视化的方式完成 AI 应用的编排，

### 应用编排的步骤

1. 确定应用场景和功能需求
2. 设计并测试 Prompts 与模型参数
3. 编排 Prompts 与用户输入
4. 发布应用
5. 观测并持续迭代

### 了解应用类型的区别

Dify 中的文本生成型应用与对话型应用在 Prompt 编排上略有差异，对话型应用需结合“对话生命周期”来满足更复杂的用户情景和上下文管理需求。

Prompt Engineering 已发展为一个潜力巨大，值得持续探索的学科。请继续往下阅读，学习两种类型应用的编排指南。

### 扩展阅读

1. [Learn Prompting](https://learnprompting.org/zh-Hans/)
2. [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
3. [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/prompt-engineering/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 提示词专家模式（已下线）
> 来源：`zh-hans/learn-more/extended-reading/prompt-engineering/expert-mode.mdx`

在 Dify 创建应用的编排默认为**简易模式**，这很适合想要快速创建应用的非技术人员，比如你想创建一个企业知识库 Chatbot 或者文章摘要生成器，利用**简易模式**编排对话前提示词，添加变量，添加上下文等简易步骤即可发布一个完整的应用。

而如果你是一个熟练掌握使用 **OpenAI** 的 **Playground** 的技术人员，正想创建一个学习导师应用，需要在提示词中针对不同的教学模块位置嵌入不同的上下文和变量，就可以选择**专家模式**。在此模式下你可以自由地编写完整的提示词，包括修改内置的提示词，调整上下文和聊天历史内容在提示词中的位置，设定必要参数等。如果你对 Chat 和 Complete 两种模型不陌生，现在专家模式可以快速切换 Chat 和 Complete 模型以满足你的需要，并且都适用于对话型应用和文本生成型应用。

在你开始尝试新模式前，你需要知道**专家模式**下的必要元素：

- **文本补全模型**

  在选择模型的时候，模型名字的右侧显示 COMPLETE 的即为文本补全模型，该类模型接受名为“提示词”的自由格式文本字符串，模型将生成一个文本补全，试图匹配你给它的任何上下文或模式。

- **聊天模型**

  在选择模型的时候，模型名字的右侧显示 CHAT 的即为聊天模型，该类模型将消息列表作为输入，并返回模型生成的消息作为输出。聊天模型使用的是聊天消息作为输入和输出，包含 SYSTEM / USER / ASSISTANT 三种消息类型。

- **停止序列 Stop_Sequences**

  是指特定的单词、短语或字符，用于向 LLM 发出停止生成文本的信号。

### 两种模式对比

| 对比维度                             | 简易模式          | 专家模式                           |
| ------------------------------------ | ----------------- | ---------------------------------- |
| 内置提示词可见性                     | 封装不可见        | 开放可见                           |
| 有无自动编排                         | 可用              | 不可用                             |
| 文本补全模型和聊天模型选择有无区别   | 无                | 文本补全模型和聊天模型选择后有编排区别 |
| 变量插入                             | 有                | 有                                 |
| 内容块校验                           | 无                | 有                                 |
| SYSTEM / USER / ASSISTANT三种消息类型编排 | 无                | 有                                 |
| 上下文参数设置                       | 可设置            | 可设置                             |
| 查看 PROMPT LOG                      | 可查看完整提示词日志 | 可查看完整提示词日志               |
| 停止序列 Stop_Sequences 参数设置     | 无                | 可设置                             |

> **警告：**

在**专家模式**下修改提示词并发布应用后，将无法返回至**简易模式**。

### 操作说明

1. **如何进入专家模式**

   创建应用后，在提示词编排页可以切换至**专家模式**，在此模式下可以编辑完整的应用提示词。

   ![专家模式入口](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/prompt-engineering/prompt-engineering-1/71e30fafb41d5ea234141323be1816c4.png)

2. **修改插入上下文参数**

   在**简易模式**和**专家模式**下，都可以对插入上下文的参数进行修改，参数包含了 **TopK** 和 **Score 阈值**。

   ![上下文参数设置](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/prompt-engineering/prompt-engineering-1/5a7a296cd7259b0342b09a0ec6f1023a.png)

3. **设置停止序列 Stop_Sequences**

   我们不期望 LLM 生成多余的内容，所以需要设置指特定的单词、短语或字符，告知 LLM 停止生成文本。

4. **快捷插入变量和内容块**

   在**专家模式**下，你可以在文本编辑器中输入“`/`”，快捷调出内容块来插入提示词中。内容块分为：`上下文`、`变量`、`会话历史`、`查询内容`。

   ![快捷键 “/”](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/prompt-engineering/prompt-engineering-1/e778e139b9db5c5e417b4bf568e9606f.png)

5. **输入对话前提示词**

   系统的提示词初始模板提供了必要的参数和 LLM 回复要求，可以根据需求进行定制化修改。

6. **调试日志**

   编排调试时不仅可以查看用户的输入和 LLM 的回复。在**专家模式**下，点击发送消息左上角图标，可以看到完整的提示词。

   ![调试日志入口](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/prompt-engineering/prompt-engineering-1/72db185cf68e8f27267e2e3d0d154b90.png)

调试历史可以在初始的构建应用主界面左侧导航栏的“日志与标注”中查看。

![日志与标注界面查看提示词日志](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/prompt-engineering/prompt-engineering-1/0a37cb6a650018e73459cf42edcc0c73.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/prompt-engineering/expert-mode.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 提示词初始模板参考
> 来源：`zh-hans/learn-more/extended-reading/prompt-engineering/prompt-engineering-template.mdx`

为了实现对 LLM 更加定制化的要求来满足开发人员的需要，Dify 在**专家模式**下将内置的完整提示词完全开放，并在编排界面提供了初始模板。以下是四种初始模板参考：

### 1. 使用聊天模型构建对话型应用模板

* **SYSTEM**

```
Use the following context as your learned knowledge, inside <context></context> XML tags.

<context>
{{#context#}}
</context>

When answer to user:
- If you don't know, just say that you don't know.
- If you don't know when you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.
{{pre_prompt}}
```

* **USER**

```
{{Query}} //这里输入查询的变量
```

* **ASSISTANT**

```Python
"" 
```

#### **模板结构（Prompt Structure）：**

* 上下文（`Context`）
* 预编排提示词（`Pre-prompt`）
* 查询变量（`Query`）

### 2. 使用聊天模型构建文本生成型应用模板

* **SYSTEM**

```
Use the following context as your learned knowledge, inside <context></context> XML tags.

<context>
{{#context#}}
</context>

When answer to user:
- If you don't know, just say that you don't know.
- If you don't know when you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.
{{pre_prompt}}
```

* **USER**

```
{{Query}} //这里输入查询的变量，常用的是输入段落形式的变量
```

* **ASSISTANT**

```Python
"" 
```

#### **模板结构（Prompt Structure）：**

* 上下文（`Context`）
* 预编排提示词（`Pre-prompt`）
* 查询变量（`Query`）

### 3. 使用文本补全模型构建对话型应用模板

```Python
Use the following context as your learned knowledge, inside <context></context> XML tags.

<context>
{{#context#}}
</context>

When answer to user:
- If you don't know, just say that you don't know.
- If you don't know when you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.

{{pre_prompt}}

Here is the chat histories between human and assistant, inside <histories></histories> XML tags.

<histories>
{{#histories#}}
</histories>

Human: {{#query#}}

Assistant: 
```

**模板结构（Prompt Structure）：**

* 上下文（`Context`）
* 预编排提示词（`Pre-prompt`）
* 会话历史（`History`）
* 查询变量（`Query`）

### 4. 使用文本补全模型构建文本生成型应用模板

```Python
Use the following context as your learned knowledge, inside <context></context> XML tags.

<context>
{{#context#}}
</context>

When answer to user:
- If you don't know, just say that you don't know.
- If you don't know when you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.

{{pre_prompt}}
{{query}}
```

**模板结构（Prompt Structure）：**

* 上下文（`Context`）
* 预编排提示词（`Pre-prompt`）
* 查询变量（`Query`）

> **警告：**

Dify 与部分模型厂商针对系统提示词做了联合深度优化，部分模型下的初始模板可能与以上示例不同。

### 参数释义

* 上下文（`Context`）：用于将知识库中的相关文本作为提示词上下文插入至完整的提示词中。
* 对话前提示词（`Pre-prompt`）：在**简易模式**下编排的对话前提示词将插入至完整提示词中。
* 会话历史（`History`）：使用文本生成模型构建聊天应用时，系统会将用户会话历史作为上下文插入至完整提示词中。由于部分模型对角色前缀的响应有所差异，你也可以在对话历史的设置中修改对话历史中的角色前缀名，例如：将 “`Assistant`” 改为 “`AI`”。
* 查询内容（`Query`）：查询内容为变量值，用于插入用户在聊天中输入的问题。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/prompt-engineering/prompt-engineering-template.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 设计提示词 & 编排应用
> 来源：`zh-hans/learn-more/extended-reading/prompt-engineering.mdx`
> 摘要：掌握如何使用 Dify 编排应用和实践 Prompt Engineering，通过内置的两种应用类型，搭建出高价值的 AI 应用。

Dify 的核心理念是可声明式的定义 AI 应用，包括 Prompt、上下文和插件等等的一切都可以通过一个 YAML 文件描述（这也是为什么称之为 Dify ）。最终呈现的是单一 API 或开箱即用的 WebApp。

与此同时，Dify 提供了一个易用的 Prompt 编排界面，开发者能以 Prompt 为基础所见即所得的编排出各种应用特性。听上去是不是很简单？

无论简单或是复杂的 AI 应用，好的 Prompt 可以有效提高模型输出的质量，降低错误率，并满足特定场景的需求。Dify 已提供对话型和文本生成型两种常见的应用形态，这个章节会带你以可视化的方式完成 AI 应用的编排，

### 应用编排的步骤

1. 确定应用场景和功能需求
2. 设计并测试 Prompts 与模型参数
3. 编排 Prompts 与用户输入
4. 发布应用
5. 观测并持续迭代

### 了解应用类型的区别

Dify 中的文本生成型应用与对话型应用在 Prompt 编排上略有差异，对话型应用需结合“对话生命周期”来满足更复杂的用户情景和上下文管理需求。

Prompt Engineering 已发展为一个潜力巨大，值得持续探索的学科。请继续往下阅读，学习两种类型应用的编排指南。

### 扩展阅读

1. [Learn Prompting](https://learnprompting.org/zh-Hans/)
2. [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
3. [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/prompt-engineering.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## RAG 概念简介
> 来源：`zh-hans/learn-more/extended-reading/retrieval-augment/README.mdx`

### RAG 的概念解释

向量检索为核心的 RAG 架构已成为解决大模型获取最新外部知识，同时解决其生成幻觉问题时的主流技术框架，并且已在相当多的应用场景中落地实践。

开发者可以利用该技术低成本地构建一个 AI 智能客服、企业智能知识库、AI 搜索引擎等，通过自然语言输入与各类知识组织形式进行对话。以一个有代表性的 RAG 应用为例：

在下图中，当用户提问时 “美国总统是谁？” 时，系统并不是将问题直接交给大模型来回答，而是先将用户问题在知识库中（如下图中的维基百科）进行向量搜索，通过语义相似度匹配的方式查询到相关的内容（拜登是美国现任第46届总统…），然后再将用户问题和搜索到的相关知识提供给大模型，使得大模型获得足够完备的知识来回答问题，以此获得更可靠的问答结果。

![RAG 基本架构](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/19b393464a4d0374498144502f024516.png)

**为什么需要这样做呢？**

我们可以把大模型比做是一个超级专家，他熟悉人类各个领域的知识，但他也有自己的局限性，比如他不知道你个人的一些状况，因为这些信息是你私人的，不会在互联网上公开，所以他没有提前学习的机会。

当你想雇佣这个超级专家来充当你的家庭财务顾问时，需要允许他在接受你的提问时先翻看一下你的投资理财记录、家庭消费支出等数据。这样他才能根据你个人的实际情况提供专业的建议。

**这就是 RAG 系统所做的事情：帮助大模型临时性地获得他所不具备的外部知识，允许它在回答问题之前先找答案。**

根据上面这个例子，我们很容易发现 RAG 系统中最核心是外部知识的检索环节。专家能不能向你提供专业的家庭财务建议，取决于能不能精确找到他需要的信息，如果他找到的不是投资理财记录，而是家庭减肥计划，那再厉害的专家都会无能为力。

### RAG vs 其它文本训练方案

* 微调（Fine-tuning） vs RAG：在达到相似结果时，RAG 在成本效率和实时性能方面具有显著优势。同时，微调技术对于数据的质量和数量要求很高。并且应用程序在使用微调模型的可能也需要 RAG 技术的支持。
* 长文本与 RAG：许多研究证实，LLM 在处理分析长文本时仍然面临着一个问题，即随着文本长度的增加，检索的准确性持续下降。因此，在任何情况下，都可以结合高精度搜索系统（RAG）。 LLM 的长文本能力和 RAG 可以完美地结合在一起，并且可以相互学习各自的长处，弥补各自的不足。

整体而言，RAG 允许大模型访问外部最新信息的数据源，从而弥补相关领域的知识缺口，提升输出的回答与知识的相关性。RAG 能够帮助 LLM 与外部来源检索的可验证实时数据相结合，输出更加准确的答案，使结果变得真实可信，降低不必要的风险。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/retrieval-augment/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 混合检索
> 来源：`zh-hans/learn-more/extended-reading/retrieval-augment/hybrid-search.mdx`

### 为什么需要混合检索？

RAG 检索环节中的主流方法是向量检索，即语义相关度匹配的方式。技术原理是通过将外部知识库的文档先拆分为语义完整的段落或句子，并将其转换（Embedding）为计算机能够理解的一串数字表达（多维向量），同时对用户问题进行同样的转换操作。

计算机能够发现用户问题与句子之间细微的语义相关性，比如 “猫追逐老鼠” 和 “小猫捕猎老鼠” 的语义相关度会高于 “猫追逐老鼠” 和 “我喜欢吃火腿” 之间的相关度。在将相关度最高的文本内容查找到后，RAG 系统会将其作为用户问题的上下文一起提供给大模型，帮助大模型回答问题。

除了能够实现复杂语义的文本查找，向量检索还有其他的优势：

* 相近语义理解（如老鼠/捕鼠器/奶酪，谷歌/必应/搜索引擎）
* 多语言理解（跨语言理解，如输入中文匹配英文）
* 多模态理解（支持文本、图像、音视频等的相似匹配）
* 容错性（处理拼写错误、模糊的描述）

虽然向量检索在以上情景中具有明显优势，但有某些情况效果不佳。比如：

* 搜索一个人或物体的名字（例如，伊隆·马斯克，iPhone 15）
* 搜索缩写词或短语（例如，RAG，RLHF）
* 搜索 ID（例如， `gpt-3.5-turbo` ， `titan-xlarge-v1.01` ）

而上面这些的缺点恰恰都是传统关键词搜索的优势所在，传统关键词搜索擅长：

* 精确匹配（如产品名称、姓名、产品编号）
* 少量字符的匹配（通过少量字符进行向量检索时效果非常不好，但很多用户恰恰习惯只输入几个关键词）
* 倾向低频词汇的匹配（低频词汇往往承载了语言中的重要意义，比如“你想跟我去喝咖啡吗？”这句话中的分词，“喝”“咖啡”会比“你”“想”“吗”在句子中承载更重要的含义）

对于大多数文本搜索的情景，首要的是确保潜在最相关结果能够出现在候选结果中。向量检索和关键词检索在检索领域各有其优势。混合搜索正是结合了这两种搜索技术的优点，同时弥补了两方的缺点。

在混合检索中，你需要在数据库中提前建立向量索引和关键词索引，在用户问题输入时，分别通过两种检索器在文档中检索出最相关的文本。

![混合检索](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/16818764adc7c9e7bfbe4be8fb3fd6ee.png)

“混合检索”实际上并没有明确的定义，本文以向量检索和关键词检索的组合为示例。如果我们使用其他搜索算法的组合，也可以被称为“混合检索”。比如，我们可以将用于检索实体关系的知识图谱技术与向量检索技术结合。

不同的检索系统各自擅长寻找文本（段落、语句、词汇）之间不同的细微联系，这包括了精确关系、语义关系、主题关系、结构关系、实体关系、时间关系、事件关系等。可以说没有任何一种检索模式能够适用全部的情景。**混合检索通过多个检索系统的组合，实现了多个检索技术之间的互补。**

### **向量检索**

定义：通过生成查询嵌入并查询与其向量表示最相似的文本分段。

![向量检索设置](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/d9f6c540579ffa7833c8e8fecab13470.png)

**TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。

**Score 阈值：** 用于设置文本片段筛选的相似度阈值，即：只召回超过设置分数的文本片段。系统默认关闭该设置，即不会对召回的文本片段相似值过滤。打开后默认值为 0.5 。

**Rerank 模型：** 你可以在“模型供应商”页面配置 Rerank 模型的 API 秘钥之后，在检索设置中打开“Rerank 模型”，系统会在语义检索后对已召回的文档结果再一次进行语义重排序，优化排序结果。设置 Rerank 模型后，TopK 和 Score 阈值设置仅在 Rerank 步骤生效。

### **全文检索**

定义：索引文档中的所有词汇，从而允许用户查询任意词汇，并返回包含这些词汇的文本片段。

![全文检索设置](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/4ba9e7aed96e64da0e6475913041ed55.png)

**TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。

**Rerank 模型：** 你可以在“模型供应商”页面配置 Rerank 模型的 API 秘钥之后，在检索设置中打开“Rerank 模型”，系统会在全文检索后对已召回的文档结果再一次进行语义重排序，优化排序结果。设置 Rerank 模型后，TopK 和 Score 阈值设置仅在 Rerank 步骤生效。

### **混合检索**

同时执行全文检索和向量检索，并应用重排序步骤，从两类查询结果中选择匹配用户问题的最佳结果，需配置 Rerank 模型 API。

![混合检索设置](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/60ab88815f84ef92a45ac239481fcefd.png)

**TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。系统默认值为 3 。

**Rerank 模型：** 你可以在“模型供应商”页面配置 Rerank 模型的 API 秘钥之后，在检索设置中打开“Rerank 模型”，系统会在混合检索后对已召回的文档结果再一次进行语义重排序，优化排序结果。设置 Rerank 模型后，TopK 和 Score 阈值设置仅在 Rerank 步骤生效。

### 创建知识库时设置检索模式

进入“知识库->创建知识库”页面并在检索设置中设置不同的检索模式：

![创建知识库时设置检索模式](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/36f3a2e700529cdfdab067acc1340d4e.png)

### 知识库设置中修改检索模式

进入“知识库->选择知识库->设置”页面中可以对已创建的知识库修改不同的检索模式。

![知识库设置中修改检索模式](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/24fc8d33f05253cc83b5f6371b94b84b.png)

### 提示词编排中修改检索模式

进入“提示词编排->上下文->选择知识库->设置”页面中可以在创建应用时修改不同的检索模式。

![提示词编排中修改检索模式](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/b07e4a2c1345ab676c6e0c107651d0f9.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/retrieval-augment/hybrid-search.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 重排序
> 来源：`zh-hans/learn-more/extended-reading/retrieval-augment/rerank.mdx`

### 为什么需要重排序？

混合检索能够结合不同检索技术的优势获得更好的召回结果，但在不同检索模式下的查询结果需要进行合并和归一化（将数据转换为统一的标准范围或分布，以便更好地进行比较、分析和处理），然后再一起提供给大模型。这时候我们需要引入一个评分系统：重排序模型（Rerank Model）。

**重排序模型会计算候选文档列表与用户问题的语义匹配度，根据语义匹配度重新进行排序，从而改进语义排序的结果**。其原理是计算用户问题与给定的每个候选文档之间的相关性分数，并返回按相关性从高到低排序的文档列表。常见的 Rerank 模型如：Cohere rerank、bge-reranker 等。

![混合检索+重排序](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/292a7f8e50b9b6be6ababd6b84ac322f.png)

在大多数情况下，在重排序之前会有一次前置检索，这是由于计算查询与数百万个文档之间的相关性得分将会非常低效。所以，**重排序一般都放在搜索流程的最后阶段，非常适合用于合并和排序来自不同检索系统的结果**。

不过，重排序并不是只适用于不同检索系统的结果合并，即使是在单一检索模式下，引入重排序步骤也能有效帮助改进文档的召回效果，比如我们可以在关键词检索之后加入语义重排序。

在具体实践过程中，除了将多路查询结果进行归一化之外，在将相关的文本分段交给大模型之前，我们一般会限制传递给大模型的分段个数（即 TopK，可以在重排序模型参数中设置），这样做的原因是大模型的输入窗口存在大小限制（一般为 4K、8K、16K、128K 的 Token 数量），你需要根据选用的模型输入窗口的大小限制，选择合适的分段策略和 TopK 值。

需要注意的是，即使模型上下文窗口很足够大，过多的召回分段会可能会引入相关度较低的内容，导致回答的质量降低，所以重排序的 TopK 参数并不是越大越好。

重排序并不是搜索技术的替代品，而是一种用于增强现有检索系统的辅助工具。**它最大的优势是不仅提供了一种简单且低复杂度的方法来改善搜索结果，允许用户将语义相关性纳入现有的搜索系统中，而且无需进行重大的基础设施修改。**

以 Cohere Rerank 为例，你只需要注册账户和申请 API ，接入只需要两行代码。另外，他们也提供了多语言模型，也就是说你可以将不同语言的文本查询结果进行一次性排序。\\

### 如何配置 Rerank 模型？

Dify 目前已支持 Cohere Rerank 模型，进入“模型供应商-> Cohere”页面填入 Rerank 模型的 API 秘钥：

![在模型供应商内配置 Cohere Rerank 模型](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/5e113c2363a2d8de83ee235575898cb0.png)

###

### 如何获取 Cohere Rerank 模型？

登录：[https://cohere.com/rerank](https://cohere.com/rerank)，在页内注册并申请 Rerank 模型的使用资格，获取 API 秘钥。

###

### 知识库检索模式中设置 Rerank 模型

进入“知识库->创建知识库->检索设置”页面并在添加 Rerank 设置。除了在创建知识库可以设置 Rerank ，你也可以在已创建的知识库设置内更改 Rerank 配置，在应用编排的知识库召回模式设置中更改 Rerank 配置。

![知识库检索模式中设置 Rerank 模型](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/34f4e4ffdfb188fa8a3705d10487b97e.png)

**TopK：** 用于设置 Rerank 后返回相关文档的数量。

**Score 阈值：** 用于设置 Rerank 后返回相关文档的最低分值。设置 Rerank 模型后，TopK 和 Score 阈值设置仅在 Rerank 步骤生效。

### 知识库多路召回模式中设置 Rerank 模型

进入“提示词编排->上下文->设置”页面中设置为多路召回模式时需开启 Rerank 模型。

查看更多关于多路召回模式的说明，[《多路召回》](./zh-hans/guides/knowledge-base/integrate-knowledge-within-application#duo-lu-zhao-hui-tui-jian)。

![知识库多路召回模式中设置 Rerank 模型](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/24e43084b10f144c718c5b8545c1e4b4.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/retrieval-augment/rerank.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 召回模式
> 来源：`zh-hans/learn-more/extended-reading/retrieval-augment/retrieval.mdx`

当用户构建知识库问答类的 AI 应用时，如果在应用内关联了多个知识库，此时需要应用 Dify 的召回策略决定从哪些知识库中检索内容。

![召回模式设置](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/c0d6a2517ce9ba13a35cbbd5d94091aa.png)

### 召回设置

根据用户意图同时匹配所有知识库，从多路知识库查询相关文本片段，经过重排序步骤，从多路查询结果中选择匹配用户问题的最佳结果，需配置 Rerank 模型 API。在多路召回模式下，检索器会在所有与应用关联的知识库中去检索与用户问题相关的文本内容，并将多路召回的相关文档结果合并，并通过 Rerank 模型对检索召回的文档进行语义重排序。

在多路召回模式下，建议配置 Rerank 模型。你可以阅读 [重排序](./zh-hans/learn-more/extended-reading/retrieval-augment/rerank) 了解更多。

以下是多路召回模式的技术流程图：

![多路召回](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/extended-reading/retrieval-augment/af426fa2d9ba358ca769a19f70369b31.png)

由于多路召回模式不依赖于模型的推理能力或知识库描述，该模式在多知识库检索时能够获得质量更高的召回效果，除此之外加入 Rerank 步骤也能有效改进文档召回效果。因此，当创建的知识库问答应用关联了多个知识库时，我们更推荐将召回模式配置为多路召回。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/retrieval-augment/retrieval.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 什么是数组变量？
> 来源：`zh-hans/learn-more/extended-reading/what-is-array-variable.mdx`

数组变量是一种特定的数据类型，变量内通常包含多个元素。其中的元素用逗号分隔，以 `[` 开头，以 `]` 结尾。例如：

**数字型：**

```
[0,1,2,3,4,5]
```

**字符串型：**

```
["Monday", "Tuesday", "Wednesday", "Thursday"]
```

**JSON 对象：**

```
[

        "name": "Alice",
        "age": 30,
        "email": "alice@example.com"
    ,

        "name": "Bob",
        "age": 25,
        "email": "bob@example.com"
    ,

        "name": "Charlie",
        "age": 35,
        "email": "charlie@example.com"

]
```

### 使用场景

* [工作流 - 列表操作](../../guides/workflow/node/list-operator)。列表操作节点可以对文件的格式类型、文件名、大小等属性进行过滤与提取，将不同格式的文件传递给对应的处理节点，以实现对不同文件处理流的精确控制
*   [工作流 - 迭代](../../guides/workflow/node/iteration)。针对数组中的元素依次执行相同的操作步骤，直至输出所有结果，可以理解为任务批处理器。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/what-is-array-variable.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 什么是 LLMOps？
> 来源：`zh-hans/learn-more/extended-reading/what-is-llmops.mdx`

**LLMOps（Large Language Model Operations）是一个涵盖了大型语言模型（如GPT系列）开发、部署、维护和优化的一整套实践和流程。LLMOps 的目标是确保高效、可扩展和安全地使用这些强大的 AI 模型来构建和运行实际应用程序。它涉及到模型训练、部署、监控、更新、安全性和合规性等方面。**

下表说明了使用 Dify 前后开发 AI 应用的各环节差异：

<table><thead><tr><th width="199">步骤</th><th width="293">未使用 LLMOps 平台</th><th width="289">使用 Dify LLMOps 平台</th><th>时间差异</th></tr></thead><tbody><tr><td>开发应用前&后端</td><td>集成和封装 LLM 能力，花费较多时间开发前端应用</td><td>直接使用 Dify 的后端服务，可基于 WebApp 脚手架开发</td><td>-80%</td></tr><tr><td>Prompt Engineering</td><td>仅能通过调用 API 或 Playground 进行</td><td>结合用户输入数据所见即所得完成调试</td><td>-25%</td></tr><tr><td>数据准备与嵌入</td><td>编写代码实现长文本数据处理、嵌入</td><td>在平台上传文本或绑定数据源即可</td><td>-80%</td></tr><tr><td>应用日志与分析</td><td>编写代码记录日志，访问数据库查看</td><td>平台提供实时日志与分析</td><td>-70%</td></tr><tr><td>数据分析与微调</td><td>技术人员进行数据管理和创建微调队列</td><td>非技术人员可协同，可视化模型调整</td><td>-60%</td></tr><tr><td>AI 插件开发与集成</td><td>编写代码创建、集成 AI 插件</td><td>平台提供可视化工具创建、集成插件能力</td><td>-50%</td></tr></tbody></table>

在使用 LLMOps 平台如 Dify 之前，基于 LLM 开发应用的过程可能会非常繁琐和耗时。开发者需要自行处理各个阶段的任务，这可能导致效率低下、难以扩展和安全性问题。以下是使用 LLMOps 平台前的开发过程：

1. 数据准备：手动收集和预处理数据，可能涉及到复杂的数据清洗和标注工作，需要编写较多代码。
2. Prompt Engineering：开发者只能通过调用 API 或 Playground 进行 Prompt 编写和调试，缺乏实时反馈和可视化调试。
3. 嵌入和上下文管理：手动处理长上下文的嵌入和存储，难以优化和扩展，需要不少编程工作，熟悉模型嵌入和向量数据库等技术。
4. 应用监控与维护：手动收集和分析性能数据，可能无法实时发现和处理问题，甚至可能没有日志记录。
5. 模型微调：自行处理微调数据准备和训练过程，可能导致效率低下，需要编写更多代码。
6. 系统和运营：需要技术人员参与或花费成本开发管理后台，增加开发和维护成本，缺乏多人协同和对非技术人员的友好支持。

引入 Dify 这样的 LLMOps 平台后，基于 LLM 开发应用的过程将变得更加高效、可扩展和安全。以下是使用像 Dify 这样的 LLMOps 进行 LLM 应用开发的优势：

1. 数据准备：平台提供数据收集和预处理工具，简化了数据清洗和标注的工作，最小化甚至消除了编码工作。
2. Prompt Engineering：所见即所得的 Prompt 编辑和调试，可根据用户输入的数据进行实时优化和调整。
3. 嵌入和上下文管理：自动处理长上下文的嵌入、存储和管理，提高效率和扩展性，无需编写大量代码。
4. 应用监控与维护：实时监控性能数据，快速发现和处理问题，确保应用程序的稳定运行，提供完整的日志记录。
5. 微调数据准备：提供人工标注知识库的批量导出，在应用运营过程中收集线上反馈数据持续改善模型效果。
6. 系统和运营：易用的界面，非技术人员也可参与，支持多人协同，降低开发和维护成本。与传统开发方式相比，Dify 提供了更加透明和易于监控的应用管理，让团队成员更好地了解应用的运行情况。

另外，Dify 将提供 AI 插件开发和集成的功能，使得开发者可以轻松地为各种应用创建和部署基于 LLM 的插件，进一步提升了开发效率和应用的价值。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/extended-reading/what-is-llmops.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 本地部署
> 来源：`zh-hans/learn-more/faq/install-faq.mdx`

### 1. 本地部署初始化后，密码错误如何重置？

若使用 docker compose 方式部署，可执行以下命令进行重置

```
docker exec -it docker-api-1 flask reset-password
```

输入账户 email 以及两次新密码即可。

### 2. 本地部署日志中报 File not found 错误，如何解决？

```
ERROR:root:Unknown Error in completion
Traceback (most recent call last):
  File "/www/wwwroot/dify/dify/api/libs/rsa.py", line 45, in decrypt
    private_key = storage.load(filepath)
  File "/www/wwwroot/dify/dify/api/extensions/ext_storage.py", line 65, in load
    raise FileNotFoundError("File not found")
FileNotFoundError: File not found
```

该错误可能是由于更换了部署方式，或者 `api/storage/privkeys` 删除导致，这个文件是用来加密大模型密钥的，因此丢失后不可逆。可以使用如下命令进行重置加密公私钥：

*   Docker compose 部署

    ```
    docker exec -it docker-api-1 flask reset-encrypt-key-pair
    ```
*   源代码启动

    进入 api 目录

    ```
    flask reset-encrypt-key-pair
    ```

    按照提示进行重置。

### **3. 安装时后无法登录，登录成功，但后续接口均提示 401？**

这可能是由于切换了域名/网址，导致前端和服务端跨域。跨域和身份会涉及到下方的配置：

1. CORS 跨域配置
   1.  `CONSOLE_CORS_ALLOW_ORIGINS`

       控制台 CORS 跨域策略，默认为 `*`，即所有域名均可访问。
   2.  `WEB_API_CORS_ALLOW_ORIGINS`

       WebAPP CORS 跨域策略，默认为 `*`，即所有域名均可访问。

### **4. 启动后页面一直在 loading，查看请求提示 CORS 错误？**

这可能是由于切换了域名/网址，导致前端和服务端跨域，请将 `docker-compose.yml` 中所有的以下配置项改为新的域名：

`CONSOLE_API_URL:` 控制台 API 的后端 URL。
`CONSOLE_WEB_URL:` 控制台网页的前端 URL。
`SERVICE_API_URL:` 服务 API 的 URL。
`APP_API_URL:` WebApp API 的后端 URL。
`APP_WEB_URL:` WebApp 的 URL。

更多信息，请查看：[环境变量](../../getting-started/install-self-hosted/environments)

### 5. 部署后如何升级版本？

如果你是通过镜像启动，请重新拉取最新镜像完成升级。 如果你是通过源码启动，请拉取最新代码，然后启动，完成升级。

源码部署更新时，需要进入 api 目录下，执行以下命令将数据库结构迁移至最新版本：

`flask db upgrade`

### 6. 使用 Notion 导入时如何配置环境变量？

[**Notion 的集成配置地址**](https://www.notion.so/my-integrations)\*\*。\*\*进行私有化部署时，请设置以下配置：

1. **`NOTION_INTEGRATION_TYPE`** ：该值应配置为（**public/internal**）。由于 Notion 的 Oauth 重定向地址仅支持 https，如果在本地部署，请使用 Notion 的内部集成。
2. **`NOTION_CLIENT_SECRET`** ： Notion OAuth 客户端密钥（用于公共集成类型）。
3. **`NOTION_CLIENT_ID`** ： OAuth 客户端ID（用于公共集成类型）。
4. **`NOTION_INTERNAL_SECRET`** ： Notion 内部集成密钥，如果 `NOTION_INTEGRATION_TYPE` 的值为 **internal**，则需要配置此变量。

### 7. 本地部署版，如何更改空间的名称？

在数据库 `tenants` 表里修改。

### 8. 想修改访问应用的域名，在哪里修改？

在 `docker_compose.yaml` 里面找到 APP\_WEB\_URL 配置域名。

### 9. 如果发生数据库迁移，需要备份哪些东西？

需要备份数据库、配置的存储以及向量数据库数据，若为 docker compose 方式部署，可直接备份 `dify/docker/volumes` 目录下所有数据内容。

### 10. 为什么 Docker 部署 Dify，本地启动 OpenLLM 用 127.0.0.1 却无法访问本地的端口？

127.0.0.1 是容器内部地址， Dify 配置的服务器地址需要宿主机局域网 IP 地址。

### 11. 本地部署版如何解决知识库文档上传的大小限制和数量限制。

可参考官网[环境变量说明文档](./zh-hans/getting-started/install-self-hosted/environments)去配置。

### 12. 本地部署版如何通过邮箱邀请成员？

本地部署版，邀请成员可通过邮箱邀请，输入邮箱邀请后，页面显示邀请链接，复制邀请链接转发给用户，用户打开链接通过邮箱登录设置密码即可登录到你的空间内。

### 13. 本地部署版本遇到这个错误需要怎么办 Can't load tokenizer for 'gpt2'

```
Can't load tokenizer for 'gpt2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'gpt2' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.
```

可参考官网[环境变量说明文档](./zh-hans/getting-started/install-self-hosted/environments)去配置。以及相关 [Issue](https://github.com/langgenius/dify/issues/1261)。

### 14. 本地部署 80 端口被占用应该如何解决？

本地部署 80 端口被占用，可通过停止占用 80 端口的服务，或者修改 docker-compose.yaml 里面的端口映射，将 80 端口映射到其他端口。通常 Apache 和 Nginx 会占用这个端口，可通过停止这两个服务来解决。

### 15. 文本转语音遇到这个错误怎么办？

```
[openai] Error: ffmpeg is not installed
```

由于 OpenAI TTS 实现了音频流分段，源码部署时需要安装 ffmpeg 才可正常使用，详细步骤：

**Windows:**

1. 访问 [FFmpeg 官方网站](https://ffmpeg.org/download.html)，下载已经编译好的 Windows shared 库。
2. 下载并解压 FFmpeg 文件夹，它会生成一个类似于 "ffmpeg-20200715-51db0a4-win64-static" 的文件夹。
3. 将解压后的文件夹移动到你想要的位置，例如 C:\Program Files\。
4. 将 FFmpeg 的 bin 目录所在的绝对路径添加到系统环境变量中。
5. 打开命令提示符，输入"ffmpeg -version"，如果能看到 FFmpeg 的版本信息，那么说明安装成功。

**Ubuntu:**

1. 打开终端。
2. 输入以下命令来安装 FFmpeg：`sudo apt-get update`，然后输入`sudo apt-get install ffmpeg`。
3. 输入"ffmpeg -version" 来检查是否安装成功。

**CentOS:**

1. 首先，你需要启用EPEL存储库。在终端中输入：`sudo yum install epel-release`
2. 然后，输入：`sudo rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm`
3. 更新 yum 包，输入：`sudo yum update`
4. 最后，安装 FFmpeg，输入：`sudo yum install ffmpeg ffmpeg-devel`
5. 输入"ffmpeg -version" 来检查是否安装成功。

**Mac OS X:**

1. 打开终端。
2. 如果你还没有安装 Homebrew，你可以通过在终端中输入以下命令来安装：`/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"`
3. 使用 Homebrew 安装 FFmpeg，输入：`brew install ffmpeg`
4. 输入 "ffmpeg -version" 来检查是否安装成功。

### 16. 本地部署时，如果遇到 Nginx 配置文件挂载失败，如何解决？

```
Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error mounting "/run/desktop/mnt/host/d/Documents/docker/nginx/nginx.conf" to rootfs at "/etc/nginx/nginx.conf": mount /run/desktop/mnt/host/d/Documents/docker/nginx/nginx.conf:/etc/nginx/nginx.conf (via /proc/self/fd/9), flags: 0x5000: not a directory: unknown: Are you trying to mount a directory onto a file (or vice-versa)? Check if the specified host path exists and is the expected type
```

请下载完整的项目，进入 docker 执行 `docker-compose up -d` 即可。

```
git clone https://github.com/langgenius/dify.git
cd dify/docker
docker compose up -d
```

### 17. 迁移 Weaviate 向量数据到其他向量数据库

如果你想将向量数据库从 Weaviate 迁移到其它向量数据库，你需要迁移向量数据库中的数据。以下是迁移方法：

步骤：

1. 如果你从本地源代码开始，请将 `.env` 文件中的环境变量修改为你要迁移到的向量数据库。 例如：`VECTOR_STORE=qdrant`
2. 如果你从 docker-compose 开始，请将 `docker-compose.yaml` 文件中的环境变量修改为你要迁移到的向量数据库，api 和 worker 都需要修改。 例如：

```
# The type of vector store to use. Supported values are `weaviate`, `qdrant`, `milvus`, `analyticdb`.
VECTOR_STORE: weaviate
```

3. 执行以下命令

```
flask vdb-migrate # or docker exec -it docker-api-1 flask vdb-migrate
```

**经过测试的目标数据库：**

- qdrant
- milvus
- analyticdb

### 18. 为什么需要SSRF\_PROXY？

在社区版的`docker-compose.yaml`中你可能注意到了一些服务配置有`SSRF_PROXY`和`HTTP_PROXY`等环境变量，并且他们都指向了一个`ssrf_proxy`容器，这是因为为了避免SSRF攻击，关于SSRF攻击，你可以查看[这篇](https://portswigger.net/web-security/ssrf)文章。

为了避免不必要的风险，我们给所有可能造成SSRF攻击的服务都配置了一个代理，并强制如Sandbox等服务只能通过代理访问外部网络，从而确保你的数据安全和服务安全，默认的，这个代理不会拦截任何本地的请求，但是你可以通过修改`squid`的配置文件来自定义代理的行为。

#### 如何自定义代理的行为？

在`docker/volumes/ssrf_proxy/squid.conf`中，你可以找到`squid`的配置文件，你可以在这里自定义代理的行为，比如你可以添加一些ACL规则来限制代理的访问，或者添加一些`http_access`规则来限制代理的访问，例如，你的本地可以访问`192.168.101.0/24`这个网段，但是其中的`192.168.101.19`这个IP具有敏感数据，你不希望使用你本地部署的dify的用户访问到这个IP，但是想要其他的IP可以访问，你可以在`squid.conf`中添加如下规则：

```
acl restricted_ip dst 192.168.101.19
acl localnet src 192.168.101.0/24

http_access deny restricted_ip
http_access allow localnet
http_access deny all
```

当然，这只是一个简单的例子，你可以根据你的需求来自定义代理的行为，如果你的业务更加复杂，比如说需要给代理配置上游代理，或者需要配置缓存等，你可以查看[squid的配置文档](http://www.squid-cache.org/Doc/config/)来了解更多。

### 19. 如何将自己创建的应用设置为模板？

目前还不支持将你自己创建的应用设置为模板。现有的模板是由Dify官方为云版本用户参考提供的。如果你正在使用云版本，你可以将应用添加到你的工作空间或者在修改后定制它们以创建你自己的应用。如果你正在使用社区版本并且需要为你的团队创建更多的应用模板，你可以咨询我们的商务团队以获得付费技术支持：[business@dify.ai](mailto:business@dify.ai)

### 20. 502 Bad Gateway

这是因为 Nginx 将服务转发到了错误路径。首先确保容器正在运行，然后以 Root 权限运行以下命令：

```bash
docker ps -q | xargs -n 1 docker inspect --format '{{ .Name }}: {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}'
```

在输出内容中找到这两行：

```bash
/docker-web-1: 172.19.0.5
/docker-api-1: 172.19.0.7
```

记录 IP 地址，打开 Dify 源代码路径，打开 `dify/docker/nginx/conf.d` 文件，将 `http://api:5001` 替换为 `http://172.19.0.7:5001`，将 `http://web:3000` 替换为 `http://172.19.0.5:3000`，随后重启 Nginx 容器或者重载配置。

> **警告：**

   以上 IP 地址仅供参考，在实际的命令执行过程中请替换为实际 IP 地址。
   重启相关容器时，你可能需要再次根据 IP 地址进行配置。

### 21. 如何开启内容安全策略？

在 `.env` 配置文件中找到 `CSP_WHITELIST` 参数，然后填写能够被允许放行的域名，例如和所有和产品使用相关的网址、API 请求地址
此举将有助于减少潜在的 XSS 攻击。如需了解更多关于 CSP 的建议，请参考[内容安全策略](https://developer.mozilla.org/zh-hans/docs/Web/HTTP/CSP)。

### 22. 如何修改 API 服务的端口号？

API 服务与 Dify 平台使用的端口号相一致。你可以通过修改 `docker-compose.yaml` 文件内的 `nginx` 配置项，重新指定运行端口。

### 23. 如何删除旧日志和未使用的文件以减少存储使用量？

Dify**不会**自动删除数据库中的旧日志或存储中的未使用文件。请参考以下命令**手动**删除旧日志和未使用的文件。

#### 删除旧日志

你可以使用 `clear-free-plan-tenant-expired-logs` 命令指定天数删除旧日志。例如，要删除超过 30 天的日志，请运行以下命令：

1. 获取租户 ID

   ```bash
   $ docker exec -it docker-api-1 bash -c "echo 'from models import Tenant; db.session.query(Tenant.id, Tenant.name).all(); quit()' | flask shell"
   ...
   >>> [('618b5d66-a1f5-4b6b-8d12-f171182a1cb2', "Dify's Workspace")]
   ```

   - 在此示例中，租户 ID 为 `618b5d66-a1f5-4b6b-8d12-f171182a1cb2`。

2. 指定租户 ID 和天数删除旧日志

   ```bash
   $ docker exec -it docker-api-1 flask clear-free-plan-tenant-expired-logs --days 30 --batch 100 --tenant_ids 618b5d66-a1f5-4b6b-8d12-f171182a1cb2
   ...
   Starting clear free plan tenant expired logs.
   Clearing free plan tenant expired logs
   Total tenant count: 1
   [2025-04-27 05:28:22.027032] Processed 2555 messages for tenant 618b5d66-a1f5-4b6b-8d12-f171182a1cb2
   [2025-04-27 05:28:22.085901] Processed 2190 conversations for tenant 618b5d66-a1f5-4b6b-8d12-f171182a1cb2
   [2025-04-27 05:28:22.112561] Processed 5110 workflow node executions for tenant 618b5d66-a1f5-4b6b-8d12-f171182a1cb2
   ```

   - 使用 `--tenant_ids` 选项指定租户 ID。
   - 将删除比 `--days` 选项指定的天数更旧的日志。

3. （可选）删除已导出的 `free_plan_tenant_expired_logs` 目录

   ```bash
   $ docker exec -it docker-api-1 bash -c 'ls -l $OPENDAL_FS_ROOT/free_plan_tenant_expired_logs'
   ```

   - `flask clear-free-plan-tenant-expired-logs` 命令会在实际删除前，将标记为删除的日志先导出到 `free_plan_tenant_expired_logs` 目录。如果你想释放存储空间，建议随后删除该目录。
   - 删除 `free_plan_tenant_expired_logs` 目录的方法可能因存储类型不同而有所差异。上述命令适用于默认设置环境。

> **信息提示：**

  如果你希望进一步减少存储占用，也可以考虑回收存储空间（例如 [PostgreSQL 的 `VACUUM`](https://www.postgresql.org/docs/current/sql-vacuum.html)）。

#### 删除未使用的文件

你可以使用 `clear-orphaned-file-records` 命令和 `remove-orphaned-files-on-storage` 命令删除未使用的文件。

> **警告：**

  由于并非所有模式都经过完全测试，请注意这些命令可能会删除意外的文件记录或文件。
  运行命令前，请确保备份数据库和存储。
  建议在维护窗口期间运行此操作，因为这可能会导致实例负载过高。

> **警告：**

  在当前场景下，仅当存储类型为 OpenDAL（当环境变量 `STORAGE_TYPE` 设置为 `opendal`）时，才支持删除未使用的文件。
  如果你使用的存储类型不是 OpenDAL，则需要手动删除未使用的文件，或者参考脚本 [为存储接口实现 `scan` 方法](https://github.com/langgenius/dify/blob/main/api/extensions/storage/base_storage.py)。

> **信息提示：**

  如果你想跳过确认提示，可以在两个命令中使用 `--force` (`-f`) 选项。

示例一：从数据库中删除未使用的文件记录

   ```bash
   $ docker exec -it docker-api-1 flask clear-orphaned-file-records
   ...
   !!! USE WITH CAUTION !!!
   Since not all patterns have been fully tested, please note that this command may delete unintended file records.
   This cannot be undone. Please make sure to back up your database before proceeding.
   It is also recommended to run this during the maintenance window, as this may cause high load on your instance.
   Do you want to proceed? [y/N]: y
   ...
   Found 230 orphaned message_files records:
   - id: 8051365a-23ac-4ded-8c66-721f53bb46c7, message_id: 99a719aa-cc45-4856-8f84-6772d84f8ee84
   - id: 9d95b217-29f8-424c-85f6-827731b68a7a, message_id: 45f7e9d7-6194-46ea-bd53-336218b28e1e
   ...
   Do you want to proceed to delete all 230 orphaned message_files records? [y/N]: y
   - Deleting orphaned message_files records
   Removed 230 orphaned message_files records.
   ...
   Found 365 orphaned file records.
   - orphaned file id: 8a0387e6-dde7-411c-bac2-6e6d8af6ae31
   - orphaned file id: 9177f9df-7360-4434-b65f-10fdec7d38af
   ...
   Do you want to proceed to delete all 365 orphaned file records? [y/N]: y
   - Deleting orphaned file records in table upload_files
   - Deleting orphaned file records in table tool_files
   Removed 365 orphaned file records.
   ```

示例二：删除数据库中不存在的存储文件

   ```bash
   $ docker exec -it docker-api-1 flask remove-orphaned-files-on-storage
   ...
   !!! USE WITH CAUTION !!!
   Currently, this command will work only for opendal based storage (STORAGE_TYPE=opendal).
   Since not all patterns have been fully tested, please note that this command may delete unintended files.
   This cannot be undone. Please make sure to back up your storage before proceeding.
   It is also recommended to run this during the maintenance window, as this may cause high load on your instance.
   Do you want to proceed? [y/N]: y
   ...
   Found 365 orphaned files.
   - orphaned file: upload_files/618b5d66-a1f5-4b6b-8d12-f171182a1cb2/3a1d5e19-426a-4c10-91eb-cfb9b786f2dc.png
   - orphaned file: upload_files/618b5d66-a1f5-4b6b-8d12-f171182a1cb2/795986eb-d213-4cc5-8c34-c121be43ab5e.png
   ...
   Do you want to proceed to remove all 365 orphaned files? [y/N]: y
   - Removing orphaned file: upload_files/618b5d66-a1f5-4b6b-8d12-f171182a1cb2/3a1d5e19-426a-4c10-91eb-cfb9b786f2dc.png
   - Removing orphaned file: upload_files/618b5d66-a1f5-4b6b-8d12-f171182a1cb2/795986eb-d213-4cc5-8c34-c121be43ab5e.png
   ...
   Removed 365 orphaned files without errors.
   ```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/faq/install-faq.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## LLM 配置与使用
> 来源：`zh-hans/learn-more/faq/llms-use-faq.mdx`

### 1. 如何在国内环境中使用 OpenAI 代理服务器进行访问？

Dify 支持 OpenAI 的自定义 API 域名能力，支持任何兼容 OpenAI 的大模型 API 服务器。社区版中，通过 **设置 --> 模型供应商 --> OpenAI --> 编辑 API** 入口处填写目标服务器地址即可。

### **2. 如何选择基础模型？**

* gpt-3.5-turbo gpt-3.5-turbo 是 gpt-3 模型系列的升级版，它比 gpt-3 更强大，可以处理更复杂的任务。 它在理解长文本和跨文档推理方面有重大提高。 gpt-3.5 turbo 可以产生更连贯和更具说服力的文本。它在摘要、翻译和创意写作方面也有很大提高。 擅长：**长文本理解、跨文档推理、摘要、翻译、创意写作。**
* gpt-4 gpt-4 是最新最强大的 Transformer 语言模型。它拥有预训练的参数量增至约 200 亿，这使其在所有语言任务上都达到了最高水平，特别是在需要深入理解和生成长、复杂响应的任务上。gpt-4 可以处理人类语言的所有方面，包括理解抽象概念和跨页面的推理。gpt-4 是第一个真正的通用语言理解系统，它可以胜任人工智能领域内的任何自然语言处理任务。擅长： **所有 NLP 任务，语言理解，长文本生成，跨文档推理，抽象概念理解**具体可参考[文档](https://platform.openai.com/docs/models/overview)。

### **3. 为什么建议 max\_tokens 设置小一点？**

因为在自然语言处理中，较长的文本输出通常需要更长的计算时间和更多的计算资源。因此，限制输出文本的长度可以在一定程度上降低计算成本和计算时间。例如设置：max\_tokens=500 ，表示最多只考虑输出文本的前 500 个 token，而超过这个长度的部分将会被丢弃。这样做的目的是保证输出文本的长度不会超过 LLM 的接受范围，同时还可以充分利用计算资源，提高模型的运行效率。另一方面，更多的情况是，限制 max\_tokens 能够增加 prompt 的长度，如 gpt-3.5-turbo 的限制为 4097 tokens，如果设置 max\_tokens=4000，那么 prompt 就只剩下 97 tokens 可用，如果超过就会报错。

### **4. 知识库长文本如何切分比较合理？**

在一些自然语言处理应用中，通常会将文本按照段落或者句子进行切分，以便更好地处理和理解文本中的语义和结构信息。最小切分单位取决于具体的任务和技术实现。例如：

* 对于文本分类任务，通常将文本按照句子或者段落进行切分
* 对于机器翻译任务，则需要将整个句子或者段落作为切分单位。

最后，还需要进行实验和评估来确定最合适的 embedding 技术和切分单位。可以在测试集上 / 命中测试比较不同技术和切分单位的性能表现，并选择最优的方案。

### 5. 我们在获取知识库分段时用的什么距离函数？

我们使用[余弦相似度](https://en.wikipedia.org/wiki/Cosine\_similarity)。距离函数的选择通常无关紧要。OpenAI 嵌入被归一化为长度 1，这意味着：

仅使用点积可以稍微更快地计算余弦相似度

余弦相似度和欧几里德距离将导致相同的排名

* > 如果将归一化后的嵌入向量用于计算余弦相似度或欧几里德距离，并基于这些相似性度量对向量进行排序，得到的排序结果将是相同的。也就是说，无论是使用余弦相似度还是欧几里德距离来衡量向量之间的相似性，排序后的结果将是一致的。这是因为在归一化后，向量的长度不再影响它们之间的相对关系，只有方向信息被保留下来。因此，使用归一化的向量进行相似性度量时，不同的度量方法将得到相同的排序结果。在向量归一化后，将所有向量的长度缩放到 1，这意味着它们都处于单位长度上。单位向量只描述了方向而没有大小，因为它们的长度恒为 1。_具体原理可问 ChatGPT._

当嵌入向量被归一化为长度 1 后，计算两个向量之间的余弦相似度可以简化为它们的点积。因为归一化后的向量长度都为 1，点积的结果就等同于余弦相似度的结果。由于点积运算相对于其他相似度度量（如欧几里德距离）的计算速度更快，因此使用归一化的向量进行点积计算可以稍微提高计算效率。

### 6. 填写 OpenAI key，校验失败报错提示：“**校验失败： You exceeded your current quota， please check your plan and billing details。**”是什么原因？

说明你的 OpenAI key 的账号没费用了，请前往 OpenAI 充值。

### 7. 使用 OpenAI 的 key 在应用里对话，有如下报错提示，是什么原因？

报错一：

```JSON
The server encountered an internal error and was unable to complete your request。Either the server is overloaded or there is an error in the application
```

报错二：

```JSON
Rate limit reached for default-gpt-3.5-turboin organization org-wDrZCxxxxxxxxxissoZb on requestsper min。 Limit: 3 / min. Please try again in 20s. Contact us through our help center   at help.openai.com   if you continue to haveissues. Please add a payment method toyour account to increase your rate limit.Visit https://platform.openai.com/account/billingto add a payment method.
```

请检查是否达到了官方接口调用速率限制。具体请参考 [OpenAI 官方文档说明](https://platform.openai.com/docs/guides/rate-limits)。

### 8. 用户自部署后，智聊不可使用，报错如下：**Unrecognized request argument supplied:functions**，该怎么解决？

首先请检查前后端版本是否是最新版且前后端版本保持一致；其次，该错误有可能是因为你使用了 Azure OpenAI 的 key，但没有成功部署模型，请检查你使用的 Azure OpenAI 里是否部署了模型；其中 gpt-3.5-turbo 模型版本必须是 0613 以上版本。（因为 0613 之前的版本不支持 智聊 所使用的 function call 能力，所以无法使用）

### 9. 设置 OpenAI Key 时，报错如下，是什么原因？

```JSON
Error communicating with OpenAl: HTTPSConnectionPool(host='api.openai.com', port=443): Max retriesexceeded with url: /v1/chat/completions (Caused byNewConnectionError( <urllib3.connection.HTTPSConnection object at 0x7f0462ed7af0>; Failed toestablish a new connection: [Errno -3] Temporary failure in name resolution'))
```

通常情况下是由于你的环境设置了代理，请检查是否设置代理。

### 10. 应用里切换模型使用时遇到如下报错，该怎么解决？

```JSON
Anthropic: Error code: 400 - f'error': f'type': "invalid request error, 'message': 'temperature: range: -1 or 0..1)
```

由于每个模型的参数取值不同，需要按照当前模型的该参数值范围设置。

### 11. 遇到如下报错提示，该如何解决？

```JSON
Query or prefix prompt is too long, you can reduce the preix prompt, or shrink the max token, or switch to a llm with a larger token limit size
```

在编排页参数设置里，调小“最大 token”的值即可。

### 12. Dify 里面默认的模型是什么，可否使用开源的模型？

默认的模型可以在 **设置 - 模型供应商** 处配置，目前支持 OpenAI / Azure OpenAl / Anthropic 等模型厂商的文本生成型模型，同时支持 Hugging Face/ Replicate / xinference 上托管的开源模型的接入。

### 13. 在社区版中，知识库开启 **Q\&A 分段模式**一直显示排队中，是什么原因？

请检查你所使用的 Embedding 模型 api-key 是否达到了速率限制。

### 14. 用户在使用应用时遇到报错“Invalid token”，该怎么解决？

如果遇到报错为 “Invalid token”，你可尝试如下两种解决办法：

* 浏览器清除缓存（Cookies、Session Storage 和 Local Storage），如果是手机里使用则清除对应 APP 的缓存，重新访问；
* 二是重新生成一个 App 网址，重新网址进入即可。

### 15. 知识库文档上传的大小限制有哪些？

目前知识库文档上传单个文档最大是 15MB，总文档数量限制 100 个。如你本地部署版本需要调整修改该限制，请参考[文档](./zh-hans/getting-started/faq/install-faq#11.-ben-di-bu-shu-ban-ru-he-jie-jue-shu-ju-ji-wen-dang-shang-chuan-de-da-xiao-xian-zhi-he-shu-liang)。

### 16. 为什么选择了 Claude 模型，还是会消耗 OpenAI 的费用？

因为 Claude 不支持 Embedding 模型，因此 Embedding 过程以及其他对话生成，下一个问题建议等默认都是用的 OpenAI 的 key，因此还是会消耗 OpenAI 的额度。也可以在**设置-模型供应商**里设置其他默认推理模型和 Embedding 模型。

### 17. 有什么方式能控制更多地使用上下文数据而不是模型自身生成能力吗？

是否使用知识库，会和知识库的描述有关系，尽可能把知识库描述写清楚，具体可参考[此文档编写技巧](./zh-hans/advanced/datasets)。

### 18. 上传知识库文档是 Excel，该如何更好地分段？

首行设置表头，后面每行显示内容，不要有其他多余的表头设置，不要设置复杂格式的表格内容。

如下方表格示例，仅需保留第二行的表头，首行（表格1）为多余表头，需删掉。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/faq/2bdf503188184f3c2973318e132160da.png)

### 19. 买了 ChatGPT plus，为什么在 dify 里还不能使用 GPT4？

OpenAI 的 GPT4 模型 API 和 ChatGPT Plus 是两个产品。模型的 API 有自己的定价，具体参考 [OpenAI 定价文档](https://openai.com/pricing) 。付费申请要先绑卡，绑了卡会有 GPT3.5 的权限，但没有 GPT4 的权限，GPT4 的权限得有一次支付的账单，具体参考 [OpenAI 官方文档](https://platform.openai.com/account/billing/overview)。

### 20. 如何增加其他的 Embedding Model？

Dify 支持以下作为 Embedding 模型使用，只需在配置框中选择 `Embeddings` 类型即可。

* Azure
* LocalAI
* MiniMax
* OpenAI
* Replicate
* XInference

### 21. 如何把自己创建的应用设置成应用模板？

该功能为 Dify 官方提供的应用模板供云端版用户参考使用，暂未支持将自己创建的应用设置成应用模板。如你使用云端版，可 **添加到工作区** 或 **自定义** 修改后成为你自己的应用。如你使用社区版，需要为团队内创建更多的应用模板，你可咨询我们商业化团队获得付费的技术支持：`business@dify.ai`

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/faq/llms-use-faq.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 插件
> 来源：`zh-hans/learn-more/faq/plugins.mdx`

> 以下常见问题与解决办法仅适用于 `1.0.0` 社区版本。

### 安装插件时遇到异常应如何处理？

问题描述：安装插件时遇到异常信息：`plugin verification has been enabled, and the plugin you want to install has a bad signature`，应该如何处理？

解决办法：在 `.env` 配置文件的末尾添加 `FORCE_VERIFYING_SIGNATURE=false` 字段即可解决该问题。添加该字段后，Dify 平台将允许安装所有未在 Dify Marketplace 上架（审核）的插件，可能存在安全隐患。

建议在测试 / 沙箱环境内安装插件，确认安全后再安装至生产环境。

如果你希望采取更加严格的措施控制插件的安装，请参考[第三方签名验证](./zh_hans/plugins/publish-plugins/signing-plugins-for-third-party-signature-verification.mdx)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/faq/plugins.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 应用案例
> 来源：`zh-hans/learn-more/use-cases/README.mdx`

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## AI 机器人开发：融云 IM 与 Dify 集成实战
> 来源：`zh-hans/learn-more/use-cases/ai-bot-rongcloud-dify-integration-guide.mdx`

> 作者：wangqijia｜融云开发者团队
> 日期：2025 年 6 月

## 1. 概述
[融云 IM PaaS](https://www.rongcloud.cn/) 通过与 Dify 平台的深度无缝集成，打通了 C 端用户与大语言模型（LLM）之间的端到端对话链路，支持流式响应和多轮上下文，广泛应用于智能问答、内容创作、情感陪聊等场景，助力企业构建高效、智能的用户交互体验。

平台提供完善的 [AI 机器人](https://docs.rongcloud.cn/platform-chat-api/bot/overview)管理能力，支持基于指定机器人触发更丰富的事件回调，帮助开发者灵活处理各类业务场景，例如：

* 与机器人发起单聊对话
* @ 机器人触发上下文响应

此外，平台内置 AI 平台对接能力，可将机器人消息自动转发至接入的大模型平台（如 Dify），省去中间处理服务，有效提升链路稳定性，降低接入成本，加快开发交付。

本指南将介绍如何基于融云 IM 平台集成 AI 机器人，并接入 Dify 平台大模型服务。

---

# 2. 高层设计

![图示](https://docs.rongcloud.cn/platform-chat-api/assets/bot/bot-dify-high-level-design.jpg)

**工作流程**:

1. **App Server**
  * 管理机器人，处理 Webhook 回调，接收机器人消息。
2. **用户终端**
  * 发送用户消息，接收机器人响应。
3. **IM Server**
* **消息转发**：根据回调类型（如 dify\_chat, dify\_completion）转发至 Dify 对应接口，支持流式/非流式模式。
* **响应处理与会话管理**：
  * 流式：实时推送 Dify 增量内容。
  * 非流式：整合完整文本后发送。
  * 会话上下文：存储首次交互的 conversation\_id（24 小时有效），后续对话携带此 ID 确保多轮上下文。
4. **Dify**
  * 接收消息，推理生成响应，返回流式数据或完整文本。

---

# 3. 接入与部署指南

本部分将帮助你快速完成部署与接入配置，开始使用融云机器人提供的智能对话体验。

## 3.1 准备工作

在开始集成机器人之前，请确保以下准备工作已完成：

* 已在 **融云开发者控制台** 创建应用，并获取有效的 App Key 和 App Secret。
* 已完成 Dify 的部署（支持自部署或使用云平台服务）。

## 3.2 机器人回调方式

用于将机器人集成到不同平台或系统中，当前支持以下回调方式：

| 类型                   | 描述                                 |
| -------------------- | ---------------------------------- |
| **webhook**          | 通过 Webhook 实现自定义回调，适用于灵活对接外部系统。    |
| **dify\_chat**       | 接入 Dify 平台的“聊天助手”模式，用于构建多轮对话机器人。   |
| **dify\_completion** | 接入 Dify 平台的“文本生成”模式，用于生成式内容应用场景。   |
| **dify\_chatflow**   | 接入 Dify 平台的“Chatflow”模式，用于流程化对话构建。 |

## 3.3 接入步骤

1. **创建 Dify 应用**：在 Dify 中创建应用，并获取对应的 API 密钥（API Key）。
2. **创建真实用户**：在系统中创建一个用于与机器人交互的真实用户账号。
3. **配置机器人与回调地址**：创建机器人，并配置消息回调地址。当用户向机器人发送消息时，消息将回调至您的系统或 Dify 平台。
4. **验证接入效果**：使用第二步创建的用户账号向机器人发送一条单聊消息，确认用户终端是否能收到来自 Dify 的对话响应。
5. **验证连续对话效果**：使用同一用户持续向同一机器人发送消息，验证对话上下文是否正确延续。融云将自动维持与 Dify 的上下文会话，实现连续对话体验。

⚠️ 注意：调用融云服务需进行身份认证，认证信息需通过工具脚本生成，具体使用方法见下文。

---

### 步骤 1：创建 Dify 应用

消息助手采用 dify\_chatflow 模式接入大模型服务，该模式支持记忆的复杂多轮对话工作流

![图示](https://docs.rongcloud.cn/platform-chat-api/assets/bot/create-dify-app.png)

你可以查看 [dify-chatflow-dsl.yml](https://docs.rongcloud.cn/platform-chat-api/assets/bot/dify-chatflow-dsl.yml) 来了解完整的 DSL 配置示例。

---

### 步骤 2：创建真实用户

```bash
curl -X POST "https://api.rong-api.com/v3/bot/create.json" \
  -H "App-Key: 填写您的App-Key" \
  -H "Nonce: 填写您的 Nonce" \
  -H "Timestamp: 填写您的 Timestamp" \
  -H "Signature: 填写您的Signature" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "userId=LoDld8izA"
```

---

### 步骤 3：配置机器人与回调地址

与 Dify 集成，可根据实际业务场景选择消息响应模式：

* **流式模式**：适用于大模型生成内容较长或需逐步生成的场景，系统将以流消息（Streaming）方式将响应内容实时发送至用户终端，提升响应速度与用户交互体验。
* **非流式模式**：适用于需要完整响应后再展示的场景，系统将在接收到完整内容后一次性发送给用户。

开发者可按需配置响应模式，灵活适配不同交互体验需求。

```bash
curl -X POST "https://api.rong-api.com/v3/bot/create.json" \
  -H "App-Key: 填写您的App-Key" \
  -H "Nonce: 填写您的 Nonce" \
  -H "Timestamp: 填写您的 Timestamp" \
  -H "Signature: 填写您的Signature" \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "bot-test004",
    "name": "消息助手",
    "type": "Message AI",
    "profileUrl": "https://cdn.jsdelivr.net/gh/microsoft/fluentui-emoji/assets/Robot/3D/robot_3d.png",
    "integrations": [
        {
            "type": "webhook",
            "callbackUrl": "https://yourserver.com/callback",
            "objectNames":["RC:TxtMsg"],
            "events":["message:private"]
        },
        {
            "type": "dify_chatflow",
            "callbackUrl": "https://api.dify.ai/v1",
            "stream": true,
            "auth": {
                "apiKey": "填写您的 api-key"
            }
        }
    ],
    "metadata": 
        "version": 1

}'
```

---

### 步骤 4：验证接入效果

使用第二步创建的用户账号向机器人发送一条单聊消息，确认用户终端是否能收到来自 Dify 的对话响应。

```bash
curl -X POST "https://api.rong-api.com/message/private/publish.json" \
  -H "App-Key: 填写您的App-Key" \
  -H "Nonce: 填写您的 Nonce" \
  -H "Timestamp: 填写您的 Timestamp" \
  -H "Signature: 填写您的Signature" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  --data-urlencode "fromUserId=BesqX1FTg33" \
  --data-urlencode "toUserId=bot-001" \
  --data-urlencode "objectName=RC:TxtMsg" \
  --data-urlencode 'content="content":"能给我几个 AI 应用场景的点子吗？","extra":""'
```

> 以下是演示效果，截图来自融云 Sealtalk APP Demo
<div style={{ display: 'flex', justifyContent: 'space-between' }}>
  ![图示1](https://docs.rongcloud.cn/platform-chat-api/assets/bot/send-bot-message.png)
  ![图示2](https://docs.rongcloud.cn/platform-chat-api/assets/bot/send-bot-message2.png)
</div>

---

### 步骤 5：验证连续对话效果

使用同一用户持续向同一机器人发送消息，验证对话上下文是否正确延续。融云将自动维持与 Dify 的上下文会话，实现连续对话体验。

![图示](https://docs.rongcloud.cn/platform-chat-api/assets/bot/send-bot-message3.png)

> Dify 日志显示共记录了 4 条消息，验证了多轮对话过程中上下文得以正确延续，说明聊天会话在同一上下文中持续进行。

![图示](https://docs.rongcloud.cn/platform-chat-api/assets/bot/dify-log.png)

---

# 4. 使用场景

## 4.1 消息助手：触发智能对话、任务执行、内容生成等功能

* 用户向 AI 提问知识类问题，机器人通过知识库或大模型进行回答；
* 发起内容生成请求，如“帮我写一封道歉邮件”；
* 发起内容翻译请求，如“将内容翻译为英文”；
* 发起指令请求，将消息分类同步到业务系统，如“创建工单”；
* FAQ 问答：解析用户意图并自动回复；

## 4.2 陪聊助手：打造具备情感陪伴与个性化交互能力的智能聊天机器人

* 提供持续自然的闲聊体验，满足用户日常交流需求；
* 模拟具有性格特征的角色（如朋友、心理咨询师、虚拟偶像等），提升互动趣味性与沉浸感；
* 根据用户的情绪变化进行适当回应，实现基础的情绪识别与关怀；
* 可与用户设定的虚拟人物设定结合，构建个性化陪伴场景（如“我的 AI 恋人”、“职场导师”）；

---

# 5. 使用建议

## 5.1 支持设置创建人元数据

在创建机器人时，支持为创建人设置自定义元数据（metadata）。该元数据会在消息回调时一并透传至 Dify，可用于提示词变量替换、上下文定制或流程编排，提升机器人响应的个性化与灵活性。

## 5.2 为不同场景配置独立机器人与 Dify 应用

建议根据具体业务场景（如知识问答、翻译、工具使用、陪聊等）创建不同类型的机器人，并为每个机器人配置独立的 Dify 应用与专属提示词，以实现更精准的能力定位与更优质的用户体验。

---

# 6. 工具脚本

## 6.1 生成融云 HTTP 请求签名

```python

def generate_rongcloud_signature(app_secret, nonce=None, timestamp=None):
    """
    生成融云 HTTP 请求签名

    参数:
        app_secret: 融云应用的App Secret
        nonce: 随机字符串(可选)，如果不提供将自动生成
        timestamp: 时间戳(可选)，如果不提供将使用当前时间

    返回:
        包含nonce, timestamp和signature的字典
    """
    if nonce is None:
        # 生成随机字符串(由数字和字母组成的6位字符串)
        nonce = ''.join(random.choices('0123456789abcdefghijklmnopqrstuvwxyz', k=6))

    if timestamp is None:
        # 获取当前时间戳(秒)
        timestamp = str(int(time.time()))

    # 计算签名
    signature_str = app_secret + nonce + timestamp
    signature = hashlib.sha1(signature_str.encode('utf-8')).hexdigest()

    return 
        'nonce': nonce,
        'timestamp': timestamp,
        'signature': signature

if __name__ == '__main__':
    # 替换为你自己的App Secret
    app_secret = 'YOUR_APP_SECRET'

    # 生成签名
    signature_data = generate_rongcloud_signature(app_secret)

    print("生成的融云签名信息:")
    print(f"Nonce: signature_data['nonce']")
    print(f"Timestamp: signature_data['timestamp']")
    print(f"Signature: signature_data['signature']")
```

---

# 结语

感谢您通过本指南深入了解了融云 IM PaaS 平台与 Dify 大模型服务的集成过程。这一结合不仅简化了开发者在智能机器人开发中的技术门槛，还通过高效的回调机制和多轮对话支持，赋予了应用更强的交互能力与商业价值。

无论是构建知识问答助手、内容生成工具，还是打造个性化的陪聊机器人，融云与 Dify 的协作都能为您提供稳定、高效的解决方案。

未来，随着 AI 技术的不断演进，我们将持续优化平台功能，增强与更多大模型平台的兼容性，并提供更多实用工具与文档支持。期待您在开发过程中提出宝贵意见，一同推动智能对话技术的进步。

如有任何问题，欢迎随时访问融云开发者社区或联系技术支持团队。

**祝您的开发之旅顺利，项目成功！**

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/ai-bot-rongcloud-dify-integration-guide.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 构建 AI 销售数字人
> 来源：`zh-hans/learn-more/use-cases/build-ai-sales-avatar.mdx`
> 摘要：作者：[Alec Lee](mailto:alec.lee1005@gmail.com)｜AX 全球战略师 & 全栈探索者。若您发现文中存在不足或改进空间，欢迎随时联系我。

本次选择的应用场景是：**名车 AI 数字导购**，她的名字叫 **Vendy**。我们将用最简单易懂的方式，一步步搭建一个会 “听、说、想、演” 的 AI 数字销售助理。  

![TEN AgentTalk](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/053TrulienceDifyFinal.jpg)

本项目所涉及的产品：Dify × TEN × Trulience × Azure × Agora × OpenAI。

---

## 项目介绍

“会听说想演”的 AI 数字人助理由哪部分构成？本项目将集成六大平台，构建一个具备完整对话能力的名品车 AI 销售数字人（AI Sales Avatar）——**Vendy**。

她能“**听、说、想、演**” —— 也就是：**聆听用户提问、思考应答、语音回复，并以数字人形象呈现**。

👇 下图展示了系统整体集成架构图：

![AI Sales Avatar](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/001AIsalesAvatar.jpg)

### 🧩 各平台在系统中的角色分工：

👇 下图展示了系统中各平台的集成模块与工作流程：

![Trulience 工作模块图](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/002Trulience.jpg)

### 📌 各平台功能说明：

- **Dify + OpenAI**：搭建智能体，支持调用企业内部数据与 OpenAI API，并向 TEN 提供统一的对话接口（API）。

- **Trulience**：提供数字人演绎能力，向 TEN 提供数字人 ID 与访问 Token，用于虚拟形象呈现。

- **Agora**：实现语音通信与视频通话，向 TEN 提供 App ID 与 Certificate（证书）。

- **Azure Speech**：提供语音识别（STT）与语音合成（TTS）服务，向 TEN 提供以下参数：  
  `AZURE_STT_KEY`、`AZURE_STT_REGION`、`AZURE_TTS_KEY`、`AZURE_TTS_REGION`

- **TEN（平台中枢）**：作为系统的中枢平台，统一集成并调度上述所有平台的 API、密钥与 Token， 实现 AI Sales Avatar —— **Vendy** 的整体智能对话流程与实时互动能力。

📌 **小提示**：上述平台均可根据实际需求，替换为其他开源或 SaaS 方案。  
本项目所用组合为参考示例，便于学习与复用。

## 搭建销售智能体“大脑”

我们首先将在 Dify 上完成三步操作，搭建出一个基于内部数据的 AI Sales Avatar “Vendy 本体”。  

---

### 🧩 Step 1：注册 Dify 账号并配置模型 API

👉 打开 [Dify 官网](https://dify.ai)，点击右上角 “Get Started”，开始注册流程。

登录 Dify 后，在左侧菜单点击 **「Settings > Model Provider」（模型提供商）**。在页面中找到 **OpenAI** 模块，点击 **Install** 进行安装。

![Dify Models](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/005DifyModels.jpg)

在 **OpenAI** 模块中，点击蓝色链接 **「Get your API Key from OpenAI」**，系统会自动跳转到 [OpenAI 官方平台](https://platform.openai.com/api-keys)。

![Dify OpenAI](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/006DifyOpenAI.jpg)

在 OpenAI 上点击 **「+ Create new secret key」** 生成新的 API 密钥。

复制生成的 Key，并返回 Dify，在 OpenAI 模块中粘贴如下字段：

![Dify OpenAI Key](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/007DifyOpenAIKey.jpg)

完成模型配置后，我们已经准备好了运行环境，  
现在可以开始在 Dify 上构建 AI Sales Avatar 的知识本体了。

---

### 🧩 Step 2：上传 AI Sales Avatar 所需的内部资料（知识文档）

在 Dify 控制台顶部菜单，点击 **「Knowledge」**，  
然后点击 **「Create Knowledge」** 创建一个新的知识数据集。

![Dify Data](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/008Difydatasets.jpg)

在接下来的页面中，选择资料上传方式，推荐使用 **「Import from file」** 方式。

👇 如下图所示：

![DifyUpload](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/009DifydataImport.jpg)

请上传你已经准备好的企业内部资料，如产品介绍、销售手册、常见问题文档等。  
若你还没有准备相关资料，也可以用 ChatGPT 辅助生成内容。

👇 例如我们用 ChatGPT 生成了一个名品车品牌介绍的 Word 文档（Lexus、Audi、BMW 等）：

![ChatGPTUpload](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/010DifydataChatGPT.jpg)

下载好文档后，回到 Dify 上传页面，选择 **「Import from file」**，上传该文件。  
上传成功后，点击右下角的 **「Next」**，继续下一步设置。

![Dify Next](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/011DifyImportNext.jpg)

默认设置已经适用于大多数场景，建议保持原样，直接点击 **「Save & Process」** 即可。  
（如需后续提升智能体的理解精度，也可根据实际需求调整相关参数）

![Dify 知识库配置保存与处理](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/012DifyEmbedding.jpg)

✅ 若你看到以下页面，表示你的文档已经成功上传并被 Dify 系统解析完成。

![DifydataSet](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/013DifyDataUploadSucess.jpg)

到这里，我们已经完成了智能体知识库的构建部分，  
下一步，我们将创建一个智能体应用，并接入这个知识库！

---

### 🧩 Step 3：创建智能体 App，并接入知识库

进入 Dify 控制台，点击顶部菜单栏的 **「Studio」**，再点击右上角的 **「Create」** 创建新 App。

在弹出窗口中填写以下内容：

- **App Name & Icon**：如 `AI Sales Avatar`
- **Description**：
Your name is Vendy, the AI Clerk of Luxury Cars.
Your task is to provide information about luxury cars to the customers based on the knowledge.

👇 设置界面如下所示：

![DifyAvatar](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/014DifySalesAvatarSetting.jpg)

点击 **Create** 后，会进入 App 的 **Orchestrate** 编辑界面。

在 **INSTRUCTION** 栏中填写与刚才 **Description** 一致的内容：

Your name is Vendy, the AI Clerk of Luxury Cars.
Your task is to provide information about luxury cars to the customers based on the knowledge.

然后，在下方的 **Knowledge** 区块中，选择我们刚刚上传的知识文档作为参考资料。

👇 配置界面如下所示：

![Dify AvatarData](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/015DifyAvatarData.jpg)

配置完成后，可以在右侧输入框测试是否能正常调用知识库内容。  
如果返回的内容基于上传的文档，就说明智能体连接成功 ✅

测试无误后，点击右上角的 **「Publish」**，发布这个 AI 应用。

![Dify AvatarTest](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/016DifyAvataRunTest.jpg)

应用发布后，点击左侧菜单栏中的 **「API Access」**，进入后点击右上角的 **「Create Secret Key」**。
这个 API Key 是后续在 TEN 平台接入时必须使用的，请务必复制保存好。

👇 接口密钥生成界面如下所示：

![Dify API Key](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/018DifyAPI2.jpg)

🎉 恭喜你！至此，我们已经完成了 AI Sales Avatar 的“智能体本体”搭建，  
并成功获得了用于调用的 API Key。

接下来，我们将进入 **Trulience 平台**，为 AI Sales Avatar 生成她的 “数字人外貌与演绎能力” ——  
也就是构建她的虚拟形象，让她不仅能“听、说、想”，还能真实地出现在用户面前，与人互动！

---

## 创建数字人形象

### 🧩 Step 4：注册 Trulience 账号，获取数字人的 ID 和访问 Token

现在，我们将为 AI Sales Avatar 赋予一个可视化的 “数字人形象”！  
我们将使用 [Trulience 平台](https://www.trulience.com/docs#/)来生成形象，并获取用于后续连接的 **Avatar ID** 与访问 **Token**。

✅ 操作流程如下：

1️⃣ 打开 [Trulience 官网](https://trulience.com)。

点击主页上的 **「Start For Free」** 按钮，开始注册账号。

👇 页面示意图如下：

![Trulience](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/019Trulience.jpg)

2️⃣ 注册完成后，进入后台界面。点击左侧菜单的 **「IMAGE AVATARS」**，  
选择一个女性角色作为 **Vendy** 的外貌，点击绿色按钮 **「Create Avatar」** 生成数字人。

👇 选择与创建界面示意图如下：

![Trulience Avatar](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/020TrulienceAvatar.jpg)

---

3️⃣ 当你看到 **“Avatar created”** 的提示时，说明数字人已经成功创建。

👇 创建成功提示界面如下所示：

![TrulienceAvatar2](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/021TrulieceAvatarCreation.jpg)

3️⃣ 我们将左侧的名称从默认的 **Amanda** 修改为 **Vendy**，  
此时你可以在下方看到她专属的 **Avatar ID**。

👇 如下图所示：

![Trulience 修改为 Vendy 并查看 Avatar ID](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/022TrulienceAvatarName.jpg)

---

4️⃣ 接下来，点击底部按钮 **「Connect」**，浏览器会跳转到一个新的页面。  
请从网页地址（URL）中复制 `token=` 后面的那段字符串，  
这就是你的 **访问 Token**。

建议将 **Avatar ID** 与 **Token** 一并复制保存好，稍后将在 TEN 平台中使用。

---

🎉 恭喜你！  
我们已经完成了 AI Sales Avatar 的“**外貌搭建**”，并成功获得了她的 Avatar ID 与访问 Token！

---

## 赋予数字人语音能力

### 🧩 Step 5：申请 Agora 与 Azure Speech

在将 Dify 的智能体、Trulience 的数字人接入 TEN 平台之前，我们需要提前准备好语音通信和语音识别/合成所需的账号与密钥，主要包括以下服务：

- Agora
- Azure Speech

---

#### ✅ 1. Agora 实时语音通信参数

TEN 使用 **Agora** 来实现语音通话能力（“她会说话”），需要准备以下参数：

- `AGORA_APP_ID=`（App ID）  
- `AGORA_CERTIFICATE=`（Certificate）

👉 获取方式：  
登录 Agora 控制台 [https://console.agora.io](https://console.agora.io) 创建一个新项目后，即可获取上述信息。

👇 控制台页面如下：

![Agora Project](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/023Agora.jpg)

登录账号后，点击左侧栏的 **「Projects」**，  
再点击右上角的 **「Create New」** 创建一个新项目。

👇 创建项目入口界面如下：

![AgoraNew](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/024AgoraCreate.jpg)

---

📝 **输入项说明**：

- **Project Name**：填写为 `AISalesAvatar`
- **Use Case**：选择合适的用途，例如 `Enterprise Collaboration`
- **Authentication Mode**：选择 **Secure Mode: APP ID + Token（推荐）**

填写完成后，点击 **「Submit」** 完成项目创建。

👇 创建成功后，即可获取 App ID 和 Certificate：

![Agora APP ID](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/025AgoraAPPID.jpg)

项目创建成功后，将跳转到项目管理页面。  
在项目列表中，点击 **App ID** 后方的复制按钮，即可获取 **App ID**。

👇 如图所示：

![AgoraApp IDGet](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/026AgoraAPPID2.jpg)

---

在获取 App ID 后，继续点击项目右侧的 ✏️ **铅笔图标（编辑按钮）**，进入项目详情页。

在页面底部的 **Primary Certificate** 区域，点击右侧的复制按钮，  
即可复制该项目的 **Certificate**。

👇 如下图所示：

![Agora Certificate](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/027AgoraCertificate.jpg)

至此，我们已经成功获取 **Agora 的 App ID 和 Primary Certificate**，  
为后续在 TEN 平台启用语音通信功能做好了准备。

📚 如需进一步了解，可参考 [Agora 官方技术文档](https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project)。

---

#### ✅ 2. Azure Speech 参数（语音识别 + 语音合成）

**Azure** 负责将用户的语音转为文字（STT），并将 AI 回复转成语音（TTS）。  
需要准备以下 4 个环境变量：

- `AZURE_STT_KEY`
- `AZURE_STT_REGION`
- `AZURE_TTS_KEY`
- `AZURE_TTS_REGION`

👉 获取方式如下：

打开 Azure Portal，请登录 [Azure 官方门户网站](https://portal.azure.com)：  

在首页点击左上角的 **「Create a resource（创建资源）」**，  在搜索栏中输入 **Azure OpenAI**，点击进入创建页面。

👇 创建入口界面如下：

![Azure Resource](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/028Azure.jpg)

---

参考以下内容，填写基本信息（**Basics**）：

![Azure OpenAI List](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/029AzureOpenAI.jpg)

---

通常默认选择 **「公共访问」** 即可，允许服务通过互联网访问：

![Azure OpenAI Public](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/030AzureCreateAzureOpenAI.jpg)

🧩 可选步骤：你可以为资源添加如 `project=ai-agent` 等标签，便于后续分类与管理。

👇 标签与网络配置界面如下：

![Azure resourceset](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/031AzureNetwork.jpg)

---

📝 确认填写信息无误后，点击 **「Create（创建）」** 按钮，即可开始部署 Azure OpenAI 服务资源。

👇 创建部署确认界面：

![Azure createconfirm](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/032AzureReview.jpg)

👇 资源部署中画面如下：

![Azure deploy](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/033AzureDeployment.jpg)

---

部署完成后，进入 **Azure AI Foundry**，你将看到如下欢迎界面，  
可用于快速创建项目与选择模型：

![Azure AI Foundry](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/034AzureAIFoundry.jpg)

---

进入 **「Model Catalog（模型目录）」** 页面后，选择 **Azure AI Speech**：

![Azure Speech model](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/035AzureModels.jpg)

点击 **Azure-AI-Speech** 模型后，进入其详细页面，  
点击页面上方的 **「Use Service」** 按钮，即可跳转进入 Speech Playground 页面：

![Azure Speech entry](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/036AzureUseService.jpg)

进入 **Speech Playground**，选择你的语音服务资源（如下图所示），  
即可看到对应的 **API Key** 和 **Region**：

![Azure STT KeyRegion](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/037AzureSTTKey.jpg)

---

点击 **「Text to Speech」** 标签，进入 **Voice Gallery**，  
可试听多种语音风格，选择最适合你 AI Avatar 的声音类型：

![Azure TTS](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/038AzureTTSmodels.jpg)

---

点击 **「View Code」**，即可复制当前语音服务的 **API Key 和 Region**：

![AzureAPI KeyRegion](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/039AzureTTSKey.jpg)

---

🎉 **恭喜你！**  
至此，我们已经完成了 **TEN 平台运行所需的所有参数准备工作 ✅**

---

🧱 下一步，我们就可以正式在本地启动 TEN Agent 平台。并将前面搭建的所有模块：

- 🧠 智能体（Dify）
- 🔊 语音能力（Azure Speech + Agora）
- 👩‍💻 虚拟形象（Trulience）

**完整串联起来，构建真正“听说想演”的实时 AI 数字销售助理！**

---

📚 如需进一步了解 Azure Speech 与 OpenAI 服务部署，参考[官方文档](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)。

## 调试数字人语音交互系统

### 🧩 Step 6：本地部署 TEN Agent

为了运行并调试 AI Sales Avatar 的语音交互系统，需要在本地准备好 **TEN Agent 的开发环境**。

---

#### 前置准备

🔧 所需工具与安装方式一览：

| 工具     | 功能说明                  | 安装方式                         |
|----------|---------------------------|----------------------------------|
| Docker   | 运行 TEN 的容器环境        | 官网下载安装 Docker Desktop     |
| Git      | 克隆并管理 TEN 的代码仓库  | `brew install git`              |
| Node.js  | 运行前端代码（Playground） | `brew install node`             |

---

##### ✅ ① 安装 Docker

💡 Docker 是 TEN 平台的核心运行环境，所有模块都将以容器形式部署。

- 打开官网链接：👉 [https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)  
- 下载适用于 macOS 的 `.dmg` 安装包，并完成安装。
- 安装后，点击应用列表中的 Docker 图标启动。
- 等待顶部菜单栏的 🐳 图标变为绿色 表示已成功启动。
- 打开 Terminal，输入以下命令验证是否成功安装：
  ```bash
  docker -v

##### ✅ ② 安装 Git

💡 Git 是用来克隆和管理 TEN 框架代码的版本控制工具。

安装命令：`brew install git`。

验证安装：`git -v`。

##### ✅ ③ 安装 Node.js

💡 Node.js 是运行 TEN 的前端 Playground 所必需的环境。

安装命令：`brew install node`。

验证安装：`node -v`。

##### ✅ ④ 克隆 TEN Agent 框架代码

完成 Docker、Git、Node 安装后，下一步就是克隆 TEN Agent 的源代码，并配置 .env 环境变量。

🚀 1. 克隆 TEN Agent 代码仓库
在 Terminal 中执行以下命令：git clone https://github.com/TEN-Framework/TEN-Agent.git

执行后，会在本地创建一个 TEN-Agent 文件夹，
其中包含所有运行所需的代码和配置文件。

👇 如下图所示：

![TEN Clone](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/040TEN.jpg)

📦 2. 进入项目目录并复制环境变量模板
进入 ai_agents 子目录，并复制环境变量文件：

cd TEN-Agent/ai_agents
cp .env.example .env

.env 是 TEN Agent 运行所需的环境变量配置文件，
接下来你需要手动编辑它，输入密钥信息（来自 Dify、Trulience、Azure、Agora）。

👇 示例界面如下：

![TEN Agent .env](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/041TEN.jpg)

✍ 3. 编辑 `.env` 文件，填写以下变量：

请使用文本编辑器（推荐使用 **Cursor** 或 **VS Code**）打开并编辑 `.env` 文件，  
在文件末尾添加以下内容（填写你自己的密钥和区域信息）：

Agora App ID 和 Certificate
AGORA_APP_ID=your_agora_app_id
AGORA_APP_CERTIFICATE=your_agora_certificate

Azure 语音识别（STT）参数
AZURE_STT_KEY=your_stt_key
AZURE_STT_REGION=your_stt_region

Azure 语音合成（TTS）参数
AZURE_TTS_KEY=your_tts_key
AZURE_TTS_REGION=your_tts_region

👇 编辑 `.env` 文件示意图如下：

![TEN .env](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/042TENCursor.jpg)

##### ✅ Step ⑤：启动 TEN Agent 容器，编译并运行 Server

在 `.env` 环境变量配置完成后，下一步是正式启动 **TEN Agent 的容器环境**。

---

### 🐳 启动容器

进入 `ai_agents` 目录并启动 Docker 容器服务：

cd ai_agents

docker compose up -d

这会启动以下容器服务：

ten_agent_dev：用于开发和运行 Agent

ten_agent_demo：示例 Agent

ten_agent_playground：前端交互页面

👇 项目结构示意图如下：

![TEN Agent ai_agents 目录结构](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/043TENaiagents.jpg)

### 🔧 进入容器并编译 Agent Server

执行以下命令，进入开发容器：docker exec -it ten_agent_dev bash

进入容器后，执行初始化任务脚本来注册 Agent：task use

👇 项目结构示意图如下：

![task use](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/044TENtaskuse.jpg)

该命令将自动读取并链接 Agent 的配置文件（如 `manifest.json` 和 `property.json`），并自动安装所需依赖包。

👇 执行过程示意图如下：

![TEN task run](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/045TENTaskRun.jpg)

✅ 完成 `task run` 后，在浏览器中访问以下地址以打开前端页面：

👉 [https://localhost:49483]

如果运行成功，你将看到如下界面：

点击页面上方的 **「Graph」** 选项卡。

在下拉框中选择：  
➡️ **`voice_assistant_intergrated_stt (Auto Start)`**，  
然后点击右下角的 **「Save」** 保存配置。

👇 页面示意图如下：

![TEN Agent Playground](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/046TEN494483.jpg)

### ✅ 替换语音合成（TTS）模块为 **Azure 引擎**

1. 找到图中的 **TTS 模块**（如 `tts_default`）  
2. 鼠标右键点击该模块，选择 **「Replace Node with」**  
3. 在弹出的列表中选择 **`azure_tts`**

这样就完成了语音合成模块的替换.

👇 Azure TTS 模块替换示意图如下：

![TEN Agent Azure TTS Change](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/047TENAzuretts.jpg)

### 🎙️ 关于数字人的声音设置（TTS 语音）

我们可以根据数字人的形象需求，自定义她的声音。在 Microsoft 提供的语音服务页面中，列出了所有支持的语音名称。

👉 [访问地址](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts#multilingual-voices)。

---

在本例中，我们选择的是一位英文女声：

🗣️ **`en-US-AshleyNeural`**

在 Azure TTS 模块中，请将以下字段填写为：

`Azure_synthesis_voice_name=en-US-AshleyNeural`

👇 Azure TTS 语音名称设置示意图如下：

![TEN Azure_synthesis_voice_name](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/048TENAzureVoice.jpg)

### 🔁 替换 LLM 模块为 Dify 智能体

1. 右键点击 **`llm` 模块**，选择 **「Replace Node with」**  
2. 在弹出的列表中选择 **`dify_python`**

这样即可将 TEN Agent 的大语言模型（LLM）模块，接入 Dify 提供的智能体接口。

👇 操作示意图如下：

![TEN Agent Dify](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/049TENDifyAPI.jpg)

2️⃣ 完成替换后，再次右键点击新生成的 **`dify_python` 模块**，  点击 **「Update Properties」**，进入属性设置页面。

- 在 **API Key** 字段中，输入你在 Dify 平台上创建的 API Key  
- 在 **Greeting** 字段中，可以根据需求自定义欢迎语（如欢迎语音问候）

👇 设置界面示意图如下：

![TEN AgentDify API KeyGreeting](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/050TENDifyAPI2.jpg)

## ✅ 启动 TEN Agent 并连接 Trulience 数字人

---

### 🚀 启动前端页面

配置完成后，打开浏览器，访问以下地址，即可进入 TEN Agent 启动界面：

👉 [http://localhost:3000](http://localhost:3000)

👇 页面示意图如下：

![TEN Agent](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/051TEN3000.jpg)

🧠 选择智能体流程图（Graph）

1. 点击右上角的 **「Select Graph」**，在下拉菜单中选择：  
   ➤ `voice_assistant_integrated_stt`

2. 勾选 **「Enable Trulience Avatar」**，并填写以下字段：

   - **Avatar ID**（在 Trulience 创建数字人时获得）
   - **Avatar Token**（点击 Connect 后，从浏览器地址栏中复制）

3. 填写完成后，点击 **「Save changes」** 保存设置。

👇 配置界面如下图所示：

![TEN AgentTrulience](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/052TENTrulienceGrah.jpg)

🗣️ 启动语音互动，测试数字人是否连通成功

✅ 点击右上角的 **「Connect」** 按钮，完成最后测试。

如果一切配置正确，将出现以下情景：

- 🧍 数字人形象自动加载显示  
- 🗣️ 她会用自然语音向你问候，并提问，例如：  
  _“我能为你介绍哪几款豪华车？”_

- 🤖 你可以根据她的回答，验证她是否成功读取并理解了 Dify 知识库的内容。

👇 运行示意图如下：

![TEN AgentTalk](https://raw.githubusercontent.com/aleclee1005/AISalesAvatar/img/img/053TrulienceDifyFinal.jpg)

🎯 恭喜你！你现在已经拥有了完整的 **AI Sales Avatar**！

## 总结

✅ 来自 **OpenAI / Dify** 的聊天大脑  
✅ 使用 **Azure** 的自然语音合成能力（女声）  
✅ 拥有 **Trulience** 的数字人形象  
✅ 构建于 **TEN 平台** 的语音交互能力

🌟 这就是 AI Agent 最核心的完整链路：**“听 → 想 → 说 → 演 → 链接”**

📚 如需进一步了解，可参考 TEN 官方技术文档：  
👉 [https://theten.ai/docs/ten_agent/architecture_flow](https://theten.ai/docs/ten_agent/architecture_flow)

## 🛠️ 下一步扩展建议（基于 AX 架构）

在目前已搭建的「AI Sales Avatar」基础上，  
我们可以依照 **AX Architecture** 的路径，进一步扩展它在实际业务场景中的能力，  
逐步打通：  
**数据 → 模型 → 代理 → 用户接口 → 全业务生命周期管理** 的闭环链路。

---

### 🧑‍💼 嵌入网页首页，作为公司虚拟形象代表

结合 **Trulience** 的 D-Human & Avatar 能力，  
将当前数字人部署到公司首页或 Web App，  
通过自然语音问答引导访客、收集意图，构建以用户为中心的入口，承接：

- `Marketing Info`  
- `Customer Lifecycle`

---

### 📦 接入数据库 & 订单管理系统，进阶为“AI 销售代表”

将 Avatar 与公司内部系统对接，例如：

- CRM、ERP、OA、订单系统（如 Salesforce、SAP、Notion DB 等）

实现：
- 销售线索管理  
- 库存查询  
- 合同生成等闭环任务  
服务于：

- `Contract Lifecycle`  
- `Asset Lifecycle`
---

### 🔗 接入企业核心平台：从“个体应用”迈向“组织级协同”

你可以进一步将 Agent PF（平台）能力模块化，  
嵌入不同 BU 的 Data Lake 与工作流管理平台，  
实现以下多业务融合扩展场景：

- AI + Finance  
- AI + HR  
- AI + R&D  
- AI + SNS（协作）

最终推动企业整体的 AI 转型升级。

## ✨ 写在最后：一点感言

我始终相信，AI 不应只是冰冷和强大的工具，  
它更可以是人类温暖的伙伴，是个体能力的延伸与放大器。

未来，也许会有越来越多像 “**Vendy**” 这样的数字伙伴，在世界各地悄然诞生——  
她们**倾听、思考、回应、表达**，用技术的力量，守护人的尊严与创造力。

---

📣 若您也愿意加入这场全球共创的旅程，  
欢迎携手探索与分享，让每一位个体都有机会与 AI 一同成长，  
共同探索 **“一以当千、不落一人”** 的 AX 新时代。

---

谨以此文作为一次小小的尝试与记录，  
愿它化作一颗微小的种子，  
在人与 AI 和谐共生的未来中，**悄然生根、缓缓发芽。**

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/build-ai-sales-avatar.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 构建一个 Notion AI 助手
> 来源：`zh-hans/learn-more/use-cases/build-an-notion-ai-assistant.mdx`

_作者：阿乔. Dify 用户_

### 概述

Notion 是一个强大的知识管理工具。它的灵活性和可扩展性使其成为一个出色的个人知识库和共享工作空间。许多人使用它来存储他们的知识，并与他人协作，促进思想交流和新知识的创造。

然而，这些知识仍然是静态的，因为用户必须搜索他们需要的信息并阅读其中的内容才能找到他们寻求的答案。这个过程既不特别高效，也不智能。 你是否曾经梦想过拥有一个基于你的 Notion 库的 AI 助手？这个助手不仅可以帮助你审查知识库，还可以像一位经验丰富的管家一样参与交流，甚至回答其他人的问题，就好像你是自己的个人 Notion 库的主人一样。

### 如何实现自己的 Notion AI 助手?

现在，你可以通过 Dify 来实现这个梦想。Dify 是一个开源的 LLMOps（大型语言模型运维）平台。 ChatGPT 和 Claude 等大型语言模型已经利用其强大的能力改变了世界。它们的强大学习能力主要归功于丰富的训练数据。幸运的是，它们已经发展到足够智能的程度，可以从你提供的内容中进行学习，从而使从个人 Notion 库中生成创意成为现实。 在没有 Dify 的情况下，你可能需要熟悉 langchain，这是一个简化组装这些要素过程的抽象概念。

### 如何使用Dify创建自己的AI助手?

训练Notion AI助手的过程非常简单。你只需要按照如下步骤操作:

1.登录 Dify。

2.创建一个知识库。

3.将 Notion 和知识库连接起来。

4.开始训练。

5.创建自己的AI应用程序。

#### 1. 登录 Dify

点击这里登录到 Dify。你可以使用你的 GitHub 或 Google 账户方便地登录。

> 如果你使用 GitHub 账户登录，不妨给这个[项目](https://github.com/langgenius/dify)点个星星吧？这真的对我们有很大的支持！

#### 2.创建新的知识库

点击顶部侧边栏的 "Knowledge" 按钮，然后点击 "Create Knowledge" 按钮。

#### 3. 与 Notion 和你的知识库进行连接

选择 "Sync from Notion"，然后点击 "Connect" 按钮。

然后，你将被重定向到 Notion 登录页面。使用你的 Notion 帐户登录。使用你的 Notion 帐户登录。

检查 Dify 所需的权限，然后单击“选择页面”按钮。

选择你要和 Dify 同步的页面，然后点击“允许访问”按钮。

![](https://assets-docs.dify.ai/2025/03/fe00306264fa0334c6f96ba049460d08.png)

#### 4. 开始训练 <a href="#id-4-start-training" id="id-4-start-training"></a>

指定需要让 AI 学习的页面，使其能够理解 Notion 中这个部分的内容。然后点击 "下一步" 按钮。

![](https://assets-docs.dify.ai/2025/03/4e86d66f5ce46b2043f0eb9165a73572.png)

我们建议选择 "自动" 和 "高质量" 的选项来训练你的 AI 助手。然后点击 "保存并处理" 按钮。

![](https://assets-docs.dify.ai/2025/03/21184bca8647509abc58c75ad3002582.png)

等待几秒钟，embedding 处理进程完成。

![](https://assets-docs.dify.ai/2025/03/73cddadbf3b34edda974f8f47165d988.png)

#### 5. 创建你自己的 AI 应用程序[​](https://wsyfin.com/notion-dify#5-create-your-own-ai-application) <a href="#id-5-create-your-own-ai-application" id="id-5-create-your-own-ai-application"></a>

你需要创建一个AI应用，然后连接刚刚创建的知识库。返回到仪表板，然后点击“创建新应用”按钮。建议直接使用聊天应用。

![](https://assets-docs.dify.ai/2025/03/8e91ce29dd346b3edd0f26a261e27ad2.png)

选择“Prompt Eng.”并在“context”中添加你的 Notion 知识库。

![](https://assets-docs.dify.ai/2025/03/853c348bfc86a2f845a7698fe715f6f1.png)

我建议在你的 AI 应用程序中添加一个「预设提示」。就像咒语对于哈利·波特来说是必不可少的一样，某些工具或功能可以极大地增强 AI 应用程序的能力。

例如，如果你的 Notion 笔记主要关注软件开发中的问题解决，可以在其中一个提示中写道：

> 我希望你能在我的 Notion 工作区中扮演一个 IT 专家的角色，利用你对计算机科学、网络基础设施、Notion 笔记和 IT 安全的知识来解决问题。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/en/learn-more/use-cases/f5a5e95e1120906669b3c1ad4e186dea.png)

建议初始时启用 AI 主动提供用户一个起始句子，给出可以询问的线索。此外，激活「语音转文字」功能可以让用户通过语音与你的 AI 助手进行互动。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/en/learn-more/use-cases/ffa36d0313dba8ac4255424c4f880191.png)

现在你可以在“概览”中单击公共 URL 聊天与你自己的 AI 助手！

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/en/learn-more/use-cases/1f8c6f7d7f3d61a1928d25ab85f7b1ff.png)

### 通过API集成到你的项目中​

通过 Dify 打造的每个 AI 应用程序都可以通过其 API 进行访问。这种方法允许开发人员直接利用前端应用程序中强大的大型语言模型（LLM）的特性，提供真正的“后端即服务”（BaaS）体验。

通过无缝的 API 集成，你可以方便地调用你的 Notion AI 应用程序，无需复杂的配置。

在概览页面上点击「API 参考」按钮。你可以将其作为你应用程序的 API 文档参考。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/en/learn-more/use-cases/4062ac40525d573f14a8059a6605688a.png)

#### 1. 生成 API 密钥 <a href="#id-1-generate-api-secret-key" id="id-1-generate-api-secret-key"></a>

为了安全起见，建议生成 API 密钥以访问你的 AI 应用。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/en/learn-more/use-cases/b2546aa50caff4316798edc0b950661d.png)

#### 2.检索会话ID <a href="#id-2-retrieve-conversation-id" id="id-2-retrieve-conversation-id"></a>

与 AI 应用程序聊天后，你可以从“Logs & Ann.”页面检索会话 ID。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/en/learn-more/use-cases/6feec1081814299c574b5fb4af3f2bb8.png)

#### 3. 调用API <a href="#id-3-invoke-api" id="id-3-invoke-api"></a>

你可以在API文档上运行示例请求代码来调用终端中的AI应用程序。

记住替换代码中的SECRET KEY和conversation_id。

你可以在第一次输入空的conversation_id，在收到包含conversation_id的响应后将其替换。

```
curl --location --request POST 'https://api.dify.ai/v1/chat-messages' \
--header 'Authorization: Bearer ENTER-YOUR-SECRET-KEY' \
--header 'Content-Type: application/json' \
--data-raw '{
    "inputs": {},
    "query": "eh",
    "response_mode": "streaming",
    "conversation_id": "",
    "user": "abc-123"
}'
```

在终端中发送请求，你将获得成功的响应。

![](https://assets-docs.dify.ai/2025/03/fb57e6a8fdb61fbc7b3c3d42f32d2ca5.png)

如果你想继续此聊天，请将请求代码的`conversation_id`替换为你从响应中获得的`conversation_id`。

你可以在`"Logs & Ann "`页面查看所有的对话记录。

### 周期性地与 Notion 同步

如果你的 Notion 页面更新了，你可以定期与 Dify 同步，让你的人工智能助手保持最新状态。你的人工智能助手将从新内容中学习并回答新问题。

![](https://assets-docs.dify.ai/2025/03/5a2b362a900401b85f1ba69414edf076.png)

### 总结

在本教程中，我们不仅学会了如何将你的 Notion 数据导入到 Dify 中，还学会了如何使用 API 将其与你的项目集成。

Dify 是一个用户友好的 LLMOps 平台，旨在赋予更多人创建可持续的 AI 原生应用程序的能力。通过为各种应用类型设计的可视化编排，Dify 提供了可供使用的应用程序，可以帮助你利用数据打造独特的 AI 助手。如果你有任何疑问，请随时与我们联系。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/build-an-notion-ai-assistant.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 在 Dify 云端构建 AI Thesis Slack Bot
> 来源：`zh-hans/learn-more/use-cases/building-an-ai-thesis-slack-bot.mdx`

> 作者：Alec Lee。2025/03/11

## 1. 概述

随着信息时代的发展，学术研究的数量不断增长，研究人员需要更高效的方式获取最新的学术成果。AI Thesis Slack Bot 通过 AI 自动化工作流，帮助用户在 Slack 上快速获取 arXiv 论文的摘要。

它可以用于：

* 研究团队获取最新学术动态  
* 公司 AI 研究部门内部信息同步  
* 高校师生进行科研协作等场景需求

本指南将向您介绍如何搭建 AI Thesis Slack Bot，其核心工作原理，以及如何高效利用它提高生产力。

## 2. 准备工作

### 2.1 配置 OpenAI API

* 在帐户下的模型设置里配置 OpenAI 并安装 API 密钥。

![API](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/001API.jpg)

### 2.2 安装 ArXiv 和 Slack 插件

* 在 Dify 的工具里安装 **ArXiv** 和 **Slack**。

![Slack ArXiv](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/002SlackArXiv.jpg)

### 2.3 Slack 账户创建

* 在 [Slack 官方网站](https://slack.com/intl/en-gb/get-started?entry_point=help_center#/createnew) 创建一个免费的 Slack 账户。

![Slack](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/003SlackAccount.jpg)

## 3. AI Thesis Slack Bot 的工作流搭建

a.用户在 Dify AI Thesis Slack Bot 里输入关键词（如"Large Language Model"）。 

b.机器人从 arXiv 检索相关论文，筛选最新的研究成果（例2024 年 1 月 1 日后的论文）。 

c.使用 GPT-4o 进行智能整理，读取论文并生成摘要，推送到 Slack 指定的 Channel 里，格式如下：

* 📄 论文标题  
* 👤 作者  
* 📆 发布日期  
* 📌 核心内容概述 

d.机器人自动将摘要推送到 Slack，团队成员可以第一时间在 Slack 频道或私聊中查看最新的论文信息。

## 4. 具体步骤

#### 4.1 创建工作流

a.在 Dify 主页面 选择 Create from Blank，然后选择 Workflow，输入名称（AI Thesis Slack Bot）。

![Create from Blank](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/004Createfromblank.jpg)

  b.在 Tools 里 选择已安装好的 ArXiv Search。

![Tools ArXiv](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/005ToolsArXiv.jpg)

c.在节点里选择 LLM，并设置已配置好的 OpenAI 模型。

![LLM](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/006LLM.jpg)

d.在 Tools 里 选择已安装的 Slack Incoming Webhook 并点击 Authorize，添加 Slack Webhook URL。

![Slack Incoming Webhook](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/007Slackincomingwebhook.jpg)

#### 4.2 添加 Slack Webhook URL

a.进入 [Slack API 管理页面](https://api.slack.com/apps)，点击 **Create New App**（创建新应用）。

![Slack API](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/008Slackapi.jpg)

b.选择 "From scratch"（从零开始），输入应用名称（如 AI Thesis Bot），选择要发送消息的 Slack 频道。

![From Scratch](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/009Fromscratch.jpg)

c.进入 Incoming Webhooks，激活 Activate Incoming Webhooks。点击 Add New Webhook to Workspace，选择 Slack 频道，复制生成的 Webhook URL。

![Incoming Webhooks Activate](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/010IncomingwebhooksActivate.jpg)

d.粘贴 Webhook URL 到 Slack 节点 的 Slack Webhook URL 位置。

![Slack Webhook URL](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/011SlackWehookURL.jpg)

e.选择工作流最后一个节点End后，整理工作节点组建都链接好了。下面就需要配置各个节点上的参数。

![End](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/012End.jpg)

#### 4.3 配置各个节点的参数

a.Start 节点：设置关键词查询参数。

![Start](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/013StartNode.jpg)

b.ArXiv Search 节点：添加 Query String 内容（可按需求调整）。

![ArXiv Search](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/014ArvPara.jpg)

c.LLM 节点：选择模型,添加 CONTEXT,在 SYSTEM 里进行 Prompt Engineering（可按需求定制）,在 USER 里选择 Context.

![LLM Context](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/015LLMcontext.jpg)

d.Slack 节点：在 Content 里选择 LLM/Text String。

![Slack Content](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/016SlackEndP.jpg)

#### 4.4 测试和发布

a.在发布前 **试运行**，确认工作流程是否跑通后，点击 发布。

![Shiyunxing](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/018TestInupt.jpg)

b. 如果确认到 Dify 的搜索结果和 Slack 上的传输内容，恭喜您，跑通了。 

![Last P](https://raw.githubusercontent.com/aleclee1005/MyPic/refs/heads/img/019LastPTest.jpg)

## 5. 未来优化方向

目前，AI Thesis Slack Bot 主要专注于 arXiv 论文检索和摘要推送，后续可以优化： 
✅ 提高摘要质量：改进 LLM Prompt 提高精准度。 
✅ 积累检索结果：建立数据库存储历史论文。 
✅ 扩展更多数据源：支持 IEEE、Springer、ACL 等。 
✅ 个性化推荐：基于用户兴趣推送相关论文。 
✅ 多平台支持：兼容 WhatsApp、Teams、WeChat 等。

## 6. 结语

通过 AI Thesis Slack Bot，您可以实现学术信息的智能自动化推送，提升研究团队的生产力。如果希望进一步探索 AI Thesis Bot 的潜能，可以结合 Dify 和 Realtime API，开发更高级的应用，如 实时论文讨论 和 智能问答，让 AI 在学术交流和 AI 应用中发挥更大作用！ 🚀

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/building-an-ai-thesis-slack-bot.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 将 Dify 快速接入 QQ、微信、飞书、钉钉等平台
> 来源：`zh-hans/learn-more/use-cases/connect-dify-to-various-im-platforms-by-using-langbot.mdx`

## 1. 概述

市面上有多种多样的 IM 平台，接入机器人的方法各不相同，使用难度也参差不齐，导致难以快速接入 Dify 等 LLMOps 平台，使用 Dify 的强大生态。而借助 [LangBot](https://github.com/RockChinQ/LangBot)，即可在短时间内将 Dify 接入到 QQ、微信、飞书、钉钉、Telegram、Discord、Slack 等平台提供服务。同时，LangBot 还提供扩展机制和丰富的生态，能更加灵活地满足需求。

## 2. 部署 LangBot

### 2.1. 部署 LangBot

你可以通过以下三种方式部署 LangBot：

1. Docker 部署：[对应链接](https://docs.langbot.app/zh/deploy/langbot/docker.html)
2. 手动部署：[对应链接](https://docs.langbot.app/zh/deploy/langbot/manual.html)
3. 使用宝塔面板部署：[对应链接](https://docs.langbot.app/zh/deploy/langbot/one-click/bt.html)

### 2.2. 对接消息平台

参考[此页面](https://docs.langbot.app/zh/deploy/platforms/readme.html)，选择你要用的消息平台，如 QQ、微信、飞书、钉钉、Telegram、Discord等。

## 3. 接入 Dify

LangBot 使用`流水线`控制对消息的处理。首次启动时，LangBot 会自动创建一个默认流水线，请到流水线配置页面，点击打开流水线配置。  
选择`AI 能力`页，将运行器切换成`Dify 服务 API`。

![](https://assets-docs.dify.ai/2025/05/6c5bdb9df53b2bb243c369f458222d2d.png)

在其中填写您的 Dify 服务的 API 接口地址、Dify 应用类型和 API Key，完成后即可在即时通信软件上与机器人对话。

使用工作流应用时，请使用`summary`作为键传回工作流运行结果。

![](https://assets-docs.dify.ai/2025/05/9c1c34feb27eab149ee78b706af25eee.png)

当使用工作流时，LangBot 会显式传入以下参数，您可以自行在 Dify 工作流的开始节点中添加：

- `user_message_text`：用户消息的纯文本
- `session_id`：用户会话id，私聊为 `person_<id>`，群聊为 `group_<id>`
- `conversation_id`：字符串，用户会话id，由 LangBot 生成。用户重置会话后，会重新生成
- `msg_create_time`：数字类型，收到此消息的时间戳（秒）

您可以[通过插件自定义任何变量](https://docs.langbot.app/zh/plugin/dev/api-ref.html#设置请求变量)

![](https://assets-docs.dify.ai/2025/05/3032be4f7d97bfbeba98217eb8aaf925.png)

- 详细的说明请查看 LangBot 文档

## 4. 效果展示

> 下面仅为微信和飞书的示例，其他平台如 QQ、钉钉、Telegram 等平台均可接入。

![](https://assets-docs.dify.ai/2025/03/88bfcb4e72ab852069d49104ad7aa51d.png)

![](https://assets-docs.dify.ai/2025/03/9682c62f9bcafcffb0b61c2b0f5a6cb1.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/connect-dify-to-various-im-platforms-by-using-langbot.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 教你十几分钟不用代码创建 Midjourney 提示词机器人
> 来源：`zh-hans/learn-more/use-cases/create-a-midjoureny-prompt-word-robot-with-zero-code.mdx`

> 作者：歸藏的 AI 工具箱

试用了一下前几天我周刊里推荐的自然语言编程工具 Dify，它是 @goocarlos 开发的能够让一个不会代码的人只通过编写提示词生成一个 Web 应用，甚至连 API 也生成好了，你可以接入以后部署到你希望部署的平台上去。

下面这个应用就是我花 20 分钟写的，效果非常好，如果没有 Dify 我可能需要搞好久才能搞定。具体的功能就是根据输入的简短的主题生成 Midjourney 的提示词，也能帮助你快速填写常见的 Midjourney 命令。下面我会写一下这个应用的创建过程帮大家熟悉一下这个平台。

Dify 可以选择两种应用一种是对话型应用类似于 ChatGPT 那种，另一种是文本生成类应用没有多轮对话的机制点击按钮直接生成文本内容。我们要创建的 Midjoureny 提示词机器人，所以我们选择文本生成应用就行。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/b219b5b9c75c900886aead5ad6cb3294.png)

我们输入名称创建完成之后看到的页面就是我们的看板页面里面有一些数据监控和应用设置。我们先点击左侧的提示词编排，这里就是主要的工作页面了。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/951ec91c08514eb1875a9fb6bafeb906.png)

这个页面左侧是提示词设置和一些其他功能，右侧可以实时预览和使用你创建的内容。前缀提示词就是用户每次输入内容后触发的提示词了，可以理解为每次 GPT 都会按照你的前缀提示词内容去处理用户输入的信息。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/210d41ad36447209e3ccc659eb89eb26.png)

可以看一下我的前缀提示词结构，主要有两部分前面是中文写的让 GPT 按照下面英文的结构输出照片的描述。英文的结构就是生成提示词的模板了，主要意思是【主题彩色照片，错综复杂的图案，鲜明的对比，环境描述，相机型号，与输入内容相关的镜头焦距描述，与输入内容相关的构图描述，四位摄影师的名字】这个就是提示词的主要内容了。理论上你现在保存到右边预览区域输入你想生成的主题就能生成对应提示词了。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/ba226b895de57e19659daa9717b16bdd.png)

那可能有人注意到了后面的 `{{proportion}}` 和 `{{version}}` 是什么呢，可以看到我右边需要用户选择图像比例和模型版本这两个变量就是用来传递用户选择的信息的。我们看一下如何设置。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/ec83b371411f86e017c7f5297e4c5371.png)

我们的功能是把用户选择的信息填到提示词的最后方便用户直接复制不用重新填写和记忆这些命令，这里就要用到下面的变量功能。

变量的作用就是把用户表单填写或者选择的内容动态的带入到提示词里面。比如我这里创建了两个变量一个代表图像比例一个代表模型版本。点击添加按钮创建变量。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/472c2c7898e34f166866f753c446118d.png)

创建之后首先需要填写前面的变量 Key 和字段名称，变量 Key 需要英文。后面的可选开启之后这个字段就会是选填的。之后我们需要点击操作栏的设置来设置变量内容。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/15278bb2596702c23bf2b42beaef197b.png)

变量包括两种内容一种是文本变量一种是下拉选项，文本的就是用户需要手动输入，下拉的话就是选择了。这里我们主要是不想用户手打命令，所以我们选择下拉选项。增加需要的选项就行。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/0229127044d39aa788a4da64c8f4fbc2.png)

之后就是使用变量了，我们需要把变量 Key 用两个 `{}` 包起来填写到前缀提示词里。这里由于我们不想让 GPT 改用户选择的内容，我加了一句提示词“如实输出变量内容”。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/f36ff96f657354b98d8a298d7039a2c6.png)

加了上面那句话 GPT 还是有一定几率改掉我们的变量内容怎么办，我们可以在右侧模型选择这里把多样性调低，这样创造性输出就会降低，他就不容易改写我们的变量内容了。其他的几个参数的意思可看小叹号了解。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/6757f86c0585b40c5bf4fae6a8e9cf54.png)

好了到这里我们的应用就创建完成了，测试输出没问题以后点击右上角的发布按钮，你的应用就发布了。你你和用户可以通过公开访问 URL 的地址访问你的应用。可以在设置里设置应用名称以及简介、图标之类的内容。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/ee4c61c8e3f7b99784149872b3939c22.png)

这就是利用 Dify 创建一个简单 AI 应用的流程，你还可以通过生成的 API 把你的应用部署在其他平台或者更改它的 UI。同时 Dify 还支持上传你自己的数据，比如你可以建一个客服机器人帮助你回答自己产品的相关问题。教程到这里就结束了，感谢 @goocarlos 创建了这么好的产品。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/create-a-midjoureny-prompt-word-robot-with-zero-code.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 如何在几分钟内创建一个带有业务数据的官网 AI 智能客服
> 来源：`zh-hans/learn-more/use-cases/create-an-ai-chatbot-with-business-data-in-minutes.mdx`

可能 AI 智能客服是每个业务网站的标配，在大型语言模型能力广泛被应用后，智能客服的实现变得更加轻易，可定制化的程度也更高。以下内容，将指导你如何在几分钟时间内，使用 Dify 创建你网站的 AI 智能客服。**Dify 产品支持将对话型应用嵌入到网页，你**只需要**花费几分钟**就可以将对话型应用**免费**嵌入到你的官网上，**定制你的 AI 智能客服。即使非技术人员也能搞定！**

#### 首先，你需要理解 Dify.AI 是什么？

Dify 是一个开源且非常简单易用的 LLMOps 平台，让你能够可视化快速创建并运营 AI 应用的工具平台。Dify 提供了可视化的 Prompt 编排、运营、知识库管理等功能。你甚至无需具备 AI 相关的技术研究和晦涩概念的理解。Dify 对接了各个出色的大型语言模型供应商，如 OpenAI、Azure OpenAI、Antropic 等，已提供 GPT 系列、Claude 系列模型，未来也将接入优秀的开源模型。这一切都是可以在设置中切换使用。这意味着，你在创建调试应用时，可以对比不同模型的效果，以确定使用最适合你的模型。**基于 Dify，你不仅可以很轻易地开发一个 AI 智能客服，还可以创造符合你使用习惯和需求的文本写作助手、虚拟招聘 HR 专家、会议总结助手、翻译助手等各种文本生成型应用，为你的工作提效。**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/13df685b32b248d122d6903bb410f657.png)

**前提条件**

**注册或部署 Dify.AI**

Dify 是一个开源产品，你可以在 GitHub (https://github.com/langgenius/dify) 上找到它并部署在你本地或公司内网。同时它提供了云端 SaaS 版本，访问 https://dify.ai/zh 注册即可使用。

**申请 OpenAI 等模型厂商的 API key**

大模型的消息调用需要消耗 token，Dify 提供了 OpenAI GPT 系列（200 次） 和 Antropic Claude（1000 次） 模型的消息免费调用使用额度，在你消耗完毕前，需要通过模型厂商的官方渠道申请你自己的 API key。在 Dify 的【设置】--【模型提供商】处可填入 key。

#### 上传你的产品文档或知识库

如果你希望能基于公司现有的知识库和产品文档构建人工智能客服，来与用户交流，那么你需要尽可能将你产品有关的文档上传到 Dify 的知识库中。Dify 帮助你完成数据的**分段处理和清洗**。Dify知识库支持高质量和经济两种索引模式，我们推荐使用高质量模式，会消耗 token 但能提供更高的准确性。操作步骤：在 【知识库】页面，新建一个知识库，上传你的业务数据（支持批量上传多个文本），选择清洗方式，【保存并处理】，只需几秒钟即可完成处理。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/61acc0a515f4f3dfffbea7c138245e05.png)

**创建一个 AI 应用，给 AI 指令**

在【构建应用】页面创建一个对话型应用。然后开始设置 AI 指令和它在前端和用户交互的体验：

1. **给 AI 指令：** 点击左侧【提示词编排】编辑你的 Prompt ，让它扮演客服的角色与用户交流，你可以指定它和用户交流的语气、风格、限定它回答问题的范围；
2. **让 AI 拥有你的业务知识：** 在【上下文】中添加你刚才上传的目标知识库；
3. **设置一个【对话开场白】：** 点击 【添加功能】打开功能开关。目的是为 AI 应用添加一个开场白，在用户打开客服窗口时，它会先和用户打招呼，增加亲和感。
4. **设置【下一步问题建议】：** 在【添加功能】开启此功能。目的是为了让用户在提完一个问题后，给用户进行下一步提问的方向提示。
5. **选择一个合适的模型并调整参数：** 页面右上角可以选择不同的模型。不同模型的表现和消耗的 token 价格都不一样。这个例子中，我们使用 GPT3.5 模型。

在这个 case 中，我们给 AI 指定了扮演的角色：

> 指令：你将扮演 Dify 的 AI 智能客服,你是 Dify 的第一个 AI 员工，名字叫 Bob。专门解答关于 Dify 产品、团队或 LLMOps 相关的用户问题。请注意,当用户提出的问题不在你的上下文内容范围内时,请回答不知道。请以友好的语气和用户交流，可以适当加入一些 emoji 表情增进与用户之间的互动。

> 开场白：你好，我是 Bob☀️, Dify的第一位AI成员。你可以与我讨论任何与Dify产品、团队甚至LLMOps相关的问题。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/b19b0a555a9bc62e7e0f6053e9dc1824.png)

**调试 AI 智能客服的表现并发布**

完成以上的设置后，你可以在当前的页面右侧给它发送信息调试它的表现是否符合预期。然后点击【发布】。这时候你就已经拥有了一个 AI 智能客服。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/5819870c911d5df009d48b1c5e613343.png)

**将 AI 客服应用嵌入到你的前端页面**

这一步，是将准备好的 AI 智能客服嵌入到你的官网页面。依次点击【概览】->【嵌入】，选择 **script 标签方式，** 将 script 代码复制到你网站 `<head>` 或 `<body>` 标签中。如你是非技术人员，可让负责官网的开发帮忙粘贴并更新页面。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/11ce3d803fa6f3b384aae8bc33386ad9.png)

1. 将复制的代码粘贴到你官网的目标位置：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/3bd3e488fa6c513dae3a54078bda328d.png)

1. 更新你的官网，即可以得到一个拥有你业务数据的官网 AI智能客服。试一试效果：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/b883028e410ece356e9ae332be66f3b9.png)

以上通过 Dify 官网 AI 客服 Bob 的例子演示了如何将 Dify 应用嵌入到官网的具体操作步骤。当然，你还可以通过 Dify 提供的更多特性来增加 AI 客服的表现，例如增加一些变量设置，让用户在互动前填入必要的判断信息，如名字、使用的具体产品等等。 欢迎你一起来探索，定制企业的 AI 智能客服。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/create-an-ai-chatbot-with-business-data-in-minutes.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 如何在 Dify 内体验大模型“竞技场”？以 DeepSeek R1 VS o1 为例
> 来源：`zh-hans/learn-more/use-cases/dify-model-arena.mdx`

## 概述

Dify 聊天助手类型应用内预置的 [“多模型调试”](./zh_CN/guides/application-orchestrate/multiple-llms-debugging) 可以让你同时观测不同大模型对于同一问题的回答效果。本文将以 DeepSeek R1 VS o1 示例，演示在 Dify 内直观地比较各个不同大模型的回答质量。

![](https://assets-docs.dify.ai/2025/02/dd2a54e05cf5bfa252ac980ec478e3d5.png)

## 前置准备

- Dify.AI 云端版/社区版
- DeepSeek R1 API
- OpenAI o1 API

## 快速开始

### 1. 配置 LLM API Key

开始测试前，点击 **“右上角” → [“增加新供应商”](https://docs.dify.ai/zh-hans/guides/model-configuration)**，按照提示手动添加多个模型的 API Key。

### 2. 创建应用

创建 Chatbot 类型应用，填写应用名称和描述完成创建。

![](https://assets-docs.dify.ai/2025/02/7246807cbd0776564b76e1ef37dcbd4d.png)

### 3. 选择大模型

点击应用右上角的大模型选择页，选择 `o1` 模型后，轻点 **“多个模型进行调试”** 并添加 `deepseek-reasoner` 模型。 

![](https://assets-docs.dify.ai/2025/02/61d8ba00a8a89052ac7a5a9d8fb54f58.png)

### 4. 对比效果

在对话框中输入问题后，即可同时查看不同模型对于当前问题的响应情况。

![](https://assets-docs.dify.ai/2025/02/03ac1c1da6705d76b01f5867a1e24e32.gif)

如需了解更多内容，或遇到使用问题，请参考[多模型调试](./zh_CN/guides/application-orchestrate/multiple-llms-debugging)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/dify-model-arena.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 将 Dify 应用与钉钉机器人集成
> 来源：`zh-hans/learn-more/use-cases/dify-on-dingtalk.mdx`

> 本文系社区投稿，作者：zfanswer, [Dify-on-Dingtalk](https://github.com/zfanswer/dify-on-dingtalk) 开源项目作者。

IM 是天然的智能聊天机器人应用场景，校企用户有不少是使用钉钉软件的，通过在企业内部群中添加 Dify 应用，就可以打造功能强大的数字员工，帮助企业内部人员提质增效。

在本文中，我们将向你展示如何将你的 Dify 应用和钉钉机器人进行集成，**并在钉钉中实现打字机式的流式输出效果**，通过使用 [Dify-on-Dingtalk](https://github.com/zfanswer/dify-on-dingtalk) 这个开源框架，进行简单的配置就可以轻松完成这个集成任务。

先上效果图，也许你就有兴趣继续读下去了。

<div class="image-side-by-side">
  <figure>
    ![Image 1](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/7d0d8387fe0dc230cc9cf87ff2451bca.png)
  </figure>
  <figure>
    ![Image 2](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/f6eec15a3b735c01331784294df0cd2a.jpeg)
  </figure>
</div>

这里我们假设你已经创建好等待接入的 Dify 应用了，这时就需要查看你这个应用的 `访问 API` 页面，创建该应用的 API 密钥④，并且记录 API 服务器访问地址⑤。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/b5191e352f280f2c7329cbc6917a1ac2.jpeg)

所以，在此步骤中你创建了待接入的 Dify 应用，同时记录该应用的几个重要参数：**应用的类型**、**该应用 API 秘钥**、**API 服务器访问地址**。

### 2.2. 创建钉钉企业应用机器人

登录进入 [钉钉开发平台](https://open-dev.dingtalk.com/)，选择合适的组织，进入企业内部应用开发页面，创建一个企业内部应用。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/be96400ec39fd85d4791c3c94f8d4e04.jpeg)

在弹出窗口里填好 **应用名称**、**应用描述**，上传应用图标点击保存。然后自动进入应用开发配置界面，通过 `添加应用能力` 添加机器人能力。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/c83acc5a77db86d8d52b2fe5a53d0bf6.jpeg)

打开机器人配置开关，在下方出现的表单中按你的实际情况填入各必要信息，**在消息接收模式上选择 Stream 模式**。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/5ff0892e2d4fe532f08e0adfdb4f7a4c.jpeg)

点击发布后，再去到左边栏的应用发布 -> 版本管理与发布 -> 创建新版本，给应用建立一个新版本进行发布。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/792850d6c7d5f13a017f14e0b2afe9ef.jpeg)

最后回到 `凭证与基础信息`，记录下该应用的 `Client ID` 和 `Client Secret`，此时左上角应用的状态应该是 **已发布**，到此完成钉钉机器人的配置。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/f451984aefd4b7186a6d9dd8f9cf4080.jpeg)

### 2.3. 钉钉 AI 卡片配置

为了让钉钉机器人的回复也实现打字机一样的流式输出效果，需要用到钉钉近来针对 AI 功能开放的 AI 卡片。

进入钉钉开发者后台，顶部菜单 -> 开放能力 ->[卡片平台](https://open-dev.dingtalk.com/fe/card) -> 新建模板，来新建一个 AI 卡片模板，填入你喜欢的模板名称，卡片类型选择 **消息卡片**，卡片模板场景选择 **AI 卡片**，并 **关联刚才创建的应用**。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/aab6222bfa21484406f07a477b412a4d.jpeg)

点击 **创建** 后进入卡片编辑页面，这里基本不需要任何改动，如果希望机器人在出错时把具体错误信息也输出出来，可以把 `启用失败状态` 打开。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/f9c3c75624e6584f27d078003d31e817.jpeg)

最后点击保存，发布，显示 “模板发布成功”，然后返回到刚才的模板列表页面，复制 \*\* 模板 ID\*\*，保存下来一会儿会用到。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/25cf3ab088526aa4fb3caf2898ec8c61.jpeg)

## 3. 部署 Dify-on-Dingtalk

### 3.1. 下载 Dify-on-Dingtalk 项目代码

```shell
git clone https://github.com/zfanswer/dify-on-dingtalk.git
# 有网络问题的可以从 gitee 镜像仓库拉取
# git clone https://gitee.com/zfanswer/dify-on-dingtalk.git
```

### 3.2. 填写配置文件

```shell
cd dify-on-dingtalk
# 将配置文件示例拷贝到 docker 文件夹中
cd docker
cp ../.env.example .env
cp ../.bots.yaml.example .bots.yaml
# 分别修改.env 和.bots.yaml 文件，配置好所需参数。
```

本文中使用 docker 来演示如何快速启动服务，如果需要用源代码启动服务，请参考代码中 [README.md](https://github.com/zfanswer/dify-on-dingtalk/blob/main/README.md#env%25) 文件，两个文件的参数配置可参考其中的参数说明，也可按下边简易配置。

`.env` 文件主要是配置全局变量的，内容示例如下：

```shell
# 日志级别
LOG_LEVEL=INFO
# 默认每个机器人后台监听线程数，调大可加大可问答并发
# 不过不要太大根据 cpu 配置适当调整
DEFAULT_MAX_WORKERS=2
# Dify API 服务器访问地址，上文 2.1. 步骤里记录的
DIFY_OPEN_API_URL="https://api.dify.ai/v1"
# 用户各自上下文维持时间，默认 15 minutes，只对 chatbot app 有效
DIFY_CONVERSATION_REMAIN_TIME=15
# 钉钉 AI 卡片模板 ID，上文 2.3. 步骤里记录的
DINGTALK_AI_CARD_TEMPLATE_ID="<your-dingtalk-ai-card-temp-id>"
```

`.bots.yaml` 文件主要是配置钉钉机器人和 Dify 应用的绑定关系，内容示例配置如下：

```yaml
bots:
  - name: 问答助手
    # 钉钉应用凭证信息，上文 2.2. 步骤里记录的
    dingtalk_app_client_id: <your-dingtalk-app-client-id>
    dingtalk_app_client_secret: <your-dingtalk-app-client-secret>
    # Dify 应用类型，上文 2.1. 开头提到的
    dify_app_type: <chatbot or completion or workflow>
    # Dify 应用 API 密钥，上文 2.1. 步骤里记录的
    dify_app_api_key: <your-dify-api-key-per-app>
    # 目前是固定值，不用动
    handler: DifyAiCardBotHandler
  - name: 问答助手 2
    xxx 以下略 xxx
```

可以看到，在文件中通过添加一组新的 bot 设定，是支持一次性配置多个机器人和 Dify 应用绑定的，这是为了用于比如企业内部人事、法务、代码助手等需要多个机器人后边配置不同的 Dify 应用。不过需要注意的是，不要把同一个钉钉机器人绑定不同的 Dify 应用，不然具体调用哪个 Dify 应用来回答是随机的。

### 3.3. 启动 docker 容器

通过如下命令启动 docker 容器，

```shell
# 假设现在 pwd 是在 docker 文件夹下
docker compose up -d
```

待容器启动后可以通过 `docker logs < 容器 ID>` 查看服务日志确认服务是否正常启动，出现如下日志且没有报错即为正常。

```shell
2024-08-20 18:16:42.019 | INFO     | __main__:run:33 - 待启动机器人数量：1, 预计使用最大线程数：1
2024-08-20 18:16:42.019 | INFO     | __main__:run:37 - 启动第 1 个机器人：agent_chatbot
2024-08-20 18:16:42.021 | INFO     | dingtalk_stream.stream:open_connection:131 - open connection, url=https://api.dingtalk.com/v1.0/gateway/connections/open
2024-08-20 18:16:42.314 | INFO     | dingtalk_stream.stream:start:72 - endpoint is % s
```

## 4. 实际对话测试

### 4.1. 将机器人添加进群聊

从群设置中找到创建的钉钉机器人，添加进群，即可开始在群众 @机器人进行对话，该示例图片中是使用了 Dify 应用的标注功能实现关键字 help 的固定输出。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/b6df3a21b488899975b3cf95fa6c5924.jpeg)

### 4.2. 与机器人进行私聊

与机器人进行私聊有两种方法：

1. 在群聊中左键机器人头像，选择发送消息进入私聊界面；
2. 在搜索框中搜索机器人名称，在功能分类下找到机器人，点击进入私聊界面；

私聊界面中直接对话即可，不需要再 `@` 了。

![](../../.gitbook/assets/dify-on-dingtalk-demo.gif)

## 5. 后记

到此为止，Dify 应用在钉钉上的集成已经完成，希望本文给你带来了帮助。

如果你对 Dify-on-Dingtalk 的功能还有其他需求和期待，欢迎对[该项目](https://github.com/zfanswer/dify-on-dingtalk)进行贡献。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/dify-on-dingtalk.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 使用 Dify 和 Azure Bot Framework 构建 Microsoft Teams 机器人
> 来源：`zh-hans/learn-more/use-cases/dify-on-teams.mdx`

> 作者：Warren， [Microsoft 最有价值专家 (MVP)](https://mvp.microsoft.com/en-US/mvp/profile/476f41d3-6bd1-ea11-a812-000d3a8dfe0d)

## 1. 概述

随着人工智能的崛起，聊天机器人变得更聪明，更个性化，更直观。在本文中，我们将向你展示如何使用 Azure Bot Service，将 Dify 集成至 Microsoft Teams，打造团队中的 AI 助手。

在本文中将介绍如何集成 Azure Bot Service 的 Teams Channel，允许客户与你的 Microsoft Teams 聊天机器人开始对话。

## 2. 准备工作

* 安装好 Docker 和 Docker Compose
* Microsoft Teams 账户
* 一个安装了 Microsoft Teams 的手机或电脑，用于测试你的 AI 聊天机器人
* [Azure 账户](https://azure.microsoft.com/en-us/free)

## 3. 创建 Dify 基础编排聊天助手应用

首先，登录 [Dify 平台](https://cloud.dify.ai/signin)，使用 Github 登录或者使用 Google 登录。此外，你也可以参考 Dify 官方教程 [Docker Compose 部署](./zh-hans/getting-started/install-self-hosted/docker-compose) 私有部署。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/08ece9f6dd15b6ba3c44eb187ea73bdd.jpeg)

登录成功后，进入 Dify 页面，我们按照下方步骤创建一个基础编排聊天助手应用

1. 点击页面上方的工作室
2. 创建空白应用
3. 应用类型选择聊天助手
4. 聊天助手编排方式选择基础编排
5. 选择应用图标并为应用填写一个名称，比如基础编排聊天助手
6. 点击创建

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/312d1fbcd5c8f58ca41b9f8dc8131286.jpeg)

创建成功后会跳转到上图所示页面，此时继续配置应用

1. 选择模型，如 gpt-3.5-turbo-0125
2. 设置模型参数
3. 填写应用提示词

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/410dc25f76beebf8659294b06c1a4d25.jpeg)

配置完成后，可以在右侧对话框进行测试。测试完成后，进行如下操作：

1. 发布
2. 更新
3. 访问 API

接着生成基础编排聊天助手 API 密钥

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/de85ada57a6f1a0029486dbdaea62fcf.jpeg)

点击 "访问 API" 后，会跳转到上图的 API 管理页面，按照如下步骤获取 API 密钥：

1. 点击右上角 API 密钥
2. 点击创建密钥
3. 复制保存密钥

在保存密钥后，还需要查看右上角的 API 服务器，如果是 Dify 官网的应用，API 服务器地址为 `https://api.dify.ai/v1`, 如果是私有部署的，请确认你自己的 API 服务器地址。

至此，创建聊天助手的准备工作结束。在此小节中我们只需要保存好两个东西：**API 密钥** 与 **API 服务器地址**。

## 4. 创建 Azure Bot Service

转到 [Azure Marketplace](https://portal.azure.com/#view/Microsoft\_Azure\_Marketplace/GalleryItemDetailsBladeNopdl/id/Microsoft.AzureBot/selectionMode\~/false/resourceGroupId//resourceGroupLocation//dontDiscardJourney\~/false/selectedMenuId/home/launchingContext\~/%7B%22galleryItemId%22%3A%22Microsoft.AzureBot%22%2C%22source%22%3A%5B%22GalleryFeaturedMenuItemPart%22%2C%22VirtualizedTileDetails%22%5D%2C%22menuItemId%22%3A%22home%22%2C%22subMenuItemId%22%3A%22Search%20results%22%2C%22telemetryId%22%3A%22a09b3b54-129b-475f-bd39-d7285a272043%22%7D/searchTelemetryId/258b225f-e7d5-4744-bfe4-69fa701d9d5a) 画面应该会直接到 Azure Bot Service 的创建画面。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/4c3cc89a4ceb3e6cb9be70d4c74411e6.png)

确认所有设置然后创建。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/56cfee6b9f205cde4fc7880b137f2979.png)

创建好后转到 Azure Bot 页面，先把 Subscription ID 保存好。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/f1f0d8fd2f3396b75b3d9f7a94fb1534.png)

然后选择 Configuration，保存好 Microsoft App ID 然后选择 Manage Password。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/512ff24ff9ab8c1b45d580f70bdb1c78.png)

创建和保存新 client secret。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/aae10f6172de35c18456fde821e52635.png)

## 5. 创建你的聊天机器人

在这一部分，你将使用 Microsoft Bot Framework 编写一个基本的聊天机器人的代码。

#### 5.1 下载代码

```
git clone https://github.com/somethingwentwell/dify-teams-bot
```

#### 5.2 配置.env

在项目根目录创建.env，内容如下:

```
MicrosoftAppType=MultiTenant
MicrosoftAppId=< 在 (4) 获取的 Client ID>
MicrosoftAppPassword=< 在 (4) 获取的 Client Secret>
MicrosoftAppTenantId=< 在 (4) 获取的 Tenant ID>

API_ENDPOINT=< 在 (3) 获取的 Dify API 服务器地址 >
API_KEY=< 在 (3) 获取的 Dify API 密钥 >
```

#### 5.3 运行代码

执行 docker compose up

```
docker compose up
```

如果运行成功，你应该会看到

```
[+] Running 2/0
 ✔ Network dify-teams-bot_dify-network    Created                     0.0s 
 ✔ Container dify-teams-bot-nodejs-app-1  Created                     0.0s 
Attaching to nodejs-app-1
nodejs-app-1  | 
nodejs-app-1  | > echobot@1.0.0 start
nodejs-app-1  | > node ./index.js
nodejs-app-1  | 
nodejs-app-1  | (node:18) [DEP0111] DeprecationWarning: Access to process.binding ('http_parser') is deprecated.
nodejs-app-1  | (Use `node --trace-deprecation ...` to show where the warning was created)
nodejs-app-1  | (node:18) [DEP0111] DeprecationWarning: Access to process.binding ('http_parser') is deprecated.
nodejs-app-1  | 
nodejs-app-1  | restify listening to http://0.0.0.0:3978
nodejs-app-1  | 
nodejs-app-1  | Get Bot Framework Emulator: https://aka.ms/botframework-emulator
nodejs-app-1  | 
nodejs-app-1  | To talk to your bot, open the emulator select "Open Bot"
```

#### 5.4 使用 Localtunnel 将本地项目放到公网访问

Azure Bot 需要向你的后端发送消息，你需要在公共服务器上托管你的应用。一个简单的方法是使用 localtunnel。

让 Azure BotI 应用继续在 3978 端口运行，并在另一个终端窗口运行以下 localtunnel 命令：

```
npx localtunnel --port 3978
```

上述命令在你的本地服务器（运行在 3978 端口）和 localtunnel 创建的公共域之间建立了一个连接。一旦你有了 localtunnel 转发 URL，任何来自客户端对该 URL 的请求都会自动被定向到你的 FastAPI 后端。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/68b0342cca4d735de3a74a4c9425e0f6.png)

## 6. 配置你的 Azure Bot

#### 6.1 打开 Azure Bot

转到在第四步创建的 Azure Bot，并在左侧面板上选择 Configuration。

将 `Message Endpoint` 替换为在第五步中获取的 localtunnel 转发 URL。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/d1f58bff85717bc8ca7e1b6ce351f9e2.png)

#### 6.2 配置 Channels

在左侧面板上选择 Channels，点击 Microsoft Teams。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/5c7d0bca5b55cf06d68ebe02de2d78a5.png)

## 7. Teams 测试

回到在 6.2 步中创建的 Channels 页面，点击 “Open in Teams”

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/cb598b85c0426d7fb83990c65d339382.png)

发送 Teams 消息，并等待你的 AI 聊天机器人的回复。尝试向 AI 聊天机器人提问你可以向 Dify 聊天助手提问的任何问题。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/9a2f3ff1551976eb3b0eb7eca884c494.png)

## 8. 后记

现在，你的 AI 聊天机器人应该能够在 Microsoft Teams 上运行良好。如果运行良好，可以切换至使用公司的 Microsoft Teams 商业账户内的正式环境，并使用远程服务器托管，使这个 Teams 助手在生产环境中运行。希望你喜欢这个教程，我们下次再见。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/dify-on-teams.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 手把手教你把 Dify 接入微信生态
> 来源：`zh-hans/learn-more/use-cases/dify-on-wechat.mdx`

> 作者：韩方圆，"Dify on WeChat" 开源项目作者

## 1. 概述

微信作为最热门的即时通信软件，拥有巨大的流量。

微信友好的聊天窗口是天然的 AI 应用 LUI (Language User Interface)/CUI (Command User Interface)。

微信不仅有个人微信，同时提供了公众号、企业微信、企业微信应用、企业微信客服等对话渠道，拥有良好的微信生态。

把 Dify 应用接入微信生态，就能打造一个功能强大的智能客服，大大降低客服成本，同时也能够提升客户体验。本篇教程就是手把手地教你如何利用 [Dify on WeChat](https://github.com/hanfangyuan4396/dify-on-wechat) 项目，把 Dify 应用接入微信生态。

## 2. Dify 接入个人微信

### 2.1. 准备工作

#### 2.1.1. 创建聊天助手

**（1）Dify 简介**

Dify 是一个优秀的 LLMOps（大型语言模型运维）平台，Dify 的详细介绍请移步官方文档 [欢迎使用 Dify | 中文 | Dify](https://docs.dify.ai/v/zh-hans)。

**（2）登录 Dify 官方应用平台**

首先，登录 [Dify 官方应用平台](https://cloud.dify.ai/signin)，你可以选择使用 Github 登录或者使用 Google 登录。此外，你也可以参考 Dify 官方教程 [Docker Compose 部署 | 中文 | Dify](./zh-hans/getting-started/install-self-hosted/docker-compose) 私有部署，Dify 是开源项目，支持私有部署。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/4d59263223217b94f8c7b4fb8a2951b4.jpeg)

**（3）创建 Dify 基础编排聊天助手应用**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/08ece9f6dd15b6ba3c44eb187ea73bdd.jpeg)

登录成功后，进入 Dify 页面，我们按照下方步骤创建一个基础编排聊天助手应用

1. 点击页面上方的工作室
2. 创建空白应用
3. 应用类型选择聊天助手
4. 聊天助手编排方式选择基础编排
5. 选择应用图标并为应用填写一个名称，比如基础编排聊天助手
6. 点击创建

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/312d1fbcd5c8f58ca41b9f8dc8131286.jpeg)

创建成功后我们会跳转到上图所示页面，我们继续配置应用

1. 选择模型，如 gpt-3.5-turbo-0125
2. 设置模型参数
3. 填写应用提示词

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/410dc25f76beebf8659294b06c1a4d25.jpeg)

在配置完成后，我们可以在右侧对话框进行测试，在测试完成后，进行如下操作

1. 发布
2. 更新
3. 访问 API

**（4）生成基础编排聊天助手 API 密钥**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/de85ada57a6f1a0029486dbdaea62fcf.jpeg)

在点击 "访问 API" 后，我们会跳转到上图的 API 管理页面，在这个页面我们按照如下步骤获取 API 密钥：

1. 点击右上角 API 密钥
2. 点击创建密钥
3. 复制保存密钥

在保存密钥后，还需要查看右上角的 API 服务器，如果是 Dify 官网的应用，API 服务器地址为 "https://api.dify.ai/v1", 如果是私有部署的，请确认你自己的 API 服务器地址。

至此，创建聊天助手的准备工作结束，在此小节中我们只需要保存好两个东西：**API 密钥** 与**API 服务器地址**

#### 2.1.2. 下载 Dify on WeChat 项目

**（1）Dify on WeChat 项目简介**

[Dify on WeChat](https://github.com/hanfangyuan4396/dify-on-wechat) 是 [ ChatGPT on WeChat](https://github.com/zhayujie/chatgpt-on-wechat) 的下游分支，额外实现了对接 [Dify](https://github.com/langgenius/dify) API，支持 Dify 聊天助手、支持 Agent 调用工具和知识库，支持 Dify 工作流，详情请查看 GitHub 仓库 [Dify on WeChat](https://github.com/hanfangyuan4396/dify-on-wechat)。

**（2）下载代码并安装依赖**

1. 下载项目代码

```bash
git clone https://github.com/hanfangyuan4396/dify-on-wechat
cd dify-on-wechat/
```

2. 安装 python

Dify on WeChat 项目使用 python 语言编写，请在 [python 官网](https://www.python.org/downloads/) 下载安装 python，推荐安装 python3.8 以上版本，我在 ubuntu 测试过 3.11.6 版本，可以正常运行。

3. 安装核心依赖（必选）：

```bash
pip3 install -r requirements.txt  # 国内可以在该命令末尾添加 "-i https://mirrors.aliyun.com/pypi/simple" 参数，使用阿里云镜像源安装依赖
```

4. 拓展依赖 （可选，建议安装）：

```bash
pip3 install -r requirements-optional.txt # 国内可以在该命令末尾添加 "-i https://mirrors.aliyun.com/pypi/simple" 参数，使用阿里云镜像源安装依赖
```

**（3）填写配置文件**

我们在项目根目录创建名为 config.json 的文件，文件内容如下，我们在**2.1.1 小节（4）** 最后保存了**API 密钥** 与**API 服务器地址**，请把**dify\_api\_base** 配置为**API 服务器地址**；**dify\_api\_key** 配置为**API 密钥** 其他配置保持不变。

(PS: 很多朋友可能并不是严格按照我教程给出的步骤创建**聊天助手类型** 的 Dify 应用，在此特别说明一下**dify_app_type** 配置方法，如果你创建了**聊天助手** 应用请配置为**chatbot**；创建了**Agent** 应用请配置为**agent** 创建了**工作流** 应用请配置为**workflow**。)

```bash

  "dify_api_base": "https://api.dify.ai/v1",
  "dify_api_key": "app-xxx",
  "dify_app_type": "chatbot",
  "channel_type": "wx",
  "model": "dify",
  "single_chat_prefix": [""],
  "single_chat_reply_prefix": "",
  "group_chat_prefix": ["@bot"],
  "group_name_white_list": ["ALL_GROUP"]

```

### 2.2. 把基础编排聊天助手接入微信

#### 2.2.1. 快速启动测试

**（1）在 Dify on Wechat 项目根目录执行如下命令**

```bash
cd dify-on-wechat
python3 app.py   # windows 环境下该命令通常为 python app.py
```

**（2）扫码登录**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/dff732ee33dce1fffa3ea22f4fb7194b.jpeg)

本项目使用 itchat 实现个人微信登录，有封号风险，建议使用** 实名认证** 过的** 微信小号** 进行测试，在执行上述命令后，我们可以在控制台看到打印如上图所示二维码，使用微信扫码登录，登录后当看到 "itchat:Start auto replying." 字符，表示登录成功，我们可以进行测试。

**（3）对话测试**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/634f08492602c77e415c183278b7a3a0.jpeg)

我们看到，微信机器人的回复与在 Dify 测试页面上的回复一致。至此，恭喜你成功把 Dify 接入了个人微信🎉🎉🎉

(PS: 有些朋友到这里可能在日志中看到正常回复了消息，但是微信中没有收到消息，请** 不要用自己的微信给自己发消息**)

**（4）服务器部署**

1. 源码部署

```bash
cd dify-on-wechat
nohup python3 app.py & tail -f nohup.out   # 在后台运行程序并通过日志输出二维码
```

2. docker compose 部署

容器的**环境变量** 会**覆盖** config.json 文件的配置，请修改 docker/docker-compose.yml 文件环境变量为你实际的配置，配置方法与**2.1.1 小节 (4)** 的 config.json 配置一致。

请确保正确配置**DIFY\_API\_BASE**,**DIFY\_API\_KEY** 与**DIFY\_APP\_TYPE** 环境变量。

```yaml
version: '2.0'
services:
  dify-on-wechat:
    image: hanfangyuan/dify-on-wechat
    container_name: dify-on-wechat
    security_opt:
      - seccomp:unconfined
    environment:
      DIFY_API_BASE: 'https://api.dify.ai/v1'
      DIFY_API_KEY: 'app-xx'
      DIFY_APP_TYPE: 'chatbot'
      MODEL: 'dify'
      SINGLE_CHAT_PREFIX: '[""]'
      SINGLE_CHAT_REPLY_PREFIX: '""'
      GROUP_CHAT_PREFIX: '["@bot"]'
      GROUP_NAME_WHITE_LIST: '["ALL_GROUP"]'
```

然后执行如下命令启动容器

```bash
cd dify-on-wechat/docker       # 进入 docker 目录
docker compose up -d           # 启动 docker 容器
docker logs -f dify-on-wechat  # 查看二维码并登录
```

### 2.3. 把工作流编排聊天助手接入微信

在把 Dify 基础的聊天助手应用接入微信后，我们接下来增加难度，尝试把工作流编排聊天助手应用接入微信，实现一个具有 Dify 平台知识的微信智能客服，为我们解答 Dify 工作流相关知识。

#### 2.3.1. 创建知识库

**（1）下载知识库文件**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/aa7354d9fa205665142871199f82ad08.jpeg)

我们到 [dify 文档仓库](../../guides/workflow/) 下载 Dify 工作流介绍的文档。

**（2）Dify 中导入知识库**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/e89b108734c4e219ba0a88f2a09e8069.jpeg)

进入知识库页面，创建知识库

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/3c1211094029b94c00e1867e12dc0347.jpeg)

选择导入已有文本，上传刚才下载的 introduce.md 文件，点击下一步

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/8ed084c50189610e1f0c7c4b92ea45fc.jpeg)

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/ec02b1e931261efd3266c68417c4f88a.jpeg)

选择如下配置

* 分段设置：自动分段与清洗
* 索引方式：高质量
* 检索设置：向量检索

最后点击保存并处理

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/4d14d85d6f9a588298b3d1c3e34cca4f.jpeg)

我们看到知识库正在进行嵌入处理，稍等片刻，即可嵌入成功。

#### 2.3.2. 创建工作流编排聊天助手

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/56870383783474ac8edf656cfd0039c8.jpeg)

我们进入 Dify 工作室，点击从应用模板创建

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/f6bb7d07d20f0dc20ec42878ff83ee91.jpeg)

我们使用知识库 + 聊天机器人类型的模板，设置应用图标与名称，点击创建

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/006cf36de5b5a852cf2ed194ef89a176.jpeg)

跳转到工作流编排页面后，先点击知识检索节点，点击最右侧 "+" 添加知识库。我们选择之前上传好的 introduce.md 知识库，该知识库是对 Dify 工作流的基本介绍。最后我们点击添加，知识库节点设置完成。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/3687f1b90a3dba06af9d4625579196e8.jpeg)

接下来选择 LLM 节点，点击设置上下文，我们选择 result 变量，该变量存有知识检索的结果。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/4d9d7dafe2007c6205a5da92120de7d6.jpeg)

设置完 LLM 节点后，我们点击预览进行测试，输入问题：请介绍一下 dify 工作流。可以看到最终输出了 Dify 工作流的正确介绍。测试正常后，我们返回编辑模式。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/9e20dccdcbab74679c7a238d4a3db62f.jpeg)

返回编辑模式后，依次点击发布、更新、访问 API

#### 2.3.3. 生成工作流编排聊天助手 API 密钥

在跳转到 API 管理页面后，我们参照**2.1.1 小节 (4) 获取 "知识库 + 聊天机器人" 应用的 API 密钥** 与**API 服务器地址**

#### 2.3.4. 接入微信

与**2.1.2 小节（3）类似，我们在项目根目录创建名为 config.json 的文件，文件内容如下，同样把 dify\_api\_base** 配置为** 知识库 + 聊天机器人** 应用的 API 服务器地址，**dify\_api\_key** 配置为** 知识库 + 聊天机器人** 应用的 API 密钥，其他配置保持不变

```bash

  "dify_api_base": "https://api.dify.ai/v1",
  "dify_api_key": "app-xxx",
  "dify_app_type": "chatbot",
  "channel_type": "wx",
  "model": "dify",
  "single_chat_prefix": [""],
  "single_chat_reply_prefix": "",
  "group_chat_prefix": ["@bot"],
  "group_name_white_list": ["ALL_GROUP"]

```

我们按照**2.2.1 小节** 启动程序并扫码登录，然后给微信机器人发送消息，进行测试

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/1a92cbd66d81e504a72f7cb1f01567a8.jpeg)

微信机器人的回复与在 Dify 测试页面上的回复一致。恭喜你更进一步，把工作流编排应用接入了个人微信，你可以向知识库中导入更多的 Dify 官方文档，让微信机器人为你解答更多的 Dify 相关问题。

### 2.4. 把 Agent 接入微信

#### 2.4.1. 创建 Agent 应用

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/3448bd70c5071882f50667327e35739a.jpeg)

进入工作室页面，点击创建空白应用，选择 Agent，设置图标和应用名称，最后点击创建

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/4800cb647f0ff90d5521b859e9403f04.jpeg)

创建成功后，我们会进入 Agent 应用配置页面，在这个页面我们选择好对话模型，然后添加工具。我们首先添加 DALL-E 绘画工具，首次使用该工具需要授权，一般我们设置好 OpenAI API key 和 OpenAI base URL 即可使用该 DALL-E 绘画工具。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/bee33065bc070facda8ce81a54d3e3c1.jpeg)

授权成功后，我们添加 DALL-E 3 绘画工具

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/e637c7865118b52f84f619a7637a0347.jpeg)

接着，继续添加 DuckDuckGo 搜索引擎和数学工具，进行后续的工具测试

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/32bc3686664423c0f12b5d19c7bf8739.jpeg)

我们输入问题 "搜索开源项目 Dify 的 star 数量，这个数量乘以 3.14 是多少"，确认应用能够正常调用工具，我们依次点击发布、更新、访问 API

#### 2.4.2. 生成 Agent API 密钥

我们继续参照**2.1.1 小节（4）获取智能助手** 应用的**API 密钥** 与**API 服务器地址**

#### 2.4.3. 接入微信

我们在项目根目录创建名为 config.json 的文件，文件内容如下，同样把**dify\_api\_base** 配置为** 智能助手** 应用的 API 服务器地址；**dify\_api\_key** 配置为** 智能助手** 应用的 API 密钥，注意该应用为** 智能助手** 类型应用，还需要把**dify\_app\_type** 设置为**agent**，其他配置保持不变

```bash

    "dify_api_base": "https://api.dify.ai/v1",
    "dify_api_key": "app-xxx",
    "dify_app_type": "agent",
    "channel_type": "wx",
    "model": "dify",
    "single_chat_prefix": [""],
    "single_chat_reply_prefix": "",
    "group_chat_prefix": ["@bot"],
    "group_name_white_list": ["ALL_GROUP"]

```

继续参照**2.2.1 小节** 启动程序并扫码登录，然后给微信机器人发送消息，进行测试

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/8c06ab5d23c2c144b35e82524f7e38d9.jpeg)

可以看到微信机器人可以正常使用搜索和绘画工具。再一次恭喜你，把 Dify Agent 应用接入微信。也恭喜我，写到这里可以先睡觉了。

### 2.5. 把工作流接入微信

#### 2.5.1. 创建工作流应用

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/1635ba3e6b7417a49a29b42224a0aa29.jpeg)

首先你需要提前下载好我预先创建的 DSL 文件，[点击此处下载](https://github.com/hanfangyuan4396/dify-on-wechat/blob/master/dsl/chat-workflow.yml)。下载完成后，进入工作室页面，点击导入 DSL 文件，上传提前下载好的文件，最后点击创建。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/872b3fa4febd26ec20e0657398d2020b.jpeg)

创建完成后，按照上图步骤进行测试。点击运行，输入你好，确保该工作流能正常输出结果。

你可以在此工作流的基础上进行修改，但是对于** 工作流类型** 的应用，它的输入变量名称十分灵活，，为了更方便地接入微信机器人，[Dify on WeChat](https://github.com/hanfangyuan4396/dify-on-wechat) 项目约定** 工作流类型** 的应用** 输入变量命名为 `query`**，** 输出变量命名为 `text`**。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/56d2e2a1b4aac390055fb2d3e49eaf4c.jpeg)

测试没有问题后，按照上图步骤发布应用，依次点击发布、更新、访问 API。

#### 2.5.2. 生成工作流 API 密钥

我们同样参照**2.1.1 小节（4）获取工作流** 应用的**API 密钥** 与**API 服务器地址**。

#### 2.5.3. 接入微信

我们在项目根目录创建名为 config.json 的文件，文件内容如下，同样把**dify\_api\_base** 配置为** 工作流** 应用的 API 服务器地址；**dify\_api\_key** 配置为** 工作流** 应用的 API 密钥，注意该应用为** 工作流** 类型应用，还需要把**dify\_app\_type** 设置为**workflow**，其他配置保持不变

```bash

    "dify_api_base": "https://api.dify.ai/v1",
    "dify_api_key": "app-xxx",
    "dify_app_type": "workflow",
    "channel_type": "wx",
    "model": "dify",
    "single_chat_prefix": [""],
    "single_chat_reply_prefix": "",
    "group_chat_prefix": ["@bot"],
    "group_name_white_list": ["ALL_GROUP"]

```

同样参照**2.2.1 小节** 启动程序并扫码登录，然后给微信机器人发送消息，进行测试。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/c4f3c4494aa25bad1877c0dd72995b5f.jpeg)

可以看到机器人成功接通了工作流 api 并进行了回复，至此我们已经完全掌握了如何创建 Dify 所有类型的应用：基础聊天助手、工作流聊天助手、智能助手、工作流，我们也学会了如何把上述应用发布为 API，并接入微信。

接下来我将会介绍如何把应用接入到微信的其他通道，如公众号、企业微信应用、企业微信客服等。

## 3. Dify 接入企业微信个人号（仅限 Windows 环境）

> 1. 有**封号风险**，请使用企业微信**小号** 测试
> 2. 在登录旧版本的企业微信时可能会出现企业微信版本过低，无法登录情况，参考 [issue1525](https://github.com/zhayujie/chatgpt-on-wechat/issues/1525)，请尝试更换其他企业微信号重试

### 3.1. 下载安装企业微信

确保你有一台 windows 系统的电脑，然后在此电脑下载安装特定版本的企业微信，[官方下载链接](https://dldir1.qq.com/wework/work\_weixin/WeCom\_4.0.8.6027.exe)，[备用下载链接](https://www.alipan.com/s/UxQHrZ5WoxS)。

笔者目前企业微信最新版本为 4.1.33.6009。即使电脑端下载了旧版本的，然后用手机扫码登录，也会被提示版本过低需要升级 pc 端版本，且无法避免，ntwork-whl 只兼容了固定版本企业微信客户端，最新版本没有兼容。
解决方案如下：

1. 下载并安装最新版本和 4.0.8.6027 版本的企业微信。

![](https://assets-docs.dify.ai/2025/04/306b3158a547de46a05ed53942f10f4a.png)

● wxwork_last 文件夹为最新版本的企业微信
● WxWork 文件夹为 4.0.8.6027 版本

2. 先打开最新版本的企业微信，并扫码登录。

![](https://assets-docs.dify.ai/2025/04/6e0ee777cd68c094c22739612cf2fbfa.png)

打开 Wxwork_last/wxwork.exe 文件，运行最新版本的企业微信，扫码登录。

3. 登录成功后，打开设置，勾选上启动企业微信后自动登录，去掉自动更新的选项。然后关闭最新版本的企业微信程序

![](https://assets-docs.dify.ai/2025/04/a3cf375ad44138e84ac682a6683dd1b6.png)

![](https://assets-docs.dify.ai/2025/04/adde9f83465492c24b6891482893faec.png)

4. 现在再打开旧版本的企业微信，即可直接登录。

![](https://assets-docs.dify.ai/2025/04/32a45ad18fbb4de03e99753f19cb9d64.png)

运行 wxwork/wxwork.exe 即可。

### 3.2. 创建 Dify 应用

我们已经在前面的**2.1.1**、**2.3.2**、**2.4.1** 与**2.5.1** 小节分别介绍了创建基础聊天助手、工作流聊天助手、智能助手、工作流这 4 种不同的 Dify 应用，你可以根据上面的教程任意创建一种应用。

### 3.3. 下载安装 Dify on WeChat

根据**2.1.2 (2)** 步骤，下载代码并安装依赖，为了后续能按照 ntwork 依赖，** 请确保你安装的 python 版本为 3.8、3.9 或 3.10**。

### 3.4. 安装 ntwork 依赖

由于 ntwork 的安装源不是很稳定，可以下载对应的 whl 文件，使用 whl 文件离线安装 ntwork

首先需要查看你的 python 版本，在命令行中输入 python 查看版本信息，然后在 [ntwork-whl](https://github.com/hanfangyuan4396/ntwork-bin-backup/tree/main/ntwork-whl) 目录下找到对应的 whl 文件，运行 `pip install xx.whl` 安装 ntwork 依赖，注意 "xx.whl" 更换为 whl 文件的**实际路径**。

例如我的 python 版本信息为

"Python 3.8.5 (default, Sep 3 2020, 21:29:08) \[MSC v.1916 64 bit (AMD64)]"

可以看到 python 版本是**3.8.5**，并且是**AMD64**，所以对应的 whl 文件为**ntwork-0.1.3-cp38-cp38-win\_amd64.whl**，需要执行如下命令安装

```sh
pip install your-path/ntwork-0.1.3-cp38-cp38-win_amd64.whl
```

### 3.5. 填写配置文件

我们在 Dify on WeChat 项目根目录创建名为 config.json 的文件，下面是以 Dify 智能助手应用作为示例的配置文件，请正确填写你刚刚创建应用的 dify\_api\_base、dify\_api\_key、dify\_app\_type 信息，请注意 channel\_type 填写为**wework**

```json

  "dify_api_base": "https://api.dify.ai/v1",
  "dify_api_key": "app-xxx",
  "dify_app_type": "agent",
  "channel_type": "wework",
  "model": "dify",
  "single_chat_prefix": [""],
  "single_chat_reply_prefix": "",
  "group_chat_prefix": ["@bot"],
  "group_name_white_list": ["ALL_GROUP"]

```

### 3.6. 登录企业微信

务必提前在电脑扫码登录企业微信

### 3.7. 启动微信个人号机器人

运行如下命令启动机器人

```sh
cd dify-on-wechat
python app.py
```

我们可以看到终端输出如下信息，**等待 wework 程序初始化完成**，最后启动成功 \~

```bash
[INFO][2024-04-30 21:16:04][wework_channel.py:185] - 等待登录・・・・・・
[INFO][2024-04-30 21:16:05][wework_channel.py:190] - 登录信息:>>>user_id:xxx>>>>>>>>name:
[INFO][2024-04-30 21:16:05][wework_channel.py:191] - 静默延迟 60s，等待客户端刷新数据，请勿进行任何操作・・・・・・
[INFO][2024-04-30 21:17:05][wework_channel.py:224] - wework 程序初始化完成・・・・・・・・
```

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/d440a63e5e00845b1854410d63b31bdd.jpeg)

现在我们给机器人发送消息，可以看到接入成功！

## 7. 后记

我是社畜打工人，精力实在有限，只能晚上下班还有周末空闲时间维护 [Dify on WeChat](https://github.com/hanfangyuan4396/dify-on-wechat) 项目，单靠我个人开发项目进度十分缓慢，希望大家能一起参与进来这个项目，多多提 PR，让 Dify 的生态变得更好 \~

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/dify-on-wechat.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 使用 Dify 和 Twilio 构建 WhatsApp 机器人
> 来源：`zh-hans/learn-more/use-cases/dify-on-whatsapp.mdx`

> 作者：Warren， [Microsoft 最有價值專家 (MVP)](https://mvp.microsoft.com/en-US/mvp/profile/476f41d3-6bd1-ea11-a812-000d3a8dfe0d)

## 1. 概述

随着世界通过消息应用程序变得越来越紧密地连接在一起，聊天机器人已成为企业与客户进行更个人化交流的关键工具。

随着人工智能的崛起，聊天机器人变得更聪明，更个性化，更直观。在本文中，我们将向你展示如何使用使用Dify和Twilio将其与WhatsApp集成。

你将首先使用FastAPI 接入Dify设置后端，然后，你将集成Twilio的WhatsApp消息API，允许客户与你的WhatsApp聊天机器人开始对话。

使用Localtunnel，将FastAPI本地主机放在互联网上，使其可以供Twilio API通信。

## 2. 準備工作

* 安裝好Docker 和Docker Compose
* Twilio帐户： 在[這裡](https://www.twilio.com/try-twilio) 創建一個免費Twilio帳戶
* 一部安装了WhatsApp的智能手机，用于测试你的AI聊天机器人
* 对FastAPI的基本理解，这是一个使用Python 3.6+构建API的框架

## 3. 创建Dify基础编排聊天助手应用 （節錄自[手把手教你把 Dify 接入微信生态](dify-on-wechat))

首先，登录[Dify官方应用平台](https://cloud.dify.ai/signin)，你可以选择使用Github登录或者使用Google登录。此外，你也可以参考Dify官方教程[Docker Compose 部署 | 中文 | Dify](./zh-hans/getting-started/install-self-hosted/docker-compose) 私有部署，Dify是开源项目，支持私有部署。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/08ece9f6dd15b6ba3c44eb187ea73bdd.jpeg)

登录成功后，进入Dify页面，我们按照下方步骤创建一个基础编排聊天助手应用

1. 点击页面上方的工作室
2. 创建空白应用
3. 应用类型选择聊天助手
4. 聊天助手编排方式选择基础编排
5. 选择应用图标并为应用填写一个名称，比如基础编排聊天助手
6. 点击创建

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/312d1fbcd5c8f58ca41b9f8dc8131286.jpeg)

创建成功后我们会跳转到上图所示页面，我们继续配置应用

1. 选择模型，如gpt-3.5-turbo-0125
2. 设置模型参数
3. 填写应用提示词

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/410dc25f76beebf8659294b06c1a4d25.jpeg)

在配置完成后，我们可以在右侧对话框进行测试，在测试完成后，进行如下操作

1. 发布
2. 更新
3. 访问API

**（4）生成基础编排聊天助手API密钥**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/de85ada57a6f1a0029486dbdaea62fcf.jpeg)

在点击"访问API"后，我们会跳转到上图的API管理页面，在这个页面我们按照如下步骤获取API密钥：

1. 点击右上角API密钥
2. 点击创建密钥
3. 复制保存密钥

在保存密钥后，还需要查看右上角的API服务器，如果是Dify官网的应用，API服务器地址为 "https://api.dify.ai/v1", 如果是私有部署的，请确认你自己的API服务器地址。

至此，创建聊天助手的准备工作结束，在此小节中我们只需要保存好两个东西：**API密钥**与**API服务器地址**

## 4. 獲取Twilio密钥

转到\[Twilio控制台] 畫面應該會直接獲取到Account SID 和Auth Token，保存好這两个东西。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/f1586199a94ffefb18ffc4c8456a58d0.png)

## 5. 创建你的聊天机器人

在这一部分，你将使用FastAPI和Twilio编写一个基本的聊天机器人的代码。

#### 5.1 下載代碼

```
git clone https://github.com/somethingwentwell/dify-twilio-whatsapp
```

#### 5.2 配置.env

在项目根目录创建.env，內容如下:

```
TWILIO_NUMBER=+14155238886
TWILIO_ACCOUNT_SID=<在(4)獲取的Twilio Account SID>
TWILIO_AUTH_TOKEN=<在(4)獲取的Twilio Auth Token>
DIFY_URL=<在(3)獲取的Dify API服务器地址>
DIFY_API_KEY=<在(3)獲取的Dify API密钥>
```

#### 5.3 運行代码

執行docker compose up

```
docker compose up
```

如果运行成功，你应该会看到

```
dify-whatsapp-1  | INFO:     Started server process [68]
dify-whatsapp-1  | INFO:     Waiting for application startup.
dify-whatsapp-1  | INFO:     Application startup complete.
```

在浏览器中打开 http://localhost:9000。你应该看到的结果是一个JSON响应，内容为 `"msg": "working"`。

#### 5.4 使用Localtunnel 將本地项目放到公网访问

Twilio需要向你的后端发送消息，你需要在公共服务器上托管你的应用。一个简单的方法是使用localtunnel。

让FastAPI应用继续在9000端口运行，并在另一个终端窗口运行以下localtunnel命令：

```
npx localtunnel --port 9000
```

上述命令在你的本地服务器（运行在9000端口）和localtunnel创建的公共域之间建立了一个连接。一旦你有了localtunnel转发URL，任何来自客户端对该URL的请求都会自动被定向到你的FastAPI后端。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/73f585d06be68fc71c0d37622a5b6f6c.png)

#### 5.5 代码解释

**5.5.1 检查该号码是否已在白名单中，不在白名单的用户直接返回“你未注册此服务。”**

```python
enrolled_numbers = ['+14155238886']
```

对应

```python
    # Check if the number is enrolled
    if whatsapp_number not in enrolled_numbers:
        message = client.messages.create(  
            from_=f"whatsapp:twilio_number",  
            body="You are not enrolled in this service.",  
            to=f"whatsapp:whatsapp_number"  
        )
        return ""
```

**5.5.2 将WhatsApp号码作为Dify会话ID，确保用户持续保持该会话**

```python
conversation_ids = {}
```

对应

```python
    url = dify_url
    headers = {  
        'Content-Type': 'application/json',  
        'Authorization': f"Bearer {dify_api_key}",  
    }  
    data = {  
        'inputs': {},  
        'query': Body,  
        'response_mode': 'streaming',  
        'conversation_id': conversation_ids.get(whatsapp_number, ''),  
        'user': whatsapp_number,  
    }  
    response = requests.post(url, headers=headers, data=json.dumps(data), stream=True)  
    answer = []  
    for line in response.iter_lines():  
        if line:  
            decoded_line = line.decode('utf-8')  
            if decoded_line.startswith('data: '):  
                decoded_line = decoded_line[6:]  
            try:  
                json_line = json.loads(decoded_line) 
                if "conversation_id" in json_line:
                    conversation_ids[whatsapp_number] = json_line["conversation_id"]
                if json_line["event"] == "agent_thought":  
                    answer.append(json_line["thought"])  
            except json.JSONDecodeError: 
                print(json_line)  
                continue  

    merged_answer = ''.join(answer)  
```

## 6. 配置你的Twilio沙箱以供WhatsApp使用

#### 6.1 打开WhatsApp沙盒

要使用Twilio的消息API使聊天机器人能与WhatsApp用户通信，你需要配置Twilio沙箱以供WhatsApp使用。以下是操作方法：

转到[Twilio控制台](https://console.twilio.com/)并在左侧面板上选择消息选项卡。

在“试试看”下，点击“发送WhatsApp消息”。你将默认进入沙盒选项卡，你会看到一个电话号码“+14155238886”，旁边有一个加入的代码，右边有一个二维码。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/1f966b36bd5c213e4006a057b1c70c04.png)

要启用Twilio测试环境，将此代码的文本作为WhatsApp消息发送到显示的电话号码。如果你正在使用网络版本，可以点击超链接将你引导到WhatsApp聊天。

#### 6.2 配置WhatsApp沙盒

在“沙盒”选项卡旁边，选择“沙盒设置”选项卡。

复制你的localtunnel URL并附加/message。将其粘贴到“当消息进入时”旁边的框中：

Twilio沙盒webhook 完整的URL应如下所示：https://breezy-humans-help.loca.lt/message。

你将在FastAPI应用程序中配置的端点是/message，如上所述。聊天机器人的逻辑将在此端点上。

完成后，按“保存”按钮。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/6f810feee2a1eb07f718fc3f2be00b4b.png)

## 7. WhatsApp測試

掃6.1 頁面的二維碼進入WhatsApp 沙盒環境，然後发送WhatsApp消息，并等待你的AI聊天机器人的回复。尝试向AI聊天机器人提问你可以向Dify 聊天助手提问的任何问题。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/36376da1b4699289e944355282656780.jpeg)

## 8. 后记

现在，你的AI聊天机器人在WhatsApp上运行良好。也许你的下一步是使用你自己的WhatsApp商业账户，而不是Twilio沙盒，并使用服务器托管而不是在本地构建，使这个WhatsApp助手在生产中运行。希望你喜欢这个教程，我们下次再见。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/dify-on-whatsapp.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 构建 Dify 应用定时任务助手
> 来源：`zh-hans/learn-more/use-cases/dify-schedule.mdx`

> 作者：[Leo\_chen](https://github.com/leochen-g)，[Dify Schedule](https://github.com/leochen-g/dify-schedule) 与 [智能微秘书](https://github.com/leochen-g/wechat-assistant-pro) 开源项目作者

## 概述

Dify 定时任务管理工具是一个基于 GitHub Actions 的自动化解决方案，用于实现 Dify Workflow 的定时执行和状态监控。无需再为缺乏定时任务支持而感到困扰，本工具可以帮助设置自动执行任务并获取实时通知，优化你的工作效率。

> 注意：本工具仅支持 Dify Workflow 类型应用

## 🌟 核心功能

* 🔄 支持多 Workflow 并行自动执行
* ⏰ 灵活的定时配置（默认执行时间：UTC+8 06:30）
* 📱 多渠道消息通知集成
  * 企业级通知：企业微信、钉钉、飞书
  * 个人通知：微信、邮件、Server 酱、Pushplus
* 🔒 基于 GitHub Actions 的安全执行环境
* 🐲 支持青龙面板部署方案

## 🚀 快速开始

你可以通过以下两种方式设置和运行 Dify 定时任务助手：

1. **在线方式（GitHub Actions）**
2. **本地部署（青龙面板）**

### 方案一：GitHub Actions 部署

按照以下简单步骤快速配置你的自动化 Workflow：

1. **Fork 仓库** 访问 [Dify Workflow 定时助手代码仓库](https://github.com/leochen-g/dify-schedule)，点击 Fork 按钮，创建副本到你的 GitHub 账户。
2.  **配置密钥** 进入 Fork 代码仓库，依次点击 **Settings -> Secrets -> New repository secret**，添加以下密钥：

    | 密钥名称            | 填写内容                                 | 是否必填 |
    | --------------- | ------------------------------------ | ---- |
    | `DIFY_BASE_URL` | Dify 接口地址（默认：https://api.dify.ai/v1） | 否    |
    | `DIFY_TOKENS`   | Dify Workflow API 密钥（多个用 `;` 分隔）     | 是    |
    | `DIFY_INPUTS`   | Workflow 所需变量（JSON 格式）               | 否    |

    **通知配置（可选，推荐设置）**

    如果希望通过通知及时了解任务状态，可添加以下产品服务的密钥：

    | 密钥名称                     | 填写内容                                                                 | 用途     |
    | ------------------------ | -------------------------------------------------------------------- | ------ |
    | `EMAIL_USER`             | 发件人邮箱（需开启 SMTP）                                                      | 邮件通知   |
    | `EMAIL_PASS`             | 邮箱 SMTP 密码                                                           | 邮件通知   |
    | `EMAIL_TO`               | 收件人邮箱（多个用 `,` 分隔）                                                    | 邮件通知   |
    | `PUSHPLUS_TOKEN`         | [Pushplus](http://www.pushplus.plus/) 的 token                        | 微信通知   |
    | `SERVERPUSHKEY`          | [Server 酱](https://sct.ftqq.com/) 的密钥                                | 微信通知   |
    | `DINGDING_WEBHOOK`       | 钉钉机器人 webhook 地址                                                     | 钉钉通知   |
    | `WEIXIN_WEBHOOK`         | 企业微信机器人 webhook 地址                                                   | 企业微信通知 |
    | `FEISHU_WEBHOOK`         | 飞书机器人 webhook 地址                                                     | 飞书通知   |
    | `AIBOTK_KEY`             | [智能微秘书](https://wechat.aibotk.com/?r=dBL0Bn\&f=difySchedule) API Key | 微信通知   |
    | `AIBOTK_ROOM_RECIVER`    | 智能微秘书群聊名称                                                            | 微信群通知  |
    | `AIBOTK_CONTACT_RECIVER` | 智能微秘书联系人昵称                                                           | 微信私聊通知 |
3. **启用 Workflow** 前往 **Actions**标签页，启用 Workflow 以启动定时任务。

### 方案二：本地部署

> 青龙面板是一款开源的定时任务管理工具，[项目地址](https://github.com/whyour/qinglong)。

如果你的环境无法使用 GitHub Actions，你可以选择本地部署方案。通过在青龙面板中设置定时任务实现 Dify 应用的定时触发。

1. **安装青龙面板**

详细说明请参考 [项目地址](https://github.com/whyour/qinglong)。

2. **添加订阅**

在服务器中执行以下命令添加 [Dify 定时任务项目](https://github.com/leochen-g/dify-schedule) 的订阅任务：

```bash
ql repo https://github.com/leochen-g/dify-schedule.git "ql_" "utils" "sdk"
```

3. **依赖安装**
   * 导航至【依赖管理】->【NodeJS】
   * 安装 `axios` 依赖包
4. **环境变量配置**
   * `DIFY_TOKENS`：Workflow API 密钥（必填）
   * `DIFY_BASE_URL`：API 接口地址（可选）
   * 多个 token 使用分号 `;` 分隔
5. **通知配置**
   * 直接使用青龙面板内置的通知系统

## 📸 通知效果预览

<table>
  <thead>
    <tr>
      <th>微信通知示例</th>
      <th>邮件通知示例</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>!<a href="https://assets-docs.dify.ai/2025/01/854f7a601a7dc277f8df095f06b2d5f0.png">微信</a></td>
      <td>!<a href="https://assets-docs.dify.ai/2025/01/192e3ec292686129198a45562fad26cf.png">邮件</a></td>
    </tr>
  </tbody>
</table>
## ❓ 故障排查指南

### API 密钥获取流程

1. 登录 Dify 控制台
2. 进入目标 Workflow 应用
3. 访问 API 参考页面
4. 获取 API 密钥

![](https://assets-docs.dify.ai/2025/01/f7239b198b4aeac98d209bfcebae153d.png)

## 常见问题

1. **连接问题**
   * 确保私有部署的 Dify 实例具有公网访问能力
   * 验证网络连接和防火墙配置
2. **执行错误**
   * 验证应用类型是否为 Workflow
   * 检查 `DIFY_INPUTS` 配置格式（JSON）
   * 分析执行日志，确认所需变量配置完整

如遇其他问题，欢迎在 GitHub Issues 中反馈（请注意脱敏处理）。

## 🤝 贡献指南

我们欢迎社区贡献，包括但不限于：

* 功能优化建议
* Bug 修复
* 文档完善
* 新功能开发

请通过 Pull Request 或 Issue 参与项目建设。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/dify-schedule.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 如何连接 AWS Bedrock 知识库？
> 来源：`zh-hans/learn-more/use-cases/how-to-connect-aws-bedrock.mdx`

本文将简要介绍如何通过外部知识库 API 将 Dify 平台与 AWS Bedrock 知识库相连接，使得 Dify 平台内的 AI 应用能够直接获取存储在 AWS Bedrock 知识库中的内容，扩展新的信息来源渠道。

### 前置准备

* AWS Bedrock Knowledge Base
* Dify SaaS 服务 / Dify 社区版
* 后端 API 开发基础知识

### 1. 注册并创建 AWS Bedrock Knowledge Base

访问 [AWS Bedrock](https://aws.amazon.com/bedrock/)，创建 Knowledge Base 服务。

![创建 AWS Bedrock Knowledge Base](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/1bf24647a5ffeba4accecd1052011980.png)

### 2. 构建后端 API 服务

Dify 平台尚不能直接连接 AWS Bedrock Knowledge Base，需要开发团队参考 Dify 关于外部知识库连接的 [API 定义](../../guides/knowledge-base/external-knowledge-api-documentation)，手动创建后端 API 服务，建立与 AWS Bedrock 的连接。具体架构示意图请参考：

![构建后端 API 服务](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/c57ce0a77ee668268f53e91497bd5c2b.png)

你可以参考以下 2 个代码文件，构建后端服务 API。

`knowledge.py`

```python
from flask import request
from flask_restful import Resource, reqparse

from bedrock.knowledge_service import ExternalDatasetService

class BedrockRetrievalApi(Resource):
    # url : <your-endpoint>/retrieval
    def post(self):
        parser = reqparse.RequestParser()
        parser.add_argument("retrieval_setting", nullable=False, required=True, type=dict, location="json")
        parser.add_argument("query", nullable=False, required=True, type=str,)
        parser.add_argument("knowledge_id", nullable=False, required=True, type=str)
        args = parser.parse_args()

        # Authorization check
        auth_header = request.headers.get("Authorization")
        if " " not in auth_header:
            return 
                "error_code": 1001,
                "error_msg": "Invalid Authorization header format. Expected 'Bearer <api-key>' format."
            , 403
        auth_scheme, auth_token = auth_header.split(None, 1)
        auth_scheme = auth_scheme.lower()
        if auth_scheme != "bearer":
            return 
                "error_code": 1001,
                "error_msg": "Invalid Authorization header format. Expected 'Bearer <api-key>' format."
            , 403
        if auth_token:
            # process your authorization logic here
            pass

        # Call the knowledge retrieval service
        result = ExternalDatasetService.knowledge_retrieval(
            args["retrieval_setting"], args["query"], args["knowledge_id"]
        )
        return result, 200
```

`knowledge_service.py`

```python

class ExternalDatasetService:
    @staticmethod
    def knowledge_retrieval(retrieval_setting: dict, query: str, knowledge_id: str):
        # get bedrock client
        client = boto3.client(
            "bedrock-agent-runtime",
            aws_secret_access_key="AWS_SECRET_ACCESS_KEY",
            aws_access_key_id="AWS_ACCESS_KEY_ID",
            # example: us-east-1
            region_name="AWS_REGION_NAME",
        )
        # fetch external knowledge retrieval
        response = client.retrieve(
            knowledgeBaseId=knowledge_id,
            retrievalConfiguration={
                "vectorSearchConfiguration": {"numberOfResults": retrieval_setting.get("top_k"), "overrideSearchType": "HYBRID"}
            },
            retrievalQuery="text": query,
        )
        # parse response
        results = []
        if response.get("ResponseMetadata") and response.get("ResponseMetadata").get("HTTPStatusCode") == 200:
            if response.get("retrievalResults"):
                retrieval_results = response.get("retrievalResults")
                for retrieval_result in retrieval_results:
                    # filter out results with score less than threshold
                    if retrieval_result.get("score") < retrieval_setting.get("score_threshold", .0):
                        continue
                    result = 
                        "metadata": retrieval_result.get("metadata"),
                        "score": retrieval_result.get("score"),
                        "title": retrieval_result.get("metadata").get("x-amz-bedrock-kb-source-uri"),
                        "content": retrieval_result.get("content").get("text"),

                    results.append(result)
        return 
            "records": results

```

在此过程中，你可以构建 API 接口地址以及用于鉴权的 API Key 并用于后续的连接。

### 3. 获取 AWS Bedrock Knowledge Base ID

登录 AWS Bedrock Knowledge 后台，获取已创建 Knowledge Base 的 ID。此参数将会在[后续步骤](how-to-connect-aws-bedrock.md#id-5.-lian-jie-wai-bu-zhi-shi-ku)用于与 Dify 平台的连接。

![获取 AWS Bedrock Knowledge Base ID](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/03fd7e383daf419765bbfd05c3742923.png)

### 4. 关联外部知识 API

前往 Dify 平台中的 **“知识库”** 页，点击右上角的 **“外部知识库 API”**，轻点 **“添加外部知识库 API”**。

按照页面提示，依次填写以下内容：

* 知识库的名称，允许自定义名称，用于区分 Dify 平台内所连接的不同外部知识 API；
* API 接口地址，外部知识库的连接地址，可在[第二步](how-to-connect-aws-bedrock.md#id-2.-gou-jian-hou-duan-api-fu-wu)中自定义。示例 `api-endpoint/retrieval`；
* API Key，外部知识库连接密钥，可在[第二步](how-to-connect-aws-bedrock.md#id-2.-gou-jian-hou-duan-api-fu-wu)中自定义。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/4f2ce69f8c59e788beb91303c68db571.png)

### 5. 连接外部知识库

前往 **“知识库”** 页，点击添加知识库卡片下方的 **“连接外部知识库”** 跳转至参数配置页面。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/c3c30c7ed923ee1d7986e92bb35186c6.png)

填写以下参数：

* **知识库名称与描述**
*   **外部知识库 API**

    选择在[第四步](how-to-connect-aws-bedrock.md#id-4.-guan-lian-wai-bu-zhi-shi-api)中关联的外部知识库 API
*   **外部知识库 ID**

    填写在[第三步](how-to-connect-aws-bedrock.md#id-3.-huo-qu-aws-bedrock-knowledge-base-id)中获取的 AWS Bedrock knowledge base ID
*   **调整召回设置**

    \*\*Top K：\*\*用户发起提问时，将请求外部知识 API 获取相关性较高的内容分段。该参数用于筛选与用户问题相似度较高的文本片段。默认值为 3，数值越高，召回存在相关性的文本分段也就越多。

    \*\*Score 阈值：\*\*文本片段筛选的相似度阈值，只召回超过设置分数的文本片段，默认值为 0.5。数值越高说明对于文本与问题要求的相似度越高，预期被召回的文本数量也越少，结果也会相对而言更加精准。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/58c324c08c1c5fc23ab31e04967ae449.png)

设置完成后即可建立与外部知识库 API 的连接。

### 6. 测试外部知识库连接与召回

建立与外部知识库的连接后，开发者可以在 **“召回测试”** 中模拟可能的问题关键词，预览从 AWS Bedrock Knowledge Base 召回的文本分段。

![测试外部知识库的连接与召回](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/fbc64f060f9fda83847428439b07c247.png)

若对于召回结果不满意，可以尝试修改召回参数或自行调整 AWS Bedrock Knowledge Base 的检索设置。

![调整 AWS Bedrock Knowledge Base 文本处理参数](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/0984a89e4cf2a1150ec3160da14c656e.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/how-to-connect-aws-bedrock.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 如何将 Dify Chatbot 集成至 Wix 网站？
> 来源：`zh-hans/learn-more/use-cases/how-to-integrate-dify-chatbot-to-your-wix-website.mdx`

Wix 是一个非常流行的网站创建平台，它允许用户通过拖拽的方式可视化创建自己的网站。通过 iframe 代码功能，能够实现 Wix 与 Dify 聊天机器人的集成。

除此之外，你还可以使用此功能在 Wix 网页内显示来自外部服务器和其他来源的内容，例如说创建天气小部件、股票小部件、日历或任何其它自定义网页元素。

在本文中，我们将指导你如何将 Dify 聊天机器人通过 iframe 代码嵌入到你的 Wix 网站中。除了将应用嵌入至 Wix 网站内，你也可以通过同样的方法将 Dify 应用集成至你的网站、博客或其他网页中。

## 1. 获取 Dify 应用的 iFrame 代码片段

假设你已创建了一个 [Dify AI 应用](./zh-hans/guides/application-orchestrate/creating-an-application)，你可以通过以下步骤获取 Dify 应用的 iFrame 代码片段：

* 登录你的 Dify 账户
* 选择你想要嵌入的 Dify 应用
* 点击右上角的“发布”按钮
*   在发布页面中，选择 “Embed Into Site” 选项。

    ![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/238daf21d6632d7d20cc9a6b882194f9.png)
* 选择合适的样式并复制显示的 iFrame 代码，例如：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/ebab9e1f734d80e793db3675a46099fb.png)

## 2. 在 Wix 网站中嵌入 iFrame 代码片段

登录 Wix 网站，打开你要编辑的网页。点击网页左侧蓝色的 `+` （Add Elements）按钮，然后选择 **Embed Code**，最后点击 **Embed HTML** 添加一个 HTML iFrame 元素到页面。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/43b79d103da8beb69619e8f122609b89.png)

在 `HTML Settings` 框内选择 `Code` 选项，复制并粘贴你在 Dify 应用中获取的 iFrame 代码片段，然后点击 **Update** 按钮进行保存并进行预览。

以下是一个嵌入 Dify Chatbot 的 iFrame 代码示例：

```bash
<iframe src="https://udify.app/chatbot/1yS3gohroW1sKyLc" style="width: 100%; height: 100%; min-height: 700px" frameborder="0" allow="microphone"></iframe>
```

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/fb257be087645aaa5eb2ae01a4a15d8d.png)

> ⚠️ 请确保 iFrame 代码中的地址以 HTTPS 开头，HTTP 地址将无法正常显示。

## 3. 自定义 Dify Chatbot

你可以调整 Dify Chatbot 的按钮样式、位置和其它设置。

### 3.1 自定义样式

你可以通过修改 iFrame 代码中的 `style` 属性来自定义 Chatbot 按钮的样式。例如：

```bash
<iframe src="https://udify.app/chatbot/1yS3gohroW1sKyLc" style="width: 100%; height: 100%; min-height: 700px" frameborder="0" allow="microphone"></iframe>

# 添加一个 2 像素宽的黑色实线边框 border: 2px solid #000

→

<iframe src="https://udify.app/chatbot/1yS3gohroW1sKyLc" style="width: 80%; height: 80%; min-height: 500px; border: 2px solid #000;" frameborder="0" allow="microphone"></iframe>
```

### 3.2 自定义位置

你还可以通过修改 `style` 属性中的 `position` 值可以调整按钮的位置。例如：

```bash
<iframe src="https://udify.app/chatbot/1yS3gohroW1sKyLc" style="width: 100%; height: 100%; min-height: 700px" frameborder="0" allow="microphone"></iframe>

# 将 Chatbot 固定在网页右下角，距离底部和右侧 20 像素。

→

<iframe src="https://udify.app/chatbot/1yS3gohroW1sKyLc" style="width: 100%; height: 100%; min-height: 700px; position: fixed; bottom: 20px; right: 20px;" frameborder="0" allow="microphone"></iframe>
```

## 常见问题

**1. iframe 方框内未正常显示内容应如何处理？**

* 确保 URL 以 HTTPS 开头；
* 检查 `iframe` 代码中是否有拼写错误；
* 确认嵌入的内容符合 Wix 的安全政策；

**2. iframe 内容被裁剪，内容显示不全应如何处理？**

你可以调整并修改 `iframe` 代码框内的 `width` 和 `height` 的百分比值。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/how-to-integrate-dify-chatbot-to-your-wix-website.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 如何让 LLM 应用提供循序渐进的聊天体验？
> 来源：`zh-hans/learn-more/use-cases/how-to-make-llm-app-provide-a-progressive-chat-experience.mdx`

让 LLM 应用提供循序渐进的聊天体验的关键在于，LLM 自身能够感知到与用户所处的对话轮数。例如在第五轮对话时深入扩展某项话题，或者在第 X 轮对话自动回顾历史对话并给出复盘分析。

本文将为你介绍如何使用 Chatflow 类型应用预置的 `sys.dialogue_count` 系统变量，利用其会随着对话轮数自动新增 +1 的特性，编排出能够感知对话轮数，并能够向用户提供循序渐进聊天体验的 AI 应用。

### 场景 1：为用户提供循序渐进的对话深度

**应用场景：AI 编程教师**

新手刚开始学习编程知识时，初始阶段大量晦涩的专业名词将造成困扰。一个理想的学习场景是老师能够根据学生自身对知识的掌握情况，以及对话的聊天次数，循序渐进介绍更多教学内容并布置合理的学习任务。

#### 设计思路

<table>
  <thead>
    <tr>
      <th>对话轮数</th>
      <th>教学策略</th>
      <th>内容重点</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1-5 轮</td>
      <td>使用简单、易懂的语言</td>
      <td>介绍编程的基本概念（变量、数据类型、控制流等）</td>
    </tr>
    <tr>
      <td>6-10 轮</td>
      <td>逐步引入基础编程术语</td>
      <td>深入探讨基础概念，提供更多示例</td>
    </tr>
    <tr>
      <td>11-15 轮</td>
      <td>使用更多专业术语</td>
      <td>探讨特定编程主题（如面向对象编程、数据结构）</td>
    </tr>
    <tr>
      <td>15 轮以后</td>
      <td>高级编程对话</td>
      <td>讨论高级概念、最佳实践、项目开发</td>
    </tr>
  </tbody>
</table>
#### 实现方法

1. 设立第一个 LLM 节点，收集并分析用户的初始编程水平能力
2. 新增数个条件分支，判断该用户与第一个 LLM 节点的对话次数
3. 将用户分流至不同阶段编程学习 LLM 节点。

在第一个 LLM 节点后新增数个条件分支，判断 `sys.dialogue_count` 值的所处区间，然后分流至不同编程阶段的 LLM 节点。

![AI 编程教师](https://assets-docs.dify.ai/2025/01/27d15ae4fcec99e1d31403efbe8a1b53.png)

### 场景 2：定期回顾对话历史

**应用场景：语言能力测试 AI 助手**

在学习新语言时，定期复习和巩固知识点对于长期记忆至关重要。AI 语言学习助手可以通过跟踪对话轮数，在适当的时机提供回顾和测试。

#### 设计思路

<table>
  <thead>
    <tr>
      <th>对话轮数</th>
      <th>学习策略</th>
      <th>活动类型</th>
      <th>目的</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>每 10 轮</td>
      <td>知识回顾</td>
      <td>简短复习测验</td>
      <td>巩固近期学习的内容</td>
    </tr>
    <tr>
      <td>每 20 轮</td>
      <td>综合测试</td>
      <td>全面的语言能力测试，然后给出能力评估报告以及接下来的学习建议</td>
      <td>评估整体学习进度</td>
    </tr>
  </tbody>
</table>
#### 实现方法

1. 设立第一个 LLM 对话应用，收集并分析用户的初始语言能力，并给出训练习题
2. 新增条件分支，在第 10 轮对话时制订小型测验，并给出学习回顾；在第 20 轮对话时给出更加全面的测验和学习报告。其余对话轮数则正常给出单个训练习题。

通过在特定轮数回顾学生过往的学习分析报告，LLM 能够更加像一个专业老师一样重新审视并调整用户的学习计划。

![](https://assets-docs.dify.ai/2025/01/3b99ffe6ee3425789fc08da0f267afa0.png)

> 如果还想要了解更多关于工作流的编排技巧，请参考[《工作流》](./zh-hans/guides/workflow)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/how-to-make-llm-app-provide-a-progressive-chat-experience.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## DeepSeek 与 Dify 集成指南：打造具备多轮思考的 AI 应用
> 来源：`zh-hans/learn-more/use-cases/integrate-deepseek-to-build-an-ai-app.mdx`

## 概述

[DeepSeek](https://www.deepseek.com/) 作为具备多轮推理能力的开源大语言模型，以**高性能、低成本、易部署**的特性成为智能应用开发的理想基座。通过其 API 服务，开发者可快速调用 DeepSeek 的复杂逻辑推理与内容生成能力。在传统开发模式下，构建生产级 AI 应用往往需要独立完成模型适配、接口开发、交互设计等环节。

Dify 作为同样开源的生成式 AI 应用开发平台，能够帮助开发者基于 DeepSeek 大模型快速开发出更加智能的 AI 应用，你可以在 Dify 平台内获得以下开发体验：

* **可视化构建** - 通过可视化编排界面，3 分钟搭建基于 DeepSeek R1 的 AI 应用
* **知识库增强** - 关联内部文档，开启 RAG 能力并构建精准问答系统
* **工作流扩展** - 提供多种第三方工具插件、可视化拖拽式编排应用功能节点，实现复杂业务逻辑
* **数据洞察力** - 内置总对话数、应用使用用户数等数据监控模块，支持与更加专业的监控平台集成 ...

本文将详解 DeepSeek API 与 Dify 的集成步骤，助你快速实现两大核心场景：

* **智能对话机器人开发** - 直接调用 DeepSeek R1 的思维链推理能力
* **知识增强型应用构建** - 通过私有知识库实现精准信息检索与生成

> 针对金融、法律等高合规需求场景，Dify 提供 [**本地私有化部署 DeepSeek + Dify**](broken-reference)，支持 DeepSeek 模型与 Dify 平台同步部署至内网

通过 Dify × DeepSeek 的技术组合，开发者可跳过底层架构搭建，跃迁至**场景化 AI 能力落地阶段**，让大模型技术快速转化为业务生产力。

## 前置准备

### 1. 申请 DeepSeek API

访问 [DeepSeek API 开放平台](https://platform.deepseek.com/)，按照页面提示进行申请 API Key。

> 若提示链接无法访问，你也可以考虑在本地部署 DeepSeek 模型。详细说明请参考 [本地部署指南](broken-reference)

### 2. 注册 Dify

Dify 是一个能够帮助你快速搭建生成式 AI 应用的平台，通过接入 DeepSeek API，你可以快速搭建出一个能够易于使用的 DeepSeek AI 应用。

## 集成步骤

### 1. 将 DeepSeek 接入至 Dify

访问 Dify 平台，点击右上角**头像 → 设置 → 模型供应商**，找到 DeepSeek，将上文获取的 API Key 粘贴至其中。点击保存，校验通过后将出现成功提示。

![](https://assets-docs.dify.ai/2025/01/a7d6b4e05a3c9d85d0cb42f4dd018bc8.png)

### 2. 搭建 DeepSeek AI 应用

1. 轻点 Dify 平台首页左侧的"创建空白应用"，选择"聊天助手"类型应用并进行简单的命名。

![](https://assets-docs.dify.ai/2025/01/7f56bc3c836c7248043b656fa95e474e.png)

2. 选择 `deepseek-reasoner` 模型

> deepseek-reasoner 模型又称为 deepseek-r1 模型。

![](https://assets-docs.dify.ai/2025/01/de134c6285985fe1552223eb33641b9f.png)

配置完成后即可在聊天框中进行互动。

![](https://assets-docs.dify.ai/2025/01/3760e9a0cb7c2070978134d8f7f13929.png)

### 3. 为 AI 应用启用文本分析能力

[RAG（检索增强生成）](https://docs.dify.ai/zh-hans/learn-more/extended-reading/retrieval-augment)是一种先进的信息处理技术，它通过检索相关知识，向 LLM 提供必要的上下文信息，融入 LLM 的内容生成过程，提升回答的准确性和专业度。当你上传内部文档或专业资料后，AI 能够基于这些知识提供更有针对性的解答。

#### 3.1 创建知识库

将需要 AI 分析处理的文档上传至知识库中。为确保 DeepSeek 模型能够准确理解文档内容，建议使用"父子分段"模式进行文本处理 - 这种模式能够更好地保留文档的层级结构和上下文关系。如需了解详细的配置步骤，请参考：[创建知识库](https://docs.dify.ai/zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents)。

![](https://assets-docs.dify.ai/2025/01/f38af53d2b124391e2ea32f29da7d87d.png)

#### 3.2 将知识库集成至 AI 应用

在 AI 应用的"上下文"内添加知识库，在对话框内输入相关问题。LLM 将首先从知识库内获取与问题相关上下文，在此基础上进行总结并给出更高质量的回答。

![](https://assets-docs.dify.ai/2025/01/4254ec131fece172a59304414a060f4e.png)

### 4. 分享 AI 应用

构建完成后，你可以将该 AI 应用分享给他人使用或集成至其它网站内。

![](https://assets-docs.dify.ai/2025/01/d32857964683b48027d20d029e7e06c0.png)

## 阅读更多

除了构建简单的 AI 应用外，你还可以创建 Chatflow / Workflow 搭建更多复杂功能的应用（例如具备文件识别、图像识别、语音识别等能力）。详细说明请参考以下文档：

* [工作流](https://docs.dify.ai/zh-hans/guides/workflow)
* [文件上传](https://docs.dify.ai/zh-hans/guides/workflow/file-upload)
* [本地部署 DeepSeek + Dify，构建你的专属私有 AI 助手](broken-reference)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/integrate-deepseek-to-build-an-ai-app.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 使用全套开源工具构建 LLM 应用实战：在 Dify 调用 Baichuan 开源模型能力
> 来源：`zh-hans/learn-more/use-cases/practical-implementation-of-building-llm-applications-using-a-full-set-of-open-source-tools.mdx`

> 作者：Rico。Dify.AI 资深前端工程师，LLM 技术探索者。

## 背景

在当下开源大语言模型火热的背景下，有很大一部分开发者希望本地部署开源 LLM，用于研究 LLM 或者是基于开源 LLM 构建自己的 LLM 应用。笔者也正在尝试通过开源社区的一系列相关优秀项目，通过本地化部署服务来构建自己的 LLM 应用。那么本地部署一个开源 LLM 来构建一个聊天应用需要哪些准备呢？

1. **本地环境的准备：** 因为我们需要在本地部署一个开源的大模型，所以你需要准备一个相当硬核的本地环境。硬件上需要一台拥有高性能、大显存的 NVDIA 显卡，大容量高速内存以及大容量固态硬盘，软件上则需要安装显卡驱动、CUDA、Python 环境。笔者这次选择跑 Baichuan-13B-Chat 模型为例，基本配置是 CPU i9-13900K、GTX3090 24 GB 双卡、64GB 内存和 2TB 固态硬盘。
2. **一个大型语言模型（LLM）：** 这是我们构建 LLM 应用的基础。不同的 LLM 根据预训练的数据和目标任务的不同，其模型结构和学到的知识也不相同。基于不同模型构建出来的 AI 应用表现也会不一样。你可以通过火热的 AI 社区 [Hugging Face](https://huggingface.co/) 上找自己感兴趣的开源 LLMs 来进行尝试和能力对比 。
3. **一个本地部署 LLM 的推理服务：** 推理服务可以将预训练好的 LLM 模型加载到本地服务器，并提供模型预测接口，这样就可以本地化使用 LLM 模型进行各种 NLP 任务，而不需要依赖云服务。你可以使用一些优秀的 GitHub 开源项目，这些项目对热门的开源 LLM 都做了推理服务的一键部署。知名度比较高的有 [LocalAI](https://github.com/go-skynet/LocalAI)、[openLLM](https://github.com/bentoml/OpenLLM) 等。
4. **一个简单易用的“ LLM 操作系统 ” Dify.AI：** 如果要基于 LLM 的能力构建一个聊天应用，你可能需要学习研究全套的 LLM 技术栈，比如：不同模型的 API 调用、向量数据库选型、Embedding 技术研究等等。如果你使用开源项目 [Dify.AI](https://github.com/langgenius/dify)，则可以省掉这些研究学习工作，**帮助你通过可视化的界面即可快速创建基于不同 LLM 能力的** **AI** **应用。** Dify 最近的版本新增了对开源 LLMs 的支持，对托管在 HuggingFace 和 Replicate 上所有的模型都能快速调用和切换使用，同时支持本地部署方式能够基于 [OpenLLM](https://github.com/bentoml/OpenLLM) 和 [Xorbits inference](https://github.com/xorbitsai/inference) 推理服务来实现 AI 应用的构建。

笔者将尝试使用**开源的 LLMOps 平台 Dify.AI + 开源的推理服务** **Xinference** **+** **开源模型 Baichuan-13B-Chat** 为例，手把手实操教你在 windows 环境下，使用全套开源工具产品来构建一个 LLM 聊天应用。

## 环境准备

Conda 和 Python 是基础要求，本文将从零开始介绍环境配置。

#### 配置 python 环境

一般情况下建议使用 Conda 进行 python 版本管理。先根据 Conda [官网文档](https://docs.conda.io/projects/conda/en/stable/user-guide/install/index.html)安装 Conda。然后用 Conda 初始化 Python 3.11 环境：

```
conda create --name python-3-11 python=3.11
conda activate python-3-11
```

#### 安装 CUDA

推荐直接从[官网](https://developer.nvidia.com/cuda-downloads?target_os=Windows\&target_arch=x86_64\&target_version=11\&target_type=exe_local)安装。 Windows 11 选择下图版本。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/ef602bb8e4b55fbfb93208396ebfc6d2.png)

根据引导安装完，打开 `NVDIA 控制面板 -> 系统信息` 看到完成了安装。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/dc6d0b2f73a59c017a5da9582a70bc97.png)

**WSL2 准备**

由于 Dify 的 docker 部署推荐使用 WSL2 环境。所以现在先安装 WSL2 。参考[微软官方指引](https://learn.microsoft.com/en-us/windows/wsl/install)。

**第一步，管理员身份运行** **CMD** **：**

1. Win + R
2. Input CMD
3. Ctrl + Shift + Enter

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/c9b00fafc4c2c6c414a73011060e0291.png)

**第二步，在** **CMD** **中用指令安装**

```PowerShell
wsl --install
```

结果看到了支持的各种系统版本：

```PowerShell
适用于 Linux 的 Windows 子系统已安装。

以下是可安装的有效分发的列表。
请使用“wsl --install -d <分发>”安装。

NAME                                   FRIENDLY NAME
Ubuntu                                 Ubuntu
Debian                                 Debian GNU/Linux
kali-linux                             Kali Linux Rolling
Ubuntu-18.04                           Ubuntu 18.04 LTS
Ubuntu-20.04                           Ubuntu 20.04 LTS
Ubuntu-22.04                           Ubuntu 22.04 LTS
OracleLinux_7_9                        Oracle Linux 7.9
OracleLinux_8_7                        Oracle Linux 8.7
OracleLinux_9_1                        Oracle Linux 9.1
openSUSE-Leap-15.5                     openSUSE Leap 15.5
SUSE-Linux-Enterprise-Server-15-SP4    SUSE Linux Enterprise Server 15 SP4
SUSE-Linux-Enterprise-15-SP5           SUSE Linux Enterprise 15 SP5
openSUSE-Tumbleweed                    openSUSE Tumbleweed
```

我使用选择安装了默认的 Ubuntu 版本：

```PowerShell
wsl --install -d Ubuntu
```

之后就可以在 CMD 中使用 `wsl`命令进入Ubuntu 了。

**第三步，安装 Docker Desktop**

去 Docker [官方文档](https://docs.docker.com/desktop/install/windows-install/#wsl-2-backend)下载 Docker Desktop。安装时注意勾上 `Use WSL 2 instead of Hyper-V` 选项。安装完成后重启电脑。通过 CMD 查看是否正常安装好。

```PowerShell
wsl -l --verbose

 NAME                   STATE           VERSION
* Ubuntu                 Running         2
  docker-desktop         Running         2
  docker-desktop-data    Running         2
```

可以看到 WSL 中 Ubuntu 和 Docker 都运行起来了，并且确认是 WSL2 版本。

**第四步，为 WSL 配置代理**

由于每次重启后 WSL 的 ip 地址都会变更，所以我们可以编写一个脚本来解决。第 4 行改为你自己的端口号。

```Bash
#!/bin/sh
hostip=$(cat /etc/resolv.conf | grep nameserver | awk '{ print $2 }')
wslip=$(hostname -I | awk '{print $1}')
port=7890

PROXY_HTTP="http://$hostip:$port"

set_proxy(){

  git config --global http.https://github.com.proxy ${PROXY_HTTP}
  git config --global https.https://github.com.proxy $PROXY_HTTP

  echo "Proxy has been opened."
}

unset_proxy()
  unset http_proxy
  unset HTTP_PROXY
  unset https_proxy
  unset HTTPS_PROXY
  unset ALL_PROXY
  unset all_proxy
  git config --global --unset http.https://github.com.proxy
  git config --global --unset https.https://github.com.proxy

  echo "Proxy has been closed."

test_setting(){
  echo "Host IP:" ${hostip}
  echo "WSL IP:" $wslip
  echo "Try to connect to Google..."
  resp=$(curl -I -s --connect-timeout 5 -m 5 -w "%http_code" -o /dev/null www.google.com)
  if [ $resp = 200 ]; then
    echo "Proxy setup succeeded!"
  else
    echo "Proxy setup failed!"
  fi
}

if [ "$1" = "set" ]
then
  set_proxy

elif [ "$1" = "unset" ]
then
  unset_proxy

elif [ "$1" = "test" ]
then
  test_setting
else
  echo "Unsupported arguments."
fi
```

可以修改`~/.bashrc` 方便使用命令：

```Bash
alias proxy="source /path/to/proxy.sh"
```

详细可以参考了该[博客](https://www.cnblogs.com/tuilk/p/16287472.html)。

**第五步，进入 Ubuntu 安装 conda 配置 python**

和前面的环境准备一样，参照官方文档安装 conda 配置 python，不过是安装 linux 版本。

**第六步，安装 WSL 的 CUDA**

进入官网，选择 WSL-Ubuntu 版本，按照指引使用命令行安装。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/eaeaeee640f22d4d29869922e0e881d4.png)

修改`~/.bashrc`将 CUDA 添加至环境变量：

```Bash

```

**第七步，安装 PyTorch**

进入 PyTorch [官网](https://pytorch.org/)，按照环境安装 PyTorch。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/a4ed682cbf002e54f0343a9b47dd9b95.png)

这样环境准备就完成了。

## 部署推理服务 Xinference

根据 Dify 的[部署文档](./zh-hans/advanced/model-configuration/xinference)，Xinference 支持的模型种类很多。本次以 Baichuan-13B-Chat 为例。

> [Xorbits inference](https://github.com/xorbitsai/inference) 是一个强大且通用的分布式推理框架，旨在为大型语言模型、语音识别模型和多模态模型提供服务，甚至可以在笔记本电脑上使用。它支持多种与 GGML 兼容的模型，如 ChatGLM，Baichuan，Whisper，Vicuna，Orca 等。 Dify 支持以本地部署的方式接入 Xinference 部署的大型语言模型推理和 Embedding 能力。

#### 安装 Xinfernece

在 WSL 中执行如下命令：

```Bash
$ pip install "xinference"
```

上面的命令会安装 Xinference 用于推理的基础依赖。Xinference 还支持用 `ggml 推理` 和 `PyTorch 推理`，需要装如下的依赖：

```Bash
$ pip install "xinference[ggml]"
$ pip install "xinference[pytorch]"
$ pip install "xinference[all]"
```

#### 启动 Xinference 并下载部署 Baichuan-13B-Chat 模型

在 WSL 中执行下面的命令：

```Bash
$ xinference -H 0.0.0.0
```

Xinference 默认会在本地启动一个 worker，端点为：`http://127.0.0.1:9997`，端口默认为 `9997`。 默认只可本机访问，配置了 `-H 0.0.0.0`，非本地客户端可任意访问。 如需进一步修改 host 或 port，可查看 Xinference 的帮助信息：`xinference --help`。

```Bash
2023-08-25 18:08:31,204 xinference   27505 INFO     Xinference successfully started. Endpoint: http://0.0.0.0:9997
2023-08-25 18:08:31,204 xinference.core.supervisor 27505 INFO     Worker 0.0.0.0:53860 has been added successfully
2023-08-25 18:08:31,205 xinference.deploy.worker 27505 INFO     Xinference worker successfully started.
```

在浏览器中打开: [http://localhost:9997](http://localhost:9997)，选择 baichuan-chat，pytorch，13B，4bit，点击 create 部署。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/ba28b73f87c96b11dbde2421d9ab93e4.png)

或者使用 CLI 部署:

```Bash
xinference launch --model-name baichuan-chat --model-format pytorch --size-in-billions 13 --quantization 4
```

由于不同模型在不同硬件平台兼容性不同，请查看 [Xinference 内置模型](https://inference.readthedocs.io/en/latest/models/builtin/index.html) 确定创建的模型是否支持当前硬件平台。

#### 使用 Xinference 管理模型

要查看部署好的所有模型，在命令行中，执行下面的命令：

```Bash
$ xinference list 
```

会显示类似下面的信息：

```Bash
UID                                   Type    Name           Format      Size (in billions)  Quantization
------------------------------------  ------  -------------  --------  --------------------  --------------
0fc70cd0-4b2a-11ee-a428-00155d0b318a  LLM     baichuan-chat  pytorch                     13  4-bit
```

`0fc70cd0-4b2a-11ee-a428-00155d0b318a` 就是刚才部署的模型的 uid 。

## 部署 Dify.AI

主要流程参考官网[部署文档](./zh-hans/getting-started/install-self-hosted/docker-compose)。

#### Clone Dify

Clone Dify 源代码至本地。

```Bash
git clone https://github.com/langgenius/dify.git
```

#### Start Dify

进入 Dify 源代码的 docker 目录，执行一键启动命令：

```Bash
cd dify/docker
docker compose up -d
```

部署结果：

```Bash
[+] Running 7/7
 ✔ Container docker-weaviate-1  Running                                                0.0s 
 ✔ Container docker-web-1       Running                                                0.0s 
 ✔ Container docker-redis-1     Running                                                0.0s 
 ✔ Container docker-db-1        Running                                                0.0s 
 ✔ Container docker-worker-1    Running                                                0.0s 
 ✔ Container docker-api-1       Running                                                0.0s 
 ✔ Container docker-nginx-1     Started                                                0.9s 
```

最后检查是否所有容器都正常运行：

```Bash
docker compose ps
```

运行状态：

```Bash
NAME                IMAGE                              COMMAND                  SERVICE             CREATED             STATUS              PORTS
docker-api-1        langgenius/dify-api:0.3.16         "/bin/bash /entrypoi…"   api                 24 hours ago        Up 3 hours          5001/tcp
docker-db-1         postgres:15-alpine                 "docker-entrypoint.s…"   db                  33 hours ago        Up 3 hours          0.0.0.0:5432->5432/tcp
docker-nginx-1      nginx:latest                       "/docker-entrypoint.…"   nginx               24 hours ago        Up 4 minutes        0.0.0.0:80->80/tcp
docker-redis-1      redis:6-alpine                     "docker-entrypoint.s…"   redis               33 hours ago        Up 3 hours          6379/tcp
docker-weaviate-1   semitechnologies/weaviate:1.18.4   "/bin/weaviate --hos…"   weaviate            33 hours ago        Up 3 hours          
docker-web-1        langgenius/dify-web:0.3.16         "/bin/sh ./entrypoin…"   web                 33 hours ago        Up 3 hours          3000/tcp
docker-worker-1     langgenius/dify-api:0.3.16         "/bin/bash /entrypoi…"   worker              33 hours ago        Up 3 hours          5001/tcp
```

包括 3 个业务服务 `api / worker / web`，以及 4 个基础组件 `weaviate / db / redis / nginx`。

Docker 启动成功后，在浏览器中访问：`http://127.0.0.1/`。 设置过密码后登陆，会进入应用列表页。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/e08ff7a5c705854ac7a724ff15bb4b19.png)

至此，成功使用 Docker 部署了 Dify 社区版。

## 在 Dify 接入 Xinference

#### 配置模型供应商

在 `设置 > 模型供应商 > Xinference` 中填入模型信息：

* Model Name 是模型部署的名称。
* Server URL 是 Xinference 的 end point 地址。
* Model UID 则是通过 `xinference list`获取到的部署的模型的 UID。

需要注意的是 Sever Url 不能用 localhost。因为如果填 localhost，访问的是 docker 里的 localhost，会导致访问失败。解决方案是将 Sever Url 改成局域网 ip。

而 WSL 环境下则需要使用 WSL 的 IP 地址。在 WSL 中使用命令获取：

```Bash
hostname -I
172.22.195.4
```

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/b62a0703801c86c607b41046834f40fe.png)

#### 使用 Baichuan-13B-Chat

创建应用，就可以在应用中使用上一步配置的 Baichuan-13B-Chat 模型了。在 Dify 的提示词编排界面，选择 baichuan-chat 模型，设计你的应用提示词（prompt），即可发布一个可访问的 AI 应用。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/756122df2ffe44f58a9cff20cd7ec09e.png)

以上，就是本地部署 Dify 接入 Xinference 部署的 baichuan-chat 的全过程。 至此，我们基于 Baichuan-13B-Chat 的一个基本的聊天应用就基本完成了。

## 后记

当然，对于一个生产级别的 LLM 应用来说，只是完成大模型的接入和推理、聊天交互是远远不够。我们还需要针对性的对 LLM 进行 Prompt 的调优、添加私有数据作为上下文，亦或者是对 LLM 本身进行微调等工作，这需要长期的迭代和优化才能使得 LLM 应用表现越来越好。**Dify.AI 作为一个中间件工具平台，提供了一个完整 LLM App 技术栈的可视化的操作系统。完成了以上的基础服务部署后，后续的应用迭代和改进都可以基于 Dify 来完成，使得 LLM 应用的构建和管理变得更加简单和易用，在业务数据的处理上直接上传即可自动完成清洗处理，后续也将提供数据标注和改进的服务，甚至你的业务团队都可以参与协作。**

目前 LLM 的发展和应用落地还处于非常早期的阶段，相信在不久后，无论是 LLM 的能力释放，还是基于 LLM 之上的各个工具能力的不断完善，都会不断降低开发者探索 LLM 能力的门槛，让更多丰富场景的 AI 应用涌现。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/practical-implementation-of-building-llm-applications-using-a-full-set-of-open-source-tools.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 私有化部署 Ollama + DeepSeek + Dify，构建你的专属私人 AI 助手
> 来源：`zh-hans/learn-more/use-cases/private-ai-ollama-deepseek-dify.mdx`

## 概述

DeepSeek 是一款开创性的开源大语言模型，凭借其先进的算法架构和反思链能力，为 AI 对话交互带来了革新性的体验。通过私有化部署，你可以充分掌控数据安全和使用安全。你还可以灵活调整部署方案，并实现便捷的自定义系统。

Dify 作为同样开源的 AI 应用开发平台，提供完整的私有化部署方案。通过将本地部署的 DeepSeek 服务无缝集成到 Dify 平台，企业可以在确保数据隐私的前提下，在本地服务器环境内构建功能强大的 AI 应用。

以下是私有化部署方案的优势：

- **性能卓越**：提供媲美商业模型的对话交互体验
- **环境隔离**：完全离线运行，杜绝数据外泄风险
- **数据可控**：完全掌控数据资产，符合合规要求

## 前置准备

**硬件环境：**

- CPU >= 2 Core
- 显存/RAM ≥ 16 GiB（推荐）

**软件环境：**

- [Docker](https://www.docker.com/)
- Docker Compose
- [Ollama](https://ollama.com)
- [Dify 社区版](https://github.com/langgenius/dify)

## 开始部署

### 1. 安装 Ollama

[Ollama](https://ollama.com/) 是一款跨平台的大模型管理客户端（MacOS、Windows、Linux），旨在无缝部署大型语言模型 (LLM)，例如 DeepSeek、Llama、Mistral 等。Ollama 提供大模型一键部署，所有使用数据均会保存在本地机器内，提供全方面的数据隐私和安全性。

访问 [Ollama 官网](https://ollama.com/)，根据提示下载并安装 Ollama 客户端。安装完成后，在终端内运行 `ollama -v` 命令将输出版本号。

```bash
➜  ~ ollama -v
ollama version is 0.5.5
```

根据实际的环境配置，选择合适的 DeepSeek 尺寸模型进行部署。初次安装推荐安装 7B 尺寸模型。

![](https://assets-docs.dify.ai/2025/01/26978571a8d5f7188a952606f62e6a32.png)

运行命令 `ollama run deepseek-r1:7b` 安装 DeepSeek R1 模型。

![](https://assets-docs.dify.ai/2025/01/9297451d07d7704f73d6db0a83842f5f.png)

### 2. 安装 Dify 社区版

访问 Dify GitHub 项目地址，运行以下命令完成拉取代码仓库和安装流程。

```bash
git clone https://github.com/langgenius/dify.git
cd dify/docker
cp .env.example .env
docker compose up -d # 如果版本是 Docker Compose V1，使用以下命令：docker-compose up -d
```

运行命令后，你应该会看到所有容器的状态和端口映射。详细说明请参考 [Docker Compose 部署](https://docs.dify.ai/zh-hans/getting-started/install-self-hosted/docker-compose)。

Dify 社区版默认使用 80 端口，点击链接 `http://your_server_ip` 即可访问你的私有化 Dify 平台。

### 3. 将 DeepSeek 接入至 Dify

点击 Dify 平台右上角**头像 → 设置 → 模型供应商**，选择 Ollama，轻点“添加模型”。

![](https://assets-docs.dify.ai/2025/01/44e7b97087155d05d757c03e3f4f483b.png)

> 模型供应商内的 DeepSeek 对应在线 API 服务；本地部署的 DeepSeek 模型对应 Ollama 客户端。请确保 DeepSeek 模型已成功部署由 Ollama 客户端部署，详细部署说明请参考上文。

选择 LLM 模型类型。

- Model Name，填写具体部署的模型型号。上文部署的模型型号为 deepseek-r1 7b，因此填写 `deepseek-r1:7b`
- Base URL，填写 Ollama 客户端的运行地址，通常为 `http://your_server_ip:11434`。如遇连接问题，请参考[常见问题](https://docs.dify.ai/zh-hans/learn-more/use-cases/private-ai-ollama-deepseek-dify#id-1.-docker-bu-shu-shi-de-lian-jie-cuo-wu)。
- 其它选项保持默认值。根据 [DeepSeek 模型说明](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B)，最大生成长度为 32,768 Tokens。

![](https://assets-docs.dify.ai/2025/01/6f3b53427e46786ba7d1374739344142.png)

## 搭建 AI 应用

### DeepSeek AI Chatbot（简单应用）

1. 轻点 Dify 平台首页左侧的"创建空白应用"，选择"聊天助手"类型应用并进行简单的命名。

![](https://assets-docs.dify.ai/2025/01/7f56bc3c836c7248043b656fa95e474e.png)

2. 在右上角的应用类型，选择 Ollama 框架内的 `deepseek-r1:7b` 模型。

![](https://assets-docs.dify.ai/2025/01/dbd7170abd35f545481ecc0beef85333.png)

3. 在预览对话框中输入内容，验证 AI 应用是否能够正常运行。生成答复后意味着 AI 应用的搭建已完成。

![](https://assets-docs.dify.ai/2025/01/619fbbd48e55a1e6a598b4039dd631f5.png)

4. 轻点应用右上方的发布按钮，获取 AI 应用链接并分享给他人或嵌入至其它网站内。

### DeepSeek AI Chatflow / Workflow（进阶应用）

> Chatflow / Workflow 应用可以帮助你搭建功能更加复杂的 AI 应用，例如具备文件识别、图像识别、语音识别等能力。详细说明请参考[工作流文档](https://docs.dify.ai/zh-hans/guides/workflow)。

1. 轻点 Dify 平台首页左侧的"创建空白应用"，选择"Chatflow" 或 "Workflow" 类型应用并进行简单的命名。

![](https://assets-docs.dify.ai/2025/01/cb8637be4dca5a0e684fd9a21df3711f.png)

2. 添加 LLM 节点，选择 Ollama 框架内的 `deepseek-r1:7b` 模型，并在系统提示词内添加 `{{#sys.query#}}` 变量以连接起始节点。如遇 API 异常，可以通过[负载均衡](https://docs.dify.ai/zh-hans/guides/model-configuration/load-balancing)功能或[异常处理](https://docs.dify.ai/zh-hans/guides/workflow/error-handling)节点进行处理。

![](https://assets-docs.dify.ai/2025/01/c21f076398eb09d773d3e543561293e6.png)

3. 添加结束节点完成配置。你可以在预览框中输入内容以进行测试。生成答复后意味着 AI 应用的搭建已完成。

![](https://assets-docs.dify.ai/2025/01/820c37c70cb029cba60ca289e8d6e89a.png)

## 常见问题

### 1. Docker 部署时的连接错误

当使用 Docker 部署 Dify 和 Ollama 时，可能遇到以下错误：

```bash
httpconnectionpool(host=127.0.0.1, port=11434): max retries exceeded with url:/cpi/chat
(Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8562812c20>:
fail to establish a new connection:[Errno 111] Connection refused'))
httpconnectionpool(host=localhost, port=11434): max retries exceeded with url:/cpi/chat
(Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8562812c20>:
fail to establish a new connection:[Errno 111] Connection refused'))
```

**错误原因**：此错误发生是因为 Ollama 服务在 Docker 容器中无法访问。localhost 通常指向容器本身，而不是主机或其他容器。要解决此问题，需要将 Ollama 服务暴露到网络中。

**macOS 环境配置方法：**

如果 Ollama 作为 macOS 应用运行，需要使用 launchctl 设置环境变量：

1. 通过调用 `launchctl setenv` 设置环境变量：

    ```bash
    launchctl setenv OLLAMA_HOST "0.0.0.0"
    ```

2. 重启 Ollama 应用程序。

3. 如果以上步骤无效，可以使用以下方法：

    问题是在 docker 内部，你应该连接到 `host.docker.internal`，才能访问 docker 的主机，所以将 `localhost` 替换为 `host.docker.internal` 服务就可以生效了：

    ```bash
    http://host.docker.internal:11434
    ```

**Linux 环境配置方法：**

如果 Ollama 作为 systemd 服务运行，应该使用 `systemctl` 设置环境变量：

1. 通过调用 `systemctl edit ollama.service` 编辑 systemd 服务。这将打开一个编辑器。

2. 对于每个环境变量，在 `[Service]` 部分下添加一行 `Environment`：

    ```ini
    [Service]
    Environment="OLLAMA_HOST=0.0.0.0"
    ```

3. 保存并退出。

4. 重载 `systemd` 并重启 Ollama：

   ```bash
   systemctl daemon-reload
   systemctl restart ollama
   ```

**Windows 环境配置方法：**

在 Windows 上，Ollama 继承了你的用户和系统环境变量。

1. 首先通过任务栏点击 Ollama 退出程序

2. 从控制面板编辑系统环境变量

3. 为你的用户账户编辑或新建变量，比如 `OLLAMA_HOST`、`OLLAMA_MODELS` 等。

4. 点击 OK / 应用保存

5. 在一个新的终端窗口运行 `ollama`

### 2. 如何修改 Ollama 服务地址和端口号？

Ollama 默认绑定 `127.0.0.1` 端口 11434，你可以通过 `OLLAMA_HOST` 环境变量更改绑定地址。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/private-ai-ollama-deepseek-dify.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 如何训练出专属于“你”的问答机器人？
> 来源：`zh-hans/learn-more/use-cases/train-a-qa-chatbot-that-belongs-to-you.mdx`

_作者：阿乔_

_火枪击穿了专属于骑士阶层身披的铠甲与荣耀，武力对等才会有真正的平权。_

技术平权的速度从未来得如此之快。

作为兢兢业业的 CODING DevOps 项目的技术文档工程师，在为产品贡献数百篇文档后，依然止不住要在各种用户群 / 技术支持群里为客户解答问题。即使在每条答复中贴上文档链接，依然架不住新用户反复提问。（没办法，DevOps 产品中间又包含多项子产品）

_注：CODING DevOps 是腾讯云旗下的一站式研发管理平台及云原生开发工具，旨在让软件研发如同工业生产般简单高效，助力提升企业研发管理效能。_

虽然由 ChatGPT 掀起 AI 革命已来，但是它并不能够回答“我的”问题，也不能回答“你的”问题。但它却可以回答“大家”的问题。

为什么？ChatGPT 本身便是由庞大的互联网语料库训练而成，并且这部分训练数据截止于 2021 年 9 月。如果你的产品在这个日期之前就有幸在互联网中占有一席之地，那恭喜你，GPT 可以大概率可以回答出你的产品是大概是干嘛用的。因为它会从你的官网收集已有的描述语料。具体到单独的产品或公司的细节时它便开始靠胡言乱语来敷衍你了。

例如这样 🔽

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/f7ddcb5342558d19fd51d7222be5209d.png)

这里的“胡言乱语”指的是它会用其他不相关的概念进行回答，并且**你并不能够预期什么问题会有什么回答，这在商业场景下十分致命。在大多数情况下，ChatGPT 对于一些带有公理性质**的知识回答是没有问题的，作为一个可以日常侃大山闲聊的对象依然是合格的，可是你却看着它的强大的学习和理解能力望洋兴叹。

**“你这个孙悟空什么时候才能懂我，给我想要的回答？”**

这也是为什么说它能够回应大家的问题，但是却不能够回答出“我”想要的问题。

### **改变发生**

直到，Dify 横空出世。

你可以简单地将 Dify 理解为是一个能够帮助你进行数据清理和文档训练的地方。咱们也给狗屁通（GPT）补补课，手动给它补上缺失的语料。把它从通用型聊天机器人，变成你的专业问答机器人。是的，从侃大山到对答如流，这中间的鸿沟不是一点半点，需要强大的理解、归纳总结能力。不过这正是狗屁通（GPT）的强项。

### **注册并生成应用**

现在，我们打开 Dify 并注册一个聊天机器人，我们在这里选择“聊天助手”。

![](https://assets-docs.dify.ai/2024/11/8f25c739e69de061496637f08334dd1b.png)

填写基础的名称和描述，选择某个 LLM 来提供对话服务。点击发布，Duang，一个聊天机器人就做好了。访问左侧的“监测”，你可以看到这个应用的在线地址。

![](https://assets-docs.dify.ai/2024/11/15e39d55291a97e59e8349a2f84302ee.png)

但是，它现在也只是一个**通用型聊天机器人**，离商业可用的**专用型问答机器人**还差一个语料的距离。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/e753c7f36e8a2f04c8180f771e63431b.png)

### **准备语料**

Dify 提供了一个名 **“知识库”** 功能，这里就是我们上传语料的地方。

![](https://assets-docs.dify.ai/2024/11/46204d061fe14ada59735229a85e8d1a.png)

现在点击“创建知识库”选项，上传你的文本内容。

![](https://assets-docs.dify.ai/2024/11/1f35dc6c1b4ee2c307e024fb9755d417.png)

目前 Dify 仅支持上传单个文件，文件格式支持 TXT、HTML、MarkDown、PDF。

_是的没错，你也可以把电子书上传进来，用 AI 帮助你提炼书本内容。_

在正式开始训练前，我们得先把教材准备好。好在 CODING 之前的所有文档皆以 Git 代码仓库 + Markdown 的形式进行协作，因此我只需要先把文档先拉到本地中。不过我现在碰到了第一个问题，那就是如何把仓库中的这一系列 .md 文档文件合并至同一个文件中？

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/88018cc39f6b1244ffd5a1c11fc8ccbe.png)

不怕，让 AI 给我们写一段 python 吧。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/1cfbe712bec52acc0d1ee50d96e809f2.png)

试着运行这个脚本，oh，输入路径后就成功生成了一篇总合文档！如果你想了解如何让 AI 给你写代码，不妨阅读[《如何用狗屁通（GPT ）解决一个套娃问题》](http://mp.weixin.qq.com/s?__biz=MzU2Njg1NDA3Mw==\&mid=2247484248\&idx=1\&sn=50809b40f520c767483e1a7b0eefb9c1\&chksm=fca76b8ecbd0e298e627140d63e7b3383d226ab293a2e8fefa04b5a1ee12f187520560ec1579\&scene=21#wechat_redirect)。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/c8dbaf3241dbd50507165524c7ed6451.png)

### **开始训练**

现在要做的事，就是上传这个文件并静待训练成果了。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/f66100f8d87ea88b7f2d9be6f4db32c7.jpeg)

数据自动分段与清洗完成后，在刚创建的应用设置中的上下文，关联这一篇文档。为了保证响应速度和成本控制，这里直接用 gpt-4o 模型。

![](https://assets-docs.dify.ai/2024/11/5878266c7a7c8729e44fb660b8108393.png)

### **训练成功**

现在再去和这个机器人互动，看看它会回答什么？

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/22d5d5621a1b1eedfdf698cdf8a5ac2d.png)

好了，你已经是个成熟的问答机器人了，可以回答更加复杂的产品问题了。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/18558406335d11b26717e8b1cf70a673.png)

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/f81842d0d74050c03cc4895c497a26b9.png)

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/038e6c5dab7a8625079669b6bfdb6adc.png)

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/learn-more/use-cases/829c51e5c45e149957df7b5531639d2a.png)

这个问答机器人花了多久做出来，成本如何？

整理语料+训练完成控制在半个小时以内，训练成本 0.27 美元。

现在，AI 可以深入到产品内部，变成妥妥的产品专家。只要有优秀的文档，所有公司都可以打造出专用型问答机器人。

武力对等才会有真正的平权。如果你对我的实践过程同样感兴趣，可以来体验一下我做好的机器人。访问[此地址](https://udify.app/chat/F2Y4bKEWbuCb1FTC)。

不妨也来 Dify 平台训练属于你自己的机器人。做一个考试问答机器人？出题机器人？

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/learn-more/use-cases/train-a-qa-chatbot-that-belongs-to-you.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 访问 API
> 来源：`zh-hans/openapi-api-access-readme.mdx`

欢迎来到 Dify API 文档中心！本指南旨在帮助您快速上手，了解如何有效地使用本文档提供的交互功能来测试和理解 Dify API，并掌握 API 访问的关键要素。

**重要提示：**

*   **本页内容：** 主要介绍 API 文档的交互方式、全局访问配置（如 Base URL、API 密钥）以及文档贡献流程。
*   **API 端点详情：** 所有具体的 API 端点（包括其参数、请求/响应结构、功能描述及示例）内容是根据我们的 OpenAPI 规范自动生成的，并包含了最新的功能注释。**请务必查阅这些自动生成的页面以获取最准确和详细的端点信息。**

或点击顶部导航栏的`访问 API`标签页查看完整的 API 文档。

---

## 交互式 API 测试

为了方便您快速验证和理解 API，本文档中大部分 API 端点页面都内嵌了 "Try It" 的交互式测试功能。

> **步骤：**

    在您希望测试的 API 端点文档页面，通常在页面顶部或右侧区域，您会找到一个明显的 "Try It" 按钮或直接可交互的参数输入区域。

        系统可能会尝试预填，但请务必根据您的 Dify 部署环境（Cloud 或本地/私有化）选择或输入正确的 Base URL。详情请参阅下方的 [服务器地址 (Base URL)](#服务器地址-base-url) 部分。

        在认证区域，您需要填入从 Dify 应用中获取的有效 API 密钥。详情请参阅 [API 密钥 (API Key)](#api-密钥-api-key) 部分。

        如果 API 端点的 URL 中包含路径参数 (如 `/users/user_id` )或需要查询参数 (如 `?limit=10` )，请根据端点说明准确填写。

        对于 `POST`, `PUT`, `PATCH` 等需要请求体的 HTTP 方法，请参照端点文档中提供的请求体结构 (Schema) 和示例，构建正确的 JSON 内容。

    所有参数配置完毕后，点击 "Send" (或 "Execute") 按钮发起 API 调用。稍后，您将在同一区域看到 API 返回的完整响应，包括 HTTP 状态码、响应头和响应体。

---

## 🔑 API 访问配置

### 服务器地址 (Base URL)

API 请求的基础 URL 因您的 Dify 部署环境而异：

  ```bash Dify Cloud (云服务版)
https://api.dify.ai/v1
  ```

  ```bash 本地/私有化部署
http://localhost/v1
  ```

> **信息提示：**

  在进行 API 调用或使用 "Try It" 功能时，请务必确认您配置的 Base URL 是正确的。

### API 密钥 (API Key)

Dify 的**每个**应用 (App) 都拥有其专属的 API 密钥，用于接口调用的身份验证和授权。

*   **获取途径：** 您可以在您的 Dify 应用的 概览 或 `访问 API` 或 `监控` 页面中点击 `API 密钥` 管理或生成您的 API 密钥。

*   **使用方法：** 获取到 API 密钥后，请将其以 `Bearer YOUR_API_KEY` 的形式加入到 HTTP 请求的 `Authorization` 头部。

*   **重要安全提示：**

> **警告：**

      API 密钥是访问您应用数据的凭证，具有较高权限。**请务必将其视为敏感信息并妥善保管，严禁在任何客户端（如浏览器、移动应用前端）代码中硬编码或直接暴露。** 推荐将 API 密钥存储在安全的服务器端环境，并通过后端服务代理对 Dify API 的调用。

*   **访问控制：** 在 Dify 应用的 **监控 (Monitoring) -> 后端服务API (Backend Service API)** 设置中，您可以管理 API 的访问状态，例如暂时禁用所有 API 调用。

---

## 📚 关于`访问 API`以及本文档

### 文档的组成与来源

*   **本指南页 (`api-access-readme.mdx`)：** 提供如何使用 API 文档、进行交互测试以及 API 访问的通用配置信息。
*   **API 端点详情页：** 侧边栏 **"API 端点"** 分组下的所有页面，均由我们的 OpenAPI 规范 ([查看 OpenAPI 规范源文件模板](https://github.com/langgenius/dify/tree/main/web/app/components/develop/template)) **自动生成**。这些页面包含了每个端点的详细描述、参数、请求/响应示例和最新的功能注解。

### 如何为本文档做出贡献

我们非常欢迎并感谢社区成员对 Dify 文档的贡献！

    如果您希望修改 **当前您正在阅读的这个 `API 访问与交互指南` 页面**，您可以：
    1.  滚动到本页底部。
    2.  点击  **"编辑此页" (Edit this page)** 按钮。
    3.  这将会直接将您引导至 GitHub 上本 `api-access-readme.mdx` 文件的编辑界面。

      请注意：本页底部的 **"编辑此页"** 按钮 **仅作用于当前这个指南页面 (`api-access-readme.mdx`) 本身**。
      它 **不适用于** `访问 API` 详情页面。

    如果您发现 `访问 API` 详情页中某个具体 **API 端点的描述、参数说明或示例需要更新**，这些内容来源于 OpenAPI 规范文件。
    1.  请前往 Dify 的文档代码仓库。
    2.  定位到相关的 OpenAPI JSON 文件（按语言分子目录，如 `en/openapi_chatflow.json`, `zh-hans/openapi_workflow.json` 等）。
    3.  修改对应的 OpenAPI 文件内容。
    4.  提交 Pull Request 到 Dify 主仓库。

> **提示：**

      为了保持多语言文档的一致性，如果您修改了某个语言的 OpenAPI 文件，建议检查并同步更新其他语言版本中对应的 OpenAPI 文件。

    如果您发现了文档中的任何问题（无论是本指南页还是具体的 API 端点页），或者有改进建议：
    1.  您可以使用页面底部（或侧边栏）的 **"报告问题" (Report an issue)** 链接。
    2.  这通常会将您引导至本文档项目 (dify-docs) 在 GitHub 上的 Issues 页面。
    3.  请详细描述您发现的问题、问题所在的页面链接以及您的改进建议。

      准确的问题报告和富有建设性的建议同样是对社区和项目的重要贡献！

API 文档同步自 Dify 主仓库。你可以点击这个卡片，在 GitHub 上查看原始的代码。如果你发现不同步或错误的地方，欢迎提交 PR 来贡献代码。

所有贡献（无论是直接编辑还是报告问题）都需要一个 GitHub 账户。我们期待您的参与，共同打造更完善的 Dify 使用文档！

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/openapi-api-access-readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 最佳实践
> 来源：`zh-hans/plugins/best-practice/README.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

你可以阅读更加完整的最佳实践，了解如何开发功能更加复杂的插件。

  develop-a-slack-bot-plugin.md

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/best-practice/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 开发 Slack Bot 插件
> 来源：`zh-hans/plugins/best-practice/develop-a-slack-bot-plugin.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

**本文将帮助你：**

深入掌握 Slack Bot 的搭建方法，创建由 AI 驱动的 Slack 聊天机器人，在 Slack 平台上智能回答用户的问题。

### 项目背景

Dify 插件生态致力于支持更简单、更易用的接入方式。本文将以 Slack 为例，详细介绍如何开发一个 Slack Bot 插件，便于团队中的成员直接在 Slack 平台内与 LLM 对话，提升 AI 服务的使用效率。

Dify 插件生态旨在提供更简单、更便捷的接入方式。本文将以 Slack 为例，详细讲解如何开发一个 Slack Bot 插件，帮助团队成员直接在 Slack 平台使用 AI 应用，提升办公效率。

Slack 是一个自由开放的实时办公通信平台，拥有丰富的 API。其中，基于事件机制的 Webhook 功能易于上手开发。我们将利用该机制创建 Slack Bot 插件，其原理如下图所示：

![Slack Bot 原理图 ](https://assets-docs.dify.ai/2025/01/a0865d18f1ca4051601ca53fa6f92db2.png)

> 为了避免混乱，现对以下概念作出解释：
>
> * **Slack Bot** 是在 Slack 平台上的一个聊天机器人，可以被视为虚拟角色，你可以与它进行聊天互动
> * **Slack Bot 插件**指的是 Dify Marketplace上的一款插件，用于连接 Dify 应用与 Slack 平台。本文将主要围绕该插件开发展开。

**原理简介：**

1.  **向 Slack Bot 发送消息**

    当用户在 Slack 中向 Bot 机器人发出一条消息的时候，Slack Bot 会发出一个 Webhook 请求到 Dify 平台。
2.  **消息转发至 Slack Bot 插件**

    用户在与 Slack bot 对话时，需要将消息转发至 Dify 应用。好比邮件系统需要一位收件人的邮箱，此时可以通过 Slack 的 API 配置一个 Slack Webhook 的地址，并将其填入至 Slack Bot 插件并建立连接。
3.  **插件在接受到消息后，返回至某个 Dify 应用**

    Slack Bot 插件将处理 Slack 请求，发送至 Dify 中的应用。由 LLM 分析用户输入的内容并给出回应。
4.  **Dify 应用回应后，将消息返回至 Slack Bot 并回答用户**

    Slack Bot 获取 Dify 应用的回复后，通过插件将消息原路返回至 Slack Bot，使得用户能够在使用 Slack 时直接与 Dify 应用互动

### 前置准备

* Dify 插件脚手架工具，详细说明请参考[安装插件开发工具](../initialize-development-tools)。
* Python 环境，版本号 ≥ 3.12，详细说明请参考 [Python 安装教程](https://pythontest.com/python/installing-python-3-11/)，或询问 LLM 获取完整的安装教程。
* 创建 Slack App 并获取 OAuth Token

前往 [Slack API](https://api.slack.com/apps) 平台， 选择以 scratch 方式创建 Slack APP，并选择需部署应用的 Slack 空间。

![Slack api token](https://assets-docs.dify.ai/2025/01/8217c23ee16c47c586a1387a442ea6f0.png)

开启 Webhooks 功能。

![开启 Webhooks 功能](https://assets-docs.dify.ai/2025/01/fc9d7797608422219a01248f7151fc81.png)

将 App 安装至 Slack 工作区内。

![安装至工作区内](https://assets-docs.dify.ai/2025/01/6ab7226078f88853fc7f4d3520245d63.png)

获取 OAuth Token，用于后续的插件开发。

![获取 OAuth Token](https://assets-docs.dify.ai/2025/01/f08052044c8c17eebbffacdc9b2558e6.png)

### 1. 开发插件

现在开始实际的插件编码工作。在开始之前，请确保你已经阅读过[快速开始：开发 Extension 插件](./zh-hans/plugins/quick-start/develop-plugins/extension-plugin)，或已动手开发过一次 Dify 插件。

#### 初始化项目

运行以下命令初始化插件开发项目：

```bash
dify plugin init
```

按照提示填写项目的基础信息，选择 `extension` 模板，并且授予 `Apps` 和 `Endpoints` 两个权限。

如需了解更多关于插件反向调用 Dify 平台能力，请参考[反向调用：App](../../../schema-definition/reverse-invocation-of-the-dify-service/app)。

![Plugins permission](https://assets-docs.dify.ai/2024/12/d89a6282c5584fc43a9cadeddf09c0de.png)

#### 1. 编辑配置表单

在这个插件中，需要指定使用哪个 Dify 的 App 进行回复，并且在回复的时候需要使用到 Slack 的 App token，因此需要在插件表单中加上这两个字段。

修改 group 路径下的 yaml 文件，例如 `group/slack.yaml。`表单配置文件的名称由创建插件时填写的基础信息决定，你可以修改对应的 yaml 文件。

**示例代码：**

`slack.yaml`

```yaml
settings:
  - name: bot_token
    type: secret-input
    required: true
    label:
      en_US: Bot Token
      zh_Hans: Bot Token
      pt_BR: Token do Bot
      ja_JP: Bot Token
    placeholder:
      en_US: Please input your Bot Token
      zh_Hans: 请输入你的 Bot Token
      pt_BR: Por favor, insira seu Token do Bot
      ja_JP: ボットトークンを入力してください
  - name: allow_retry
    type: boolean
    required: false
    label:
      en_US: Allow Retry
      zh_Hans: 允许重试
      pt_BR: Permitir Retentativas
      ja_JP: 再試行を許可
    default: false
  - name: app
    type: app-selector
    required: true
    label:
      en_US: App
      zh_Hans: 应用
      pt_BR: App
      ja_JP: アプリ
    placeholder:
      en_US: the app you want to use to answer Slack messages
      zh_Hans: 你想要用来回答 Slack 消息的应用
      pt_BR: o app que você deseja usar para responder mensagens do Slack
      ja_JP: あなたが Slack メッセージに回答するために使用するアプリ
endpoints:
  - endpoints/slack.yaml
```

代码数据结构说明：

```
  - name: app
    type: app-selector
    scope: chat
```

*   type 字段指定为 app-selector 字段

    用户在使用插件时可以访问某个 Dify 应用并进行消息转发。
*   scope 字段指定为 chat 字段

    只能使用 `agent` 、`chatbot` 、`chatflow` 等类型的 app。

最后修改 `endpoints/slack.yaml` 文件中的请求路径和请求方式，需要将 method 修改为 POST 方式。

**示例代码：**

`endpoints/slack.yaml`

```yaml
path: "/"
method: "POST"
extra:
  python:
    source: "endpoints/slack.py"
```

#### 2. 编辑功能代码

修改 `endpoints/slack.py`文件，并在其中添加下面的代码：

````python

from typing import Mapping
from werkzeug import Request, Response
from dify_plugin import Endpoint
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError

class SlackEndpoint(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        """
        Invokes the endpoint with the given request.
        """
        retry_num = r.headers.get("X-Slack-Retry-Num")
        if (not settings.get("allow_retry") and (r.headers.get("X-Slack-Retry-Reason") == "http_timeout" or ((retry_num is not None and int(retry_num) > 0)))):
            return Response(status=200, response="ok")
        data = r.get_json()

        # Handle Slack URL verification challenge
        if data.get("type") == "url_verification":
            return Response(
                response=json.dumps("challenge": data.get("challenge")),
                status=200,
                content_type="application/json"
            )

        if (data.get("type") == "event_callback"):
            event = data.get("event")
            if (event.get("type") == "app_mention"):
                message = event.get("text", "")
                if message.startswith("<@"):
                    message = message.split("> ", 1)[1] if "> " in message else message
                    channel = event.get("channel", "")
                    blocks = event.get("blocks", [])
                    blocks[0]["elements"][0]["elements"] = blocks[0].get("elements")[0].get("elements")[1:]
                    token = settings.get("bot_token")
                    client = WebClient(token=token)
                    try: 
                        response = self.session.app.chat.invoke(
                            app_id=settings["app"]["app_id"],
                            query=message,
                            inputs={},
                            response_mode="blocking",
                        )
                        try:
                            blocks[0]["elements"][0]["elements"][0]["text"] = response.get("answer")
                            result = client.chat_postMessage(
                                channel=channel,
                                text=response.get("answer"),
                                blocks=blocks
                            )
                            return Response(
                                status=200,
                                response=json.dumps(result),
                                content_type="application/json"
                            )
                        except SlackApiError as e:
                            raise e
                    except Exception as e:
                        err = traceback.format_exc()
                        return Response(
                            status=200,
                            response="Sorry, I'm having trouble processing your request. Please try again later." + str(err),
                            content_type="text/plain",
                        )
                else:
                    return Response(status=200, response="ok")
            else:
                return Response(status=200, response="ok")
        else:
            return Response(status=200, response="ok")

```
````

为了便于测试，插件功能目前仅能重复用户输入的内容，暂不调用 Dify app。

### 2. 调试插件

前往 Dify 平台，获取 Dify 插件远程调试的连接地址和密钥。

![](https://assets-docs.dify.ai/2025/01/8d24006f0cabf5bf61640a9023c45db8.png)

回到插件项目，复制 `.env.example` 文件并重命名为 `.env`。

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_HOST=remote-url
REMOTE_INSTALL_PORT=5003
REMOTE_INSTALL_KEY=****-****-****-****-****
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内。其他团队成员也可以访问该插件。

```bash
python -m main
```

#### 设置插件 Endpoint

在 Dify 的插件管理页中找到自动安装的测试插件，新建一个 Endpoint，填写名称、Bot token、选择需要连接的 app。

![测试插件](https://assets-docs.dify.ai/2025/01/07f87e8a2786d6f5f05195961c5630c3.png)

保存后将生成一个 POST 请求地址。

![生成 POST 请求地址](https://assets-docs.dify.ai/2025/01/e6952a5798a7ae793b3fe7df6f76ea73.png)

接下来还需要完成 Slack App 的设置。

1. 启用 Event 订阅

![](https://assets-docs.dify.ai/2025/01/1d33bb9cde78a1b5656ad6a0b8350195.png)

在其中粘贴上文中生成的插件 POST 请求地址。

![](https://assets-docs.dify.ai/2025/01/65aa41f37c3800af49e944f9ff28e121.png)

勾选 Slack App 所需具备的权限。

![](https://assets-docs.dify.ai/2025/01/25c38a2cf10ec6c55ae54970d790f37e.png)

### 3. 验证插件效果

代码使用了 `self.session.app.chat.invoke` 调用 Dify 平台内的 App，并传递了 `app_id` 和 `query` 等信息，最后将 response 的内容返回至 Slack Bot。运行 `python -m main` 命令重启插件进行调试，确认 Slack Bot 是否能够正确输出 Dify App 的答复消息。

![](https://assets-docs.dify.ai/2025/01/6fc872d1343ce8503d63c5222f7f26f9.png)

### 4. 打包插件（可选）

确认插件能够正常运行后，可以通过以下命令行工具打包并命名插件。运行以后你可以在当前文件夹发现 `slack_bot.difypkg` 文件，该文件为最终的插件包。

```bash
dify plugin package ./slack_bot
```

恭喜，你已完成一个插件的完整开发、测试打包过程！

### 5. 发布插件（可选）

现在可以将它上传至 [Dify Marketplace 仓库](https://github.com/langgenius/dify-plugins) 来发布你的插件了！不过在发布前，请确保你的插件遵循了[插件发布规范](https://docs.dify.ai/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace)。

### 参考阅读

如果你想要查看完整 Dify 插件的项目代码，请前往 [GitHub 代码仓库](https://github.com/langgenius/dify-plugins)。除此之外，你可以看到其它插件的完整代码与具体细节。

如果想要了解更多插件，请参考以下内容。

**快速开始：**

* [开发 Extension 插件](../quick-start/develop-plugins/extension-plugin)
* [开发 Model 插件](./zh-hans/plugins/quick-start/develop-plugins/model-plugin/README)
* [Bundle 类型插件：将多个插件打包](./zh-hans/plugins/quick-start/develop-plugins/bundle)

**插件接口文档：**

* [Manifest](./zh-hans/plugins/schema-definition/manifest) 结构
* [Endpoint](./zh-hans/plugins/schema-definition/endpoint) 详细定义
* [反向调用 Dify 能力](./zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/)
* [工具](./zh-hans/plugins/schema-definition/tool)
* [模型](./zh-hans/plugins/schema-definition/model/)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/best-practice/develop-a-slack-bot-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 输出开发和调试插件过程中的日志
> 来源：`zh-hans/plugins/best-practice/how-to-print-strings-to-logs-for-debugging.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

作为插件开发者，你可能希望在插件处理过程中，为了开发或调试目的，将任意字符串输出到日志中。

为此，插件 SDK 实现了一个适用于 Python 标准库 `logging` 的处理器。通过使用它，你可以将任意字符串输出到**远程调试时的标准输出**以及**插件守护进程的容器日志**（仅社区版）。

## 示例

导入 `plugin_logger_handler` 并将其添加到你的 logger 处理器中。以下是工具插件的示例代码。

```python
from collections.abc import Generator
from typing import Any
from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage

# 导入 logging 和自定义处理器

from dify_plugin.config.logger_format import plugin_logger_handler

# 使用自定义处理器设置日志
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.addHandler(plugin_logger_handler)

class LoggerDemoTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:

        # 以不同级别输出日志信息
        logger.info("This is a INFO log message.")
        logger.warning("This is a WARNING log message.")
        logger.error("This is a ERROR log message.")

        yield self.create_text_message("Hello, Dify!")
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/best-practice/how-to-print-strings-to-logs-for-debugging.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Dify MCP 插件指南：一键连接 Zapier 并自动发送邮件
> 来源：`zh-hans/plugins/best-practice/how-to-use-mcp-zapier.mdx`

**本文将帮助你：**

为 Dify 工作空间安装 MCP SSE 插件，远程调用 Zapier MCP 服务以实现自动发送邮件。

## 项目背景

Anthropic 于 2024 年底推出了模型上下文协议（MCP）。作为一项新兴的开放协议，MCP 为 LLM 与外部应用之间构建了双向通信通道，就像是 AI 的“USB-C”接口，帮助模型发现、理解并安全调用各种外部工具或 API。

这意味着：开发者不再需要为对接每一个外部服务而编写复杂的定制接口。用户可以体验到 AI 轻松调用海量第三方应用的能力，无论是处理日常办公任务、分析数据，还是执行营销自动化，AI 正从“智能对话”迈向“高效行动”。

在 Dify 社区里，MCP 同样备受关注。社区开发者在插件市场贡献了多个 MCP 插件，你可以轻松地通过插件将外部 MCP 服务接入至 Dify Agent 应用或工作流中。

本文将以 MCP SSE 插件为例，详细介绍如何在 Dify 内使用 MCP 插件连接 Zapier 并完成自动邮件发送流程。

## 前置准备

- Dify 云端版 / Dify 社区版 ≥ v1.0.0
- Zapier 账号

## 在 Dify 中初始化 Zapier MCP 服务

Zapier 的 MCP Server 将其已有的 7000+ 应用和 30,000+ 操作（Action）统一封装到了一个 MCP Server URL 中。你可以在 Zapier 后台，自主选择和配置需要的工具及操作，比如发邮件、在 CRM 中创建记录、在 Slack 中发送通知等。只需将 MCP Server URL 填入 Dify MCP 插件的配置，就能让 LLM 在对话或流程中，自动调用这些工具完成各类任务。

### 步骤一：申请 Zapier MCP Server URL

1. 访问 [Zapier MCP 设置页面](https://actions.zapier.com/settings/mcp/)。
2. 获取 MCP Server URL，稍后填写至 Dify 的插件配置。

![](https://assets-docs.dify.ai/2025/04/15bba178b0adddcd3e1961807dfe14f0.png)

3. 点击 URL 下方的 “Edit MCP Actions”，进入工具和操作的添加页面。

4. 点击 “Add a new action”，搜索 `Gmail: Send Email`。你也可以根据实际需求选择添加不同的邮件操作。

![](https://assets-docs.dify.ai/2025/04/718e214166ca6eed6771d44f3b6ab718.png)

5. 以“发送邮件”为例：

在 Gmail 账户下方点击 “Connect”，然后登录并授权你的 Gmail 邮箱。

对于邮件的收件人 (To)、主题 (Subject) 和正文 (Body) 等字段，可以选择 “Have AI guess a value for this field” ，具体内容将由 Agent 根据实际对话和场景动态决定。

![](https://assets-docs.dify.ai/2025/04/637ce6b46ab706f4512a2dceb25a8162.png)

6. 设置完成后，你还可以继续添加不同的 Action，丰富 Agent 可用的工具集。

### 步骤二：安装 MCP SSE 插件

1. 前往 Dify 插件市场，搜索 MCP SSE 插件并点击安装。

![](https://assets-docs.dify.ai/2025/04/20174032b8feb624a52ac36d65e7c0fa.png)

> 为确保服务稳定，建议使用 v0.0.4 插件版本；你可以在工作空间内的插件详情页调整版本。
> ![](https://assets-docs.dify.ai/2025/04/b076d40ea120dea544df49bc52199ad6.png)

2. 点击插件页的 To Authorize 按钮，将上文中获取的 Zapier MCP Server URL 粘贴至插件内。地址格式参考：

```json
{
  "server_name": {
    "url": "https://actions.zapier.com/mcp/*******/sse",
    "headers": {},
    "timeout": 5,
    "sse_read_timeout": 300
  }
}
```

![](https://assets-docs.dify.ai/2025/04/5ba078e8804c1bee5bcec167d260a92a.png)

### 步骤三：创建 Dify Agent 应用并启用 MCP SSE 服务

1. 创建 Agent 类型应用

从导航选择 「工作室」，在应用列表内选择 「从空白创建」 并选择 Agent 应用类型，填写应用名称后完成创建。

![](https://assets-docs.dify.ai/2025/04/aaef5e115211c2b04382552e537877fa.png)

2. 添加 MCP 工具

在应用工具栏中分别添加 `Fetch MCP Tools` 和 `Call MCP Tool`。

![](https://assets-docs.dify.ai/2025/04/4e570e4e42720b3e202d409fa93f983a.png)

3. 配置 LLM

使用 MCP 时可能会消耗大量 Tokens，因此建议使用更具性价比的 LLM。本文将以 `deepseek-chat` 模型为例。你可以前往 [DeepSeek Platform](https://platform.deepseek.com/usage) 申请 API Key 并将其填写至 「设置」 → 「模型供应商」 → 「DeepSeek」内。

> 若你并未在模型供应商内检索到 DeepSeek 模型，请前往 Dify 插件市场安装 DeepSeek 插件。

## 使用场景一：使用 MCP 服务自动发送单条邮件

配置完成后，只需通过与 Agent 对话，即可自动生成邮件草稿，并发送给指定收件人。

![](https://assets-docs.dify.ai/2025/04/fc76cc8e7dd7476199e9810fa5403f3b.png)

在对话框内要求 LLM 完成邮件发送任务。等待 MCP 运行完成后，邮件将自动发送至收件人。

![](https://assets-docs.dify.ai/2025/04/dc80a8fb00800e8938f3918fc908bc1b.png)

## 使用场景二：在 Workflow 中配置 MCP Agent Strategy

除了将 MCP SSE 插件作为工具添加到 Agent 外，你还可以在 Workflow 中使用 MCP Agent Strategy 插件。安装完成后，在对应的 Agent 节点内进行配置，具体操作如下：

![](https://assets-docs.dify.ai/2025/04/0a340d4cc4a549e6b7420b39cfd805d6.png)

将以下 JSON 结构作为模板，其中 `url` 值替换为 MCP Server 地址，然后将修改后的完整 JSON，复制粘贴到 `MCP SERVER URL` 配置框内：

```json
{
  "server_name": {
    "url": "https://actions.zapier.com/mcp/*******/sse",
    "headers": {},
    "timeout": 5,
    "sse_read_timeout": 300
  }
}
```

![](https://assets-docs.dify.ai/2025/04/883c70b8a714c0c7e7a25f5f712c59e0.png)

配置完成后，当 Workflow 运行到该 Agent 节点时，就能够根据 Prompt 指令，利用配置好的 Zapier MCP Server 来执行任务。如下图所示，调用 Gmail 发送邮件：

![](https://assets-docs.dify.ai/2025/04/a201fb50200737881e4ddc0b31518336.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/best-practice/how-to-use-mcp-zapier.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 常见问题
> 来源：`zh-hans/plugins/faq.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

## 安装插件时提示上传失败如何处理？

**错误详情**：出现 `PluginDaemonBadRequestError: plugin_unique_identifier is not valid` 报错提示。

**解决办法**：将插件项目下的 `manifest.yaml` 文件和 `/provider` 路径下的 `.yaml` 文件中的 `author` 字段修改为 GitHub ID。

重新运行插件打包命令并安装新的插件包。

## 安装插件时遇到异常应如何处理？

**问题描述**：安装插件时遇到异常信息：`plugin verification has been enabled, and the plugin you want to install has a bad signature`，应该如何处理？

**解决办法**：在 `/docker/.env` 配置文件的末尾添加 `FORCE_VERIFYING_SIGNATURE=false` 字段，运行以下命令重启 Dify 服务：

```bash
cd docker
docker compose down
docker compose up -d
```

添加该字段后，Dify 平台将允许安装所有未在 Dify Marketplace 上架（审核）的插件，可能存在安全隐患。

建议在测试 / 沙箱环境内安装插件，确认安全后再安装至生产环境。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/faq.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 功能简介
> 来源：`zh-hans/plugins/introduction.mdx`

> 如需在社区版中体验插件功能，请将版本号升级至 v1.0.0。

### 什么是插件？

插件是 Dify 平台的扩展模块，让你可以轻松地接入**第三方模型与工具**，显著提升应用能力。通过插件系统，你的 AI 应用能够更好地"看"、"听"、"说"、"画"、"计算"、"推理"，并连接外部 API，执行真实世界的操作。

这是一个对开发者更加友好，可扩展性更强的第三方服务扩展模块。虽然 Dify 平台已内置多个由官方维护与社区贡献者开发的工具，但现有的工具难以全面覆盖各类细分场景的需求，而一个新工具的开发到嵌入至平台又需要较长周期。

为了让开发过程更加敏捷，我们决定开放生态并提供完善的插件开发 SDK，让每位开发者都能够轻松地打造属于自己的工具，轻松使用**第三方模型与工具**，显著提升应用能力。

### 插件有哪些优势？

新的插件系统突破了原有框架的限制，提供更丰富和强大的扩展能力。提供五种类型插件，每一种类型对应成熟的场景解决方案，赋予开发者用无限的创意改造 Dify 应用的空间。
同时，插件系统也为用户提供了便捷的功能扩展方式：

-   **即插即用**：通过 [Dify Marketplace](https://marketplace.dify.ai/) 或本地文件安装，无需编程知识即可使用强大的功能扩展。
-   **丰富生态**：访问由开发者社区贡献的各类插件，涵盖模型接入、工具集成、智能策略等多个方面。
-   **灵活分享**：可以通过 [Dify Marketplace](https://marketplace.dify.ai/)、[GitHub](./zh-hans/plugins/publish-plugins/publish-plugin-on-personal-github-repo) 或[本地文件](./zh-hans/plugins/publish-plugins/package-plugin-file-and-publish)的形式获取和分享插件。

> Dify Marketplace 是一个面向用户和开发者的开放生态系统，提供模型、工具、AI Agent、Extensions 和插件包等丰富的资源。通过 Marketplace，你可以为现有 Dify 应用无缝接入第三方服务，增强现有应用的能力，共同推动 Dify 生态的发展。

无论你是想要接入新的模型、添加特定工具帮助扩展 Dify 平台的现有功能，都可以在丰富的插件市场里找到所需资源。**我们希望更多的开发者能够参与共建 Dify 生态并从中获益。**

![Dify Plugin Marketplace](https://assets-docs.dify.ai/2025/01/83f9566063db7ae4886f6a139f3f81ff.png)

### 插件有哪些类型？

-   **Models（模型）**

    各类 AI 模型的接入插件，让你能够轻松使用不同的 AI 模型，无需复杂的配置过程。

        你的第一个开源贡献：通过简单修改配置文件，为 Dify 添加 **新模型**
        支持，无需任何专业编程经验。

-   **Tools（工具）**

    能够被 Chatflow / Workflow / Agent 类型应用所调用的第三方服务，用于增强 Dify 应用的能力。

-   **Agent 策略**

    为 [Agent 节点](./zh-hans/guides/workflow/node/agent)提供不同的推理和决策逻辑，优化工具选择和结果处理。

-   **Extensions（扩展）**

    通过简单的 HTTP 服务调用即可使用的轻量级扩展功能。

-   **Bundle（插件包）**

    预先组合好的插件集合，可以一次性安装多个相关插件，简化配置流程。

### 快速开始使用插件

想要开始使用插件增强你的 Dify 应用吗？请参考以下指南：

    了解如何在 Dify 应用中安装和配置插件，开始享受扩展功能带来的便利

    学习如何有效管理、更新和卸载已安装的插件

### 想要开发自己的插件？

如果你对创建自己的插件感兴趣，欢迎访问我们的开发者文档：

    访问完整的插件开发者文档，学习如何创建、调试和发布你的插件。包含详细的技术指南、API
    参考和最佳实践。

### 发现更多插件

浏览 [Dify Marketplace](https://marketplace.dify.ai/) 发现由社区贡献的优质插件，为你的应用找到完美的功能扩展。

### 获取帮助

如果在使用插件过程中遇到问题，请参考：

    查看插件使用的常见问题和解决方案

---

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/introduction.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 插件管理
> 来源：`zh-hans/plugins/manage-plugins.mdx`

本文档将指导 Workspace 所有者、管理员配置和管理插件的权限设置。插件权限控制决定了哪些用户可以执行插件相关的操作。

### 调整插件权限

团队所有者、管理员可以在 Dify 平台首页右上角的 **“插件”** 页控制以下插件权限：

*   **安装和管理插件权限**

    此权限控制谁可以安装和管理系统中的插件。

    可选项：

    * **Everyone（所有人）**：允许 Workspace 内所有用户安装和管理插件
    * **Admins（管理员）**：仅限 Workspace 管理员安装和管理插件
    * **No one（无人）**：禁止所有人安装和管理插件
*   **插件调试权限**

    此权限控制谁可以进行插件的调试工作。

    可选项：

    * **Everyone（所有人）**：允许 Workspace 内所有用户调试插件
    * **Admins（管理员）**：仅限 Workspace 管理员调试插件
    * **No one（无人）**：禁止所有人调试插件

![插件权限](https://assets-docs.dify.ai/2024/12/a2bca75a7757b7cafae2cb4ba0ad9fff.png)

### 升级插件

点击 Dify 平台右上角的“插件”按钮，选择需要更新的插件，轻点插件标题右侧 **“升级”** 钮。

![](https://assets-docs.dify.ai/2024/12/83bd5ec12ec914c73d0ea2a5992cd6df.png)

### 删除插件

点击 Dify 平台右上角的“插件”按钮，你可以看到当前 Workspace 内的所有已安装插件。点击“删除” icon 或插件详情页右侧的 Remove 移除插件。

![移除 plugin](https://assets-docs.dify.ai/2024/12/6cb1c000d20720c16ae3c0a70df26fd3.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/manage-plugins.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 发布插件
> 来源：`zh-hans/plugins/publish-plugins/README.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

### 发布方式

为了满足不同开发者的发布需求，Dify 提供了以下三种插件发布方式：

#### **1. Marketplace**

**简介**：Dify 官方提供的插件市场，用户可以在此浏览、搜索并一键安装各类插件。

**特点**：

* 插件经审核后上线，**安全可靠**。
* 可直接安装至个人或团队的 **Workspace** 中。

**发布流程**：

* 将插件项目提交至 **Dify Marketplace** [代码仓库](https://github.com/langgenius/dify-plugins)。
* 经过官方审核后，插件将在市场内公开发布，供其他用户安装使用。

详细说明请参考：

  publish-to-dify-marketplace

#### 2. **GitHub 仓库**

**简介**：将插件开源或托管在 **GitHub** 上，方便他人查看、下载和安装。

**特点**：

* 便于**版本管理**和**开源共享**。
* 用户可通过插件链接直接安装，无需平台审核。

**发布流程**：

* 将插件代码推送至 GitHub 仓库。
* 分享仓库链接，用户可通过链接将插件集成至 **Dify Workspace**。

详细说明请参考：

  publish-plugin-on-personal-github-repo.md

#### 3. 插件文件包（本地安装）

**简介**：将插件打包成本地文件（如 `.difypkg` 格式），通过文件分享的方式供他人安装。

**特点**：

* 不依赖在线平台，**快速灵活**地分享插件。
* 适用于**私有插件**或**内部测试**。

**发布流程**：

* 将插件项目打包为本地文件。
* 在 Dify 插件页面点击**上传插件**，选择本地文件安装插件。

你可以将插件项目打包为一个本地文件并分享给他人，在插件页上传文件后即可将插件安装至 Dify Workspace 内。

详细说明请参考：

  package-plugin-file-and-publish.md

### **发布建议**

* **想要推广插件** → **推荐使用 Marketplace**，通过官方审核保障插件质量，提升曝光度。
* **开源共享项目** → **推荐使用 GitHub**，方便版本管理与社区协作。
* **快速分发或内部测试** → **推荐使用插件文件**，简单高效地安装和分享。

> 安装非 Dify 市场内的插件时，有可能遇到第三方签名验证问题。解决办法请参考[第三方签名验证](./signing-plugins-for-third-party-signature-verification.mdx)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/publish-plugins/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 打包为本地文件与分享
> 来源：`zh-hans/plugins/publish-plugins/package-plugin-file-and-publish.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

完成插件开发后，你可以将插件项目打包为一个本地文件并分享给他人，通过插件文件后即可安装至 Dify Workspace 内。

* **特点**：
  * 便于**版本管理**和**开源共享**。
  * 用户可通过插件链接直接安装，无需平台审核。
* **发布流程**：
  * 将插件代码推送至 GitHub 仓库。
  * 分享仓库链接，用户可通过链接将插件集成至 **Dify Workspace**。

本文将介绍如何将插件项目打包为本地文件，以及如何使用本地文件安装插件。

### 前置准备

* **Dify 插件开发工具**，详细说明请参考[安装插件开发工具](../quick-start/develop-plugins/initialize-development-tools)。

配置完成后，在终端输入 `dify version` 命令，检查是否输出版本号信息以确认已安装必要的开发工具。

### 打包插件

> 打包插件前，请确保插件的 `manifest.yaml` 文件和 `/provider` 路径下的 `.yaml` 文件中的 `author` 字段与 GitHub ID 保持一致。

插件项目开发完成后，请确保已完成[远程连接测试](../quick-start/develop-plugins/extension-plugin#tiao-shi-cha-jian)。需前往插件项目的上一级目录，运行以下插件打包命令：

```bash
dify plugin package ./your_plugin_project
```

运行命令后将在当前路径下生成以 `.difypkg` 后缀结尾的文件。

![生成插件文件](https://assets-docs.dify.ai/2024/12/98e09c04273eace8fe6e5ac976443cca.png)

### 安装插件

访问 Dify 插件管理页，轻点右上角的**安装插件** → **通过本地文件**安装，或将插件文件拖拽至页面空白处安装插件。

![安装插件文件](https://assets-docs.dify.ai/2024/12/8c31c4025a070f23455799f942b91a57.png)

### 发布插件

你可以将插件文件分享给他人，或上传至互联网供他人下载。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/publish-plugins/package-plugin-file-and-publish.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 自动发布插件
> 来源：`zh-hans/plugins/publish-plugins/plugin-auto-publish-pr.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

### 背景

当插件贡献者需要严肃更新 **已被其他用户使用的 Dify 插件** 时，流程通常非常繁琐：贡献者需要先修改插件源码并更新版本号，将更改推送到插件源码仓库，并在 fork 的 dify-plugin 仓库中创建新分支。随后，贡献者需要手动打包插件并上传打包文件，再创建 PR 合并到原始 dify-plugin 仓库。这个过程必须在每次插件代码变更时重复，非常耗时低效。

为了简化这一流程，我们构建了基于 GitHub Actions 的自动化工作流 **Plugin Auto-PR**。借助这个工具，插件贡献者可以一键完成插件打包、分支推送以及 PR 创建。

### 概念简介

#### GitHub Actions

GitHub Actions 是 GitHub 提供的内置 CI/CD 服务，可以自动化各种构建、测试和部署任务。

**运行原理**：当触发条件（如 push 代码）满足时，GitHub 会自动分配虚拟机运行你的工作流。所有操作都在 GitHub 云端完成。

![Workflow](https://assets-docs.dify.ai/2025/04/60534de8e220f860947b32a8329a8349.png)

**免费额度**：

* 公共仓库：无限制
* 私有仓库：每月 2000 分钟

#### Plugin Auto-PR

**运行原理**：

1. 当你推送代码到插件源码仓库的 main 分支时，触发工作流
2. 工作流从 `manifest.yaml` 文件中读取插件信息
3. 自动打包插件为 `.difypkg` 文件
4. 将打包文件推送到你 fork 的 `dify-plugins` 仓库中
5. 创建新分支并提交更改
6. 自动创建 PR 请求合并到上游仓库

### 环境准备

#### 仓库要求

* 你已拥有自己的插件源码仓库（例如：`your-name/plugin-source`）
* 你已拥有自己的 fork 插件仓库（例如：`your-name/dify-plugins`）
* 你的 fork 仓库中已有插件目录结构：

```
dify-plugins/
└── your-author-name
    └── plugin-name
```

#### 权限要求

此工作流需要适当的权限才能正常运行：

* 你需要创建一个有足够权限的 GitHub Personal Access Token (PAT)
* 该 PAT 必须有权向你的 fork 仓库推送代码
* 该 PAT 必须有权向上游仓库创建 PR

### 参数与配置项说明

#### 必要参数

插件自动发布工作流需要你正确配置以下关键元素：

**manifest.yaml 文件**：这是整个自动化流程的核心配置源。你需要确保以下字段正确无误：

* `name`：插件名称（将用于生成包名和分支名）
* `version`：版本号（每次更新时需要递增）
* `author`：GitHub 用户名（用于确定目标仓库路径）

**PLUGIN_ACTION Secret**：你需要在插件源码仓库中正确设置此密钥。

* 值要求：必须是具有足够权限的个人访问令牌（PAT）
* 权限要求：能够推送分支到你的 fork 仓库，能够创建 PR 到上游仓库

#### 自动生成的参数

工作流会**自动处理以下内容**，无需手动干预：

* GitHub 用户名：从 `manifest.yaml` 的 `author` 字段读取
* 作者文件夹名称：与 `author` 字段保持一致
* 插件名称：从 `manifest.yaml` 的 `name` 字段读取
* 分支名称：`bump-插件名-plugin-版本号`
* 打包文件名：`插件名-版本号.difypkg`
* PR 标题和内容：基于插件名称和版本自动生成

### 安装配置步骤

> **步骤：**

    确保你已经 fork 了官方的 `dify-plugins` 仓库，并且有自己的插件源码仓库。

    导航到你的插件源码仓库，点击 **Settings > Secrets and variables > Actions > New repository secret**，创建 GitHub Secret：

    * 名称填写： `PLUGIN_ACTION`
    * 值填写： 拥有目标仓库（`your-name/dify-plugins`）写入权限的 GitHub Personal Access Token (PAT)

    ![Create Secrets](https://assets-docs.dify.ai/2025/04/8abd72b677dd24752910c304c76f1c26.png)

    在仓库中创建 `.github/workflows/`目录，并在此目录中创建名为 `plugin-publish.yml` 的文件，再将以下内容复制到该文件中：

    ```yaml
    # .github/workflows/auto-pr.yml
    name: Auto Create PR on Main Push

    on:
      push:
        branches: [ main ]  # Trigger on push to main

    jobs:
      create_pr: # Renamed job for clarity
        runs-on: ubuntu-latest
        steps:
          - name: Checkout code
            uses: actions/checkout@v3

          - name: Print working directory # Kept for debugging
            run: |
              pwd
              ls -la

          - name: Download CLI tool
            run: |
              # Create bin directory in runner temp
              mkdir -p $RUNNER_TEMP/bin
              cd $RUNNER_TEMP/bin

              # Download CLI tool
              wget https://github.com/langgenius/dify-plugin-daemon/releases/download/0.0.6/dify-plugin-linux-amd64
              chmod +x dify-plugin-linux-amd64

              # Show download location and file
              echo "CLI tool location:"
              pwd
              ls -la dify-plugin-linux-amd64

          - name: Get basic info from manifest # Changed step name and content
            id: get_basic_info
            run: |
              PLUGIN_NAME=$(grep "^name:" manifest.yaml | cut -d' ' -f2)
              echo "Plugin name: $PLUGIN_NAME"
              echo "plugin_name=$PLUGIN_NAME" >> $GITHUB_OUTPUT

              VERSION=$(grep "^version:" manifest.yaml | cut -d' ' -f2)
              echo "Plugin version: $VERSION"
              echo "version=$VERSION" >> $GITHUB_OUTPUT

              # If the author's name is not your github username, you can change the author here
              AUTHOR=$(grep "^author:" manifest.yaml | cut -d' ' -f2)
              echo "Plugin author: $AUTHOR"
              echo "author=$AUTHOR" >> $GITHUB_OUTPUT

          - name: Package Plugin
            id: package
            run: |
              # Use the downloaded CLI tool to package
              cd $GITHUB_WORKSPACE
              # Use variables for package name
              PACKAGE_NAME="${{ steps.get_basic_info.outputs.plugin_name }}-${{ steps.get_basic_info.outputs.version }}.difypkg"
              # Use CLI from runner temp
              $RUNNER_TEMP/bin/dify-plugin-linux-amd64 plugin package . -o "$PACKAGE_NAME"

              # Show packaging result
              echo "Package result:"
              ls -la "$PACKAGE_NAME"
              echo "package_name=$PACKAGE_NAME" >> $GITHUB_OUTPUT

              # Show full file path and directory structure (kept for debugging)
              echo "\\nFull file path:"
              pwd
              echo "\\nDirectory structure:"
              tree || ls -R

          - name: Checkout target repo
            uses: actions/checkout@v3
            with:
              # Use author variable for repository
              repository: ${{steps.get_basic_info.outputs.author}}/dify-plugins
              path: dify-plugins
              token: ${{ secrets.PLUGIN_ACTION }}
              fetch-depth: 1 # Fetch only the last commit to speed up checkout
              persist-credentials: true # Persist credentials for subsequent git operations

          - name: Prepare and create PR
            run: |
              # Debug info (kept)
              echo "Debug: Current directory $(pwd)"
              # Use variable for package name
              PACKAGE_NAME="${{ steps.get_basic_info.outputs.plugin_name }}-${{ steps.get_basic_info.outputs.version }}.difypkg"
              echo "Debug: Package name: $PACKAGE_NAME"
              ls -la

              # Move the packaged file to the target directory using variables
              mkdir -p dify-plugins/${{ steps.get_basic_info.outputs.author }}/${{ steps.get_basic_info.outputs.plugin_name }}
              mv "$PACKAGE_NAME" dify-plugins/${{ steps.get_basic_info.outputs.author }}/${{ steps.get_basic_info.outputs.plugin_name }}/

              # Enter the target repository directory
              cd dify-plugins

              # Configure git
              git config user.name "GitHub Actions"
              git config user.email "actions@github.com"

              # Ensure we are on the latest main branch
              git fetch origin main
              git checkout main
              git pull origin main

              # Create and switch to a new branch using variables and new naming convention
              BRANCH_NAME="bump-${{ steps.get_basic_info.outputs.plugin_name }}-plugin-${{ steps.get_basic_info.outputs.version }}"
              git checkout -b "$BRANCH_NAME"

              # Add and commit changes (using git add .)
              git add .
              git status # for debugging
              # Use variables in commit message
              git commit -m "bump ${{ steps.get_basic_info.outputs.plugin_name }} plugin to version ${{ steps.get_basic_info.outputs.version }}"

              # Push to remote (use force just in case the branch existed before from a failed run)
              git push -u origin "$BRANCH_NAME" --force

              # Confirm branch has been pushed and wait for sync (GitHub API might need a moment)
              git branch -a
              echo "Waiting for branch to sync..."
              sleep 10  # Wait 10 seconds for branch sync

          - name: Create PR via GitHub API
            env:
              GH_TOKEN: ${{ secrets.PLUGIN_ACTION }} # Use the provided token for authentication
            run: |
              gh pr create \
                --repo langgenius/dify-plugins \
                --head "${{ steps.get_basic_info.outputs.author }}:${{ steps.get_basic_info.outputs.plugin_name }}-${{ steps.get_basic_info.outputs.version }}" \
                --base main \
                --title "bump ${{ steps.get_basic_info.outputs.plugin_name }} plugin to version ${{ steps.get_basic_info.outputs.version }}" \
                --body "bump ${{ steps.get_basic_info.outputs.plugin_name }} plugin package to version ${{ steps.get_basic_info.outputs.version }}

                Changes:
                - Updated plugin package file" || echo "PR already exists or creation skipped." # Handle cases where PR already exists

          - name: Print environment info # Kept for debugging
            run: |
              echo "GITHUB_WORKSPACE: $GITHUB_WORKSPACE"
              echo "Current directory contents:"
              ls -R
    ```

    确保 `manifest.yaml` 文件正确设置以下字段：

    ```yaml
    version: 0.0.x  # Version number
    author: your-github-username  # GitHub username/Author name
    name: your-plugin-name  # Plugin name
    ```

### 使用指南

#### 初次使用流程

首次设置自动发布工作流时，需要完成以下步骤：

1. 确保你已经 fork 了官方的 `dify-plugins` 仓库
2. 确保你的插件源码仓库结构正确
3. 在插件源码仓库中设置 `PLUGIN_ACTION Secret`
4. 创建工作流文件 `.github/workflows/plugin-publish.yml`
5. 确保 `manifest.yaml` 文件中的 `name` 和 `author` 字段正确配置

#### 后续更新流程

设置完成后，每次需要发布新版本时，只需：

1. 修改插件代码
2. 更新 `manifest.yaml` 中的 `version` 字段

![Release](https://assets-docs.dify.ai/2025/04/9eed2b9110e91e18008b399e58198f03.png)

3. 将所有更改推送到 main 分支
4. 等待 GitHub Actions 自动完成打包、分支创建和 PR 提交

### 执行效果展示

当你推送代码到插件源码仓库的 main 分支时，GitHub Actions 将自动执行发布流程：

* 自动打包插件为 `plugin-name-version.difypkg` 格式
* 自动将打包文件推送到目标仓库
* 自动创建 PR 合并到 fork 仓库

![Outcome](https://assets-docs.dify.ai/2025/04/60d5de910c6ce2482c67ddec3320311f.png)

### 示例仓库

你可以参考[示例仓库](https://github.com/Yevanchen/exa-in-dify)，了解完整的配置细节和最佳实践。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/publish-plugins/plugin-auto-publish-pr.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 发布至个人 GitHub 仓库
> 来源：`zh-hans/plugins/publish-plugins/publish-plugin-on-personal-github-repo.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

支持通过 GitHub 仓库链接安装插件。插件开发完成后，你可以选择将插件发布至公开 GitHub 仓库供其他人下载和使用。该方式具备以下优势：

• **个人管理**：你可以完全控制插件的代码和更新

• **快速分享**：通过 GitHub 链接即可轻松分享给其他用户或团队成员，便于测试和使用

• **协作与反馈**：将插件开源后，有可能会吸引 GitHub 上潜在的协作者，帮助您快速改进插件

本文将指导你如何将插件发布到 GitHub 仓库。

### 准备工作

* GitHub 账号
* 创建一个新的公开 GitHub 仓库
* 本地已安装 Git 工具

关于 GitHub 的基础知识，请参考 [GitHub 文档](https://docs.github.com/en/repositories/creating-and-managing-repositories/creating-a-new-repository)。

### 1. 完善插件项目

将上传至公开的 GitHub 意味着你将公开插件。请确保你已完成插件的调试和验证，并已完善插件的 `README.md` 文件说明。

建议说明文件包含以下内容：

* 插件的简介和功能描述
* 安装和配置步骤
* 使用示例
* 联系方式或贡献指南

### 2. 初始化本地插件仓库

将插件公开上传至 GitHub 之前，请确保已完成插件的调试和验证工作。在终端中导航到插件项目文件夹，并运行以下命令：

```bash
git init
git add .
git commit -m "Initial commit: Add plugin files"
```

如果你是第一次使用 Git，可能还需要配置 Git 用户名和邮箱：

```bash
git config --global user.name "Your Name"
git config --global user.email "your.email@example.com"
```

### 3. 连接远程仓库

使用以下命令，将本地仓库连接到 GitHub 仓库：

```bash
git remote add origin https://github.com/<your-username>/<repository-name>.git
```

### 4. 上传插件文件

> 打包插件前，请确保插件的 `manifest.yaml` 文件和 `/provider` 路径下的 `.yaml` 文件中的 author 字段与 GitHub ID 保持一致。

将插件项目推送到 GitHub 仓库：

```bash
git branch -M main
git push -u origin main
```

上传代码时建议附上标签，以便后续打包代码。

```bash
git tag -a v0.0.1 -m "Release version 0.0.1"

git push origin v0.0.1
```

### 5. 打包插件代码

前往 GitHub 代码仓库的 Releases 页，创建一个新的版本发布。发布版本时需上传插件文件。关于如何打包插件文件，详细说明请阅读[打包插件](./zh-hans/plugins/publish-plugins/README)。

![打包插件](https://assets-docs.dify.ai/2024/12/5cb4696348cc6903e380287fce8f529d.png)

### 通过 GitHub 安装插件

其他人可以通过 GitHub 仓库地址安装该插件。访问 Dify 平台的插件管理页，选择通过 GitHub 安装插件，输入仓库地址后，选择版本号和包文件完成安装。

![](https://assets-docs.dify.ai/2024/12/3c2612349c67e6898a1f33a7cc320468.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/publish-plugins/publish-plugin-on-personal-github-repo.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 发布至 Dify Marketplace
> 来源：`zh-hans/plugins/publish-plugins/publish-to-dify-marketplace/README.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

Dify Marketplace 欢迎来自合作伙伴和社区开发者的插件上架申请，您的贡献将进一步丰富 Dify 插件的可能性。本指引将提供清晰的发布流程和最佳实践建议，让您的插件能够顺利发布，并为社区带来价值。

请按照以下步骤，在 [GitHub 代码仓库](https://github.com/langgenius/dify-plugins)提交您的插件 Pull Request（PR）并接受审核，通过后插件将正式上线至 Dify Marketplace。

### 插件的发布流程

将插件发布至 Dify Marketplace 包含以下步骤：

1. 根据[插件开发者准则](plugin-developer-guidelines)完成插件的开发和测试；
2. 根据[插件隐私政策准则](plugin-privacy-protection-guidelines)撰写该插件隐私政策，并将该隐私政策的文件路径或 URL 写入插件 [Manifest 文件](../../schema-definition/manifest)；
3. 完成插件打包；
4. Fork [Dify Plugins](https://github.com/langgenius/dify-plugins) 代码仓库；
5. 创建 Organization 目录，在 Organization 目录下创建插件名目录，将插件的代码和 pkg 文件上传至对应的插件名目录下；
6. 遵循 GitHub 中的 PR Template 内容格式提交 Pull Request (PR) ，等待审核；
7. 审核通过后，插件代码将合并至 Main 分支，插件自动上架至 [Dify Marketplace](https://marketplace.dify.ai/)。

插件提交、审核和上架流程图：

![The process of uploading plugins](https://assets-docs.dify.ai/2025/01/05df333acfaf662e99316432db23ba9f.png)

> **信息提示：**

**Note**:

上图中的 Contributor Agreement 指的是[插件开发者准则](plugin-developer-guidelines)。

***

### Pull Request (PR) 审核期间

积极回应审查人员的提问和反馈：

* **14 天内**未解决的 PR 评论将被标记为过时（可重新开启）。
* **30 天内**未解决的 PR 评论将被关闭（不可重新开启，需要创建新 PR）。

***

### **Pull Request (PR) 审核通过后**

**1. 持续维护**

* 处理用户报告的问题和功能请求。
* 在发生重大 API 变更时迁移插件：
  * Dify 将提前发布变更通知和迁移说明。
  * Dify 工程师可提供迁移支持。

**2. Marketplace 公开 Beta 测试阶段的限制**

* 避免对现有插件引入破坏性更改。

***

### 审核流程

**1. 审核顺序**

* 按照 **先到先审** 的顺序处理 PR。审核将在 1 周内开始。如有延迟，审查人员将通过评论通知 PR 作者。

**2. 审核重点**

* 检查插件名称、描述和设置说明是否清晰且具有指导性。
* 检查插件的 [Manifest 文件](../../schema-definition/manifest)是否符合格式规范，并包含有效的作者联系信息。

3. **插件的功能性和相关性**

* 根据[插件开发说明](../../quick-start/develop-plugins/)测试插件。
* 确保插件在 Dify 生态系统中的用途合理。

[Dify.AI](https://dify.ai/) 保留接受或拒绝插件提交的权利。

***

### 常见问题

1. **如何判断插件是否独特？**

示例：一个 Google 搜索插件仅增加了多语言版本，应被视为现有插件的优化。但如果插件实现了显著的功能改进（如优化批量处理或错误处理），则可以作为新插件提交。

2. **如果我的 PR 被标记为过时或关闭怎么办？**

被标记为过时的 PR 可以在解决反馈后重新开启。被关闭的 PR（超过 30 天）需要重新创建一个新 PR。

3. **Beta 测试阶段可以更新插件吗？**

可以，但应避免引入破坏性更改。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 插件开发者准则
> 来源：`zh-hans/plugins/publish-plugins/publish-to-dify-marketplace/plugin-developer-guidelines.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

### 提交 Pull Request (PR) 之前

1. **确保插件功能正常且文档齐全**

* 验证插件的功能是否正常运行。
* 提供全面的 **README 文件**，包括：
  * 设置说明和使用指南。
  * 插件用户需用的代码、API、凭据或其他信息，以便连接插件到服务。
* 确保收集的用户信息仅用于连接服务和改进插件功能。
* 根据[插件隐私政策准则](plugin-privacy-protection-guidelines)准备隐私政策内容文件或在线文档 URL。

2. **验证插件的贡献价值**

* 确保插件为 Dify 用户提供了独特价值。
* 插件应引入 Dify 或其他插件尚未提供的功能或服务。
* 遵循社区标准：
  * 内容非暴力，尊重全球用户群体。
  * 符合集成服务的相关政策。
* **如何检查是否已有类似插件？**
  * 避免提交与现有插件或 PR 重复的功能，除非新插件具备以下特点：
    * 引入新功能。
    * 提供性能改进。
  * **如何判断插件是否足够独特：**
    * 如果插件仅在现有功能上做出小幅调整（如添加语言参数），建议直接扩展现有插件。
    * 如果插件实现了重大功能变化（如优化批量处理或改进错误处理），可以提交为新插件。
    * 不确定？请在提交 PR 中附上简要说明，解释为什么需要提交新插件。

**示例：** 以Google 搜索插件为例，它接受单个输入查询并使用 Google 搜索 API 输出 Google 搜索结果列表。如果您提供具有类似底层实现的新 Google 搜索插件，但对输入进行了细微调整（例如添加新的语言参数），我们建议扩展现有插件。另一方面，如果您以新的方式实现了插件执行优化的批量搜索和错误处理能力，则可被视作单独的插件进行审核。

3. **确保插件符合下列隐私数据规范**

**信息披露要求：**

* 要求开发者在提交应用/工具时，**必须**声明是否收集任何类型的用户个人数据。
* 如果收集，需要**简单列出**收集的数据类型（例如：用户名、邮箱、设备ID、位置信息等），**无需过于详细**。
* 开发者**必须**提供隐私政策链接，隐私政策只需要陈述收集了什么信息、怎么使用这些信息、以及哪些信息会和第三方披露，以及第三方相关的隐私政策链接。

**审核重点：**

* **形式审核：** 检查是否按要求声明了数据收集情况。
* **高危数据排查：** 重点关注是否收集了敏感数据（例如：健康信息、财务信息、儿童个人信息等），如果收集了敏感数据，则需要**额外审核**其使用目的和安全性措施。
* **恶意行为排查：** 检查是否存在明显恶意行为，例如未经用户同意私自收集数据、上传用户数据到未知服务器等。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace/plugin-developer-guidelines.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 插件隐私政策准则
> 来源：`zh-hans/plugins/publish-plugins/publish-to-dify-marketplace/plugin-privacy-protection-guidelines.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

向 Dify Marketplace 提交插件上架申请时，您需要公开说明如何处理用户数据。以下是关于填写插件相关隐私问题和用户数据处理的指南。

插件隐私政策声明内容围绕以下问题展开：

**您的插件是否收集和使用用户个人数据？** 如有，请整理并列出具体类型。

> 个人数据指可识别特定个人的任何信息，包括单独或与其他信息结合后可用于识别、联系或定位个人的信息。

#### **1. 列出所收集的数据类型**

**类型一：直接识别信息**

* 姓名（全名、名、姓）
* 邮箱
* 手机号
* 住址
* 身份证件号（身份证、护照、驾照等）

**类型二：间接识别信息**

* 设备识别码（IMEI、MAC 地址、设备 ID）
* IP 地址
* 位置信息（GPS 坐标、城市、地区）
* 在线标识（cookies、广告 ID）
* 用户名
* 头像
* 生物特征（指纹、人脸识别）
* 浏览记录
* 购物记录
* 健康数据
* 财务信息

**类型三：被用于识别个人的组合信息**

* 年龄
* 性别
* 职业
* 兴趣爱好

即使您的插件本身不收集个人信息，也请确认插件使用的第三方服务是否涉及数据收集或处理。作为开发者，您需要公开所有数据收集活动，包括第三方服务的数据处理。请务必阅读第三方服务的隐私政策，确保在提交时声明插件涉及的所有数据收集情况。

例如，当你正在开发的插件涉及 Slack 服务时，请在插件的隐私政策声明文件中引用 [Slack 的隐私政策](https://slack.com/trust/privacy/privacy-policy)并声明数据收集情况。

#### 2. 填写最新版本的插件隐私政策

**插件隐私政策**必须包含：

* 收集的数据类型
* 数据用途
* 是否与第三方共享数据（如有，请列出第三方服务的名称及其隐私政策链接）
* 如果不熟悉隐私政策写法，可以参考由 Dify 官方维护插件内的隐私政策

#### **3. 在插件 Manifest 文件内引入隐私政策声明**

详细字段的填写说明请参考 [Manifest](../../schema-definition/manifest)。

### **常见问题**

1. **什么是"收集和使用"用户个人数据？有哪些常见案例？**

“收集和使用”指对用户数据进行收集、传输、使用或共享。常见情况包括：

* 通过表单收集个人信息；
* 使用登录功能（含第三方认证）；
* 收集可能包含个人信息的输入或资源；
* 分析用户行为、互动和使用情况；
* 存储通讯内容，如消息、聊天记录、邮箱；
* 访问关联社交媒体的用户资料；
* 收集健康数据，如运动、心率、医疗信息；
* 保存搜索记录或浏览行为；
* 处理财务信息，如银行资料、信用分、交易记录。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace/plugin-privacy-protection-guidelines.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 第三方签名验证
> 来源：`zh-hans/plugins/publish-plugins/signing-plugins-for-third-party-signature-verification.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

> **警告：**

此功能仅在 Dify 社区版中可用，Dify 云端版目前不支持第三方签名验证。

第三方签名验证允许 Dify 管理员安全地安装尚未在 Dify 市场上提供的插件，而无需修改 `.env` 文件绕开签名验证安全限制。

**使用场景：**

* 一经同意，Dify 管理员可以为插件添加由开发者发送的签名。
* 插件开发者可以为他们的插件添加签名，并将其与公钥一起发布给无法禁用签名验证的 Dify 管理员。

Dify 管理员和插件开发者都可以使用预先生成的密钥对为插件添加签名。此外，管理员可以配置 Dify 在插件安装过程中使用特定公钥强制执行签名验证。

## 生成用于签名和验证的密钥对

使用以下命令生成新的密钥对，用于添加和验证插件签名：

```bash
dify signature generate -f your_key_pair
```

运行此命令后，将在当前目录中生成两个文件：

* **私钥**：`your_key_pair.private.pem`
* **公钥**：`your_key_pair.public.pem`

私钥用于签名插件，公钥用于验证插件的签名。

> **警告：**
请妥善保管私钥。如果私钥被泄露，攻击者可以为任何插件添加有效签名，这将危及 Dify 社区版的安全性。

## 为插件添加签名并验证

运行以下命令为插件添加签名。请注意，你需要指定**待签名的插件文件**和**私钥**：

```bash
dify signature sign your_plugin_project.difypkg -p your_key_pair.private.pem
```

执行命令后，将在同一目录中生成一个新的插件文件，文件名中添加了 `signed`：`your_plugin_project.signed.difypkg`

你可以使用以下命令验证插件是否已正确签名。运行命令时需要指定**已签名的插件文件**和**公钥**：

```bash
dify signature verify your_plugin_project.signed.difypkg -p your_key_pair.public.pem
```

> **信息提示：**
如果省略公钥参数，验证将使用 Dify 市场公钥。在这种情况下，对于任何未从 Dify 市场下载的插件文件，签名验证将失败。

## 启用第三方签名验证

Dify 管理员可以在安装插件前强制使用预先批准的公钥进行签名验证。

### 放置公钥

将用于签名的私钥对应的**公钥**放在插件守护程序可以访问的位置。

例如，在 `docker/volumes/plugin_daemon` 下创建 `public_keys` 目录，并将公钥文件复制到对应路径：

```bash
mkdir docker/volumes/plugin_daemon/public_keys
cp your_key_pair.public.pem docker/volumes/plugin_daemon/public_keys
```

### 环境变量配置

在 `plugin_daemon` 容器中，配置以下环境变量：

* `THIRD_PARTY_SIGNATURE_VERIFICATION_ENABLED`
  * 启用第三方签名验证。
  * 将此项设置为 `true` 以启用此功能。
* `THIRD_PARTY_SIGNATURE_VERIFICATION_PUBLIC_KEYS`
  * 指定用于签名验证的公钥文件路径。
  * 你可以列出多个公钥文件，用逗号分隔。

以下是配置这些变量的 Docker Compose 覆盖文件 (`docker-compose.override.yaml`) 示例：

```yaml
services:
  plugin_daemon:
    environment:
      FORCE_VERIFYING_SIGNATURE: true
      THIRD_PARTY_SIGNATURE_VERIFICATION_ENABLED: true
      THIRD_PARTY_SIGNATURE_VERIFICATION_PUBLIC_KEYS: /app/storage/public_keys/your_key_pair.public.pem
```

> **信息提示：**
请注意，`docker/volumes/plugin_daemon` 在 `plugin_daemon` 容器中被挂载到 `/app/storage`。确保在 `THIRD_PARTY_SIGNATURE_VERIFICATION_PUBLIC_KEYS` 中指定的路径对应于容器内的路径。

要应用这些更改，请重启 Dify 服务：

```bash
cd docker
docker compose down
docker compose up -d
```

重启服务后，第三方签名验证功能将在当前社区版环境中启用。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/publish-plugins/signing-plugins-for-third-party-signature-verification.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 快速开始
> 来源：`zh-hans/plugins/quick-start/README.mdx`

根据不同需求，按照以下路径有选择性地阅读文档：

### 我想要使用插件

如果你希望快速安装并使用插件，建议优先阅读以下内容：

  install-plugins

### 我想要开发插件

如果你计划自己开发插件，可以按照以下内容顺序逐步深入：

#### 1. 快速开始

参考各类型插件的开发示例，快速了解插件的基本结构和开发流程。

  tool-plugin

  extension-plugin

  model-plugin

  bundle

  agent-strategy-plugin

#### 2. 进阶开发

阅读**接口定义文档**，深入了解插件开发过程中的**关键接口**和**实现细节**。

  schema-definition

你可以根据自身需求，有针对性地学习和掌握插件的使用或开发知识。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 插件调试
> 来源：`zh-hans/plugins/quick-start/debug-plugin.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

插件开发完成后，接下来需要测试插件是否可以正常运行。Dify 提供便捷地远程调试方式，帮助你快速在测试环境中验证插件功能。

前往[“插件管理”](https://cloud.dify.ai/plugins)页获取远程服务器地址和调试 Key。

![](https://assets-docs.dify.ai/2025/04/2779338a43687f3e00155baccdd6d06c.png)

回到插件项目，拷贝 `.env.example` 文件并重命名为 `.env`，将获取的远程服务器地址和调试 Key 等信息填入其中。

`.env` 文件：

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_URL=debug.dify.ai:5003
REMOTE_INSTALL_KEY=********-****-****-****-************
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内，团队中的其他成员也可以访问该插件。

![](https://assets-docs.dify.ai/2024/12/ec26e5afc57bbfeb807719638f603807.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/debug-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 插件开发
> 来源：`zh-hans/plugins/quick-start/develop-plugins/README.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

### 快速开始

你可以通过以下**插件开发示例**，了解如何开发不同类型的插件，快速上手并掌握插件开发过程中可能涉及的功能组件。正式开始插件开发前，需要在本地环境中安装并初始化开发脚手架。请参考以下内容：

  initialize-development-tools.md

以 **GoogleSearch** 工具为例，介绍如何开发工具类插件。开发示例请参考以下内容：

  tool-plugin.md

以 **Anthropic** 和 **Xinference** 模型为例，分别介绍如何开发**模型插件**（又称为**模型供应商**），其中包含预定义模型和自定义模型插件两种类型。

* 预定义模型是指已经由 AI 厂商训练好并面向市场的模型，通常是闭源模型（例如 GPT 系列模型和 Claude 系列模型），你可以直接调用这些模型能力完成特定任务，无需进行额外的训练或配置。
* 自定义模型插件允许开发者集成私有训练或已进行特定配置的私有模型，以满足本地场景要求。

开发示例请参考以下内容：

  model-plugin

Extension 插件允许开发者将业务代码封装为插件，并自动提供 Endpoint 请求入口，可以被理解为托管在 Dify 平台内的 API 服务。开发示例请参考以下内容：

  extension-plugin

### 接口文档

如果你想阅读插件项目的详细接口文档，请阅读以下标准规范文档：

1. [通用结构标准定义](../../schema-definition/general-specifications)
2. [Manifest 标准定义](../../schema-definition/manifest)
3. [工具接入标准定义](../../schema-definition/tool)
4. [模型接入简介](../../schema-definition/model/)
5. [Endpoint 标准定义](../../schema-definition/endpoint)
6. [扩展 Agent 策略](../../schema-definition/agent)
7. 反向调用 Dify 平台能力
   1. 反向调用 [app.md](../../schema-definition/reverse-invocation-of-the-dify-service/app)
   2. 反向调用 [model.md](../../schema-definition/reverse-invocation-of-the-dify-service/model)
   3. 反向调用节点 [node.md](../../schema-definition/reverse-invocation-of-the-dify-service/node)
   4. 反向调用工具 [tool.md](../../schema-definition/reverse-invocation-of-the-dify-service/tool)
8. [插件持久化存储能力](../../schema-definition/persistent-storage)

### 贡献指南

想为官方插件市场贡献更多插件，或面向社区开源插件？请参考以下详细的插件贡献指南：

*   [Marketplace 发布指南](../../publish-plugins/publish-to-dify-marketplace/)

    了解如何将你的插件发布至 Dify Marketplace，向更多 Dify 用户分享你的成果。
*   [GitHub 发布指南](../../publish-plugins/publish-plugin-on-personal-github-repo)

    学习如何在 GitHub 上发布和管理插件，确保插件的持续优化和社区协作。

欢迎加入贡献者行列，与全球开发者共同完善 Dify 生态系统！

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Agent 策略插件
> 来源：`zh-hans/plugins/quick-start/develop-plugins/agent-strategy-plugin.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

Agent 策略插件能够帮助 LLM 执行推理或决策逻辑，包括工具选择、调用和结果处理，以更加自动化的方式处理问题。

本文将演示如何创建一个具备工具调用（Function Calling）能力，自动获取当前准确时间的插件。

### 前置准备

* Dify 插件脚手架工具
* Python 环境，版本号 ≥ 3.12

关于如何准备插件开发的脚手架工具，详细说明请参考[安装插件开发工具](initialize-development-tools)。

> **信息提示：**
**Tips**：在终端运行 `dify version` 命令，检查是否出现版本号以确认成功安装脚手架工具。

### 1. 初始化插件模板

运行以下命令，初始化 Agent 插件开发模板。

```bash
dify plugin init
```

按照页面提示，填写对应信息。参考以下代码中的备注信息，进行设置。

```bash
➜ ./dify-plugin-darwin-arm64 plugin init                                                                                                                                 ─╯
Edit profile of the plugin
Plugin name (press Enter to next step): # 填写插件的名称
Author (press Enter to next step): # 填写插件作者
Description (press Enter to next step): # 填写插件的描述
---
Select the language you want to use for plugin development, and press Enter to continue,
BTW, you need Python 3.12+ to develop the Plugin if you choose Python.
-> python # 选择 Python 环境
  go (not supported yet)
---
Based on the ability you want to extend, we have divided the Plugin into four types: Tool, Model, Extension, and Agent Strategy.

- Tool: It's a tool provider, but not only limited to tools, you can implement an endpoint there, for example, you need both Sending Message and Receiving Message if you are
- Model: Just a model provider, extending others is not allowed.
- Extension: Other times, you may only need a simple http service to extend the functionalities, Extension is the right choice for you.
- Agent Strategy: Implement your own logics here, just by focusing on Agent itself

What's more, we have provided the template for you, you can choose one of them below:
  tool
-> agent-strategy # 选择 Agent 策略模板
  llm
  text-embedding
---
Configure the permissions of the plugin, use up and down to navigate, tab to select, after selection, press enter to finish
Backwards Invocation:
Tools:
    Enabled: [✔]  You can invoke tools inside Dify if it's enabled # 默认开启
Models:
    Enabled: [✔]  You can invoke models inside Dify if it's enabled # 默认开启
    LLM: [✔]  You can invoke LLM models inside Dify if it's enabled # 默认开启
  → Text Embedding: [✘]  You can invoke text embedding models inside Dify if it's enabled
    Rerank: [✘]  You can invoke rerank models inside Dify if it's enabled
    TTS: [✘]  You can invoke TTS models inside Dify if it's enabled
    Speech2Text: [✘]  You can invoke speech2text models inside Dify if it's enabled
    Moderation: [✘]  You can invoke moderation models inside Dify if it's enabled
Apps:
    Enabled: [✘]  Ability to invoke apps like BasicChat/ChatFlow/Agent/Workflow etc.
Resources:
Storage:
    Enabled: [✘]  Persistence storage for the plugin
    Size: N/A  The maximum size of the storage
Endpoints:
    Enabled: [✘]  Ability to register endpoints
```

初始化插件模板后将生成一个代码文件夹，包含插件开发过程中所需的完整资源。熟悉 Agent 策略插件的整体代码结构有助于插件的开发过程。

```text
├── GUIDE.md               # User guide and documentation
├── PRIVACY.md            # Privacy policy and data handling guidelines
├── README.md             # Project overview and setup instructions
├── _assets/             # Static assets directory
│   └── icon.svg         # Agent strategy provider icon/logo
├── main.py              # Main application entry point
├── manifest.yaml        # Basic plugin configuration
├── provider/           # Provider configurations directory
│   └── basic_agent.yaml # Your agent provider settings
├── requirements.txt    # Python dependencies list
└── strategies/         # Strategy implementation directory
    ├── basic_agent.py  # Basic agent strategy implementation
    └── basic_agent.yaml # Basic agent strategy configuration
```

插件的功能代码集中在 `strategies/` 目录内。

### 2. 开发插件功能

Agent 策略插件的开发主要围绕以下两个文件展开：

* 插件声明文件：`strategies/basic_agent.yaml`
* 插件功能代码：`strategies/basic_agent.py`

#### 2.1 定义参数

要创建一个 Agent 插件，首先需要在 `strategies/basic_agent.yaml` 文件中定义插件所需的参数。这些参数决定了插件的核心功能，例如调用 LLM 模型和使用工具的能力。

建议优先配置以下四个基础参数：

1. **model**：指定要调用的大语言模型（LLM），如 GPT-4、GPT-4o-mini 等。

2. **tools**：定义插件可以使用的工具列表，增强插件功能。

3. **query**：设置与模型交互的提示词或输入内容。

4. **maximum_iterations**：限制插件执行的最大迭代次数，避免过度计算。

示例代码：

```yaml
identity:
  name: basic_agent # the name of the agent_strategy
  author: novice # the author of the agent_strategy
  label:
    en_US: BasicAgent # the engilish label of the agent_strategy
description:
  en_US: BasicAgent # the english description of the agent_strategy
parameters:
  - name: model # the name of the model parameter
    type: model-selector # model-type
    scope: tool-call&llm # the scope of the parameter
    required: true
    label:
      en_US: Model
      zh_Hans: 模型
      pt_BR: Model
  - name: tools # the name of the tools parameter
    type: array[tools] # the type of tool parameter
    required: true
    label:
      en_US: Tools list
      zh_Hans: 工具列表
      pt_BR: Tools list
  - name: query # the name of the query parameter
    type: string # the type of query parameter
    required: true
    label:
      en_US: Query
      zh_Hans: 查询
      pt_BR: Query
  - name: maximum_iterations
    type: number
    required: false
    default: 5
    label:
      en_US: Maxium Iterations
      zh_Hans: 最大迭代次数
      pt_BR: Maxium Iterations
    max: 50 # if you set the max and min value, the display of the parameter will be a slider
    min: 1
extra:
  python:
    source: strategies/basic_agent.py

```

完成参数配置后，插件将在自动生成相应的设置的使用页面，方便你进行直观、便捷的调整和使用。

![Agent 策略插件的使用页面](https://assets-docs.dify.ai/2025/01/d011e2eba4c37f07a9564067ba787df8.png)

#### 2.2 获取参数并执行

当使用者在插件的使用页面完成基础的信息填写后，插件需要处理已填写的传入参数。因此需要先在 `strategies/basic_agent.py` 文件内定义 Agent 参数类供后续使用。

校验传入参数：

```python
from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity
from pydantic import BaseModel

class BasicParams(BaseModel):
    maximum_iterations: int
    model: AgentModelConfig
    tools: list[ToolEntity]
    query: str

```

获取参数后，执行具体的业务逻辑：

```python
class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)
```

#### 2.3 调用模型

在 Agent 策略插件中，**调用模型**是核心执行逻辑之一。可以通过 SDK 提供的 `session.model.llm.invoke()` 方法高效地调用 LLM 模型，实现文本生成、对话处理等功能。

如果希望模型具备**调用工具**的能力，首先需要确保模型能够输出符合工具调用格式的输入参数。也就是说，模型需要根据用户指令生成符合工具接口要求的参数。

构造以下参数：

* model：模型信息
* prompt\_messages：提示词
* tools：工具信息（Function Calling 相关）
* stop：停止符
* stream：是否支持流式输出

方法定义示例代码：

```python
def invoke(
        self,
        model_config: LLMModelConfig,
        prompt_messages: list[PromptMessage],
        tools: list[PromptMessageTool] | None = None,
        stop: list[str] | None = None,
        stream: bool = True,
    ) -> Generator[LLMResultChunk, None, None] | LLMResult:...
```

要查看完整的功能实现，请参考模型调用[示例代码](agent-strategy-plugin#diao-yong-gong-ju-1)。

该代码实现了以下功能：用户输入指令后，Agent 策略插件会自动调用 LLM，根据生成结果构建并传递工具调用所需的参数，使模型能够灵活调度已接入的工具，高效完成复杂任务。

![生成工具的请求参数](https://assets-docs.dify.ai/2025/01/01e32c2d77150213c7c929b3cceb4dae.png)

#### 2.4 为模型添加记忆

当使用 Agent 插件调用模型时，为模型添加记忆功能能够极大提升对话体验。通过记忆功能，模型可以理解完整的对话上下文，实现连贯的交互体验和精准的工具调用。

具体实现步骤：

1. 配置记忆功能

在 Agent 插件的 YAML 配置文件 `strategies/agent.yaml` 中添加 `history-messages` 特性：

```yaml
identity:
  name: basic_agent  # Agent策略名称
  author: novice     # 作者
  label:
    en_US: BasicAgent  # 英文标签
description:
  en_US: BasicAgent    # 英文描述
features:
  - history-messages   # 启用历史消息功能
...
```

2. 启用记忆设置

修改插件配置文件并重启后，你将在节点配置界面中看到 **记忆** 开关。点击右侧的开关按钮，启用记忆功能。

启用后，您可以通过 **窗口大小** 滑块调整记忆窗口，它决定了模型能够“记住”多少之前的对话内容。

3. 调试历史消息

添加以下代码，查看历史消息内容：

```python
class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)
        print(f"history_messages: params.model.history_prompt_messages")
        ...
```

![History messages](https://assets-docs.dify.ai/2025/04/cb11fae7981dae431966f83fa99f1dfb.png)

控制台将显示类似如下输出：

```
history_messages: []
history_messages: [UserPromptMessage(role=, content='hello, my name is novice', name=None), AssistantPromptMessage(role=, content='Hello, Novice! How can I assist you today?', name=None, tool_calls=[])]
```

4. 将历史消息集成到模型调用

最后，修改模型调用代码，将历史消息拼接到当前查询：

```python
class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)

        chunks: Generator[LLMResultChunk, None, None] | LLMResult = (
            self.session.model.llm.invoke(
                model_config=LLMModelConfig(**params.model.model_dump(mode="json")),
                # 添加历史消息
                prompt_messages=params.model.history_prompt_messages
                + [UserPromptMessage(content=params.query)],
                tools=[
                    self._convert_tool_to_prompt_message_tool(tool)
                    for tool in params.tools
                ],
                stop=params.model.completion_params.get("stop", [])
                if params.model.completion_params
                else [],
                stream=True,
            )
        )
        ...
```

5. 效果验证

添加加记忆功能后，模型能够基于历史对话进行回复。在下图示例中，模型成功地记住了之前对话中提及的用户名称，实现了对话的连贯性。

![Outcome](https://assets-docs.dify.ai/2025/04/6bdd3d2c6a455ae8e463bd6abab5c3a4.png)

#### 2.5 调用工具

填写工具参数后，需赋予 Agent 策略插件实际调用工具的能力。可以通过 SDK 中的`session.tool.invoke()` 函数进行工具调用。

构造以下参数：

* provider：工具提供商
* tool\_name：工具名称
* parameters：输入参数

方法定义示例代码：

```python
 def invoke(
        self,
        provider_type: ToolProviderType,
        provider: str,
        tool_name: str,
        parameters: dict[str, Any],
    ) -> Generator[ToolInvokeMessage, None, None]:...
```

若希望通过 LLM 直接生成参数完成工具调用，请参考以下工具调用的示例代码：

```python
tool_instances = (
    tool.identity.name: tool for tool in params.tools if params.tools else {}
)
for tool_call_id, tool_call_name, tool_call_args in tool_calls:
    tool_instance = tool_instances[tool_call_name]
    self.session.tool.invoke(
        provider_type=ToolProviderType.BUILT_IN,
        provider=tool_instance.identity.provider,
        tool_name=tool_instance.identity.name,
        parameters=**tool_instance.runtime_parameters, **tool_call_args,
    )
```

如需查看完整的功能代码，请阅读调用工具[示例代码](agent-strategy-plugin#diao-yong-gong-ju-1)。

实现这部分的功能代码后，Agent 策略插件将具备自动 Function Calling 的能力，例如自动获取当前时间：

![工具调用](https://assets-docs.dify.ai/2025/01/80e5de8acc2b0ed00524e490fd611ff5.png)

#### 2.6 日志创建

在 **Agent 策略插件**中，通常需要执行多轮操作才能完成复杂任务。记录每轮操作的执行结果对于开发者来说非常重要，有助于追踪 Agent 的执行过程、分析每一步的决策依据，从而更好地评估和优化策略效果。

为了实现这一功能，可以利用 SDK 中的 `create_log_message` 和 `finish_log_message` 方法记录日志。这种方式不仅可以在模型调用前后实时记录操作状态，还能帮助开发者快速定位问题。

场景示例：

* 在模型调用之前，记录一条“开始调用模型”的日志，帮助开发者明确任务执行进度。
* 在模型调用成功后，记录一条“调用成功”的日志，方便追踪模型响应的完整性。

```python
model_log = self.create_log_message(
            label=f"params.model.model Thought",
            data={},
            metadata="start_at": model_started_at, "provider": params.model.provider,
            status=ToolInvokeMessage.LogMessage.LogStatus.START,
        )
yield model_log
self.session.model.llm.invoke(...)
yield self.finish_log_message(
    log=model_log,
    data=
        "output": response,
        "tool_name": tool_call_names,
        "tool_input": tool_call_inputs,
    ,
    metadata=
        "started_at": model_started_at,
        "finished_at": time.perf_counter(),
        "elapsed_time": time.perf_counter() - model_started_at,
        "provider": params.model.provider,
    ,
)
```

设置完成后，工作流日志将输出执行结果：

![Agent 输出执行结果](https://assets-docs.dify.ai/2025/01/96516388a4fb1da9cea85fc1804ff377.png)

在 Agent 执行的过程中，有可能会产生多轮日志。若日志能具备层级结构将有助于开发者查看。通过在日志记录时传入 parent 参数，不同轮次的日志可以形成上下级关系，使日志展示更加清晰、易于追踪。

**引用方法：**

```python
function_call_round_log = self.create_log_message(
    label="Function Call Round1 ",
    data={},
    metadata={},
)
yield function_call_round_log

model_log = self.create_log_message(
    label=f"params.model.model Thought",
    data={},
    metadata="start_at": model_started_at, "provider": params.model.provider,
    status=ToolInvokeMessage.LogMessage.LogStatus.START,
    # add parent log
    parent=function_call_round_log,
)
yield model_log
```

### 插件功能示例代码

#### 调用模型

以下代码将演示如何赋予 Agent 策略插件调用模型的能力：

```python

from collections.abc import Generator
from typing import Any, cast

from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig, LLMResult, LLMResultChunk
from dify_plugin.entities.model.message import (
    PromptMessageTool,
    UserPromptMessage,
)
from dify_plugin.entities.tool import ToolInvokeMessage, ToolParameter, ToolProviderType
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity
from pydantic import BaseModel

class BasicParams(BaseModel):
    maximum_iterations: int
    model: AgentModelConfig
    tools: list[ToolEntity]
    query: str

class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)
        chunks: Generator[LLMResultChunk, None, None] | LLMResult = (
            self.session.model.llm.invoke(
                model_config=LLMModelConfig(**params.model.model_dump(mode="json")),
                prompt_messages=[UserPromptMessage(content=params.query)],
                tools=[
                    self._convert_tool_to_prompt_message_tool(tool)
                    for tool in params.tools
                ],
                stop=params.model.completion_params.get("stop", [])
                if params.model.completion_params
                else [],
                stream=True,
            )
        )
        response = ""
        tool_calls = []
        tool_instances = (
            tool.identity.name: tool for tool in params.tools if params.tools else {}
        )

        for chunk in chunks:
            # check if there is any tool call
            if self.check_tool_calls(chunk):
                tool_calls = self.extract_tool_calls(chunk)
                tool_call_names = ";".join([tool_call[1] for tool_call in tool_calls])
                try:
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls,
                        ensure_ascii=False,
                    )
                except json.JSONDecodeError:
                    # ensure ascii to avoid encoding error
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls
                    )
                print(tool_call_names, tool_call_inputs)
            if chunk.delta.message and chunk.delta.message.content:
                if isinstance(chunk.delta.message.content, list):
                    for content in chunk.delta.message.content:
                        response += content.data
                        print(content.data, end="", flush=True)
                else:
                    response += str(chunk.delta.message.content)
                    print(str(chunk.delta.message.content), end="", flush=True)

            if chunk.delta.usage:
                # usage of the model
                usage = chunk.delta.usage

        yield self.create_text_message(
            text=f"response or json.dumps(tool_calls, ensure_ascii=False)\n"
        )
        result = ""
        for tool_call_id, tool_call_name, tool_call_args in tool_calls:
            tool_instance = tool_instances[tool_call_name]
            tool_invoke_responses = self.session.tool.invoke(
                provider_type=ToolProviderType.BUILT_IN,
                provider=tool_instance.identity.provider,
                tool_name=tool_instance.identity.name,
                parameters=**tool_instance.runtime_parameters, **tool_call_args,
            )
            if not tool_instance:
                tool_invoke_responses = {
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": f"there is not a tool named {tool_call_name}",
                }
            else:
                # invoke tool
                tool_invoke_responses = self.session.tool.invoke(
                    provider_type=ToolProviderType.BUILT_IN,
                    provider=tool_instance.identity.provider,
                    tool_name=tool_instance.identity.name,
                    parameters=**tool_instance.runtime_parameters, **tool_call_args,
                )
                result = ""
                for tool_invoke_response in tool_invoke_responses:
                    if tool_invoke_response.type == ToolInvokeMessage.MessageType.TEXT:
                        result += cast(
                            ToolInvokeMessage.TextMessage, tool_invoke_response.message
                        ).text
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.LINK
                    ):
                        result += (
                            f"result link: cast(ToolInvokeMessage.TextMessage, tool_invoke_response.message).text."
                            + " please tell user to check it."
                        )
                    elif tool_invoke_response.type in 
                        ToolInvokeMessage.MessageType.IMAGE_LINK,
                        ToolInvokeMessage.MessageType.IMAGE,
                    :
                        result += (
                            "image has been created and sent to user already, "
                            + "you do not need to create it, just tell the user to check it now."
                        )
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.JSON
                    ):
                        text = json.dumps(
                            cast(
                                ToolInvokeMessage.JsonMessage,
                                tool_invoke_response.message,
                            ).json_object,
                            ensure_ascii=False,
                        )
                        result += f"tool response: text."
                    else:
                        result += f"tool response: tool_invoke_response.message!r."

                tool_response = 
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": result,

        yield self.create_text_message(result)

    def _convert_tool_to_prompt_message_tool(
        self, tool: ToolEntity
    ) -> PromptMessageTool:
        """
        convert tool to prompt message tool
        """
        message_tool = PromptMessageTool(
            name=tool.identity.name,
            description=tool.description.llm if tool.description else "",
            parameters={
                "type": "object",
                "properties": {},
                "required": [],
            },
        )

        parameters = tool.parameters
        for parameter in parameters:
            if parameter.form != ToolParameter.ToolParameterForm.LLM:
                continue

            parameter_type = parameter.type
            if parameter.type in 
                ToolParameter.ToolParameterType.FILE,
                ToolParameter.ToolParameterType.FILES,
            :
                continue
            enum = []
            if parameter.type == ToolParameter.ToolParameterType.SELECT:
                enum = (
                    [option.value for option in parameter.options]
                    if parameter.options
                    else []
                )

            message_tool.parameters["properties"][parameter.name] = 
                "type": parameter_type,
                "description": parameter.llm_description or "",

            if len(enum) > 0:
                message_tool.parameters["properties"][parameter.name]["enum"] = enum

            if parameter.required:
                message_tool.parameters["required"].append(parameter.name)

        return message_tool

    def check_tool_calls(self, llm_result_chunk: LLMResultChunk) -> bool:
        """
        Check if there is any tool call in llm result chunk
        """
        return bool(llm_result_chunk.delta.message.tool_calls)

    def extract_tool_calls(
        self, llm_result_chunk: LLMResultChunk
    ) -> list[tuple[str, str, dict[str, Any]]]:
        """
        Extract tool calls from llm result chunk

        Returns:
            List[Tuple[str, str, Dict[str, Any]]]: [(tool_call_id, tool_call_name, tool_call_args)]
        """
        tool_calls = []
        for prompt_message in llm_result_chunk.delta.message.tool_calls:
            args = {}
            if prompt_message.function.arguments != "":
                args = json.loads(prompt_message.function.arguments)

            tool_calls.append(
                (
                    prompt_message.id,
                    prompt_message.function.name,
                    args,
                )
            )

        return tool_calls
```

#### 调用工具

以下代码展示了如何为 Agent 策略插件实现模型调用并向工具发送规范化请求。

```python

from collections.abc import Generator
from typing import Any, cast

from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig, LLMResult, LLMResultChunk
from dify_plugin.entities.model.message import (
    PromptMessageTool,
    UserPromptMessage,
)
from dify_plugin.entities.tool import ToolInvokeMessage, ToolParameter, ToolProviderType
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity
from pydantic import BaseModel

class BasicParams(BaseModel):
    maximum_iterations: int
    model: AgentModelConfig
    tools: list[ToolEntity]
    query: str

class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)
        chunks: Generator[LLMResultChunk, None, None] | LLMResult = (
            self.session.model.llm.invoke(
                model_config=LLMModelConfig(**params.model.model_dump(mode="json")),
                prompt_messages=[UserPromptMessage(content=params.query)],
                tools=[
                    self._convert_tool_to_prompt_message_tool(tool)
                    for tool in params.tools
                ],
                stop=params.model.completion_params.get("stop", [])
                if params.model.completion_params
                else [],
                stream=True,
            )
        )
        response = ""
        tool_calls = []
        tool_instances = (
            tool.identity.name: tool for tool in params.tools if params.tools else {}
        )

        for chunk in chunks:
            # check if there is any tool call
            if self.check_tool_calls(chunk):
                tool_calls = self.extract_tool_calls(chunk)
                tool_call_names = ";".join([tool_call[1] for tool_call in tool_calls])
                try:
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls,
                        ensure_ascii=False,
                    )
                except json.JSONDecodeError:
                    # ensure ascii to avoid encoding error
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls
                    )
                print(tool_call_names, tool_call_inputs)
            if chunk.delta.message and chunk.delta.message.content:
                if isinstance(chunk.delta.message.content, list):
                    for content in chunk.delta.message.content:
                        response += content.data
                        print(content.data, end="", flush=True)
                else:
                    response += str(chunk.delta.message.content)
                    print(str(chunk.delta.message.content), end="", flush=True)

            if chunk.delta.usage:
                # usage of the model
                usage = chunk.delta.usage

        yield self.create_text_message(
            text=f"response or json.dumps(tool_calls, ensure_ascii=False)\n"
        )
        result = ""
        for tool_call_id, tool_call_name, tool_call_args in tool_calls:
            tool_instance = tool_instances[tool_call_name]
            tool_invoke_responses = self.session.tool.invoke(
                provider_type=ToolProviderType.BUILT_IN,
                provider=tool_instance.identity.provider,
                tool_name=tool_instance.identity.name,
                parameters=**tool_instance.runtime_parameters, **tool_call_args,
            )
            if not tool_instance:
                tool_invoke_responses = {
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": f"there is not a tool named {tool_call_name}",
                }
            else:
                # invoke tool
                tool_invoke_responses = self.session.tool.invoke(
                    provider_type=ToolProviderType.BUILT_IN,
                    provider=tool_instance.identity.provider,
                    tool_name=tool_instance.identity.name,
                    parameters=**tool_instance.runtime_parameters, **tool_call_args,
                )
                result = ""
                for tool_invoke_response in tool_invoke_responses:
                    if tool_invoke_response.type == ToolInvokeMessage.MessageType.TEXT:
                        result += cast(
                            ToolInvokeMessage.TextMessage, tool_invoke_response.message
                        ).text
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.LINK
                    ):
                        result += (
                            f"result link: cast(ToolInvokeMessage.TextMessage, tool_invoke_response.message).text."
                            + " please tell user to check it."
                        )
                    elif tool_invoke_response.type in 
                        ToolInvokeMessage.MessageType.IMAGE_LINK,
                        ToolInvokeMessage.MessageType.IMAGE,
                    :
                        result += (
                            "image has been created and sent to user already, "
                            + "you do not need to create it, just tell the user to check it now."
                        )
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.JSON
                    ):
                        text = json.dumps(
                            cast(
                                ToolInvokeMessage.JsonMessage,
                                tool_invoke_response.message,
                            ).json_object,
                            ensure_ascii=False,
                        )
                        result += f"tool response: text."
                    else:
                        result += f"tool response: tool_invoke_response.message!r."

                tool_response = 
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": result,

        yield self.create_text_message(result)

    def _convert_tool_to_prompt_message_tool(
        self, tool: ToolEntity
    ) -> PromptMessageTool:
        """
        convert tool to prompt message tool
        """
        message_tool = PromptMessageTool(
            name=tool.identity.name,
            description=tool.description.llm if tool.description else "",
            parameters={
                "type": "object",
                "properties": {},
                "required": [],
            },
        )

        parameters = tool.parameters
        for parameter in parameters:
            if parameter.form != ToolParameter.ToolParameterForm.LLM:
                continue

            parameter_type = parameter.type
            if parameter.type in 
                ToolParameter.ToolParameterType.FILE,
                ToolParameter.ToolParameterType.FILES,
            :
                continue
            enum = []
            if parameter.type == ToolParameter.ToolParameterType.SELECT:
                enum = (
                    [option.value for option in parameter.options]
                    if parameter.options
                    else []
                )

            message_tool.parameters["properties"][parameter.name] = 
                "type": parameter_type,
                "description": parameter.llm_description or "",

            if len(enum) > 0:
                message_tool.parameters["properties"][parameter.name]["enum"] = enum

            if parameter.required:
                message_tool.parameters["required"].append(parameter.name)

        return message_tool

    def check_tool_calls(self, llm_result_chunk: LLMResultChunk) -> bool:
        """
        Check if there is any tool call in llm result chunk
        """
        return bool(llm_result_chunk.delta.message.tool_calls)

    def extract_tool_calls(
        self, llm_result_chunk: LLMResultChunk
    ) -> list[tuple[str, str, dict[str, Any]]]:
        """
        Extract tool calls from llm result chunk

        Returns:
            List[Tuple[str, str, Dict[str, Any]]]: [(tool_call_id, tool_call_name, tool_call_args)]
        """
        tool_calls = []
        for prompt_message in llm_result_chunk.delta.message.tool_calls:
            args = {}
            if prompt_message.function.arguments != "":
                args = json.loads(prompt_message.function.arguments)

            tool_calls.append(
                (
                    prompt_message.id,
                    prompt_message.function.name,
                    args,
                )
            )

        return tool_calls
```

#### 完整功能代码示例

包含**调用模型、调用工具**以及**输出多轮日志功能**的完整插件代码示例：

```python

from collections.abc import Generator
from typing import Any, cast

from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig, LLMResult, LLMResultChunk
from dify_plugin.entities.model.message import (
    PromptMessageTool,
    UserPromptMessage,
)
from dify_plugin.entities.tool import ToolInvokeMessage, ToolParameter, ToolProviderType
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity
from pydantic import BaseModel

class BasicParams(BaseModel):
    maximum_iterations: int
    model: AgentModelConfig
    tools: list[ToolEntity]
    query: str

class BasicAgentAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        params = BasicParams(**parameters)
        function_call_round_log = self.create_log_message(
            label="Function Call Round1 ",
            data={},
            metadata={},
        )
        yield function_call_round_log
        model_started_at = time.perf_counter()
        model_log = self.create_log_message(
            label=f"params.model.model Thought",
            data={},
            metadata="start_at": model_started_at, "provider": params.model.provider,
            status=ToolInvokeMessage.LogMessage.LogStatus.START,
            parent=function_call_round_log,
        )
        yield model_log
        chunks: Generator[LLMResultChunk, None, None] | LLMResult = (
            self.session.model.llm.invoke(
                model_config=LLMModelConfig(**params.model.model_dump(mode="json")),
                prompt_messages=[UserPromptMessage(content=params.query)],
                tools=[
                    self._convert_tool_to_prompt_message_tool(tool)
                    for tool in params.tools
                ],
                stop=params.model.completion_params.get("stop", [])
                if params.model.completion_params
                else [],
                stream=True,
            )
        )
        response = ""
        tool_calls = []
        tool_instances = (
            tool.identity.name: tool for tool in params.tools if params.tools else {}
        )
        tool_call_names = ""
        tool_call_inputs = ""
        for chunk in chunks:
            # check if there is any tool call
            if self.check_tool_calls(chunk):
                tool_calls = self.extract_tool_calls(chunk)
                tool_call_names = ";".join([tool_call[1] for tool_call in tool_calls])
                try:
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls,
                        ensure_ascii=False,
                    )
                except json.JSONDecodeError:
                    # ensure ascii to avoid encoding error
                    tool_call_inputs = json.dumps(
                        tool_call[1]: tool_call[2] for tool_call in tool_calls
                    )
                print(tool_call_names, tool_call_inputs)
            if chunk.delta.message and chunk.delta.message.content:
                if isinstance(chunk.delta.message.content, list):
                    for content in chunk.delta.message.content:
                        response += content.data
                        print(content.data, end="", flush=True)
                else:
                    response += str(chunk.delta.message.content)
                    print(str(chunk.delta.message.content), end="", flush=True)

            if chunk.delta.usage:
                # usage of the model
                usage = chunk.delta.usage

        yield self.finish_log_message(
            log=model_log,
            data=
                "output": response,
                "tool_name": tool_call_names,
                "tool_input": tool_call_inputs,
            ,
            metadata=
                "started_at": model_started_at,
                "finished_at": time.perf_counter(),
                "elapsed_time": time.perf_counter() - model_started_at,
                "provider": params.model.provider,
            ,
        )
        yield self.create_text_message(
            text=f"response or json.dumps(tool_calls, ensure_ascii=False)\n"
        )
        result = ""
        for tool_call_id, tool_call_name, tool_call_args in tool_calls:
            tool_instance = tool_instances[tool_call_name]
            tool_invoke_responses = self.session.tool.invoke(
                provider_type=ToolProviderType.BUILT_IN,
                provider=tool_instance.identity.provider,
                tool_name=tool_instance.identity.name,
                parameters=**tool_instance.runtime_parameters, **tool_call_args,
            )
            if not tool_instance:
                tool_invoke_responses = {
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": f"there is not a tool named {tool_call_name}",
                }
            else:
                # invoke tool
                tool_invoke_responses = self.session.tool.invoke(
                    provider_type=ToolProviderType.BUILT_IN,
                    provider=tool_instance.identity.provider,
                    tool_name=tool_instance.identity.name,
                    parameters=**tool_instance.runtime_parameters, **tool_call_args,
                )
                result = ""
                for tool_invoke_response in tool_invoke_responses:
                    if tool_invoke_response.type == ToolInvokeMessage.MessageType.TEXT:
                        result += cast(
                            ToolInvokeMessage.TextMessage, tool_invoke_response.message
                        ).text
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.LINK
                    ):
                        result += (
                            f"result link: cast(ToolInvokeMessage.TextMessage, tool_invoke_response.message).text."
                            + " please tell user to check it."
                        )
                    elif tool_invoke_response.type in 
                        ToolInvokeMessage.MessageType.IMAGE_LINK,
                        ToolInvokeMessage.MessageType.IMAGE,
                    :
                        result += (
                            "image has been created and sent to user already, "
                            + "you do not need to create it, just tell the user to check it now."
                        )
                    elif (
                        tool_invoke_response.type == ToolInvokeMessage.MessageType.JSON
                    ):
                        text = json.dumps(
                            cast(
                                ToolInvokeMessage.JsonMessage,
                                tool_invoke_response.message,
                            ).json_object,
                            ensure_ascii=False,
                        )
                        result += f"tool response: text."
                    else:
                        result += f"tool response: tool_invoke_response.message!r."

                tool_response = 
                    "tool_call_id": tool_call_id,
                    "tool_call_name": tool_call_name,
                    "tool_response": result,

        yield self.create_text_message(result)

    def _convert_tool_to_prompt_message_tool(
        self, tool: ToolEntity
    ) -> PromptMessageTool:
        """
        convert tool to prompt message tool
        """
        message_tool = PromptMessageTool(
            name=tool.identity.name,
            description=tool.description.llm if tool.description else "",
            parameters={
                "type": "object",
                "properties": {},
                "required": [],
            },
        )

        parameters = tool.parameters
        for parameter in parameters:
            if parameter.form != ToolParameter.ToolParameterForm.LLM:
                continue

            parameter_type = parameter.type
            if parameter.type in 
                ToolParameter.ToolParameterType.FILE,
                ToolParameter.ToolParameterType.FILES,
            :
                continue
            enum = []
            if parameter.type == ToolParameter.ToolParameterType.SELECT:
                enum = (
                    [option.value for option in parameter.options]
                    if parameter.options
                    else []
                )

            message_tool.parameters["properties"][parameter.name] = 
                "type": parameter_type,
                "description": parameter.llm_description or "",

            if len(enum) > 0:
                message_tool.parameters["properties"][parameter.name]["enum"] = enum

            if parameter.required:
                message_tool.parameters["required"].append(parameter.name)

        return message_tool

    def check_tool_calls(self, llm_result_chunk: LLMResultChunk) -> bool:
        """
        Check if there is any tool call in llm result chunk
        """
        return bool(llm_result_chunk.delta.message.tool_calls)

    def extract_tool_calls(
        self, llm_result_chunk: LLMResultChunk
    ) -> list[tuple[str, str, dict[str, Any]]]:
        """
        Extract tool calls from llm result chunk

        Returns:
            List[Tuple[str, str, Dict[str, Any]]]: [(tool_call_id, tool_call_name, tool_call_args)]
        """
        tool_calls = []
        for prompt_message in llm_result_chunk.delta.message.tool_calls:
            args = {}
            if prompt_message.function.arguments != "":
                args = json.loads(prompt_message.function.arguments)

            tool_calls.append(
                (
                    prompt_message.id,
                    prompt_message.function.name,
                    args,
                )
            )

        return tool_calls
```

### 3. 调试插件

配置插件的声明文件与功能代码后，在插件的目录内运行 `python -m main` 命令重启插件。接下来需测试插件是否可以正常运行。Dify 提供远程调试方式，前往[“插件管理”](https://cloud.dify.ai/plugins)获取调试 Key 和远程服务器地址。

![Image](https://assets-docs.dify.ai/2024/12/053415ef127f1f4d6dd85dd3ae79626a.png)

回到插件项目，拷贝 `.env.example` 文件并重命名为 `.env`，将获取的远程服务器地址和调试 Key 等信息填入至 `REMOTE_INSTALL_HOST` 与 `REMOTE_INSTALL_KEY` 参数内。

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_URL=debug.dify.ai:5003
REMOTE_INSTALL_KEY=********-****-****-****-************
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内。其他团队成员也可以访问该插件。

![访问插件](https://assets-docs.dify.ai/2025/01/c82ec0202e5bf914b36e06c796398dd6.png)

### 打包插件（可选）

确认插件能够正常运行后，可以通过以下命令行工具打包并命名插件。运行以后你可以在当前文件夹发现 `google.difypkg` 文件，该文件为最终的插件包。

```bash
# 将 ./basic_agent 替换为插件项目的实际路径
dify plugin package ./basic_agent/
```

恭喜，你已完成一个工具类型插件的完整开发、调试与打包过程！

### 发布插件（可选）

现在可以将它上传至 [Dify Plugins 代码仓库](https://github.com/langgenius/dify-plugins)来发布你的插件了！上传前，请确保插件已遵循[插件发布规范](https://docs.dify.ai/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace)。审核通过后，代码将合并至主分支并自动上线至 [Dify Marketplace](https://marketplace.dify.ai/)。

### 探索更多

复杂任务往往需要多轮思考和多次工具调用。为了实现更智能的任务处理，通常采用循环执行的策略：**模型调用 → 工具调用**，直到任务完成或达到设定的最大迭代次数。

在这个过程中，提示词（Prompt）管理变得尤为重要。为了高效地组织和动态调整模型输入，建议参考插件内 Function Calling 功能的[完整实现代码](https://github.com/langgenius/dify-official-plugins/blob/main/agent-strategies/cot_agent/strategies/function_calling.py)，了解如何通过标准化的方式来让模型调用外部工具并处理返回结果。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/agent-strategy-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Bundle 插件包
> 来源：`zh-hans/plugins/quick-start/develop-plugins/bundle.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

Bundle 插件包是多个插件的集合。它可以将多个插件打包在一个插件内，以达到批量安装插件的效果，同时提供更强大的服务。

你可以通过 Dify cli 工具将多个插件打包为 Bundle。Bundle 插件包提供三种类型，分别为：

* `Marketplace` 类型。储存了插件的 id 与版本信息。导入时会通过 Dify Marketplace 下载具体的插件包。
* `GitHub` 类型。储存了 GitHub 的仓库地址、 release 版本号和 asset 文件名。导入时 Dify 会访问对应的 GitHub 仓库下载插件包。
* `Package` 类型。插件包会直接被储存在 Bundle 中。它不储存引用源，但可能会造成 Bundle 包体积较大的问题。

### 前置准备

* Dify 插件脚手架工具
* Python 环境，版本号 ≥ 3.10

关于如何准备插件开发的脚手架工具，详细说明请参考[安装插件开发工具](initialize-development-tools)。

### 创建 Bundle 项目

在当前路径下，运行脚手架命令行工具，创建一个新的插件包项目。

```bash
./dify-plugin-darwin-arm64 bundle init
```

如果你已将该二进制文件重命名为了 `dify` 并拷贝到了 `/usr/local/bin` 路径下，可以运行以下命令创建新的插件项目：

```bash
dify bundle init
```

#### 1. 填写插件信息

按照提示配置插件名称、作者信息与插件描述。如果你是团队协作，也可以将作者填写为组织名。

> 名称长度必须为 1-128 个字符，并且只能包含字母、数字、破折号和下划线。

![Bundle basic information](https://assets-docs.dify.ai/2024/12/03a1c4cdc72213f09523eb1b40832279.png)

填写信息后敲击回车，将自动创建 Bundle 插件项目目录。

![](https://assets-docs.dify.ai/2024/12/356d1a8201fac3759bf01ee64e79a52b.png)

#### 2. 添加依赖

* **Marketplace**

执行以下命令：

```bash
dify-plugin bundle append marketplace . --marketplace_pattern=langgenius/openai:0.0.1
```

其中 marketplace\_pattern 为插件在 marketplace 中的引用，格式为 `组织名/插件名:版本号`。

* **Github**

执行以下命令：

```bash
dify-plugin bundle append github . --repo_pattern=langgenius/openai:0.0.1/openai.difypkg
```

其中 repo\_pattern 为插件在 github 中的引用，格式为 `组织名/仓库名:release/附件名`。

* **Package**

执行以下命令：

```bash
dify-plugin bundle append package . --package_path=./openai.difypkg
```

其中 package\_path 为插件包的目录。

### 打包 Bundle 项目

运行以下命令打包 Bundle 插件：

```bash
dify-plugin bundle package ./bundle
```

执行命令后，当前目录下将自动创建 `bundle.difybndl` 文件，该文件即为最后的打包结果。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/bundle.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Extension 插件
> 来源：`zh-hans/plugins/quick-start/develop-plugins/extension-plugin.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

本文将引导你快速开发一个 Extension 类型的插件，以帮助你了解插件开发的基础流程。

### 前置准备

* Dify 插件脚手架工具
* Python 环境，版本号 ≥ 3.12

关于如何准备插件开发的脚手架工具，详细说明请参考[安装插件开发工具](initialize-development-tools)。

### 创建新项目 <a href="#chuang-jian-xin-xiang-mu" id="chuang-jian-xin-xiang-mu"></a>

在当前路径下，运行脚手架命令行工具，创建一个新的 dify 插件项目。

```
./dify-plugin-darwin-arm64 plugin init
```

如果你已将该二进制文件重命名为了 `dify` 并拷贝到了 `/usr/local/bin` 路径下，可以运行以下命令创建新的插件项目：

```bash
dify plugin init
```

### **填写插件信息**

按照提示配置插件名称、作者信息与插件描述。如果你是团队协作，也可以将作者填写为组织名。

> 插件名称长度必须为 1-128 个字符，并且只能包含字母、数字、破折号和下划线。

![Plugins details](https://assets-docs.dify.ai/2024/12/75cfccb11fe31c56c16429b3998f2eb0.png)

填写完成后，在插件开发语言环节中选择 Python。

![Plugins development: Python](https://assets-docs.dify.ai/2024/11/1129101623ac4c091a3f6f75f4103848.png)

### 3. 选择插件类型并初始化项目模板

脚手架工具内的所有模板均已提供完整的代码项目。出于演示说明，本文将以 `Extension` 类型插件模板作为示例。对于已熟悉插件的开发者而言，无需借助模板，可参考[接口文档](../../schema-definition/)指引完成不同类型的插件开发。

![Extension](https://assets-docs.dify.ai/2024/11/ff08f77b928494e10197b456fc4e2d5b.png)

#### 配置插件权限

插件还需要读取 Dify 主平台的权限才能正常连接。需要为该示例插件授予以下权限：

* Tools
* LLMs
* Apps
* 启用持久化存储 Storage，分配默认大小存储
* 允许注册 Endpoint

> 在终端内使用方向键选择权限，使用 “Tab” 按钮授予权限。

勾选所有权限项后，轻点回车完成插件的创建。系统将自动生成插件项目代码。

![Plugins 权限](https://assets-docs.dify.ai/2024/11/5518ca1e425a7135f18f499e55d16bdd.png)

插件的基础文件结构包含以下内容：

```
.
├── GUIDE.md
├── README.md
├── _assets
│   └── icon.svg
├── endpoints
│   ├── your-project.py
│   └── your-project.yaml
├── group
│   └── your-project.yaml
├── main.py
├── manifest.yaml
└── requirements.txt
```

* `GUIDE.md` 一个简短的引导教程，带领你完成插件的编写流程。
* `README.md` 关于当前插件的简介信息，你需要把有关该插件的介绍和使用方法填写至该文件内。
* `_assets` 存储所有与当前插件相关的多媒体文件。
* `endpoints` 按照 cli 中的引导创建的一个 `Extension` 类型插件模板，该目录存放所有 Endpoint 的功能实现代码。
* `group` 指定密钥类型、多语言设置以及 API 定义的文件路径。
* `main.py` 整个项目的入口文件。
* `manifest.yaml` 整个插件的基础配置文件，包含该插件需要什么权限、是什么类型的扩展等配置信息。
* `requirements.txt` 存放 Python 环境的依赖项。

### 开发插件

#### 1. 定义插件的请求入口 Endpoint

编辑 `endpoints/test_plugin.yaml` ，参考以下代码进行修改：

```yaml
path: "/neko"
method: "GET"
extra:
  python:
    source: "endpoints/test_plugin.py"
```

该代码的意图是定义该插件的入口路径为 `/neko`，请求方法为 GET 类型。插件的功能实现代码为 `endpoints/test_plugin.py` 文件。

#### 2. 编写插件功能

插件功能：请求服务，输出一只彩虹猫。

编写插件的功能实现代码 `endpoints/test_plugin.py` 文件，参考以下示例代码：

```python [expandable]
from typing import Mapping
from werkzeug import Request, Response
from flask import Flask, render_template_string
from dify_plugin import Endpoint

app = Flask(__name__)

class NekoEndpoint(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        ascii_art = '''
⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛⬛️⬜️⬜️⬜️⬜️⬜⬜️⬜️️
🟥🟥⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️🟥🟥🟥🟥🟥🟥🟥🟥⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬛🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧⬛️⬜️⬜️⬜️⬜️⬜⬜️️
🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥⬛️🥧🥧🥧💟💟💟💟💟💟💟💟💟💟💟💟💟🥧🥧🥧⬛️⬜️⬜️⬜️⬜⬜️️
🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥⬛️🥧🥧💟💟💟💟💟💟🍓💟💟🍓💟💟💟💟💟🥧🥧⬛️⬜️⬜️⬜️⬜️⬜️️
🟧🟧🟥🟥🟥🟥🟥🟥🟥🟥🟧🟧🟧🟧🟧🟧🟧🟧🟥🟥🟥🟥🟥🟥🟥⬛🥧💟💟🍓💟💟💟💟💟💟💟💟💟💟💟💟💟💟🥧⬛️⬜️⬜️⬜️⬜⬜️️
🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧⬛️🥧💟💟💟💟💟💟💟💟💟💟⬛️⬛️💟💟🍓💟💟🥧⬛️⬜️⬛️️⬛️️⬜⬜️️
🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧⬛️🥧💟💟💟💟💟💟💟💟💟⬛️🌫🌫⬛💟💟💟💟🥧⬛️⬛️🌫🌫⬛⬜️️
🟨🟨🟧🟧🟧🟧🟧🟧🟧🟧🟨🟨🟨🟨🟨🟨🟨🟨🟧⬛️⬛️⬛️⬛️🟧🟧⬛️🥧💟💟💟💟💟💟🍓💟💟⬛️🌫🌫🌫⬛💟💟💟🥧⬛️🌫🌫🌫⬛⬜️️
🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨⬛️🌫🌫⬛️⬛️🟧⬛️🥧💟💟💟💟💟💟💟💟💟⬛️🌫🌫🌫🌫⬛️⬛️⬛️⬛️🌫🌫🌫🌫⬛⬜️️
🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨⬛️⬛️🌫🌫⬛️⬛️⬛️🥧💟💟💟🍓💟💟💟💟💟⬛️🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫⬛⬜️️
🟩🟩🟨🟨🟨🟨🟨🟨🟨🟨🟩🟩🟩🟩🟩🟩🟩🟩🟨🟨⬛⬛️🌫🌫⬛️⬛️🥧💟💟💟💟💟💟💟🍓⬛️🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫⬛️
🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩⬛️⬛️🌫🌫⬛️🥧💟🍓💟💟💟💟💟💟⬛️🌫🌫🌫⬜️⬛️🌫🌫🌫🌫🌫⬜️⬛️🌫🌫⬛️
️🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩⬛️⬛️⬛️⬛️🥧💟💟💟💟💟💟💟💟⬛️🌫🌫🌫⬛️⬛️🌫🌫🌫⬛️🌫⬛️⬛️🌫🌫⬛️
🟦🟦🟩🟩🟩🟩🟩🟩🟩🟩🟦🟦🟦🟦🟦🟦🟦🟦🟩🟩🟩🟩🟩🟩⬛️⬛️🥧💟💟💟💟💟🍓💟💟⬛🌫🟥🟥🌫🌫🌫🌫🌫🌫🌫🌫🌫🟥🟥⬛️
🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦⬛️🥧🥧💟🍓💟💟💟💟💟⬛️🌫🟥🟥🌫⬛️🌫🌫⬛️🌫🌫⬛️🌫🟥🟥⬛️
🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦⬛️🥧🥧🥧💟💟💟💟💟💟💟⬛️🌫🌫🌫⬛️⬛️⬛️⬛️⬛️⬛️⬛️🌫🌫⬛️⬜️
🟪🟪🟦🟦🟦🟦🟦🟦🟦🟦🟪🟪🟪🟪🟪🟪🟪🟪🟦🟦🟦🟦🟦🟦⬛️⬛️⬛️🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧⬛️🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫⬛️⬜️⬜️
🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪⬛️🌫🌫🌫⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬜️⬜️⬜️
🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪⬛️🌫🌫⬛️⬛️⬜️⬛️🌫🌫⬛️⬜️⬜️⬜️⬜️⬜️⬛️🌫🌫⬛️⬜️⬛️🌫🌫⬛️⬜️⬜️⬜️⬜️
⬜️⬜️🟪🟪🟪🟪🟪🟪🟪🟪⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️🟪🟪🟪🟪🟪⬛️⬛️⬛️⬛⬜️⬜️⬛️⬛️⬛️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬛️⬛️⬛️⬜️⬜️⬛️⬛️⬜️⬜️⬜️⬜️⬜️️
        '''
        ascii_art_lines = ascii_art.strip().split('\n')
        with app.app_context():
            return Response(render_template_string('''
    <!DOCTYPE html>
    <html>
    <head>
        <style>
            body 
                background-color: black;
                color: white;
                overflow: hidden;
                margin: 0;
                padding: 0;

            #ascii-art 
                font-family: monospace;
                white-space: pre;
                position: absolute;
                top: 50%;
                transform: translateY(-50%);
                display: inline-block;
                font-size: 16px;
                line-height: 1;

        </style>
    </head>
    <body>
        <div id="ascii-art"></div>
        <script>
            var asciiArtLines = {{ ascii_art_lines | tojson }};
            var asciiArtDiv = document.getElementById("ascii-art");
            var index = 0;
            function displayNextLine() {
                if (index < asciiArtLines.length) {
                    var line = asciiArtLines[index];
                    var lineElement = document.createElement("div");
                    lineElement.innerHTML = line;
                    asciiArtDiv.appendChild(lineElement);
                    index++;
                    setTimeout(displayNextLine, 100);
                } else 
                    animateCat();

            }
            function animateCat() {
                var pos = 0;
                var screenWidth = window.innerWidth;
                var catWidth = asciiArtDiv.offsetWidth;
                function move() {
                    asciiArtDiv.style.left = pos + "px";
                    pos += 2;
                    if (pos > screenWidth) {
                        pos = -catWidth;
                    }
                    requestAnimationFrame(move);
                }
                move();
            }
            displayNextLine();
        </script>
    </body>
    </html>
        ''', ascii_art_lines=ascii_art_lines), status=200, content_type="text/html")
```

运行此代码需要先安装以下 Python 依赖包：

```python
pip install werkzeug
pip install flask
pip install dify-plugin
```

### 调试插件

接下来需测试插件是否可以正常运行。Dify 提供远程调试方式，前往“插件管理”页获取调试 Key 和远程服务器地址。

![](https://assets-docs.dify.ai/2024/11/1cf15bc59ea10eb67513c8bdca557111.png)

回到插件项目，拷贝 `.env.example` 文件并重命名为 `.env`，将获取的远程服务器地址和调试 Key 等信息填入其中。

`.env` 文件

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_HOST=remote-url
REMOTE_INSTALL_PORT=5003
REMOTE_INSTALL_KEY=****-****-****-****-****
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内。其他团队成员也可以访问该插件。

![](https://assets-docs.dify.ai/2024/11/0fe19a8386b1234755395018bc2e0e35.png)

在插件内新增 Endpoint，随意填写名称和 `api_key` 等信息。访问自动生成的 URL，即可看到由插件提供的网页服务。

![](https://assets-docs.dify.ai/2024/11/c76375b8df2449d0d8c31a7c2a337579.png)

### 打包插件

确认插件能够正常运行后，可以通过以下命令行工具打包并命名插件。运行以后你可以在当前文件夹发现 `neko.difypkg` 文件，该文件为最终的插件包。

```bash
dify-plugin package ./neko
```

恭喜，你已完成一个插件的完整开发、测试打包过程！

### 发布插件

现在可以将它上传至 [Dify Plugins 代码仓库](https://github.com/langgenius/dify-plugins) 来发布你的插件了！上传前，请确保你的插件遵循了[插件发布规范](https://docs.dify.ai/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace)。审核通过后，代码将合并至主分支并自动上线至 [Dify Marketplace](https://marketplace.dify.ai/)。

### 探索更多

**快速开始：**

* [Tool 插件：Google Search](tool-plugin)
* [Model 插件](model-plugin/)
* [Bundle 插件：将多个插件打包](bundle)

**插件接口文档：**

* [Manifest](../../schema-definition/manifest) 结构
* [Endpoint](../../schema-definition/endpoint) 详细定义
* [反向调用 Dify 能力](../../schema-definition/reverse-invocation-of-the-dify-service/)
* [工具](../../schema-definition/tool)
* [模型](../../schema-definition/model/)
* [扩展 Agent 策略](../../schema-definition/agent)

**最佳实践：**

[开发 Slack Bot 插件](../../best-practice/develop-a-slack-bot-plugin)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/extension-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 安装插件开发工具
> 来源：`zh-hans/plugins/quick-start/develop-plugins/initialize-development-tools.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

在开始开发 Dify 插件之前，请准备以下先决条件：

* [Dify 插件 CLI 工具](https://github.com/langgenius/dify-plugin-daemon?tab=readme-ov-file#cli)
* [Python 3.12+](https://docs.python.org/3.12/using/index.html)

## **1. 安装 Dify 插件 CLI 工具**

Dify 插件 CLI 工具可以通过 Homebrew（在 Linux 和 macOS 上）或独立的二进制可执行文件（在 Windows、Linux 和 macOS 上）进行安装。

### 通过 Homebrew 安装

对于 macOS 和 Linux 用户，建议使用 [Homebrew](https://brew.sh/) 安装 Dify 插件 CLI。

首先添加 [Dify 插件 CLI 工具的 Homebrew 配方](https://github.com/langgenius/homebrew-dify)，然后使用 `brew install` 命令进行安装。

```bash
brew tap langgenius/dify
brew install dify
```

要检查安装是否成功，请运行 `dify version`，应该会显示版本代码。
```bash
dify version
```

要升级 Dify 插件 CLI 工具，请运行以下命令：

```bash
brew upgrade dify
```

### 通过二进制可执行文件安装

**下载二进制可执行文件：**

在 [Dify 插件 CLI 工具](https://github.com/langgenius/dify-plugin-daemon/releases) 的发布页面的资产列表中，选择并下载适合操作系统（Linux / macOS / Windows）和芯片架构（`amd64` 为 x86 芯片 / `arm64` 为 ARM 或 Apple 的 M 芯片）的二进制可执行文件。

以 **macOS M 芯片** 为例。下载 `dify-plugin-darwin-arm64` 文件，并通过以下命令授予其执行权限：
```bash
chmod +x ./dify-plugin-darwin-arm64
mv ./dify-plugin-darwin-arm64 ./dify
```

要检查安装是否成功，请运行 `./dify version`，应该会显示版本代码。
```bash
./dify version
```

> 如果系统显示“Apple 无法验证”的错误，请前往 **设置 → 隐私与安全 → 安全性**，点击“仍要打开”按钮。

> **信息提示：**

    **提示：**
    为了在系统范围内全局使用 `dify` 命令，建议将二进制文件重命名为 `dify` 并复制到 `/usr/local/bin` 系统路径中。

## 2. **开发插件**

请参考以下内容以获得不同类型插件开发的示例。

  工具插件

  模型插件

  Agent策略插件

  扩展插件

  打包插件

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/initialize-development-tools.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Model 插件
> 来源：`zh-hans/plugins/quick-start/develop-plugins/model-plugin/README.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

Model 模型插件使 Dify 平台能够调用该模型供应商下的所有 LLM。例如，安装 OpenAI 模型插件后，Dify 平台即可调用 OpenAI 提供的 `GPT-4`、`GPT-4o-2024-05-13` 等模型。

### 模型插件结构

为了便于理解在开发模型插件过程中可能涉及的概念，以下是模型插件内的结构简介：

* **模型供应商**：大模型的开发公司，例如 **OpenAI、Anthropic、Google** 等；
* **模型分类**：根据模型供应商的不同，存在大语言模型（LLM）、文本嵌入模型（Text embedding）、语音转文字（Speech2text）等分类；
* **具体模型**：`claude-3-5-sonnet`、`gpt-4-turbo` 等。

插件项目中的代码层级结构：

```bash
- 模型供应商
    - 模型分类
        - 具体模型
```

以 **Anthropic** 为例，模型插件的示例结构如下：

```bash
- Anthropic
    - llm
        claude-3-5-sonnet-20240620 
        claude-3-haiku-20240307
        claude-3-opus-20240229 
        claude-3-sonnet-20240229 
        claude-instant-1.2 
        claude-instant-1
```

以 OpenAI 为例，因为它支持多种模型类型，所以存在多层模型分类，结构如下：

```bash
├── models
│   ├── llm
│   │   ├── chatgpt-4o-latest
│   │   ├── gpt-3.5-turbo
│   │   ├── gpt-4-0125-preview
│   │   ├── gpt-4-turbo
│   │   ├── gpt-4o
│   │   ├── llm
│   │   ├── o1-preview
│   │   └── text-davinci-003
│   ├── moderation
│   │   ├── moderation
│   │   └── text-moderation-stable
│   ├── speech2text
│   │   ├── speech2text
│   │   └── whisper-1
│   ├── text_embedding
│   │   ├── text-embedding-3-large
│   │   └── text_embedding
│   └── tts
│       ├── tts-1-hd
│       ├── tts-1
│       └── tts
```

### 开始开发模型插件

请参考以下顺序阅读文档，了解如何开发一个模型插件。

1. [创建模型供应商](./zh-hans/plugins/quick-start/develop-plugins/model-plugin/create-model-providers)
2. 接入[预定义](./zh-hans/guides/model-configuration/predefined-model) / [自定义](./zh-hans/plugins/quick-start/develop-plugins/model-plugin/customizable-model)模型
3. [调试插件](./zh-hans/plugins/quick-start/debug-plugin)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/model-plugin/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 创建模型供应商
> 来源：`zh-hans/plugins/quick-start/develop-plugins/model-plugin/create-model-providers.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

创建 Model 类型插件的第一步是初始化插件项目并创建模型供应商文件，随后编写具体的预定义 / 自定义模型代码。

### 前置准备 <a href="#qian-zhi-zhun-bei" id="qian-zhi-zhun-bei"></a>

* Dify 插件脚手架工具
* Python 环境，版本号 ≥ 3.12

关于如何准备插件开发的脚手架工具，详细说明请参考[安装插件开发工具](../initialize-development-tools)。

### 创建新项目 <a href="#chuang-jian-xin-xiang-mu" id="chuang-jian-xin-xiang-mu"></a>

在脚手架命令行工具的路径下，创建一个新的 dify 插件项目。

```
./dify-plugin-darwin-arm64 plugin init
```

如果你已将该二进制文件重命名为了 `dify` 并拷贝到了 `/usr/local/bin` 路径下，可以运行以下命令创建新的插件项目：

```bash
dify plugin init
```

### 选择模型插件模板 <a href="#xuan-ze-cha-jian-lei-xing-he-mu-ban" id="xuan-ze-cha-jian-lei-xing-he-mu-ban"></a>

脚手架工具内的所有模板均已提供完整的代码项目，选择 `LLM` 类型插件模板。

![Plugin type: llm](https://assets-docs.dify.ai/2024/12/8efe646e9174164b9edbf658b5934b86.png)

#### 配置插件权限

为该 LLM 插件配置以下权限：

* Models
* LLM
* Storage

![模型插件权限](https://assets-docs.dify.ai/2024/12/10f3b3ee6c03a1215309f13d712455d4.png)

#### 模型类型配置说明

模型供应商支持以下两种模型的配置方式：

*   `predefined-model` **预定义模型**

    常见的大模型类型，只需要配置统一的供应商凭据即可使用模型供应商下的预定义模型。例如，`OpenAI` 模型供应商下提供 `gpt-3.5-turbo-0125` 和 `gpt-4o-2024-05-13` 等一系列预定义模型。详细开发说明请参考接入预定义模型。
*   `customizable-model` **自定义模型**

    需要手动新增每个模型的凭据配置，例如 `Xinference`，它同时支持 LLM 和 Text Embedding，但是每个模型都有唯一的 **model\_uid**，如果想要将两者同时接入，需要为每个模型配置一个 **model\_uid**。详细开发说明请参考接入自定义模型。

两种配置方式**支持共存**，即存在供应商支持 `predefined-model` + `customizable-model` 或 `predefined-model` 等，即配置了供应商统一凭据可以使用预定义模型和从远程获取的模型，若新增了模型，则可以在此基础上额外使用自定义的模型。

### 新增模型供应商

新增一个模型供应商主要包含以下几个步骤：

1.  **创建模型供应商配置 YAML** **文件**

    在供应商目录下新增一个 YAML 文件，用于描述供应商的基本信息和参数配置。按照 ProviderSchema 的要求编写内容，确保与系统的规范保持一致。
2.  **编写模型供应商代码**

    创建供应商 class 代码，实现一个符合系统接口要求的 Python class 用于对接供应商的 API，完成核心功能实现。

***

以下是每个步骤的完整操作详情。

#### 1. **创建模型供应商配置文件**

Manifest 是 YAML 格式文件，声明了模型供应商基础信息、所支持的模型类型、配置方式、凭据规则。插件项目模板将在 `/providers` 路径下自动生成配置文件。

以下是 `Anthropic` 模型配置文件 `anthropic.yaml` 的示例代码：

```yaml
provider: anthropic
label:
  en_US: Anthropic
description:
  en_US: Anthropic's powerful models, such as Claude 3.
  zh_Hans: Anthropic 的强大模型，例如 Claude 3。
icon_small:
  en_US: icon_s_en.svg
icon_large:
  en_US: icon_l_en.svg
background: "#F0F0EB"
help:
  title:
    en_US: Get your API Key from Anthropic
    zh_Hans: 从 Anthropic 获取 API Key
  url:
    en_US: https://console.anthropic.com/account/keys
supported_model_types:
  - llm
configurate_methods:
  - predefined-model
provider_credential_schema:
  credential_form_schemas:
    - variable: anthropic_api_key
      label:
        en_US: API Key
      type: secret-input
      required: true
      placeholder:
        zh_Hans: 在此输入您的 API Key
        en_US: Enter your API Key
    - variable: anthropic_api_url
      label:
        en_US: API URL
      type: text-input
      required: false
      placeholder:
        zh_Hans: 在此输入您的 API URL
        en_US: Enter your API URL
models:
  llm:
    predefined:
      - "models/llm/*.yaml"
    position: "models/llm/_position.yaml"
extra:
  python:
    provider_source: provider/anthropic.py
    model_sources:
      - "models/llm/llm.py"
```

如果接入的供应商提供自定义模型，比如`OpenAI`提供微调模型，需要添加`model_credential_schema` 字段。

以下是 `OpenAI` 家族模型的示例代码：

```yaml
model_credential_schema:
  model: # 微调模型名称
    label:
      en_US: Model Name
      zh_Hans: 模型名称
    placeholder:
      en_US: Enter your model name
      zh_Hans: 输入模型名称
  credential_form_schemas:
  - variable: openai_api_key
    label:
      en_US: API Key
    type: secret-input
    required: true
    placeholder:
      zh_Hans: 在此输入您的 API Key
      en_US: Enter your API Key
  - variable: openai_organization
    label:
        zh_Hans: 组织 ID
        en_US: Organization
    type: text-input
    required: false
    placeholder:
      zh_Hans: 在此输入您的组织 ID
      en_US: Enter your Organization ID
  - variable: openai_api_base
    label:
      zh_Hans: API Base
      en_US: API Base
    type: text-input
    required: false
    placeholder:
      zh_Hans: 在此输入您的 API Base
      en_US: Enter your API Base
```

如需查看更多完整的模型供应商 YAML 规范，详情请参考[模型接口文档](../../../schema-definition/model/model-schema)。

#### 2. **编写模型供应商代码**

在 `/providers` 文件夹下创建一个同名的 python 文件，例如 `anthropic.py` 并实现一个 `class` ，继承 `__base.provider.Provider` 基类，例如 `AnthropicProvider`。

以下是 `Anthropic` 示例代码：

```python

from dify_plugin.entities.model import ModelType
from dify_plugin.errors.model import CredentialsValidateFailedError
from dify_plugin import ModelProvider

logger = logging.getLogger(__name__)

class AnthropicProvider(ModelProvider):
    def validate_provider_credentials(self, credentials: dict) -> None:
        """
        Validate provider credentials

        if validate failed, raise exception

        :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
        """
        try:
            model_instance = self.get_model_instance(ModelType.LLM)
            model_instance.validate_credentials(model="claude-3-opus-20240229", credentials=credentials)
        except CredentialsValidateFailedError as ex:
            raise ex
        except Exception as ex:
            logger.exception(f"self.get_provider_schema().provider credentials validate failed")
            raise ex
```

供应商需要继承 `__base.model_provider.ModelProvider` 基类，实现 `validate_provider_credentials` 供应商统一凭据校验方法即可。

```python
def validate_provider_credentials(self, credentials: dict) -> None:
    """
    Validate provider credentials
    You can choose any validate_credentials method of model type or implement validate method by yourself,
    such as: get model list api

    if validate failed, raise exception

    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
    """
```

当然也可以先预留 `validate_provider_credentials` 实现，在模型凭据校验方法实现后直接复用。

#### **自定义模型供应商**

对于其它类型模型供应商而言，请参考以下配置方法。

对于像 `Xinference` 这样的自定义模型供应商，可以跳过完整实现的步骤。只需创建一个名为 `XinferenceProvider` 的空类，并在其中实现一个空的 `validate_provider_credentials` 方法。

**具体说明：**

• `XinferenceProvider` 是一个占位类，用于标识自定义模型供应商。

• `validate_provider_credentials` 方法虽然不会被实际调用，但必须存在，这是因为其父类是抽象类，要求所有子类都实现这个方法。通过提供一个空实现，可以避免因未实现抽象方法而导致的实例化错误。

```python
class XinferenceProvider(Provider):
    def validate_provider_credentials(self, credentials: dict) -> None:
        pass
```

初始化模型供应商后，接下来需要接入供应商所提供的具体 llm 模型。详细说明请参考以下内容：

* [接入预定义模型](../../../../guides/model-configuration/predefined-model)
* [接入自定义模型](../../../../guides/model-configuration/customizable-model)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/model-plugin/create-model-providers.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入自定义模型
> 来源：`zh-hans/plugins/quick-start/develop-plugins/model-plugin/customizable-model.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

自定义模型指的是需要自行部署或配置的 LLM。本文将以 [Xinference 模型](https://inference.readthedocs.io/en/latest/)为例，演示如何在模型插件内接入自定义模型。

自定义模型默认包含模型类型和模型名称两个参数，无需在供应商 yaml 文件定义。

供应商配置文件无需实现 `validate_provider_credential`。Runtime 会根据用户选择的模型类型或模型名称，自动调用对应模型层的 `validate_credentials` 方法进行验证。

### 接入自定义模型插件

接入自定义模型分为以下步骤：

1.  **创建模型供应商文件**

    明确自定义模型中所包含的模型类型。
2.  **根据模型类型创建代码文件**

    根据模型的类型（如 `llm` 或 `text_embedding`）创建代码文件。确保每种模型类型有独立的逻辑分层，便于维护和扩展。
3.  **根据不同的模型模块，编写模型调用代码**

    在对应的模型类型模块下，创建一个与模型类型同名的 Python 文件（例如 llm.py）。在文件中定义实现具体模型逻辑的类，该类应符合系统的模型接口规范。
4.  **调试插件**

    为新增的供应商功能编写单元测试和集成测试，确保所有功能模块符合预期，并能够正常运行。

***

### 1. **创建模型供应商文件**

在插件项目的 `/provider` 路径下，新建 `xinference.yaml` 文件。

`Xinference` 家族模型支持 `LLM``，Text Embedding` 和 `Rerank` 模型类型，因此需要在 `xinference.yaml` 文件中包含上述模型类型。

示例代码：

```yaml 14-17
provider: xinference # 确定供应商标识
label: # 供应商展示名称，可设置 en_US 英文、zh_Hans 中文两种语言，zh_Hans 不设置将默认使用 en_US。
  en_US: Xorbits Inference
icon_small: # 小图标，可以参考其他供应商的图标，存储在对应供应商实现目录下的 _assets 目录，中英文策略同 label
  en_US: icon_s_en.svg
icon_large: # 大图标
  en_US: icon_l_en.svg
help: # 帮助
  title:
    en_US: How to deploy Xinference
    zh_Hans: 如何部署 Xinference
  url:
    en_US: https://github.com/xorbitsai/inference
supported_model_types: # 支持的模型类型，Xinference 同时支持 LLM/Text Embedding/Rerank
- llm
- text-embedding
- rerank
configurate_methods: # Xinference 为本地部署的供应商，并且没有预定义模型，需要用什么模型需要根据 Xinference 的文档进行部署，因此此处的方法为自定义模型。
- customizable-model
provider_credential_schema:
  credential_form_schemas:
```

接着需要定义 `provider_credential_schema` 字段。`Xinference 支持` text-generation，embeddings 和 reranking 模型，示例代码如下：

```yaml 10,14,17
provider_credential_schema:
  credential_form_schemas:
  - variable: model_type
    type: select
    label:
      en_US: Model type
      zh_Hans: 模型类型
    required: true
    options:
    - value: text-generation
      label:
        en_US: Language Model
        zh_Hans: 语言模型
    - value: embeddings
      label:
        en_US: Text Embedding
    - value: reranking
      label:
        en_US: Rerank
```

Xinference 中的每个模型都需要定义名称 `model_name`。

```yaml
  - variable: model_name
    type: text-input
    label:
      en_US: Model name
      zh_Hans: 模型名称
    required: true
    placeholder:
      zh_Hans: 填写模型名称
      en_US: Input model name
```

Xinference 模型需要使用者输入模型的本地部署地址，插件内需要提供允许填写 Xinference 模型的本地部署地址（server\_url）和模型 UID 的位置，示例代码如下：

```yaml 1,10
  - variable: server_url
    label:
      zh_Hans: 服务器 URL
      en_US: Server url
    type: text-input
    required: true
    placeholder:
      zh_Hans: 在此输入 Xinference 的服务器地址，如 https://example.com/xxx
      en_US: Enter the url of your Xinference, for example https://example.com/xxx
  - variable: model_uid
    label:
      zh_Hans: 模型 UID
      en_US: Model uid
    type: text-input
    required: true
    placeholder:
      zh_Hans: 在此输入您的 Model UID
      en_US: Enter the model uid
```

填写所有参数后即可完成自定义模型供应商 yaml 配置文件的创建。接下来需为配置文件内定义的模型添加具体的功能代码文件。

### 2. 编写模型代码

Xinference 模型供应商的模型类型包含 llm、rerank、speech2text、tts 类型，因此需要在 /models 路径下为每个模型类型创建独立的分组，并创建对应的功能代码文件。

下文将以 llm 类型为例，说明如何创建 `llm.py` 代码文件。创建代码时需创建一个 Xinference LLM 类，可以取名为 `XinferenceAILargeLanguageModel`，继承 `__base.large_language_model.LargeLanguageModel` 基类，实现以下几个方法：

* **LLM 调用**

LLM 调用的核心方法，同时支持流式和同步返回。

```python
def _invoke(self, model: str, credentials: dict,
            prompt_messages: list[PromptMessage], model_parameters: dict,
            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,
            stream: bool = True, user: Optional[str] = None) \
        -> Union[LLMResult, Generator]:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param model_parameters: model parameters
    :param tools: tools for tool calling
    :param stop: stop words
    :param stream: is stream response
    :param user: unique user id
    :return: full response or stream response chunk generator result
    """
```

实现代码时，需要注意使用两个函数来返回数据，分别用于处理同步返回和流式返回。

Python 会将函数中包含 `yield` 的关键字函数识别为生成器函数，返回的数据类型固定为 `Generator`，因此需要分别实现同步和流式返回，例如以下示例代码：

> 该示例使用了简化参数，实际编写代码时需参考上文中的参数列表。

```python
def _invoke(self, stream: bool, **kwargs) \
        -> Union[LLMResult, Generator]:
    if stream:
          return self._handle_stream_response(**kwargs)
    return self._handle_sync_response(**kwargs)

def _handle_stream_response(self, **kwargs) -> Generator:
    for chunk in response:
          yield chunk
def _handle_sync_response(self, **kwargs) -> LLMResult:
    return LLMResult(**response)
```

* **预计算输入 Tokens**

如果模型未提供预计算 tokens 的接口，可以直接返回 0。

```python
def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                 tools: Optional[list[PromptMessageTool]] = None) -> int:
  """
  Get number of tokens for given prompt messages

  :param model: model name
  :param credentials: model credentials
  :param prompt_messages: prompt messages
  :param tools: tools for tool calling
  :return:
  """
```

在某些情况下，如果不想直接返回 0，可以使用 `self._get_num_tokens_by_gpt2(text: str)` 方法计算 tokens。该方法位于 `AIModel` 基类中，使用 GPT-2 的 Tokenizer 进行计算。但请注意，这是一个替代方案，计算结果可能存在一定误差。

* **模型凭据校验**

与供应商凭据校验类似，这里针对单个模型进行校验。

```python
def validate_credentials(self, model: str, credentials: dict) -> None:
    """
    Validate model credentials

    :param model: model name
    :param credentials: model credentials
    :return:
    """
```

* **模型参数 Schema**

与[预定义模型类型](./zh-hans/plugins/quick-start/develop-plugins/model-plugin/integrate-the-predefined-model)不同，由于未在 YAML 文件中预设模型所支持的参数，因此需要动态生成模型参数的 Schema。

例如，Xinference 支持 `max_tokens`、`temperature` 和 `top_p` 三种模型参数。然而一些供应商（例如 OpenLLM）会根据具体模型支持不同的参数。

举例来说，供应商 `OpenLLM` 的 A 模型支持 `top_k` 参数，而 B 模型则不支持 `top_k`。在该情况下，需要动态生成每个模型对应的参数 Schema，示例代码如下：

```python
  def get_customizable_model_schema(self, model: str, credentials: dict) -> AIModelEntity | None:
      """
          used to define customizable model schema
      """
      rules = [
          ParameterRule(
              name='temperature', type=ParameterType.FLOAT,
              use_template='temperature',
              label=I18nObject(
                  zh_Hans='温度', en_US='Temperature'
              )
          ),
          ParameterRule(
              name='top_p', type=ParameterType.FLOAT,
              use_template='top_p',
              label=I18nObject(
                  zh_Hans='Top P', en_US='Top P'
              )
          ),
          ParameterRule(
              name='max_tokens', type=ParameterType.INT,
              use_template='max_tokens',
              min=1,
              default=512,
              label=I18nObject(
                  zh_Hans='最大生成长度', en_US='Max Tokens'
              )
          )
      ]

      # if model is A, add top_k to rules
      if model == 'A':
          rules.append(
              ParameterRule(
                  name='top_k', type=ParameterType.INT,
                  use_template='top_k',
                  min=1,
                  default=50,
                  label=I18nObject(
                      zh_Hans='Top K', en_US='Top K'
                  )
              )
          )

      """
          some NOT IMPORTANT code here
      """

      entity = AIModelEntity(
          model=model,
          label=I18nObject(
              en_US=model
          ),
          fetch_from=FetchFrom.CUSTOMIZABLE_MODEL,
          model_type=model_type,
          model_properties=
              ModelPropertyKey.MODE:  ModelType.LLM,
          ,
          parameter_rules=rules
      )

      return entity
```

* **调用异常错误映射表**

当模型调用异常时需要映射到 Runtime 指定的 `InvokeError` 类型，方便 Dify 针对不同错误做不同后续处理。

Runtime Errors:

* `InvokeConnectionError` 调用连接错误
* `InvokeServerUnavailableError` 调用服务方不可用
* `InvokeRateLimitError` 调用达到限额
* `InvokeAuthorizationError` 调用鉴权失败
* `InvokeBadRequestError` 调用传参有误

```python
@property
def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
    """
    Map model invoke error to unified error
    The key is the error type thrown to the caller
    The value is the error type thrown by the model,
    which needs to be converted into a unified error type for the caller.

    :return: Invoke error mapping
    """
```

如需了解更多接口方法，请参考[接口文档：Model](./zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/model)。

如需获取本文所涉及的完整代码文件，请访问 [GitHub 代码仓库](https://github.com/langgenius/dify-official-plugins/tree/main/models/xinference)。

### 3. 调试插件

插件开发完成后，接下来需测试插件是否可以正常运行。详细说明请参考：

  debug-plugins.md

### 4. 发布插件

如果想要将插件发布至 Dify Marketplace，请参考以下内容：

  publish-to-dify-marketplace

### **探索更多**

**快速开始：**

* [开发 Extension 插件](./zh-hans/plugins/quick-start/develop-plugins/extension-plugin)
* [开发 Tool 插件](./zh-hans/plugins/quick-start/develop-plugins/tool-plugin)
* [Bundle 插件：将多个插件打包](./zh-hans/plugins/quick-start/develop-plugins/bundle)

**插件接口文档：**

* [Manifest](./zh-hans/plugins/schema-definition/manifest) 结构
* [Endpoint](./zh-hans/plugins/schema-definition/endpoint) 详细定义
* [反向调用 Dify 能力](./zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/app)
* [工具](./zh-hans/plugins/schema-definition/tool)
* [模型](./zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/model)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/model-plugin/customizable-model.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接入预定义模型
> 来源：`zh-hans/plugins/quick-start/develop-plugins/model-plugin/integrate-the-predefined-model.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

请确保你已创建[模型供应商](create-model-providers)，接入预定义模型大致分为以下步骤：

1.  **按模型类型创建不同的模块结构**

    根据模型的类型（如 `llm` 或 `text_embedding`），在供应商模块下创建相应的子模块。确保每种模型类型有独立的逻辑分层，便于维护和扩展。
2.  **编写模型调用代码**

    在对应的模型类型模块下，创建一个与模型类型同名的 Python 文件（例如 llm.py）。在文件中定义实现具体模型逻辑的类，该类应符合系统的模型接口规范。
3.  **添加预定义模型配置**

    如果供应商提供了预定义模型，为每个模型创建与模型名称同名的 `YAML` 文件（例如 `claude-3.5.yaml`）。按照 [AIModelEntity](../../../schema-definition/model/model-designing-rules#aimodelentity) 的规范编写文件内容，描述模型的参数和功能。
4.  **测试插件**

    为新增的供应商功能编写单元测试和集成测试，确保所有功能模块符合预期，并能够正常运行。

***

以下是接入详情：

### **1. 按模型类型创建不同的模块结构**

模型供应商下可能提供了不同的模型类型，例如 Openai 提供了 `llm` 或 `text_embedding` 等模型类型。需在供应商模块下创建相应的子模块，确保每种模型类型有独立的逻辑分层，便于维护和扩展。

当前支持模型类型如下：

* `llm` 文本生成模型
* `text_embedding` 文本 `Embedding` 模型
* `rerank` Rerank 模型
* `speech2text` 语音转文字
* `tts` 文字转语音
* `moderation` 审查

以 `Anthropic` 为例，系列模型内仅包含 LLM 类型模型，因此仅需在 `/models` 路径下新建 `/llm` 文件夹，并新增不同型号模型的 yaml 文件。详细代码结构请参考 [GitHub 代码仓库](https://github.com/langgenius/dify-official-plugins/tree/main/models/anthropic/models/llm)。

![](https://assets-docs.dify.ai/2024/12/b5ef5d7c759742e4c4d34865e8608843.png)

```bash
├── models
│   └── llm
│       ├── _position.yaml
│       ├── claude-2.1.yaml
│       ├── claude-2.yaml
│       ├── claude-3-5-sonnet-20240620.yaml
│       ├── claude-3-haiku-20240307.yaml
│       ├── claude-3-opus-20240229.yaml
│       ├── claude-3-sonnet-20240229.yaml
│       ├── claude-instant-1.2.yaml
│       ├── claude-instant-1.yaml
│       └── llm.py
```

若模型供应商内包含多种类型的大模型，例如 `OpenAI` 家族模型下包含 `llm` 和 `text_embedding` ，`moderation`，`speech2text`，`tts` 类模型，则需要在 `/models` 路径下为每种类型创建对应的文件夹。结构如下：

```bash
├── models
│   ├── common_openai.py
│   ├── llm
│   │   ├── _position.yaml
│   │   ├── chatgpt-4o-latest.yaml
│   │   ├── gpt-3.5-turbo.yaml
│   │   ├── gpt-4-0125-preview.yaml
│   │   ├── gpt-4-turbo.yaml
│   │   ├── gpt-4o.yaml
│   │   ├── llm.py
│   │   ├── o1-preview.yaml
│   │   └── text-davinci-003.yaml
│   ├── moderation
│   │   ├── moderation.py
│   │   └── text-moderation-stable.yaml
│   ├── speech2text
│   │   ├── speech2text.py
│   │   └── whisper-1.yaml
│   ├── text_embedding
│   │   ├── text-embedding-3-large.yaml
│   │   └── text_embedding.py
│   └── tts
│       ├── tts-1-hd.yaml
│       ├── tts-1.yaml
│       └── tts.py
```

建议将所有模型配置都准备完毕后再开始模型代码的实现，完整的 YAML 规则请参考[模型设计规则](../../../schema-definition/model/model-designing-rules)。如需查看更多代码详情，请参考示例 [GitHub 代码仓库](https://github.com/langgenius/dify-official-plugins/tree/main/models)。

### 2. **编写模型调用代码**

接下来需要在 `/models` 路径下创建 `llm.py` 代码文件。以 `Anthropic` 为例，在 `llm.py` 中创建一个 Anthropic LLM 类并取名为 `AnthropicLargeLanguageModel`，继承 `__base.large_language_model.LargeLanguageModel` 基类。

以下是部分功能的示例代码：

*   **LLM 调用**

    请求 LLM 的核心方法，同时支持流式和同步返回。

```python
def _invoke(self, model: str, credentials: dict,
            prompt_messages: list[PromptMessage], model_parameters: dict,
            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,
            stream: bool = True, user: Optional[str] = None) \
        -> Union[LLMResult, Generator]:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param model_parameters: model parameters
    :param tools: tools for tool calling
    :param stop: stop words
    :param stream: is stream response
    :param user: unique user id
    :return: full response or stream response chunk generator result
    """
```

在实现时，需要注意使用两个函数来分别处理同步返回和流式返回。这是因为 Python 中含有 `yield` 关键字的函数会被识别为生成器函数，其返回类型固定为 `Generator`。为了保证逻辑清晰并适应不同返回需求，同步返回和流式返回需要独立实现。

以下是示例代码（示例中参数进行了简化，实际实现时请根据完整参数列表编写）：

```python
def _invoke(self, stream: bool, **kwargs) -> Union[LLMResult, Generator]:
    """根据返回类型调用对应的处理函数。"""
    if stream:
        return self._handle_stream_response(**kwargs)
    return self._handle_sync_response(**kwargs)

def _handle_stream_response(self, **kwargs) -> Generator:
    """处理流式返回逻辑。"""
    for chunk in response:  # 假设 response 是流式数据迭代器
        yield chunk

def _handle_sync_response(self, **kwargs) -> LLMResult:
    """处理同步返回逻辑。"""
    return LLMResult(**response)  # 假设 response 是完整的响应字典
```

* **预计算输入 tokens 数**

如果模型未提供预计算 tokens 的接口，可以直接返回 0，用于表明该功能不适用或未实现。例如：

```python
def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                   tools: Optional[list[PromptMessageTool]] = None) -> int:
    """
    Get number of tokens for given prompt messages

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param tools: tools for tool calling
    :return:
    """
```

* **调用异常错误映射表**

当模型调用异常时需要映射到 Runtime 指定的 `InvokeError` 类型，方便 Dify 针对不同错误做不同后续处理。

Runtime Errors:

* `InvokeConnectionError` 调用连接错误
* `InvokeServerUnavailableError` 调用服务方不可用
* `InvokeRateLimitError` 调用达到限额
* `InvokeAuthorizationError` 调用鉴权失败
* `InvokeBadRequestError` 调用传参有误

```python
@property
def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
    """
    Map model invoke error to unified error
    The key is the error type thrown to the caller
    The value is the error type thrown by the model,
    which needs to be converted into a unified error type for the caller.

    :return: Invoke error mapping
    """
```

完整代码详情请参考 [GitHub 代码仓库](https://github.com/langgenius/dify-official-plugins/blob/main/models/anthropic/models/llm/llm.py)。

### **3. 添加预定义模型配置**

如果供应商提供了预定义模型，为每个模型创建与模型名称同名的 `YAML` 文件（例`如 claude-3.5.yaml`）。按照 [AIModelEntity](../../../schema-definition/model/model-designing-rules#aimodelentity) 的规范编写文件内容，描述模型的参数和功能。

`claude-3-5-sonnet-20240620` 模型示例代码：

```yaml
model: claude-3-5-sonnet-20240620
label:
  en_US: claude-3-5-sonnet-20240620
model_type: llm
features:
  - agent-thought
  - vision
  - tool-call
  - stream-tool-call
  - document
model_properties:
  mode: chat
  context_size: 200000
parameter_rules:
  - name: temperature
    use_template: temperature
  - name: top_p
    use_template: top_p
  - name: top_k
    label:
      zh_Hans: 取样数量
      en_US: Top k
    type: int
    help:
      zh_Hans: 仅从每个后续标记的前 K 个选项中采样。
      en_US: Only sample from the top K options for each subsequent token.
    required: false
  - name: max_tokens
    use_template: max_tokens
    required: true
    default: 8192
    min: 1
    max: 8192
  - name: response_format
    use_template: response_format
pricing:
  input: '3.00'
  output: '15.00'
  unit: '0.000001'
  currency: USD
```

### 4. 调试插件

接下来需测试插件是否可以正常运行。Dify 提供远程调试方式，前往“插件管理”页获取调试 Key 和远程服务器地址。

![](https://assets-docs.dify.ai/2024/11/1cf15bc59ea10eb67513c8bdca557111.png)

回到插件项目，拷贝 `.env.example` 文件并重命名为 `.env`，将获取的远程服务器地址和调试 Key 等信息填入其中。

`.env` 文件

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_HOST=remote-url
REMOTE_INSTALL_PORT=5003
REMOTE_INSTALL_KEY=****-****-****-****-****
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内。其他团队成员也可以访问该插件。

![](https://assets-docs.dify.ai/2024/12/e11acb42ccb23c824f400b7e19fb2952.png)

你可以在“设置” → “模型供应商”输入 API Key 以初始化该模型供应商。

![](https://assets-docs.dify.ai/2024/12/662de537d70a3607c240a05294a9f3e1.png)

### 发布插件

现在可以将它上传至 [Dify Plugins 代码仓库](https://github.com/langgenius/dify-plugins) 来发布你的插件了！上传前，请确保你的插件遵循了[插件发布规范](https://docs.dify.ai/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace)。审核通过后，代码将合并至主分支并自动上线至 [Dify Marketplace](https://marketplace.dify.ai/)。

### 探索更多

**快速开始：**

* [开发 Extension 类型插件](../extension-plugin)
* [开发 Model 类型插件](./)
* [Bundle 类型插件：将多个插件打包](../bundle)

**插件接口文档：**

* [Manifest](../../../schema-definition/manifest) 结构
* [Endpoint](../../../schema-definition/endpoint) 详细定义
* [反向调用 Dify 能力](../../../schema-definition/reverse-invocation-of-the-dify-service/)
* [工具](../../../schema-definition/tool)
* [模型](../../../schema-definition/model/)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/model-plugin/integrate-the-predefined-model.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Tool 插件
> 来源：`zh-hans/plugins/quick-start/develop-plugins/tool-cha-jian.mdx`

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/tool-cha-jian.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 为工具插件添加 OAuth 支持
> 来源：`zh-hans/plugins/quick-start/develop-plugins/tool-oauth.mdx`

![b0e673ba3e339b31ac36dc3cd004df04787bcaa64bb6d2cac6feb7152b7b515f.png](./images/b0e673ba3e339b31ac36dc3cd004df04787bcaa64bb6d2cac6feb7152b7b515f.png)

本文档介绍如何为你的工具插件添加 [OAuth](https://oauth.net/2/) 支持。

对于需要通过第三方服务（如 Gmail 或 GitHub）访问用户数据的工具插件而言，OAuth 是一种更好的授权方式：在获得用户明确同意的情况下，允许工具插件代表用户执行操作，而无需用户手动输入 API 密钥。

## 介绍

Dify 的 OAuth 配置涉及两个独立流程，开发者应当充分理解并根据流程进行设计。

### 流程一：OAuth 客户端设置（由管理员 / 开发者完成）

  在 Dify Cloud 上，Dify 团队会为热门工具插件创建 OAuth 应用并设置 OAuth 客户端，为用户节省自行配置的麻烦。

  而对于自托管的 Dify 实例，管理员需自行完成此设置流程。

首先，Dify 实例的管理员或开发者需要在第三方服务中将 OAuth 应用注册为受信任应用，以获得将 Dify 工具供应商配置为 OAuth 客户端所需的必要凭证。

下面以 Dify 的 Gmail 工具供应商为例。

    1. 前往 [Google Cloud Console](https://console.cloud.google.com) ，创建新项目或选择现有项目。
    2. 启用所需的 API（如 Gmail API）。

    1. 前往 **API 和服务** \> **OAuth 权限请求页面**。
    2. 对于公开插件，选择 **外部** 受众群体类型。
    3. 填写应用名称、用户支持邮箱和开发者联系方式。
    4. （可选）添加授权域名。
    5. 选择 **目标对象** \> **测试用户**，添加测试用户以进行测试。

    1. 前往 **API 和服务** \> **凭证**。
    2. 点击 **创建凭证** \> **OAuth 客户端 ID**。
    3. 选择 **Web 应用**，点击 **创建**。
    4. 保存生成的凭证信息，包括客户端 ID 和客户端密钥。

    在 OAuth 客户端配置窗口中，输入客户端 ID（client_ID）和客户端密钥（client_secret），以将工具供应商设置为客户端。

    ![acd5f5057235c3a0c554abaedcf276fb48f80567f0231eae9158a795f8e1c45d.png](images/acd5f5057235c3a0c554abaedcf276fb48f80567f0231eae9158a795f8e1c45d.png)

    在 Google OAuth 客户端页面，填写由 Dify 生成的重定向 URI。

    ![dfe60a714a275c5bf65f814673bd2f0a0db4fda27573a2f0b28a1c39e4c61da2.png](images/dfe60a714a275c5bf65f814673bd2f0a0db4fda27573a2f0b28a1c39e4c61da2.png)

> **信息提示：**

      Dify 在 OAuth 客户端配置弹窗中显示`redirect_uri`，通常遵循以下格式：

      ```bash
      https://your-dify-domain/console/api/oauth/plugin/plugin-id/provider-name/tool-name/callback
      ```

      对于自托管的 Dify 实例，`your-dify-domain` 应与 `CONSOLE_WEB_URL` 保持一致。

> **提示：**

  不同第三方服务的要求各异，请务必查阅目标集成服务的特定 OAuth 文档。

### 流程二：用户授权（由 Dify 用户完成）

OAuth 客户端配置完成后，Dify 用户即可授权插件访问他们的个人账户。

![833c205f5441910763b27d3e3ff0c4449a730a690da91abc3ce032c70da04223.png](images/833c205f5441910763b27d3e3ff0c4449a730a690da91abc3ce032c70da04223.png)

## 步骤

### 1. 在供应商的 Manifest 文件中定义 OAuth 的参数架构

供应商的 Manifest 文件中的 `oauth_schema` 字段为插件 OAuth 定义凭证需求及授权流程产出，涉及以下两种参数架构。

#### client_schema

定义 OAuth 客户端设置所需的输入参数架构。

```yaml gmail.yaml
oauth_schema:
  client_schema:
    - name: "client_id"
      type: "secret-input"
      required: true
      url: "https://developers.google.com/identity/protocols/oauth2"
    - name: "client_secret"
      type: "secret-input" 
      required: true
```

> **信息提示：**

  `url` 字段直接链接至第三方服务的帮助文档，有助于为管理员/开发人员解惑。

#### credentials_schema

定义用户授权流程产生的凭证参数架构（由 Dify 自动管理）。

```yaml
# 同样在 oauth_schema 下
  credentials_schema:
    - name: "access_token"
      type: "secret-input"
    - name: "refresh_token"
      type: "secret-input"
    - name: "expires_at"
      type: "secret-input"
```

> **信息提示：**

  同时包含 `oauth_schema` 和 `credentials_for_provider` 字段，为用户提供 OAuth 和 API 密钥两种认证选项。

### 2. 在工具供应商中完成所需的 OAuth 方法实现

在实现 `ToolProvider` 的位置，添加以下代码：

```python
from dify_plugin.entities.oauth import ToolOAuthCredentials
from dify_plugin.errors.tool import ToolProviderCredentialValidationError, ToolProviderOAuthError
```

`ToolProvider` 类必须实现以下三个 OAuth 方法（以 `GmailProvider` 为例）：

> **警告：**

  为避免安全隐患，在任何情况下都不应在 `ToolOAuthCredentials` 的凭证中返回 `client_secret`（客户端密钥）。

```python _oauth_get_authorization_url expandable
def _oauth_get_authorization_url(self, redirect_uri: str, system_credentials: Mapping[str, Any]) -> str:
	"""
	使用 OAuth 客户端设置流程中的凭据生成授权 URL。 
    此 URL 是用户授权应用程序访问其资源的地址。
    """
    # 生成随机状态值用于 CSRF 保护（建议所有 OAuth 流程使用）
    state = secrets.token_urlsafe(16)

    # 定义 Gmail 特定的作用域范围。请求最小必要权限
    scope = "read:user read:data"  # 替换为所需的权限范围

    # 组装 Gmail 特定的请求参数
    params = 
        "client_id": system_credentials["client_id"],    # 来自 OAuth 客户端设置
        "redirect_uri": redirect_uri,                    # 由 Dify 生成，请勿修改
        "scope": scope,                                  
        "response_type": "code",                         # 标准 OAuth 授权码流程
        "access_type": "offline",                        # 关键：获取刷新令牌（若支持）
        "prompt": "consent",                             # 当权限范围变更时强制重新授权（若支持）
        "state": state,                                  # CSRF 保护

    return f"self._AUTH_URL?urllib.parse.urlencode(params)"
```

```python _oauth_get_credentials expandable
def _oauth_get_credentials(
    self, redirect_uri: str, system_credentials: Mapping[str, Any], request: Request
) -> ToolOAuthCredentials:
    """
    将授权码交换为访问令牌和刷新令牌。
	此方法用于为单个账户连接创建一套凭证。
    """
    # 从 OAuth 回调中提取授权码
    code = request.args.get("code")
    if not code:
        raise ToolProviderOAuthError("Authorization code not provided")

    # 检查来自 OAuth 提供程序的授权错误
    error = request.args.get("error")
    if error:
        error_description = request.args.get("error_description", "")
        raise ToolProviderOAuthError(f"OAuth authorization failed: error - error_description")

    # 使用 OAuth 客户端设置凭据将授权码交换为令牌

	# 组装 Gmail 特定的请求载荷
    data = 
        "client_id": system_credentials["client_id"],        # 来自 OAuth 客户端设置
        "client_secret": system_credentials["client_secret"], # 来自 OAuth 客户端设置
        "code": code,                                        # 来自用户授权
        "grant_type": "authorization_code",                  # 标准 OAuth 流程类型
        "redirect_uri": redirect_uri,                        # 必须与授权 URL 完全匹配

    headers = "Content-Type": "application/x-www-form-urlencoded"

    try:
        response = requests.post(
            self._TOKEN_URL,
            data=data,
            headers=headers,
            timeout=10
        )
        response.raise_for_status()

        token_data = response.json()

        # 处理响应中的 OAuth 提供商错误
        if "error" in token_data:
            error_desc = token_data.get('error_description', token_data['error'])
            raise ToolProviderOAuthError(f"Token exchange failed: error_desc")

        access_token = token_data.get("access_token")
        if not access_token:
            raise ToolProviderOAuthError("No access token received from provider")

        # 构建与你的 credentials_schema 匹配的凭据字典
        credentials = 
            "access_token": access_token,
            "token_type": token_data.get("token_type", "Bearer"),

        # 若支持刷新令牌，则需包含（对长期访问至关重要）
        refresh_token = token_data.get("refresh_token")
        if refresh_token:
            credentials["refresh_token"] = refresh_token

        # 处理令牌过期时间。某些提供程序不提供 expires_in
        expires_in = token_data.get("expires_in", 3600)  # Default to 1 hour
        expires_at = int(time.time()) + expires_in

        return ToolOAuthCredentials(credentials=credentials, expires_at=expires_at)

    except requests.RequestException as e:
        raise ToolProviderOAuthError(f"Network error during token exchange: str(e)")
    except Exception as e:
        raise ToolProviderOAuthError(f"Failed to exchange authorization code: str(e)")
```

```python _oauth_refresh_credentials
def _oauth_refresh_credentials(
    self, redirect_uri: str, system_credentials: Mapping[str, Any], credentials: Mapping[str, Any]
) -> ToolOAuthCredentials:
    """
    使用刷新令牌刷新凭证。 
	当令牌过期时，Dify 将自动调用此方法。
    """
    refresh_token = credentials.get("refresh_token")
    if not refresh_token:
        raise ToolProviderOAuthError("No refresh token available")

    # 标准 OAuth 刷新令牌流程
    data = 
        "client_id": system_credentials["client_id"],       # 来自 OAuth 客户端设置
        "client_secret": system_credentials["client_secret"], # 来自 OAuth 客户端设置
        "refresh_token": refresh_token,                     # 来自先前的授权
        "grant_type": "refresh_token",                      # OAuth 刷新流程

    headers = "Content-Type": "application/x-www-form-urlencoded"

    try:
        response = requests.post(
            self._TOKEN_URL,
            data=data,
            headers=headers,
            timeout=10
        )
        response.raise_for_status()

        token_data = response.json()

        # 处理刷新错误
        if "error" in token_data:
            error_desc = token_data.get('error_description', token_data['error'])
            raise ToolProviderOAuthError(f"Token refresh failed: error_desc")

        access_token = token_data.get("access_token")
        if not access_token:
            raise ToolProviderOAuthError("No access token received from provider")

        # 构建新凭证，保留现有的刷新令牌
            "access_token": access_token,
            "token_type": token_data.get("token_type", "Bearer"),
            "refresh_token": refresh_token,  # 保留现有的刷新令牌
        }

        # 处理令牌过期时间
        expires_in = token_data.get("expires_in", 3600)

        # 若提供了新的刷新令牌，则进行更新
        new_refresh_token = token_data.get("refresh_token")
        if new_refresh_token:
            new_credentials["refresh_token"] = new_refresh_token

        # 为 Dify 的令牌管理计算新的过期时间戳
        expires_at = int(time.time()) + expires_in

        return ToolOAuthCredentials(credentials=new_credentials, expires_at=expires_at)

    except requests.RequestException as e:
        raise ToolProviderOAuthError(f"Network error during token refresh: str(e)")
    except Exception as e:
        raise ToolProviderOAuthError(f"Failed to refresh credentials: str(e)")
```

### 3. 在工具中访问令牌

你可以在 `Tool` 实现中使用 OAuth 凭证进行经过身份验证的 API 调用，示例如下：

```python
class YourTool(BuiltinTool):
    def _invoke(self, user_id: str, tool_parameters: dict[str, Any]) -> ToolInvokeMessage:
        if self.runtime.credential_type == CredentialType.OAUTH:
            access_token = self.runtime.credentials["access_token"]

        response = requests.get("https://api.service.com/data",
                              headers={"Authorization": f"Bearer {access_token}"})
        return self.create_text_message(response.text)
```

`self.runtime.credentials` 自动提供当前用户的令牌。Dify 自动处理令牌刷新机制。

对于同时支持 OAuth 和 API 密钥认证的插件，可使用 `self.runtime.credential_type` 来区分两种认证类型。

### 4. 指定正确的版本

插件 SDK 和 Dify 的早期版本不支持 OAuth 认证。因此，需将插件 SDK 版本设置如下：

```
dify_plugin>=0.4.2,<0.5.0.
```

在 `manifest.yaml`中， 添加最低 Dify 版本要求：

```yaml
meta:
  version: 0.0.1
  arch:
    - amd64
    - arm64
  runner:
    language: python
    version: "3.12"
    entrypoint: main
  minimum_dify_version: 1.7.1
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/tool-oauth.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Tool 插件
> 来源：`zh-hans/plugins/quick-start/develop-plugins/tool-plugin.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

工具指的是能够被 Chatflow / Workflow / Agent 类型应用所调用的第三方服务，提供完整的 API 实现能力，用于增强 Dify 应用的能力。例如为应用添加在线搜索、图片生成等额外功能。

![](https://assets-docs.dify.ai/2024/12/7e7bcf1f9e3acf72c6917ea9de4e4613.png)

在本文中，**“工具插件”** 指的是一个完整的项目，其中包含工具供应商文件、功能代码等结构。一个工具供应商内允许包含多个 Tools（可以理解为单个工具中提供的额外功能），结构如下：

```
- 工具供应商
    - Tool A
    - Tool B
```

![工具插件结构](https://assets-docs.dify.ai/2025/02/60c4c86a317d865133aa460592eac079.png)

本文将以 `Google Search` 为例，介绍如何快速开发一个工具插件。

### 前置准备

* Dify 插件脚手架工具
* Python 环境，版本号 ≥ 3.12

关于如何准备插件开发的脚手架工具，详细说明请参考[安装插件开发工具](initialize-development-tools)。

### 创建新项目

运行脚手架命令行工具，创建一个新的 dify 插件项目。

```bash
./dify-plugin-darwin-arm64 plugin init
```

如果你已将该二进制文件重命名为 `dify` 并拷贝至 `/usr/local/bin` 路径下，可以运行以下命令创建新的插件项目：

```bash
dify plugin init
```

> 下文将使用 `dify` 作为命令行示例。如遇到问题，请将 `dify` 命令替换为命令行工具的所在路径。

### 选择插件类型和模板

脚手架工具内的所有模板均已提供完整的代码项目。在本文实例中，选择 `Tool` 插件。

> 如果你已熟悉插件开发，无需借助模板，可参考[接口文档](../../schema-definition/)指引完成不同类型的插件开发。

![插件类型：工具](https://assets-docs.dify.ai/2024/12/dd3c0f9a66454e15868eabced7b74fd6.png)

#### 配置插件权限

插件还需读取 Dify 平台的权限，为该示例插件授予以下权限：

* Tools
* Apps
* 启用持久化存储 Storage，分配默认大小存储
* 允许注册 Endpoint

> 在终端内使用方向键选择权限，使用 “Tab” 按钮授予权限。

勾选所有权限项后，轻点回车完成插件的创建。系统将自动生成插件项目代码。

![插件权限](https://assets-docs.dify.ai/2024/12/9cf92c2e74dce55e6e9e331d031e5a9f.png)

### 开发工具插件

#### 1. 创建工具供应商文件

工具供应商文件为 yaml 格式文件，可以理解为工具插件的基础配置入口，用于向工具提供必要的授权信息。

前往插件模板项目中的 `/provider` 路径，将其中的 yaml 文件重命名为 `google.yaml`。该 `yaml` 文件将包含工具供应商的信息，包括供应商名称、图标、作者等详情。这部分信息将在安装插件时进行展示。

**示例代码**

```yaml
identity: # 工具供应商的基本信息
  author: Your-name # 作者
  name: google # 名称，唯一，不允许和其他供应商重名
  label: # 标签，用于前端展示
    en_US: Google # 英文标签
    zh_Hans: Google # 中文标签
  description: # 描述，用于前端展示
    en_US: Google # 英文描述
    zh_Hans: Google # 中文描述
  icon: icon.svg # 工具图标，需要放置在 _assets 文件夹下
  tags: # 标签，用于前端展示
    - search
```

确保该文件路径位于 `/tools` 目录，完整的路径如下：

```yaml
plugins:
  tools:
    - "google.yaml"
```

其中 `google.yaml` 文件需要使用其在插件项目的绝对路径。在本例中，它位于项目根目录。YAML 文件中的 identity 字段解释如下：`identity` 包含了工具供应商的基本信息，包括作者、名称、标签、描述、图标等。

* 图标需要属于附件资源，需要将其放置在项目根目录的 `_assets` 文件夹下。
* 标签可以帮助用户通过分类快速找到插件，以下是目前所支持的所有标签。

```python
class ToolLabelEnum(Enum):
  SEARCH = 'search'
  IMAGE = 'image'
  VIDEOS = 'videos'
  WEATHER = 'weather'
  FINANCE = 'finance'
  DESIGN = 'design'
  TRAVEL = 'travel'
  SOCIAL = 'social'
  NEWS = 'news'
  MEDICAL = 'medical'
  PRODUCTIVITY = 'productivity'
  EDUCATION = 'education'
  BUSINESS = 'business'
  ENTERTAINMENT = 'entertainment'
  UTILITIES = 'utilities'
  OTHER = 'other'
```

#### **2. 补全第三方服务凭据**

为了便于开发，选择采用第三方服务 `SerpApi` 所提供的 Google Search API 。 `SerpApi` 要求填写 API Key 进行使用，因此需要在 `yaml` 文件内添加 `credentials_for_provider` 字段。

完整代码如下：

```yaml
identity:
  author: Dify
  name: google
  label:
    en_US: Google
    zh_Hans: Google
    pt_BR: Google
  description:
    en_US: Google
    zh_Hans: GoogleSearch
    pt_BR: Google
  icon: icon.svg
  tags:
    - search
credentials_for_provider: #添加 credentials_for_provider 字段
  serpapi_api_key:
    type: secret-input
    required: true
    label:
      en_US: SerpApi API key
      zh_Hans: SerpApi API key
    placeholder:
      en_US: Please input your SerpApi API key
      zh_Hans: 请输入你的 SerpApi API key
    help:
      en_US: Get your SerpApi API key from SerpApi
      zh_Hans: 从 SerpApi 获取您的 SerpApi API key
    url: https://serpapi.com/manage-api-key
tools:
  - tools/google_search.yaml
extra:
  python:
    source: google.py
```

* 其中 `credentials_for_provider` 的子级结构需要满足 [ProviderConfig](../../schema-definition/general-specifications#providerconfig) 的规范。
* 需要指定该供应商包含了哪些工具。本示例仅包含了一个 `tools/google_search.yaml` 文件。
* 作为供应商，除了定义其基础信息外，还需要实现一些它的代码逻辑，因此需要指定其实现逻辑，在本例子中，将功能的代码文件放在了 `google.py` 中，但是暂时不实现它，而是先编写 `google_search` 的代码。

#### 3. 填写工具 yaml 文件

一个工具插件下可以有多个工具功能，每个工具功能需要一个 `yaml` 文件进行描述，包含工具功能的基本信息、参数、输出等。

仍以 `GoogleSearch` 工具为例，在 `/tools`文件夹内新建一个 `google_search.yaml` 文件。

```yaml
identity:
  name: google_search
  author: Dify
  label:
    en_US: GoogleSearch
    zh_Hans: 谷歌搜索
    pt_BR: GoogleSearch
description:
  human:
    en_US: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.
    zh_Hans: 一个用于执行 Google SERP 搜索并提取片段和网页的工具。输入应该是一个搜索查询。
    pt_BR: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.
  llm: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.
parameters:
  - name: query
    type: string
    required: true
    label:
      en_US: Query string
      zh_Hans: 查询语句
      pt_BR: Query string
    human_description:
      en_US: used for searching
      zh_Hans: 用于搜索网页内容
      pt_BR: used for searching
    llm_description: key words for searching
    form: llm
extra:
  python:
    source: tools/google_search.py
```

* `identity` 包含了工具的基本信息，包括名称、作者、标签、描述等。
* `parameters` 参数列表
  * `name` （必填）参数名称，唯一，不允许和其他参数重名。
  * `type` （必填）参数类型，目前支持`string`、`number`、`boolean`、`select`、`secret-input`、`file`、`files`、`model-selector`、`app-selector` 九种类型，分别对应字符串、数字、布尔值、下拉框、加密输入框、文件、文件集、模型选择、应用选择，对于敏感信息，请使用 `secret-input` 类型。
  * `label`（必填）参数标签，用于前端展示。
  * `form` （必填）表单类型，目前支持`llm`、`form`两种类型。
    * 在 Agent 应用中，`llm` 表示该参数 LLM 自行推理，`form` 表示要使用该工具可提前设定的参数。
    * 在 Workflow 应用中，`llm`和`form` 均需要前端填写，但 `llm` 的参数会做为工具节点的输入变量。
  * `required` 是否必填
    * 在 `llm` 模式下，如果参数为必填，则会要求 Agent 必须要推理出这个参数。
    * 在 `form` 模式下，如果参数为必填，则会要求用户在对话开始前在前端填写这个参数。
  * `options` 参数选项
    * 在 `llm` 模式下，Dify 会将所有选项传递给 LLM，LLM 可以根据这些选项进行推理。
    * 在 `form` 模式下，`type` 为 `select` 时，前端会展示这些选项。
  * `default` 默认值。
  * `min` 最小值，当参数类型为`number`时可以设定。
  * `max` 最大值，当参数类型为`number`时可以设定。
  * `human_description` 用于前端展示的介绍，支持多语言。
  * `placeholder` 字段输入框的提示文字，在表单类型为`form`，参数类型为`string`、`number`、`secret-input`时，可以设定，支持多语言。
  * `llm_description` 传递给 LLM 的介绍。为了使得 LLM 更好理解这个参数，请在这里写上关于这个参数尽可能详细的信息，以便 LLM 能够理解该参数。

#### 4.  准备工具代码

填写工具的配置信息以后，可以开始编写工具的功能代码，实现工具的逻辑目的。在`/tools`目录下创建`google_search.py`，内容如下：

```python
from collections.abc import Generator
from typing import Any

from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage

SERP_API_URL = "https://serpapi.com/search"

class GoogleSearchTool(Tool):
    def _parse_response(self, response: dict) -> dict:
        result = {}
        if "knowledge_graph" in response:
            result["title"] = response["knowledge_graph"].get("title", "")
            result["description"] = response["knowledge_graph"].get("description", "")
        if "organic_results" in response:
            result["organic_results"] = [

                    "title": item.get("title", ""),
                    "link": item.get("link", ""),
                    "snippet": item.get("snippet", ""),

                for item in response["organic_results"]
            ]
        return result

    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        params = 
            "api_key": self.runtime.credentials["serpapi_api_key"],
            "q": tool_parameters["query"],
            "engine": "google",
            "google_domain": "google.com",
            "gl": "us",
            "hl": "en",

        response = requests.get(url=SERP_API_URL, params=params, timeout=5)
        response.raise_for_status()
        valuable_res = self._parse_response(response.json())

        yield self.create_json_message(valuable_res)
```

该例子的含义为请求 `serpapi`，并使用 `self.create_json_message` 返回一串 `json` 的格式化数据，如果想了解更多的返回数据类型，可以参考[工具接口文档](../../schema-definition/tool)。

#### 4. 完成工具供应商代码

最后需要创建一个供应商的实现代码，用于实现凭据验证逻辑。如果凭据验证失败，将会抛出`ToolProviderCredentialValidationError`异常。验证成功后，将正确请求 `google_search` 工具服务。

在 `/provider` 目录下创建 `google.py` 文件，代码的内容如下：

```python
from typing import Any

from dify_plugin import ToolProvider
from dify_plugin.errors.tool import ToolProviderCredentialValidationError
from tools.google_search import GoogleSearchTool

class GoogleProvider(ToolProvider):
    def _validate_credentials(self, credentials: dict[str, Any]) -> None:
        try:
            for _ in GoogleSearchTool.from_credentials(credentials).invoke(
                tool_parameters="query": "test", "result_type": "link",
            ):
                pass
        except Exception as e:
            raise ToolProviderCredentialValidationError(str(e))
```

### 调试插件

插件开发完成后，接下来需要测试插件是否可以正常运行。Dify 提供便捷地远程调试方式，帮助你快速在测试环境中验证插件功能。

前往[“插件管理”](https://cloud.dify.ai/plugins)页获取远程服务器地址和调试 Key。

![](https://assets-docs.dify.ai/2024/12/053415ef127f1f4d6dd85dd3ae79626a.png)

回到插件项目，拷贝 `.env.example` 文件并重命名为 `.env`，将获取的远程服务器地址和调试 Key 等信息填入其中。

`.env` 文件：

```bash
INSTALL_METHOD=remote
REMOTE_INSTALL_URL=debug.dify.ai:5003
REMOTE_INSTALL_KEY=********-****-****-****-************
```

运行 `python -m main` 命令启动插件。在插件页即可看到该插件已被安装至 Workspace 内，团队中的其他成员也可以访问该插件。

![](https://assets-docs.dify.ai/2024/11/0fe19a8386b1234755395018bc2e0e35.png)

### 打包插件（可选）

确认插件能够正常运行后，可以通过以下命令行工具打包并命名插件。运行以后你可以在当前文件夹发现 `google.difypkg` 文件，该文件为最终的插件包。

```
dify plugin package ./google
```

恭喜，你已完成一个工具类型插件的完整开发、调试与打包过程！

### 发布插件（可选）

如果想要将插件发布至 Dify Marketplace，请确保你的插件遵循了[插件发布规范](https://docs.dify.ai/zh-hans/plugins/publish-plugins/publish-to-dify-marketplace)。审核通过后，代码将合并至主分支并自动上线至 [Dify Marketplace](https://marketplace.dify.ai/)。

  publish-plugins

### 探索更多

#### **快速开始：**

* [开发 Extension 插件](extension-plugin)
* [开发 Model 插件](model-plugin/)
* [Bundle 插件：将多个插件打包](bundle)

#### **插件接口文档：**

* [Manifest](../../schema-definition/manifest) 结构
* [Endpoint](../../schema-definition/endpoint) 详细定义
* [反向调用 Dify 能力](../../schema-definition/reverse-invocation-of-the-dify-service/)
* [工具](../../schema-definition/tool)
* [模型](../../schema-definition/model/)
* [扩展 Agent 策略](../../schema-definition/agent)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/develop-plugins/tool-plugin.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 安装与使用插件
> 来源：`zh-hans/plugins/quick-start/install-plugins.mdx`

### 安装插件

点击 Dify 平台右上角的“插件”，前往插件管理页，支持通过 **Marketplace、GitHub、上传本地文件**三种方式安装插件。

![安装插件](https://assets-docs.dify.ai/2025/01/a56c40245090d9252557dcc6f4064a14.png)

#### Marketplace

你可以选择任意插件，点&#x51FB;**“安装”**&#x6309;钮将插件安装至当前 Workspace 内。

![通过 Marketplace 安装插件](https://assets-docs.dify.ai/2025/01/6ae8b661b7fa01b228a954d00ef552f3.png)

#### GitHub

你可以直接通过 GitHub 代码仓库链接安装插件，使用此方法安装插件时需确保插件满足代码规范。插件代码仓库需创建 Release 并在附件中包含 `.difypkg` 后缀的文件包。详细说明请参考[发布插件：GitHub](../publish-plugins/publish-plugin-on-personal-github-repo)。

![通过 GitHub 安装](https://assets-docs.dify.ai/2025/01/4026a12a915e3fe9bd057d8827acfdce.png)

**上传本地文件**

本地文件指的是 `.difypkg` 后缀的文件包，常用于离线环境或测试环境。开发者可通过此方式安装除官方市场以外的插件文件。对于组织而言，可以开发维护内部插件并通过本地上传的方式安装，避免公开敏感信息。

关于如何打包插件并获取 `.difypkg` 文件，详细说明请参考[打包插件](../publish-plugins/package-plugin-file-and-publish)。

### 使用插件

将插件安装至 Workspace 后即可在 Dify 应用内进行使用。下文将简要介绍不同类型的插件对应不同的使用方法。

#### 模型插件

以 `OpenAI` 为例，安装模型插件后，点击右上角的**头像页 → 设置 → 模型供应商**，配置 API Key 即可激活该模型供应商。

![授权 OpenAI API Key](https://assets-docs.dify.ai/2025/01/3bf32d49975931e5924baa749aa7812f.png)

授权后可以在所有应用类型内选择并使用该大语言模型。

![使用模型类型插件](https://assets-docs.dify.ai/2024/12/4a38b1ea534ca68515839c518c250d2f.png)

#### 工具插件

工具插件支持在 Chatflow、Workflow、Agent 应用内使用。部分插件在安装后可能还要求进行 API Key 或其它形式的授权，手动添加授权后才能正常使用。

> API Key 属敏感信息，授权仅对当前用户有效。团队中的其他人使用该插件时仍需手动输入授权密钥。

本章节将以 `Google Search` 工具为例，介绍如何使用工具插件。在 Dify Marketplace 搜索并安装插件后，按照页面提示输入 API Key 完成插件授权过程。

![授权插件](https://assets-docs.dify.ai/2024/11/972de4c9fa00f792a1ab734b080aafdc.png)

#### Agent

创建 Agent 应用后，在应用编排页下方找到 **“工具”** 选项。选中已安装的工具插件。

使用应用时，输入使用工具的指令文本，例如输入 “当日新闻” 即可调用插件使用谷歌搜索引擎进行在线内容检索。

![Agent 工具](https://assets-docs.dify.ai/2024/12/78f833811cb0c3d5cbbb1a941cffc769.png)

#### Chatflow / Workflow

Chatflow 和 Workflow 类型应用共用一套工作流编排画布，因此工具插件的使用方法一致。

你可以点击节点末尾的 + 号，选择已安装的谷歌插件工具，并将节点与上游节点相连线。

![Chatflow / Workflow 工具](https://assets-docs.dify.ai/2024/12/7e7bcf1f9e3acf72c6917ea9de4e4613.png)

在插件的输入变量中填写用户输入的查询内容 query 变量，或其它需要在线检索的信息。

![Tools 输入项](https://assets-docs.dify.ai/2024/12/a67c4cffd8fdf33297d462b2e6d01d27.png)

你已了解如何使用 `Google Search` 工具。如需了解其它插件的使用方法，请参考插件详情页的指导使用插件。

![使用插件](https://assets-docs.dify.ai/2025/01/9d826302637638f705a94f73bd653958.png)

### 阅读更多

如需了解如何上手开发插件，请阅读以下内容：

  develop-plugins

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/quick-start/install-plugins.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 接口定义
> 来源：`zh-hans/plugins/schema-definition/README.mdx`

manifest.md

  endpoint.md

  model.md

  general-specifications.md

  persistent-storage.md

  reverse-invocation-of-the-dify-service

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Agent
> 来源：`zh-hans/plugins/schema-definition/agent.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

Agent 策略是一个定义了标准输入内容与输出格式的可扩展模板。通过开发具体 Agent 策略接口的功能代码，你可以实现众多不同的 Agent 策略如 CoT（思维链）/ ToT（思维树）/ GoT（思维图）/ BoT（思维骨架），实现一些诸如 [Sementic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/)  的复杂策略。

### 在 Manifest 内添加字段

在插件中添加 Agent 策略需要在 `manifest.yaml` 文件内新增 `plugins.agent_strategies` 字段，并且也需要定义 Agent 供应商，示例代码如下

```yaml
version: 0.0.2
type: plugin
author: "langgenius"
name: "agent"
plugins:
  agent_strategies:
    - "provider/agent.yaml"
```

此处已省去 `manifest` 文件内部分无关的字段。如需了解 Manifest 的详细格式，请参考 [Manifest](./zh-hans/plugins/schema-definition/manifest) 文档。

### 定义 Agent 供应商

随后，你需要新建 `agent.yaml` 文件并填写基础的 Agent 供应商信息。

```yaml
identity:
  author: langgenius
  name: agent
  label:
    en_US: Agent
    zh_Hans: Agent
    pt_BR: Agent
  description:
    en_US: Agent
    zh_Hans: Agent
    pt_BR: Agent
  icon: icon.svg
strategies:
  - strategies/function_calling.yaml
```

其主要包含一些描述性质的基础内容，并且指明当前供应商包含哪些策略。在上述示例代码中仅指定了一个最基础的 `function_calling.yaml` 策略文件。

### 定义并实现 Agent 策略

#### 定义

接下来需要定义能够实现 Agent 策略的代码。新建一个 `function_calling.yaml` 文件：

```yaml
identity:
  name: function_calling
  author: Dify
  label:
    en_US: FunctionCalling
    zh_Hans: FunctionCalling
    pt_BR: FunctionCalling
description:
  en_US: Function Calling is a basic strategy for agent, model will use the tools provided to perform the task.
  zh_Hans: Function Calling 是一个基本的 Agent 策略，模型将使用提供的工具来执行任务。
  pt_BR: Function Calling is a basic strategy for agent, model will use the tools provided to perform the task.
parameters:
  - name: model
    type: model-selector
    scope: tool-call&llm
    required: true
    label:
      en_US: Model
      zh_Hans: 模型
      pt_BR: Model
  - name: tools
    type: array[tools]
    required: true
    label:
      en_US: Tools list
      zh_Hans: 工具列表
      pt_BR: Tools list
  - name: query
    type: string
    required: true
    label:
      en_US: Query
      zh_Hans: 用户提问
      pt_BR: Query
  - name: max_iterations
    type: number
    required: false
    default: 5
    label:
      en_US: Max Iterations
      zh_Hans: 最大迭代次数
      pt_BR: Max Iterations
    max: 50
    min: 1
extra:
  python:
    source: strategies/function_calling.py
```

代码格式类似 [`Tool` 标准格式](./zh-hans/plugins/schema-definition/tool)，定义了 `model` `tools` `query` `max_iterations` 等一共四个参数，以便于实现最基础的 Agent 策略。该代码的含义是可以允许用户选择模型和需要使用的工具，配置最大迭代次数并最终传入一个 query 后开始执行 Agent。

#### 编写功能实现代码

**获取参数**

根据上文定义的四个参数，其中 model 类型参数为`model-selector`，tool 类型参数为特殊的 `array[tools]。`在参数中获取到的形式可以通过 SDK 中内置的 `AgentModelConfig` 和 `list[ToolEntity]`进行转换。

```python
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity

class FunctionCallingParams(BaseModel):
    query: str
    model: AgentModelConfig
    tools: list[ToolEntity] | None
    maximum_iterations: int = 3

 class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        """
        Run FunctionCall agent application
        """
        fc_params = FunctionCallingParams(**parameters)
```

**调用模型**

调用指定模型是 Agent 插件中必不可少的能力。通过 SDK 中的 `session.model.invoke()` 函数调用模型。可以从 model 中获取所需的传入参数。

invoke model 的方法签名示例代码：

```python
def invoke(
        self,
        model_config: LLMModelConfig,
        prompt_messages: list[PromptMessage],
        tools: list[PromptMessageTool] | None = None,
        stop: list[str] | None = None,
        stream: bool = True,
    ) -> Generator[LLMResultChunk, None, None] | LLMResult:
```

需要传入模型信息 `model_config`，prompt 信息 `prompt_messages` 和工具信息 `tools`。

其中`prompt_messages`参数可以参考以下示例代码调用；而`tool_messages`则需要进行一定的转换。

请参考 invoke model 使用方法的示例代码：

```python
from collections.abc import Generator
from typing import Any

from pydantic import BaseModel

from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.model.message import (
    PromptMessageTool,
    SystemPromptMessage,
    UserPromptMessage,
)
from dify_plugin.entities.tool import ToolParameter
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity

class FunctionCallingParams(BaseModel):
    query: str
    instruction: str | None
    model: AgentModelConfig
    tools: list[ToolEntity] | None
    maximum_iterations: int = 3

class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        """
        Run FunctionCall agent application
        """
        # init params
        fc_params = FunctionCallingParams(**parameters)
        query = fc_params.query
        model = fc_params.model
        stop = fc_params.model.completion_params.get("stop", []) if fc_params.model.completion_params else []
        prompt_messages = [
            SystemPromptMessage(content="your system prompt message"),
            UserPromptMessage(content=query),
        ]
        tools = fc_params.tools
        prompt_messages_tools = self._init_prompt_tools(tools)

        # invoke llm
        chunks = self.session.model.llm.invoke(
            model_config=LLMModelConfig(**model.model_dump(mode="json")),
            prompt_messages=prompt_messages,
            stream=True,
            stop=stop,
            tools=prompt_messages_tools,
        )

    def _init_prompt_tools(self, tools: list[ToolEntity] | None) -> list[PromptMessageTool]:
        """
        Init tools
        """

        prompt_messages_tools = []
        for tool in tools or []:
            try:
                prompt_tool = self._convert_tool_to_prompt_message_tool(tool)
            except Exception:
                # api tool may be deleted
                continue

            # save prompt tool
            prompt_messages_tools.append(prompt_tool)

        return prompt_messages_tools

    def _convert_tool_to_prompt_message_tool(self, tool: ToolEntity) -> PromptMessageTool:
        """
        convert tool to prompt message tool
        """
        message_tool = PromptMessageTool(
            name=tool.identity.name,
            description=tool.description.llm if tool.description else "",
            parameters={
                "type": "object",
                "properties": {},
                "required": [],
            },
        )

        parameters = tool.parameters
        for parameter in parameters:
            if parameter.form != ToolParameter.ToolParameterForm.LLM:
                continue

            parameter_type = parameter.type
            if parameter.type in 
                ToolParameter.ToolParameterType.FILE,
                ToolParameter.ToolParameterType.FILES,
            :
                continue
            enum = []
            if parameter.type == ToolParameter.ToolParameterType.SELECT:
                enum = [option.value for option in parameter.options] if parameter.options else []

            message_tool.parameters["properties"][parameter.name] = 
                "type": parameter_type,
                "description": parameter.llm_description or "",

            if len(enum) > 0:
                message_tool.parameters["properties"][parameter.name]["enum"] = enum

            if parameter.required:
                message_tool.parameters["required"].append(parameter.name)

        return message_tool

```

**调用工具**

调用工具同样是 Agent 插件必不可少的能力。可以通过`self.session.tool.invoke()`进行调用。invoke tool 的方法签名示例代码：

```python
def invoke(
        self,
        provider_type: ToolProviderType,
        provider: str,
        tool_name: str,
        parameters: dict[str, Any],
    ) -> Generator[ToolInvokeMessage, None, None]
```

必须的参数有 `provider_type`, `provider`, `tool_name`, `parameters`。其中 `tool_name` 和`parameters`在 Function Calling 中往往都由 LLM 生成。使用 invoke tool 的示例代码：

```python
from dify_plugin.entities.tool import ToolProviderType

class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        """
        Run FunctionCall agent application
        """
        fc_params = FunctionCallingParams(**parameters)

        # tool_call_name and tool_call_args parameter is obtained from the output of LLM
        tool_instances = tool.identity.name: tool for tool in fc_params.tools if fc_params.tools else {}
        tool_instance = tool_instances[tool_call_name]
        tool_invoke_responses = self.session.tool.invoke(
            provider_type=ToolProviderType.BUILT_IN,
            provider=tool_instance.identity.provider,
            tool_name=tool_instance.identity.name,
            # add the default value
            parameters=**tool_instance.runtime_parameters, **tool_call_args,
        )
```

`self.session.tool.invoke()`函数的输出是一个 Generator，代表着同样需要进行流式解析。

解析方法请参考以下函数：

```python

from collections.abc import Generator
from typing import cast

from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.tool import ToolInvokeMessage

def parse_invoke_response(tool_invoke_responses: Generator[AgentInvokeMessage]) -> str:
    result = ""
    for response in tool_invoke_responses:
        if response.type == ToolInvokeMessage.MessageType.TEXT:
            result += cast(ToolInvokeMessage.TextMessage, response.message).text
        elif response.type == ToolInvokeMessage.MessageType.LINK:
            result += (
                f"result link: cast(ToolInvokeMessage.TextMessage, response.message).text."
                + " please tell user to check it."
            )
        elif response.type in 
            ToolInvokeMessage.MessageType.IMAGE_LINK,
            ToolInvokeMessage.MessageType.IMAGE,
        :
            result += (
                "image has been created and sent to user already, "
                + "you do not need to create it, just tell the user to check it now."
            )
        elif response.type == ToolInvokeMessage.MessageType.JSON:
            text = json.dumps(cast(ToolInvokeMessage.JsonMessage, response.message).json_object, ensure_ascii=False)
            result += f"tool response: text."
        else:
            result += f"tool response: response.message!r."
    return result
```

#### Log

如果你希望看到 Agent 思考的过程，除了通过查看正常返回的消息以外，还可以使用专门的接口实现以树状结构展示整个 Agent 的思考过程。

**创建日志**

* 该接口创建并返回一个 `AgentLogMessage`，该 Message 表示日志中树的一个节点。
* 如果有传入 parent 则表示该节点具备父节点。
* 状态默认为"Success"（成功）。但如果你想要更好地展示任务执行过程，可以先设置状态为"start"来显示"正在执行"的日志，等任务完成后再将该日志的状态更新为"Success"。这样用户就能清楚地看到任务从开始到完成的整个过程。
* label 将用于最终给用户展示日志标题。

```python
    def create_log_message(
        self,
        label: str,
        data: Mapping[str, Any],
        status: AgentInvokeMessage.LogMessage.LogStatus = AgentInvokeMessage.LogMessage.LogStatus.SUCCESS,
        parent: AgentInvokeMessage | None = None,
    ) -> AgentInvokeMessage
```

**完成日志**

如果在前一个步骤选择了 start 状态作为初始状态，可以使用完成日志的接口来更改状态。

```python
    def finish_log_message(
        self,
        log: AgentInvokeMessage,
        status: AgentInvokeMessage.LogMessage.LogStatus = AgentInvokeMessage.LogMessage.LogStatus.SUCCESS,
        error: Optional[str] = None,
    ) -> AgentInvokeMessage
```

**实例**

这个示例展示了一个简单的两步执行过程：首先输出一条"正在思考"的状态日志，然后完成实际的任务处理。

```python
class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        thinking_log = self.create_log_message(
            data=
                "Query": parameters.get("query"),
            ,
            label="Thinking",
            status=AgentInvokeMessage.LogMessage.LogStatus.START,
        )

        yield thinking_log

        llm_response = self.session.model.llm.invoke(
            model_config=LLMModelConfig(
                provider="openai",
                model="gpt-4o-mini",
                mode="chat",
                completion_params={},
            ),
            prompt_messages=[
                SystemPromptMessage(content="you are a helpful assistant"),
                UserPromptMessage(content=parameters.get("query")),
            ],
            stream=False,
            tools=[],
        )

        thinking_log = self.finish_log_message(
            log=thinking_log,
        )

        yield thinking_log

        yield self.create_text_message(text=llm_response.message.content)
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/agent.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Endpoint
> 来源：`zh-hans/plugins/schema-definition/endpoint.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

本文将以[彩虹猫](../quick-start/develop-plugins/extension-plugin)项目为例，说明插件内的 Endpoint 的结构。完整的插件代码请参考 [GitHub 仓库](https://github.com/langgenius/dify-plugin-sdks/tree/main/python/examples/neko)。

### 组定义

一个 `Endpoint` 组是多个 `Endpoint` 的集合，在 `Dify` 插件内新建 `Endpoint` 时可能需要填写如下配置。

![](https://assets-docs.dify.ai/2024/11/763dbf86e4319591415dc5a1b6948ccb.png)

除了 `Endpoint Name` 外，你可以通过编写组的配置信息来添加新的表单项，点击保存后，你可以看到其中包含的多个接口，它们将使用相同的配置信息。

![](https://assets-docs.dify.ai/2024/11/b778b7093b7df0dc80a476c65ddcbe58.png)

#### **结构**

* `settings`(map\[string] [ProviderConfig](general-specifications#providerconfig) )：Endpoint 配置定义
* `endpoints`(list\[string], required)：指向具体的 `endpoint` 接口定义

```yaml
settings:
  api_key:
    type: secret-input
    required: true
    label:
      en_US: API key
      zh_Hans: API key
      ja_Jp: API key
      pt_BR: API key
    placeholder:
      en_US: Please input your API key
      zh_Hans: 请输入你的 API key
      ja_Jp: あなたの API key を入れてください
      pt_BR: Por favor, insira sua chave API
endpoints:
  - endpoints/duck.yaml
  - endpoints/neko.yaml
```

### 接口定义

* `path`(string)：遵循 werkzeug 接口标准
* `method`(string)：接口方法，仅支持`HEAD` `GET` `POST` `PUT` `DELETE` `OPTIONS`
* `extra`(object)：除基础信息外的配置信息
  * `python`(object)
    * `source`(string)：实现该接口的源代码

```yaml
path: "/duck/<app_id>"
method: "GET"
extra:
  python:
    source: "endpoints/duck.py"
```

### 接口实现

需要实现一个继承自 `dify_plugin.Endpoint` 子类，并实现 `_invoke` 方法。

* **输入参数**
  * `r`(Request)：`werkzeug` 中的 `Request` 对象
  * `values`(Mapping)：从 path 中解析到的路径参数
  * `settings`(Mapping)：该 `Endpoint` 的配置信息
* **返回**
  * `werkzeug` 中的 `Response` 对象，支持流式返回
  * 不支持直接返回字符串

示例代码：

```python

from typing import Mapping
from werkzeug import Request, Response
from dify_plugin import Endpoint

class Duck(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        """
        Invokes the endpoint with the given request.
        """
        app_id = values["app_id"]

        def generator():
            yield f"app_id   
"

        return Response(generator(), status=200, content_type="text/html")
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/endpoint.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 通用规范定义
> 来源：`zh-hans/plugins/schema-definition/general-specifications.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

本文将简要介绍插件开发中常见的结构。

### 路径规范

在 Manifest 或任意 yaml 文件中填写文件路径时，根据不同的类型的文件，遵循下面两条规范：

* 如果目标文件是一个图片或视频等多媒体文件时，例如填写插件的 `icon` ，你应该将这些文件放置于插件根目录下的 `_assets` 文件夹中。
* 如果目标文件是一个普通文本文件，如 `.py` `.yaml` 等代码文件，你应该填写该文件在插件项目内的绝对路径。

### 通用结构

在定义插件时，有一些数据结构是可以在工具、模型、Endpoint 之间共用的，这里定义了这些共用结构。

#### I18nObject

`I18nObject` 是一个符合 [IETF BCP 47](https://tools.ietf.org/html/bcp47) 标准的国际化结构，目前支持的四种语言为

* en\_US
* zh\_Hans
* ja\_Jp
* pt\_BR

#### ProviderConfig

`ProviderConfig` 为一个通用的供应商表单结构，适用于 `Tool`与`Endpoint`

* `name`(string)：表单项名称
* `label`([I18nObject](general-specifications#i18nobject), requierd)：遵循 [IETF BCP 47](https://tools.ietf.org/html/bcp47)
* `type`([provider\_config\_type](general-specifications#providerconfigtype-string), requierd)：表单类型
* `scope`([provider\_config\_scope](general-specifications#providerconfigscope-string))：可选项范围，根据`type`变动
* `required`(bool)：不能为空
* `default`(any)：默认值，仅支持基础类型 `float` `int` `string`
* `options`(list\[[provider\_config\_option](general-specifications#providerconfigoption-object)])：可选项，仅当 type 为 `select` 时使用
* `helper`(object)：帮助文档链接的 label，遵循 [IETF BCP 47](https://tools.ietf.org/html/bcp47)
* `url` (string)：帮助文档链接
* `placeholder`(object)：遵循 [IETF BCP 47](https://tools.ietf.org/html/bcp47)

#### ProviderConfigOption(object)

* `value`(string, required)：值
* `label`(object, required)：遵循 [IETF BCP 47](https://tools.ietf.org/html/bcp47)

#### ProviderConfigType(string)

* `secret-input` (string)：配置信息将被加密
* `text-input`(string)：普通文本
* `select`(string)：下拉框
* `boolean`(bool)：开关
* `model-selector`(object)：模型配置信息，包含供应商名称、模型名称、模型参数等
* `app-selector`(object)：app id
* `tool-selector`(object)：工具配置信息，包含工具供应商、名称、参数等
* `dataset-selector`(string)：TBD

#### ProviderConfigScope(string)

* 当 `type` 为 `model-selector` 时
  * `all`
  * `llm`
  * `text-embedding`
  * `rerank`
  * `tts`
  * `speech2text`
  * `moderation`
  * `vision`
* 当 `type` 为 `app-selector` 时
  * `all`
  * `chat`
  * `workflow`
  * `completion`
* 当`type` 为 `tool-selector` 时
  * `all`
  * `plugin`
  * `api`
  * `workflow`

#### ModelConfig

* `provider` (string): 包含 plugin\_id 的模型供应商名称，形如 `langgenius/openai/openai`。
* `model` (string): 具体的模型名称。
* `model_type` (enum): 模型类型的枚举，可以参考该文档。

#### NodeResponse

* `inputs` (dict): 最终输入到节点中的变量。
* `outputs` (dict): 节点的输出结果。
* `process_data` (dict): 节点运行过程中产生的数据。

#### ToolSelector

* `provider_id` (string): 工具供应商名称
* `tool_name` (string): 工具名称
* `tool_description` (string): 工具描述
* `tool_configuration` (dict\[str, Any]): 工具的配置信息
* `tool_parameters` (dict\[str, dict]): 需要 LLM 推理的参数
  * `name` (string): 参数名称
  * `type` (string): 参数类型
  * `required` (bool): 是否必填
  * `description` (string): 参数描述
  * `default` (any): 默认
  * `options`(list\[string]): 可选项

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/general-specifications.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Manifest
> 来源：`zh-hans/plugins/schema-definition/manifest.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

Manifest 是一个符合 yaml 规范的文件，它定义了**插件**最基础的信息，包括但不限于插件名称、作者、包含的工具、模型等信息。

若该文件的格式错误，插件的解析和打包过程都将会失败。

### 代码示例

下面是一个 Manifest 文件的简单示例，将在下文解释各个数据的含义和作用。

如需参考其它插件的代码，请参考 [GitHub 代码仓库](https://github.com/langgenius/dify-official-plugins/blob/main/tools/google/manifest.yaml)。

```yaml
version: 0.0.1
type: "plugin"
author: "Yeuoly"
name: "neko"
label:
  en_US: "Neko"
created_at: "2024-07-12T08:03:44.658609186Z"
icon: "icon.svg"
resource:
  memory: 1048576
  permission:
    tool:
      enabled: true
    model:
      enabled: true
      llm: true
    endpoint:
      enabled: true
    app:
      enabled: true
    storage: 
      enabled: true
      size: 1048576
plugins:
  endpoints:
    - "provider/neko.yaml"
meta:
  version: 0.0.1
  arch:
    - "amd64"
    - "arm64"
  runner:
    language: "python"
    version: "3.11"
    entrypoint: "main"
privacy: "./privacy.md"
```

### 版本管理

插件的版本由 `manifest` 文件中的 `version` 字段管理。版本号必须符合 `大版本.小版本.补丁版本` 格式，否则自动更新可能无法正常工作。

### 结构

* `version`(version, required)：插件的版本
* `type`(type, required)：插件类型，目前仅支持 `plugin`，未来支持 `bundle`
* `author`(string, required)：作者，在 Marketplace 中定义为组织名
* `label`(label, required)：多语言名称
* `created_at`(RFC3339, required)：创建时间，Marketplace 上要求创建时间不得大于当前时间
* `icon`(asset, required)：图标路径
* `resource` (object)：需要申请的资源
  * `memory` (int64)：最大内存占用，主要与 SaaS 上的 AWS Lambda 资源申请相关，单位字节
  * `permission`(object)：权限申请
    * `tool`(object)：反向调用工具的权限
      * `enabled` (bool)
    * `model`(object)：反向调用模型的权限
      * `enabled`(bool)
      * `llm`(bool)
      * `text_embedding`(bool)
      * `rerank`(bool)
      * `tts`(bool)
      * `speech2text`(bool)
      * `moderation`(bool)
    * `node`(object)：反向调用节点的权限
      * `enabled`(bool)
    * `endpoint`(object)：允许注册 `endpoint` 的权限
      * `enabled`(bool)
    * `app`(object)：反向调用`app`的权限
      * `enabled`(bool)
    * `storage`(object)：申请持久化存储的权限
      * `enabled`(bool)
      * `size`(int64)：最大允许多大的持久化内存，单位字节
* `plugins`(object, required)：插件扩展的具体能力的`yaml`文件列表，插件包内的绝对路径，如需要扩展模型，则需要定义一个类似于 `openai.yaml`的文件，并将该文件路径填写在此处，且该路径上的文件必须真实存在，否则打包将失败。
  * 格式
    * `tools`(list\[string])：插件扩展的[工具](tool)供应商
    * `models`(list\[string])：插件扩展的[模型](model/)供应商
    * `endpoints`(list\[string])：插件扩展的 [Endpoints](endpoint) 供应商
    * `agent_strategies` (list\[string])：插件扩展的 Agent 策略供应商
  * 限制
    * 不允许同时扩展工具与模型
    * 不允许没有任意扩展
    * 不允许同时扩展模型与 Endpoint
    * 目前仅支持各类型扩展最多一个供应商
* `meta`(object)
  * `version`(version, required)：`manifest` 格式版本，初始版本 `0.0.1`
  * `arch`(list\[string], required)：支持的架构，目前仅支持 `amd64` `arm64`
  * `runner`(object, required)：运行时配置
    * `language`(string)：目前仅支持 python
    * `version`(string)：语言的版本，目前仅支持 `3.12`
    * `entrypoint`(string)：程序入口，在 python 下应为 `main`
* `privacy` (string, optional)：可选项，指定插件隐私政策文件的相对路径或 URL，例如 `"./privacy.md"` 或 `"https://your-web/privacy"`。如果计划将插件上架至 Dify Marketplace，**该字段为必填项**，用于提供明确的用户数据使用和隐私声明。详细填写指引请参考[插件隐私政策准则](../publish-plugins/publish-to-dify-marketplace/plugin-privacy-protection-guidelines)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/manifest.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Model
> 来源：`zh-hans/plugins/schema-definition/model/README.mdx`

模型接口包含以下内容：

  model-designing-rules.md

  model-schema.md

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/model/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 模型设计规则
> 来源：`zh-hans/plugins/schema-definition/model/model-designing-rules.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

* 模型供应商规则基于 [Provider](model-designing-rules#provider) 实体。
* 模型规则基于 [AIModelEntity](model-designing-rules#aimodelentity) 实体。

> 以下所有实体均基于 `Pydantic BaseModel`，可在 `entities` 模块中找到对应实体。

### Provider

* `provider` (string) 供应商标识，如：`openai`
* `label` (object) 供应商展示名称，i18n，可设置 `en_US` 英文、`zh_Hans` 中文两种语言
  * `zh_Hans` (string) \[optional] 中文标签名，`zh_Hans` 不设置将默认使用 `en_US`。
  * `en_US` (string) 英文标签名
* `description` (object) \[optional] 供应商描述，i18n
  * `zh_Hans` (string) \[optional] 中文描述
  * `en_US` (string) 英文描述
* `icon_small` (string) \[optional] 供应商小 ICON，存储在对应供应商实现目录下的 `_assets` 目录，中英文策略同 `label`
  * `zh_Hans` (string) \[optional] 中文 ICON
  * `en_US` (string) 英文 ICON
* `icon_large` (string) \[optional] 供应商大 ICON，存储在对应供应商实现目录下的 \_assets 目录，中英文策略同 label
  * `zh_Hans` (string) \[optional] 中文 ICON
  * `en_US` (string) 英文 ICON
* `background` (string) \[optional] 背景颜色色值，例：#FFFFFF，为空则展示前端默认色值。
* `help` (object) \[optional] 帮助信息
  * `title` (object) 帮助标题，i18n
    * `zh_Hans` (string) \[optional] 中文标题
    * `en_US` (string) 英文标题
  * `url` (object) 帮助链接，i18n
    * `zh_Hans` (string) \[optional] 中文链接
    * `en_US` (string) 英文链接
* `supported_model_types` (array\[[ModelType](model-designing-rules#modeltype)]) 支持的模型类型
* `configurate_methods` (array\[[ConfigurateMethod](model-designing-rules#configuratemethod)]) 配置方式
* `provider_credential_schema` (\[[ProviderCredentialSchema](model-designing-rules#providercredentialschema)]) 供应商凭据规格
* `model_credential_schema` (\[[ModelCredentialSchema](model-designing-rules#modelcredentialschema)]) 模型凭据规格

### AIModelEntity

* `model` (string) 模型标识，如：`gpt-3.5-turbo`
* `label` (object) \[optional] 模型展示名称，i18n，可设置 `en_US` 英文、`zh_Hans` 中文两种语言
  * `zh_Hans` (string) \[optional] 中文标签名
  * `en_US` (string) 英文标签名
* `model_type` (\[ModelType]\(#ModelType)) 模型类型
* `features` (array\[\[ModelFeature]\(#ModelFeature)]) \[optional] 支持功能列表
* `model_properties` (object) 模型属性
  * `mode` (\[LLMMode]\(#LLMMode)) 模式 (模型类型 `llm` 可用)
  * `context_size` (int) 上下文大小 (模型类型 `llm` `text-embedding` 可用)
  * `max_chunks` (int) 最大分块数量 (模型类型 `text-embedding moderation` 可用)
  * `file_upload_limit` (int) 文件最大上传限制，单位：MB。（模型类型 `speech2text` 可用）
  * `supported_file_extensions` (string) 支持文件扩展格式，如：mp3,mp4（模型类型 `speech2text` 可用）
  * `default_voice` (string) 缺省音色，必选：alloy,echo,fable,onyx,nova,shimmer（模型类型 `tts` 可用）
  * `voices` (list) 可选音色列表。
    * `mode` (string) 音色模型。（模型类型 `tts` 可用）
    * `name` (string) 音色模型显示名称。（模型类型 `tts` 可用）
    * `language` (string) 音色模型支持语言。（模型类型 `tts` 可用）
  * `word_limit` (int) 单次转换字数限制，默认按段落分段（模型类型 `tts` 可用）
  * `audio_type` (string) 支持音频文件扩展格式，如：mp3,wav（模型类型 `tts` 可用）
  * `max_workers` (int) 支持文字音频转换并发任务数（模型类型 `tts` 可用）
  * `max_characters_per_chunk` (int) 每块最大字符数 (模型类型 `moderation` 可用)
* `parameter_rules` (array\[[ParameterRule](model-designing-rules#parameterrule)]) \[optional] 模型调用参数规则
* `pricing` (\[[PriceConfig](model-designing-rules#priceconfig)]) \[optional] 价格信息
* `deprecated` (bool) 是否废弃。若废弃，模型列表将不再展示，但已经配置的可以继续使用，默认 False。

### ModelType

* `llm` 文本生成模型
* `text-embedding` 文本 Embedding 模型
* `rerank` Rerank 模型
* `speech2text` 语音转文字
* `tts` 文字转语音
* `moderation` 审查

### ConfigurateMethod

* `predefined-model` 预定义模型

表示用户只需要配置统一的供应商凭据即可使用供应商下的预定义模型。

* `customizable-model` 自定义模型

用户需要新增每个模型的凭据配置。

* `fetch-from-remote` 从远程获取

与 `predefined-model` 配置方式一致，只需要配置统一的供应商凭据即可，模型通过凭据信息从供应商获取。

### ModelFeature

* `agent-thought` Agent 推理，一般超过 70B 有思维链能力。
* `vision` 视觉，即：图像理解。
* `tool-call` 工具调用
* `multi-tool-call` 多工具调用
* `stream-tool-call` 流式工具调用

### FetchFrom

* `predefined-model` 预定义模型
* `fetch-from-remote` 远程模型

### LLMMode

* `completion` 文本补全
* `chat` 对话

### ParameterRule

* `name` (string) 调用模型实际参数名
* `use_template` (string) \[optional] 使用模板

默认预置了 5 种变量内容配置模板：

* `temperature`
* `top_p`
* `frequency_penalty`
* `presence_penalty`
* `max_tokens`

可在 use\_template 中直接设置模板变量名，将会使用 entities.defaults.PARAMETER\_RULE\_TEMPLATE 中的默认配置不用设置除 `name` 和 `use_template` 之外的所有参数，若设置了额外的配置参数，将覆盖默认配置。可参考 `openai/llm/gpt-3.5-turbo.yaml`。

* `label` (object) \[optional] 标签，i18n
* `zh_Hans`(string) \[optional] 中文标签名
* `en_US` (string) 英文标签名
* `type`(string) \[optional] 参数类型
  * `int` 整数
  * `float` 浮点数
  * `string` 字符串
  * `boolean` 布尔型
* `help` (string) \[optional] 帮助信息
* `zh_Hans` (string) \[optional] 中文帮助信息
* `en_US` (string) 英文帮助信息
* `required` (bool) 是否必填，默认 False。
* `default`(int/float/string/bool) \[optional] 默认值
* `min`(int/float) \[optional] 最小值，仅数字类型适用
* `max`(int/float) \[optional] 最大值，仅数字类型适用
* `precision`(int) \[optional] 精度，保留小数位数，仅数字类型适用
* `options` (array\[string]) \[optional] 下拉选项值，仅当 `type` 为 `string` 时适用，若不设置或为 null 则不限制选项值

### PriceConfig

* `input` (float) 输入单价，即 Prompt 单价
* `output` (float) 输出单价，即返回内容单价
* `unit` (float) 价格单位，如以 1M tokens 计价，则单价对应的单位 token 数为 `0.000001`
* `currency` (string) 货币单位

### ProviderCredentialSchema

* `credential_form_schemas` (array\[[CredentialFormSchema](model-designing-rules#credentialformschema)]) 凭据表单规范

### ModelCredentialSchema

* `model` (object) 模型标识，变量名默认 `model`
  * `label` (object) 模型表单项展示名称
    * `en_US` (string) 英文
    * `zh_Hans`(string) \[optional] 中文
  * `placeholder` (object) 模型提示内容
    * `en_US`(string) 英文
    * `zh_Hans`(string) \[optional] 中文
* `credential_form_schemas` (array\[[CredentialFormSchema](model-designing-rules#credentialformschema)]) 凭据表单规范

### CredentialFormSchema

* `variable` (string) 表单项变量名
* `label` (object) 表单项标签名
  * `en_US`(string) 英文
  * `zh_Hans` (string) \[optional] 中文
* `type` (\[FormType]\(#FormType)) 表单项类型
* `required` (bool) 是否必填
* `default`(string) 默认值
* `options` (array\[[FormOption](model-designing-rules#formoption)]) 表单项为 `select` 或 `radio` 专有属性，定义下拉内容
* `placeholder`(object) 表单项为 `text-input` 专有属性，表单项 PlaceHolder
  * `en_US`(string) 英文
  * `zh_Hans` (string) \[optional] 中文
* `max_length` (int) 表单项为`text-input`专有属性，定义输入最大长度，0 为不限制。
* `show_on` (array\[[FormShowOnObject](model-designing-rules#formshowonobject)]) 当其他表单项值符合条件时显示，为空则始终显示。

#### FormType

* `text-input` 文本输入组件
* `secret-input` 密码输入组件
* `select` 单选下拉
* `radio` Radio 组件
* `switch` 开关组件，仅支持 `true` 和 `false`

#### FormOption

* `label` (object) 标签
  * `en_US`(string) 英文
  * `zh_Hans`(string) \[optional] 中文
* `value` (string) 下拉选项值
* `show_on` (array\[[FormShowOnObject](model-designing-rules#formshowonobject)]) 当其他表单项值符合条件时显示，为空则始终显示。

#### FormShowOnObject

* `variable` (string) 其他表单项变量名
* `value` (string) 其他表单项变量值

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/model/model-designing-rules.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 模型接口
> 来源：`zh-hans/plugins/schema-definition/model/model-schema.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

这里介绍供应商和各模型类型需要实现的接口方法和参数说明。

### 模型供应商

继承 `__base.model_provider.ModelProvider` 基类，实现以下接口：

```python
def validate_provider_credentials(self, credentials: dict) -> None:
    """
    Validate provider credentials
    You can choose any validate_credentials method of model type or implement validate method by yourself,
    such as: get model list api

    if validate failed, raise exception

    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
    """
```

* `credentials` (object) 凭据信息

凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 定义，传入如：`api_key` 等。验证失败请抛出 `errors.validate.CredentialsValidateFailedError` 错误。**注：预定义模型需完整实现该接口，自定义模型供应商只需要如下简单实现即可：**

```python
class XinferenceProvider(Provider):
    def validate_provider_credentials(self, credentials: dict) -> None:
        pass
```

### 模型

模型分为 5 种不同的模型类型，不同模型类型继承的基类不同，需要实现的方法也不同。

#### 通用接口

所有模型均需要统一实现下面 2 个方法：

* 模型凭据校验

与供应商凭据校验类似，这里针对单个模型进行校验。

```python
def validate_credentials(self, model: str, credentials: dict) -> None:
    """
    Validate model credentials

    :param model: model name
    :param credentials: model credentials
    :return:
    """
```

参数：

* `model` (string) 模型名称
* `credentials` (object) 凭据信息

凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。验证失败请抛出 `errors.validate.CredentialsValidateFailedError` 错误。

* 调用异常错误映射表

当模型调用异常时需要映射到 Runtime 指定的 `InvokeError` 类型，方便 Dify 针对不同错误做不同后续处理。Runtime Errors:

* `InvokeConnectionError` 调用连接错误
* `InvokeServerUnavailableError` 调用服务方不可用
* `InvokeRateLimitError` 调用达到限额
* `InvokeAuthorizationError` 调用鉴权失败
* `InvokeBadRequestError` 调用传参有误

```python
@property
def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
    """
    Map model invoke error to unified error
    The key is the error type thrown to the caller
    The value is the error type thrown by the model,
    which needs to be converted into a unified error type for the caller.

    :return: Invoke error mapping
    """
```

也可以直接抛出对应 Erros，并做如下定义，这样在之后的调用中可以直接抛出`InvokeConnectionError`等异常。

#### LLM

继承 `__base.large_language_model.LargeLanguageModel` 基类，实现以下接口：

* LLM 调用

实现 LLM 调用的核心方法，可同时支持流式和同步返回。

```python
def _invoke(self, model: str, credentials: dict,
            prompt_messages: list[PromptMessage], model_parameters: dict,
            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,
            stream: bool = True, user: Optional[str] = None) \
        -> Union[LLMResult, Generator]:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param model_parameters: model parameters
    :param tools: tools for tool calling
    :param stop: stop words
    :param stream: is stream response
    :param user: unique user id
    :return: full response or stream response chunk generator result
    """
```

* 参数：
  * `model` (string) 模型名称
  * `credentials` (object) 凭据信息

凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

* `prompt_messages` (array\[[PromptMessage](model-schema#promptmessage)]) Prompt 列表

若模型为 `Completion` 类型，则列表只需要传入一个 [UserPromptMessage](model-schema#userpromptmessage) 元素即可；若模型为 `Chat` 类型，需要根据消息不同传入 [SystemPromptMessage](model-schema#systempromptmessage), [UserPromptMessage](model-schema#userpromptmessage), [AssistantPromptMessage](model-schema#assistantpromptmessage), [ToolPromptMessage](model-schema#toolpromptmessage) 元素列表

\- `model_parameters` (object) 模型参数模型参数由模型 YAML 配置的 `parameter_rules` 定义。

\- `tools` (array\[[PromptMessageTool](model-schema#promptmessagecontent)]) \[optional] 工具列表，等同于 `function calling` 中的 `function`。即传入 tool calling 的工具列表。

\- `stop` (array\[string]) \[optional] 停止序列模型返回将在停止序列定义的字符串之前停止输出。

\- `stream` (bool) 是否流式输出，默认 True流式输出返回 Generator\[[LLMResultChunk](model-schema#llmresultchunk)]，非流式输出返回 [LLMResult](model-schema#llmresult)。

\- `user` (string) \[optional] 用户的唯一标识符可以帮助供应商监控和检测滥用行为。

* 返回

流式输出返回 Generator\[[LLMResultChunk](model-schema#llmresultchunk)]，非流式输出返回 [LLMResult](model-schema#llmresult)。

* 预计算输入 tokens

若模型未提供预计算 tokens 接口，可直接返回 0。

```python
def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                   tools: Optional[list[PromptMessageTool]] = None) -> int:
    """
    Get number of tokens for given prompt messages

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param tools: tools for tool calling
    :return:
    """
```

参数说明见上述 `LLM 调用`。该接口需要根据对应`model`选择合适的`tokenizer`进行计算，如果对应模型没有提供`tokenizer`，可以使用`AIModel`基类中的`_get_num_tokens_by_gpt2(text: str)`方法进行计算。

* 获取自定义模型规则 \[可选]

```python
def get_customizable_model_schema(self, model: str, credentials: dict) -> Optional[AIModelEntity]:
    """
    Get customizable model schema

    :param model: model name
    :param credentials: model credentials
    :return: model schema
    """
```

当供应商支持增加自定义 LLM 时，可实现此方法让自定义模型可获取模型规则，默认返回 None。

对于 `OpenAI` 供应商下的大部分微调模型，可以通过其微调模型名称获取到其基类模型，如`gpt-3.5-turbo-1106`，然后返回基类模型的预定义参数规则，参考 [OpenAI](https://github.com/langgenius/dify-official-plugins/tree/main/models/openai) 的具体实现。

#### TextEmbedding

继承 `__base.text_embedding_model.TextEmbeddingModel` 基类，实现以下接口：

* Embedding 调用

```python
def _invoke(self, model: str, credentials: dict,
            texts: list[str], user: Optional[str] = None) \
        -> TextEmbeddingResult:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param texts: texts to embed
    :param user: unique user id
    :return: embeddings result
    """
```

* 参数：

\
\-  `model` (string) 模型名称

\
\- `credentials` (object) 凭据信息

凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。

\
\- `texts` (array\[string]) 文本列表，可批量处理

\
\- `user` (string) \[optional] 用户的唯一标识符\
可以帮助供应商监控和检测滥用行为。

* 返回：

[TextEmbeddingResult](model-schema#textembeddingresult) 实体。

* 预计算 tokens

```python
def get_num_tokens(self, model: str, credentials: dict, texts: list[str]) -> int:
    """
    Get number of tokens for given prompt messages

    :param model: model name
    :param credentials: model credentials
    :param texts: texts to embed
    :return:
    """
```

参数说明见上述 `Embedding 调用`。

同上述 `LargeLanguageModel`，该接口需要根据对应 `model` 选择合适的 `tokenizer` 进行计算，如果对应模型没有提供 `tokenizer`，可以使用`AIModel`基类中的`_get_num_tokens_by_gpt2(text: str)`方法进行计算。

#### Rerank

继承 `__base.rerank_model.RerankModel` 基类，实现以下接口：

* rerank 调用

```python
def _invoke(self, model: str, credentials: dict,
            query: str, docs: list[str], score_threshold: Optional[float] = None, top_n: Optional[int] = None,
            user: Optional[str] = None) \
        -> RerankResult:
    """
    Invoke rerank model

    :param model: model name
    :param credentials: model credentials
    :param query: search query
    :param docs: docs for reranking
    :param score_threshold: score threshold
    :param top_n: top n
    :param user: unique user id
    :return: rerank result
    """
```

* 参数：

\
\- `model` (string) 模型名称\
\- `credentials` (object) 凭据信息\
凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。
\- `query` (string) 查询请求内容\
\- `docs` (array\[string]) 需要重排的分段列表\
\- `score_threshold` (float) \[optional] Score 阈值\
\- `top_n` (int) \[optional] 取前 n 个分段\
\- `user` (string) \[optional] 用户的唯一标识符\
可以帮助供应商监控和检测滥用行为。

* 返回：

[RerankResult](model-schema#rerankresult) 实体。

#### Speech2text

\
继承 `__base.speech2text_model.Speech2TextModel` 基类，实现以下接口：\

* Invoke 调用

```python
def _invoke(self, model: str, credentials: dict,
            file: IO[bytes], user: Optional[str] = None) \
        -> str:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param file: audio file
    :param user: unique user id
    :return: text for given audio file
    """        
```

* 参数：

\
\- `model` (string) 模型名称\
\- `credentials` (object) 凭据信息\
凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。
\- `file` (File) 文件流\
\- `user` (string) \[optional] 用户的唯一标识符\
可以帮助供应商监控和检测滥用行为。

* 返回：

语音转换后的字符串。

#### Text2speech

继承 `__base.text2speech_model.Text2SpeechModel` 基类，实现以下接口：

* Invoke 调用

```python
def _invoke(self, model: str, credentials: dict, content_text: str, streaming: bool, user: Optional[str] = None):
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param content_text: text content to be translated
    :param streaming: output is streaming
    :param user: unique user id
    :return: translated audio file
    """        
```

* 参数：

\
\- `model` (string) 模型名称\
\- `credentials` (object) 凭据信息\
凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。
\- `content_text` (string) 需要转换的文本内容\
\- `streaming` (bool) 是否进行流式输出\
\- `user` (string) \[optional] 用户的唯一标识符\
可以帮助供应商监控和检测滥用行为。

* 返回：

文本转换后的语音流。

#### Moderation

继承 `__base.moderation_model.ModerationModel` 基类，实现以下接口：

* Invoke 调用

```python
def _invoke(self, model: str, credentials: dict,
            text: str, user: Optional[str] = None) \
        -> bool:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param text: text to moderate
    :param user: unique user id
    :return: false if text is safe, true otherwise
    """
```

* 参数：

\
\- `model` (string) 模型名称\
\- `credentials` (object) 凭据信息\
凭据信息的参数由供应商 YAML 配置文件的 `provider_credential_schema` 或 `model_credential_schema` 定义，传入如：`api_key` 等。
\- `text` (string) 文本内容\
\- `user` (string) \[optional] 用户的唯一标识符\
可以帮助供应商监控和检测滥用行为。

* 返回：

False 代表传入的文本安全，True 则反之。

### 实体

#### PromptMessageRole

消息角色

```python
class PromptMessageRole(Enum):
    """
    Enum class for prompt message.
    """
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"
    TOOL = "tool"
```

#### PromptMessageContentType

消息内容类型，分为纯文本和图片。

```python
class PromptMessageContentType(Enum):
    """
    Enum class for prompt message content type.
    """
    TEXT = 'text'
    IMAGE = 'image'
```

#### PromptMessageContent

消息内容基类，仅作为参数声明用，不可初始化。

```python
class PromptMessageContent(BaseModel):
    """
    Model class for prompt message content.
    """
    type: PromptMessageContentType
    data: str  # 内容数据
```

当前支持文本和图片两种类型，可支持同时传入文本和多图。
需要分别初始化 `TextPromptMessageContent` 和 `ImagePromptMessageContent` 传入。

#### TextPromptMessageContent

```python
class TextPromptMessageContent(PromptMessageContent):
    """
    Model class for text prompt message content.
    """
    type: PromptMessageContentType = PromptMessageContentType.TEXT
```

若传入图文，其中文字需要构造此实体作为 `content` 列表中的一部分。

#### ImagePromptMessageContent

```python
class ImagePromptMessageContent(PromptMessageContent):
    """
    Model class for image prompt message content.
    """
    class DETAIL(Enum):
        LOW = 'low'
        HIGH = 'high'

    type: PromptMessageContentType = PromptMessageContentType.IMAGE
    detail: DETAIL = DETAIL.LOW  # 分辨率
```

若传入图文，其中图片需要构造此实体作为 `content` 列表中的一部分\
`data` 可以为 `url` 或者图片 `base64` 加密后的字符串。

#### PromptMessage

所有 Role 消息体的基类，仅作为参数声明用，不可初始化。

```python
class PromptMessage(ABC, BaseModel):
    """
    Model class for prompt message.
    """
    role: PromptMessageRole  # 消息角色
    content: Optional[str | list[PromptMessageContent]] = None  # 支持两种类型，字符串和内容列表，内容列表是为了满足多模态的需要，可详见 PromptMessageContent 说明。
    name: Optional[str] = None  # 名称，可选。
```

#### UserPromptMessage

UserMessage 消息体，代表用户消息。

```python
class UserPromptMessage(PromptMessage):
    """
    Model class for user prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.USER
```

#### AssistantPromptMessage

代表模型返回消息，通常用于 `few-shots` 或聊天历史传入。

```python
class AssistantPromptMessage(PromptMessage):
    """
    Model class for assistant prompt message.
    """
    class ToolCall(BaseModel):
        """
        Model class for assistant prompt message tool call.
        """
        class ToolCallFunction(BaseModel):
            """
            Model class for assistant prompt message tool call function.
            """
            name: str  # 工具名称
            arguments: str  # 工具参数

        id: str  # 工具 ID，仅在 OpenAI tool call 生效，为工具调用的唯一 ID，同一个工具可以调用多次
        type: str  # 默认 function
        function: ToolCallFunction  # 工具调用信息

    role: PromptMessageRole = PromptMessageRole.ASSISTANT
    tool_calls: list[ToolCall] = []  # 模型回复的工具调用结果（仅当传入 tools，并且模型认为需要调用工具时返回）
```

其中 `tool_calls` 为调用模型传入 `tools` 后，由模型返回的 `tool call` 列表。

#### SystemPromptMessage

代表系统消息，通常用于设定给模型的系统指令。

```python
class SystemPromptMessage(PromptMessage):
    """
    Model class for system prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.SYSTEM
```

#### ToolPromptMessage

代表工具消息，用于工具执行后将结果交给模型进行下一步计划。

```python
class ToolPromptMessage(PromptMessage):
    """
    Model class for tool prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.TOOL
    tool_call_id: str  # 工具调用 ID，若不支持 OpenAI tool call，也可传入工具名称
```

基类的 `content` 传入工具执行结果。

#### PromptMessageTool

```python
class PromptMessageTool(BaseModel):
    """
    Model class for prompt message tool.
    """
    name: str  # 工具名称
    description: str  # 工具描述
    parameters: dict  # 工具参数 dict

```

***

#### LLMResult

```python
class LLMResult(BaseModel):
    """
    Model class for llm result.
    """
    model: str  # 实际使用模型
    prompt_messages: list[PromptMessage]  # prompt 消息列表
    message: AssistantPromptMessage  # 回复消息
    usage: LLMUsage  # 使用的 tokens 及费用信息
    system_fingerprint: Optional[str] = None  # 请求指纹，可参考 OpenAI 该参数定义
```

#### LLMResultChunkDelta

流式返回中每个迭代内部 `delta` 实体

```python
class LLMResultChunkDelta(BaseModel):
    """
    Model class for llm result chunk delta.
    """
    index: int  # 序号
    message: AssistantPromptMessage  # 回复消息
    usage: Optional[LLMUsage] = None  # 使用的 tokens 及费用信息，仅最后一条返回
    finish_reason: Optional[str] = None  # 结束原因，仅最后一条返回
```

#### LLMResultChunk

流式返回中每个迭代实体

```python
class LLMResultChunk(BaseModel):
    """
    Model class for llm result chunk.
    """
    model: str  # 实际使用模型
    prompt_messages: list[PromptMessage]  # prompt 消息列表
    system_fingerprint: Optional[str] = None  # 请求指纹，可参考 OpenAI 该参数定义
    delta: LLMResultChunkDelta  # 每个迭代存在变化的内容
```

#### LLMUsage

```python
class LLMUsage(ModelUsage):
    """
    Model class for llm usage.
    """
    prompt_tokens: int  # prompt 使用 tokens
    prompt_unit_price: Decimal  # prompt 单价
    prompt_price_unit: Decimal  # prompt 价格单位，即单价基于多少 tokens 
    prompt_price: Decimal  # prompt 费用
    completion_tokens: int  # 回复使用 tokens
    completion_unit_price: Decimal  # 回复单价
    completion_price_unit: Decimal  # 回复价格单位，即单价基于多少 tokens 
    completion_price: Decimal  # 回复费用
    total_tokens: int  # 总使用 token 数
    total_price: Decimal  # 总费用
    currency: str  # 货币单位
    latency: float  # 请求耗时(s)
```

***

#### TextEmbeddingResult

```python
class TextEmbeddingResult(BaseModel):
    """
    Model class for text embedding result.
    """
    model: str  # 实际使用模型
    embeddings: list[list[float]]  # embedding 向量列表，对应传入的 texts 列表
    usage: EmbeddingUsage  # 使用信息
```

#### EmbeddingUsage

```python
class EmbeddingUsage(ModelUsage):
    """
    Model class for embedding usage.
    """
    tokens: int  # 使用 token 数
    total_tokens: int  # 总使用 token 数
    unit_price: Decimal  # 单价
    price_unit: Decimal  # 价格单位，即单价基于多少 tokens
    total_price: Decimal  # 总费用
    currency: str  # 货币单位
    latency: float  # 请求耗时(s)
```

***

#### RerankResult

```python
class RerankResult(BaseModel):
    """
    Model class for rerank result.
    """
    model: str  # 实际使用模型
    docs: list[RerankDocument]  # 重排后的分段列表        
```

#### RerankDocument

```python
class RerankDocument(BaseModel):
    """
    Model class for rerank document.
    """
    index: int  # 原序号
    text: str  # 分段文本内容
    score: float  # 分数
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/model/model-schema.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 持久化存储
> 来源：`zh-hans/plugins/schema-definition/persistent-storage.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

如果单独审视插件中的 Tool 及 Endpoint，不难发现大多数情况下其只能完成单轮交互，请求后返回数据，任务结束。

如果有需要长期储存的数据，如实现持久化的记忆，需要插件具备持久化存储能力。**持久化储机制能够让插件具备在相同 Workspace 持久存储数据的能力**，目前通过提供 KV 数据库满足存储需求，未来可能会根据实际的使用情况推出更灵活更强大的储存接口。

### 储存 Key

#### **入口**

```python
    self.session.storage
```

#### **接口**

```python
    def set(self, key: str, val: bytes) -> None:
        pass
```

可以注意到传入的是一个 bytes，因此实际上你可以在其中储存文件。

### 获取 Key

#### **入口**

```python
    self.session.storage
```

#### **接口**

```python
    def get(self, key: str) -> bytes:
        pass
```

### 删除 Key

#### **入口**

```python
    self.session.storage
```

#### **接口**

```python
    def delete(self, key: str) -> None:
        pass
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/persistent-storage.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 反向调用 Dify 服务
> 来源：`zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/README.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

插件可以自由调用 Dify 主平台内的部分服务，用以提升插件的能力。

### 可被调用的 Dify 模块

*   [App](app)

    插件能够访问 Dify 平台内 App 的数据。
*   [Model](model)

    插件能够反向调用 Dify 平台内的 LLM 能力，包括平台内的所有模型类型与功能，例如 TTS、Rerank 等。
*   [Tool](tool)

    插件能够调用 Dify 平台内的其它工具类型插件。
*   [Node](node)

    插件能够调用 Dify 平台内某个 Chatflow/Workflow 应用内的节点。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## App
> 来源：`zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/app.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

反向调用 App 指的是插件能够访问 Dify 中的 App 数据。该模块同时支持流式与非流式的 App 调用。

**接口类型：**

* 对于 `Chatbot/Agent/Chatflow`  类型应用而言，它们都属于聊天类型的应用，因此拥有相同类型的输入参数和输出参数，因此可被统一视为**聊天接口。**
* 对于 Workflow 应用而言，它单独占据一个 **Workflow 接口。**
* 对于 Completion（文本生成应用）应用而言，它单独占据一个 **Completion 接口**。

请注意，插件仅允许访问插件所在的 Workspace 中的 App。

### 调用聊天接口

#### **入口**

```python
    self.session.app.chat
```

#### **接口规范**

```python
    def invoke(
        self,
        app_id: str,
        inputs: dict,
        response_mode: Literal["streaming", "blocking"],
        conversation_id: str,
        files: list,
    ) -> Generator[dict, None, None] | dict:
        pass
```

当 `response_mode` 为 `streaming` 时，该接口将直接返回 `Generator[dict]`，否则直接返回 `dict`，具体的接口字段请参考 `ServiceApi` 的返回结果。

#### **用例**

我们可以在一个 `Endpoint` 中调用 Chat 类型的 App，并将结果直接返回。

```python

from typing import Mapping
from werkzeug import Request, Response
from dify_plugin import Endpoint

class Duck(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        """
        Invokes the endpoint with the given request.
        """
        app_id = values["app_id"]

        def generator():
            response = self.session.app.workflow.invoke(
                app_id=app_id, inputs={}, response_mode="streaming", files=[]
            )

            for data in response:
                yield f"json.dumps(data)   
"

        return Response(generator(), status=200, content_type="text/html")
```

### 调用 Workflow 接口

#### **入口**

```python
    self.session.app.workflow
```

#### **接口规范**

```python
    def invoke(
        self,
        app_id: str,
        inputs: dict,
        response_mode: Literal["streaming", "blocking"],
        files: list,
    ) -> Generator[dict, None, None] | dict:
        pass
```

### 调用 Completion 接口

#### **入口**

```python
    self.session.app.completion
```

**接口规范**

```python
    def invoke(
        self,
        app_id: str,
        inputs: dict,
        response_mode: Literal["streaming", "blocking"],
        files: list,
    ) -> Generator[dict, None, None] | dict:
        pass
```

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/app.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Model
> 来源：`zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/model.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

反向调用 Model 指的是插件能够反向调用 Dify 内 LLM 的能力，包括平台内的所有模型类型与功能，例如 TTS、Rerank 等。

不过请注意，调用模型需要传入一个 `ModelConfig` 类型的参数，它的结构可以参考 [通用规范定义](../general-specifications)，并且对于不同类型的模型，该结构会存在细微的差别。

例如对于 `LLM` 类型的模型，还需要包含 `completion_params` 与 `mode` 参数，你可以手动构建该结构，或者使用 `model-selector` 类型的参数或配置。

### 调用 LLM

#### **入口**

```python
    self.session.model.llm
```

#### **端点**

```python
    def invoke(
        self,
        model_config: LLMModelConfig,
        prompt_messages: list[PromptMessage],
        tools: list[PromptMessageTool] | None = None,
        stop: list[str] | None = None,
        stream: bool = True,
    ) -> Generator[LLMResultChunk, None, None] | LLMResult:
        pass
```

请注意，如果你调用的模型不具备 `tool_call` 的能力，那么此处传入的 `tools` 将不会生效。

#### **用例**

如果想在 `Tool` 中调用 `OpenAI` 的 `gpt-4o-mini` 模型，请参考以下示例代码：

```python
from collections.abc import Generator
from typing import Any

from dify_plugin import Tool
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin.entities.model.message import SystemPromptMessage, UserPromptMessage

class LLMTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        response = self.session.model.llm.invoke(
            model_config=LLMModelConfig(
                provider='openai',
                model='gpt-4o-mini',
                mode='chat',
                completion_params={}
            ),
            prompt_messages=[
                SystemPromptMessage(
                    content='you are a helpful assistant'
                ),
                UserPromptMessage(
                    content=tool_parameters.get('query')
                )
            ],
            stream=True
        )

        for chunk in response:
            if chunk.delta.message:
                assert isinstance(chunk.delta.message.content, str)
                yield self.create_text_message(text=chunk.delta.message.content)
```

可以留意到代码中传入了 `tool_parameters` 中的 `query` 参数。

### **最佳实践**

并不建议手动来构建 `LLMModelConfig`，而是允许用户可以在 UI 上选择自己想使用的模型，在这种情况下可以修改一下工具的参数列表，按照如下配置，添加一个 `model` 参数：

```yaml
identity:
  name: llm
  author: Dify
  label:
    en_US: LLM
    zh_Hans: LLM
    pt_BR: LLM
description:
  human:
    en_US: A tool for invoking a large language model
    zh_Hans: 用于调用大型语言模型的工具
    pt_BR: A tool for invoking a large language model
  llm: A tool for invoking a large language model
parameters:
  - name: prompt
    type: string
    required: true
    label:
      en_US: Prompt string
      zh_Hans: 提示字符串
      pt_BR: Prompt string
    human_description:
      en_US: used for searching
      zh_Hans: 用于搜索网页内容
      pt_BR: used for searching
    llm_description: key words for searching
    form: llm
  - name: model
    type: model-selector
    scope: llm
    required: true
    label:
      en_US: Model
      zh_Hans: 使用的模型
      pt_BR: Model
    human_description:
      en_US: Model
      zh_Hans: 使用的模型
      pt_BR: Model
    llm_description: which Model to invoke
    form: form
extra:
  python:
    source: tools/llm.py
```

请注意在该例子中指定了 `model` 的 `scope` 为 `llm`，那么此时用户就只能选择 `llm` 类型的参数，从而可以将上述用例的代码改成以下代码：

```python
from collections.abc import Generator
from typing import Any

from dify_plugin import Tool
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin.entities.model.message import SystemPromptMessage, UserPromptMessage

class LLMTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        response = self.session.model.llm.invoke(
            model_config=tool_parameters.get('model'),
            prompt_messages=[
                SystemPromptMessage(
                    content='you are a helpful assistant'
                ),
                UserPromptMessage(
                    content=tool_parameters.get('query')
                )
            ],
            stream=True
        )

        for chunk in response:
            if chunk.delta.message:
                assert isinstance(chunk.delta.message.content, str)
                yield self.create_text_message(text=chunk.delta.message.content)
```

### 调用 Summary

你可以请求该端点来总结一段文本，它会使用你当前 workspace 内的系统模型来总结文本。

**入口**

```python
    self.session.model.summary
```

**端点**

* `text` 为需要被总结的文本。
* `instruction` 为你想要额外添加的指令，它可以让你风格化地总结文本。

```python
    def invoke(
        self, text: str, instruction: str,
    ) -> str:
```

### 调用 TextEmbedding

**入口**

```python
    self.session.model.text_embedding
```

**端点**

```python
    def invoke(
        self, model_config: TextEmbeddingResult, texts: list[str]
    ) -> TextEmbeddingResult:
        pass
```

### 调用 Rerank

**入口**

```python
    self.session.model.rerank
```

**端点**

```python
    def invoke(
        self, model_config: RerankModelConfig, docs: list[str], query: str
    ) -> RerankResult:
        pass
```

### 调用 TTS

**入口**

```python
    self.session.model.tts
```

**端点**

```python
    def invoke(
        self, model_config: TTSModelConfig, content_text: str
    ) -> Generator[bytes, None, None]:
        pass
```

请注意 `tts` 端点返回的 `bytes` 流是一个 `mp3` 音频字节流，每一轮迭代返回的都是一个完整的音频。如果你想做更深入的处理任务，请选择合适的库进行。

### 调用 Speech2Text

**入口**

```python
    self.session.model.speech2text
```

**端点**

```python
    def invoke(
        self, model_config: Speech2TextModelConfig, file: IO[bytes]
    ) -> str:
        pass
```

其中 `file` 是一个 `mp3` 格式编码的音频文件。

### 调用 Moderation

**入口**

```python
    self.session.model.moderation
```

**端点**

```python
    def invoke(self, model_config: ModerationModelConfig, text: str) -> bool:
        pass
```

若该端点返回 `true` 则表示 `text` 中包含敏感内容。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/model.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Node
> 来源：`zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/node.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

反向调用 Node 指的是插件能够访问 Dify 中 Chatflow/Workflow 应用内部分节点的能力。

`Workflow` 中的 `ParameterExtractor（参数提取器）`与 `QuestionClassifier（问题分类）`节点封装了较为复杂的 Prompt 与代码逻辑，可以通过 LLM 来完成许多硬编码难以解决的任务。插件能够调用这两个节点。

### 调用参数提取器节点;

#### **入口**

```python
    self.session.workflow_node.parameter_extractor
```

#### **接口**

```python
    def invoke(
        self,
        parameters: list[ParameterConfig],
        model: ModelConfig,
        query: str,
        instruction: str = "",
    ) -> NodeResponse
        pass
```

其中 `parameters` 是需要提取出的参数的列表，`model` 符合 `LLMModelConfig` 规范，`query` 为提取参数的源文本，`instruction` 为一些可能额外需要给到 LLM 的指令，`NodeResponse` 的结构请参考该[文档](../general-specifications#noderesponse)。

#### **用例**

如果想要提取对话中的某个人名，可以参考以下代码：

```python
from collections.abc import Generator
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin import Tool
from dify_plugin.entities.workflow_node import ModelConfig, ParameterConfig

class ParameterExtractorTool(Tool):
    def _invoke(
        self, tool_parameters: dict
    ) -> Generator[ToolInvokeMessage, None, None]:
        response = self.session.workflow_node.parameter_extractor.invoke(
            parameters=[
                ParameterConfig(
                    name="name",
                    description="name of the person",
                    required=True,
                    type="string",
                )
            ],
            model=ModelConfig(
                provider="langgenius/openai/openai",
                name="gpt-4o-mini",
                completion_params={},
            ),
            query="My name is John Doe",
            instruction="Extract the name of the person",
        )

        yield self.create_text_message(response.outputs["name"])
```

### 调用问题分类节点

#### **入口**

```python
    self.session.workflow_node.question_classifier
```

#### **接口**

```python
    def invoke(
        self,
        classes: list[ClassConfig],
        model: ModelConfig,
        query: str,
        instruction: str = "",
    ) -> NodeResponse:
        pass
```

该接口参数与 `ParameterExtractor` 一致，最终的返回结果储存在 `NodeResponse.outputs['class_name']` 中。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/node.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Tool
> 来源：`zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/tool.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

当遇到以下需求时：

* 某个工具类型插件已经实现好了一个功能，但效果未达预期，需要对数据进行二次加工。
* 某个任务需要使用到爬虫，希望能够自由选择爬虫服务。
* 需要集合多个工具的返回结果，但是通过 Workflow 应用不好处理。

此时需要在插件中调用其他已经实现好的工具，该工具可能是市场中的某个工具插件，可能是自主构建的 Workflow as a Tool，亦或是自定义工具。

上述需求可以通过调用插件的 `self.session.tool` 字段来实现。

### 调用已安装的工具

允许插件调用已安装在当前 Workspace 内的各个工具，其中也包含其它工具类型的插件。

**入口**

```python
    self.session.tool
```

**接口**

```python
    def invoke_builtin_tool(
        self, provider: str, tool_name: str, parameters: dict[str, Any]
    ) -> Generator[ToolInvokeMessage, None, None]:
        pass
```

其中 provider 为 plugin 的 ID 加上工具供应商名称，格式形如 `langgenius/google/google`，tool\_name 为具体的工具名称，`parameters` 为最后传递给该工具的参数。

### 调用 Workflow as Tool

如需了解关于 Workflow as Tool 的更多说明，请参考[此文档](tool#diao-yong-workflow-as-tool)。

**入口**

```python
    self.session.tool
```

**接口**

```python
    def invoke_workflow_tool(
        self, provider: str, tool_name: str, parameters: dict[str, Any]
    ) -> Generator[ToolInvokeMessage, None, None]:
        pass
```

此时的 provider 为该 tool 的 ID，tool\_name 在创建该 tool 的时候会要求填写。

### 调用 Custom Tool

**入口**

```python
    self.session.tool
```

**接口**

```python
    def invoke_api_tool(
        self, provider: str, tool_name: str, parameters: dict[str, Any]
    ) -> Generator[ToolInvokeMessage, None, None]:
        pass
```

此时的 `provider` 为该 tool 的 ID，`tool_name` 为 OpenAPI 中的 `operation_id`，若不存在，即为 Dify 自动生成的 `tool_name`，可以在工具管理页中看到具体的名称。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/reverse-invocation-of-the-dify-service/tool.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Tool
> 来源：`zh-hans/plugins/schema-definition/tool.mdx`

<p>作为我们文档重组的一部分，此页面正在逐步淘汰。</p>

  <p><u><b>点击此卡片</b></u>跳转到包含最新信息的更新版本。</p>

  <p>如果您在新的文档中发现任何差异或需要改进的地方，请使用页面底部的“报告问题”按钮。</p>

在阅读详细的接口文档之前，请确保你已经阅读过[快速开始开发插件：工具](./zh-hans/plugins/quick-start/develop-plugins/tool-plugin)，并对 Dify 插件的工具接入流程已有大致了解。

### 数据结构

#### 消息返回

Dify 支持`文本` `链接` `图片` `文件BLOB` `JSON` 等多种消息类型，你可以通过以下不同的接口返回不同类型的消息。

在默认情况下，一个工具在 `workflow` 中的输出会包含 `files` `text` `json` 三个固定变量，且你可以通过下面的方法来返回这三个变量的数据。

例如使用 `create_image_message` 来返回图片，但是同时工具也支持自定义的输出变量，从而可以更方便地在 `workflow` 中引用这些变量。

#### **图片 URL**

只需要传递图片的 URL，Dify 将通过链接自动下载图片并返回给用户。

```python
    def create_image_message(self, image: str) -> ToolInvokeMessage:
        pass
```

#### **链接**

如果你需要返回一个链接，使用以下接口。

```python
    def create_link_message(self, link: str) -> ToolInvokeMessage:
        pass
```

#### **文本**

如果你需要返回一个文本消息，使用以下接口。

```python
    def create_text_message(self, text: str) -> ToolInvokeMessage:
        pass
```

**文件**

如果你需要返回文件的原始数据，如图片、音频、视频、PPT、Word、Excel 等，可以使用以下接口。

* `blob` 文件的原始数据，bytes 类型。
* `meta` 文件的元数据。如果开发者需要明确的文件类型，请指定`mime_type`，否则 Dify 将使用`octet/stream`作为默认类型。

```python
    def create_blob_message(self, blob: bytes, meta: dict = None) -> ToolInvokeMessage:
        pass
```

#### **JSON**

如果你需要返回一个格式化的 JSON，可以使用以下接口。这通常用于 workflow 中的节点间的数据传递。在 agent 模式中，大部分大模型也都能够阅读和理解 JSON。

* `object` 一个 Python 的字典对象，会被自动序列化为 JSON。

```python
    def create_json_message(self, json: dict) -> ToolInvokeMessage:
        pass
```

#### **变量**

对于非流式输出的变量，你可以使用以下接口返回，如创建多份，后者将覆盖前者。

```python
    def create_variable_message(self, variable_name: str, variable_value: Any) -> ToolInvokeMessage:
        pass
```

#### **流式变量**

如果你想以“打字机”效果输出一段文字，可以使用流式变量输出文本。如果你在 `chatflow` 应用中使用 `answer` 节点并引用了该变量，那么文本将以“打字机”的效果输出。但目前该方法仅支持字符串类型的数据。

```python
    def create_stream_variable_message(
        self, variable_name: str, variable_value: str
    ) -> ToolInvokeMessage:
```

#### 返回变量定义

如果想要在 `workflow` 应用中引用 `tool` 的输出变量，则有必要提前定义有哪些变量可能被输出。Dify 插件支持使用 [`json_schema`](https://json-schema.org/)格式的输出变量定义，以下是一个简单的示例：

```yaml
identity:
  author: author
  name: tool
  label:
    en_US: label
    zh_Hans: 标签
    ja_JP: レベル
    pt_BR: etiqueta
description:
  human:
    en_US: description
    zh_Hans: 描述
    ja_JP: 説明
    pt_BR: descrição
  llm: description
output_schema:
  type: object
  properties:
    name:
      type: string
```

上述示例代码定义了一个简单的工具，并为它指定了 `output_schema`，其中包含一个 `name` 字段，此时可以在 `workflow` 中引用该字段。但是请注意，还需要在工具的实现代码中返回一个变量才可以真正使用，否则将得到一个 `None` 返回结果。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/plugins/schema-definition/tool.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 用户协议
> 来源：`zh-hans/policies/agreement/README.mdx`

### 服务条款与隐私政策

您可以通过以下内容了解在使用 Dify.AI 时需遵循的服务条款和隐私政策。

* [服务条款](https://dify.ai/terms)
* [隐私政策](https://dify.ai/privacy)

### 合规认证

Dify.AI 已获取以下认证：

* **SOC 2 Type I**
* **SOC 2 Type II**
* **ISO 27001:2022 Certification**
* **GDPR DPA**

如需了解如何下载并查看上述合规证书，请参考以下文档：

  获取合规报告

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/policies/agreement/README.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 获取合规报告
> 来源：`zh-hans/policies/agreement/get-compliance-report.mdx`

Dify.AI 在产品上线之初就收到了来自全球个人开发者和企业用户的询问：_**Dify.AI 是否符合信息安全和数据隐私合规要求？**_&#x56E0;此，团队从产品设计阶段起便严格遵循行业标准，逐步建立了完善的信息安全与数据隐私合规管理体系。

Dify.AI 已正式通过 **SOC 2 Type I、SOC 2 Type II、ISO 27001:2022 及 GDPR** 认证，标志着产品在数据安全、隐私保护及合规性方面达到了国际领先标准。这一里程碑进一步彰显了 Dify.AI 对用户数据安全的坚定承诺。

如果您使用 Dify 的云版本作为供应商安全评估的一部分，您可以点击页面**右上角**，选择**合规性**，下载所需的报告，查看 Dify 的合规性报告和认证。

对于企业版客户，如需查看合规报告证书，请联系对接人员发起商务流程以获取合规性报告。

### 可用的合规认证

不同等级的 Dify 团队所可以下载和查看不同的合规认证：

<table>
  <thead>
    <tr>
      <th>合规报告</th>
      <th>Free / Sandbox</th>
      <th>Professional</th>
      <th>Team</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>SOC 2 Type I Report</td>
      <td>-</td>
      <td>✅</td>
      <td>✅</td>
    </tr>
    <tr>
      <td>SOC 2 Type II Report</td>
      <td>-</td>
      <td>-</td>
      <td>✅</td>
    </tr>
    <tr>
      <td>ISO 27001: 2022 Certificate</td>
      <td>-</td>
      <td>-</td>
      <td>✅</td>
    </tr>
    <tr>
      <td>GDPR Data Processing Agreement</td>
      <td>✅</td>
      <td>✅</td>
      <td>✅</td>
    </tr>
  </tbody>
</table>
> 如果你当前的团队级别无法查看所需要的合规认证，请前往[定价页](https://dify.ai/pricing)升级你的团队。

下文将为你说明如何获取不同的合规认证报告。

#### SOC 2 Type I 报告

**SOC 2 Type I** 报告是一份第三方审计报告，用于评估和确认组织在特定时间点的安全控制措施的设计和实施情况。SOC 2（**System and Organization Controls 2**）是基于五个信任服务原则制定的数据管理和保护标准：**安全性、可用性、处理完整性、机密性和隐私**。Type I 报告专门用于评估组织在审计时是否具备满足相关标准的适当控制措施。

仅团队**所有者**可以在 **右上角 → 合规** 下载 Dify 的 SOC 2 Type I 报告。

![SOC 2 Type I 报告](https://assets-docs.dify.ai/2025/02/552f4358bea904c4bf12a131a410916c.png)

#### SOC 2 Type II 报告

**SOC 2 Type II** 报告是一份第三方审计报告，用于评估和确认组织在特定时期内的安全控制措施的设计和实施情况。SOC 2（**System and Organization Controls 2**）是基于五个信任服务原则制定的数据管理和保护标准：**安全性、可用性、处理完整性、机密性和隐私**。Type II 报告详细说明了组织的安全控制措施在一段时间内的运行效果，让利益相关者确信组织始终遵守敏感数据管理的行业标准。

仅团队**所有者**可以在 **右上角 → 合规** 下载 Dify 的 SOC 2 Type II 报告。

![SOC 2 Type II 报告](https://assets-docs.dify.ai/2025/02/06975e86faba9928a11c962a57aa454f.png)

#### ISO 27001:2022 认证

**ISO 27001:2022** 认证是一项国际认可的**信息安全管理体系（ISMS）**&#x6807;准。它是 **ISO/IEC 27000 标准族**的一部分，通过全面的安全控制措施保护敏感信息。ISO 27001:2022 标准旨在帮助组织建立、实施、维护和持续改进其信息安全管理体系。**2022** 版本的标准反映了信息安全领域的最新更新和最佳实践，以适应当前的安全挑战和技术进步。它通过实施风险管理和安全控制，为管理公司敏感信息提供了系统方法，确保信息的机密性、完整性和可用性。

仅团队**所有者**可以在 **右上角 → 合规** 下载 Dify 的 ISO 27001:2022 报告。

![ISO 27001:2022 报告](https://assets-docs.dify.ai/2025/02/7aaf7771af28bf7182bf7fda40c7b5bb.png)

#### GDPR 数据处理协议

**数据保护协议（DPA）是根据通用数据保护条例（GDPR）要求，在数据控制者**和**数据处理者**之间签订的具有法律约束力的合同。GDPR 于 2018 年 5 月生效，为欧盟（EU）内的数据保护制定了法律框架，适用于处理欧盟居民个人数据的组织。当数据控制者聘请第三方处理者处理个人数据时，需要签订 DPA，以确保双方遵守 GDPR 义务并保护数据主体的权利。

**任何人**都可以在 Dify.AI 官方网站下载 Dify 的 DPA。

![DPA](https://assets-docs.dify.ai/2025/02/291cddb3bf9dfd8c92967eabb87b95a0.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/policies/agreement/get-compliance-report.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 隐私政策
> 来源：`zh-hans/policies/agreement/privacy.mdx`

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/policies/agreement/privacy.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 服务条款
> 来源：`zh-hans/policies/agreement/tos.mdx`

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/policies/agreement/tos.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 开源许可
> 来源：`zh-hans/policies/open-source.mdx`

Dify 的社区版本是开源的，采用基于 Apache 2.0 的开源许可，并附加额外条件。详细信息请参阅 [LICENSE](https://github.com/langgenius/dify/blob/main/LICENSE) 文件。

如有任何许可相关的问题或疑问，请联系 [business@dify.ai](mailto:business@dify.ai)。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/policies/open-source.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Dify 品牌使用指南
> 来源：`zh-hans/resources/about-dify/dify-brand-guidelines.mdx`

Dify 的品牌识别不仅仅是一个徽标，它代表着我们对“理性构建、系统性清晰与开放协作”的理念承诺。
当你被正式授权或认可为 Dify 生态的一部分时，你所传递的，正是我们所坚持的价值观。
在任何官方或合作身份下使用 Dify 品牌资产，即意味着你共同承担起维护品牌视觉系统与产品理念的一部分责任。
所有使用行为必须遵循《Dify 品牌使用指南》，并与《品牌使用条款》中所阐述的原则保持一致。
未经明确书面授权，不得以任何方式暗示 Dify 的官方背书、合作关系或认证。
若发现误用，Dify 有权随时撤销使用权限。

参考：[Dify 品牌使用条款](./zh-hans/resources/about-dify/dify-brand-usage-terms)。

## 我们的徽标

![](https://assets-docs.dify.ai/2025/05/8fdc43456b4eaa80a97144f572734d15.png)

## 徽标使用规范

Dify 的徽标不只是产品标识，它代表着信任、清晰与技术可信度。
为维护品牌完整性，徽标的使用必须符合官方指南。
不当使用或随意放置可能会产生误导，暗示非实际存在的合作关系。
请在明确允许的情境下，合理、规范地使用 Dify 徽标。

### 适用场景示例

- 与 Dify 官方合作伙伴的联合品牌内容
- 作为 Dify 赞助商或参展方出现在活动素材中
- 多品牌展示环境中出现（如「logo garden」）
- 在引用 Dify 技术的文档、演示或产品集成中使用

## 配色规范

在条件允许的情况下，优先使用 Dify 官方双色徽标。
该版本最能体现我们品牌在结构与清晰度之间的视觉平衡。
如遇以下情况，可使用替代色版本：

- 背景颜色限制对比度
- 特定印刷或数字环境中技术受限
- 排版需要使用单色或反白版本

![](https://assets-docs.dify.ai/2025/05/099d7f811983533566c3269dd7e3ccd2.png)

## 保持清晰可读

为确保识别性和清晰度，Dify 徽标四周应保留最小安全留白区域，避免被文字、图片或其他图形元素干扰。
- 若空间允许，建议留出更多留白以提升可读性。
- 请勿压缩或靠近其他元素，遵守留白规范是确保品牌统一性的关键。

![](https://assets-docs.dify.ai/2025/05/e001f6009c7a64c97f7174c7efc7c061.png)

## 联合品牌规范

![](https://assets-docs.dify.ai/2025/05/68800461c5b609f960446236d9022105.png)

当 Dify 与其他品牌联合出现时，请始终遵循以下排列规则，以确保视觉清晰与品牌平衡：
- 使用细线垂直分隔 Dify 徽标与合作方徽标
- 保持两者之间的相对位置和比例不变
- 不得更改排列顺序、对齐方式，或单独缩放任一徽标

## 多品牌排列规范

![](https://assets-docs.dify.ai/2025/05/234b116641e2590d656f5318ad2f02cc.png)

当 Dify 与两个或以上品牌并列时，请遵守以下规则：

- 多品牌并列时，不使用分隔线
- 所有徽标之间应保持统一、等距间隔
- 若合作由对方主导，对方徽标应置于最前，其他品牌（含 Dify）按英文字母顺序排列
- 所有徽标须等高对齐，不可变形或缩放
- 保持品牌配色、留白与整体间距一致

## 合作伙伴徽章使用规范

![](https://assets-docs.dify.ai/2025/05/3429fc70b342164bf145825fb47cc1fd.png)

Dify 合作伙伴徽章仅限 Dify 签约授权的合作伙伴使用，用于表示与 Dify 的官方关系。
徽章可用于合作方主导的市场传播、演示、文档或活动物料中，前提是内容中涉及 Dify 产品、集成或支持。
使用时须遵循以下规则：
- 保持徽章周围最小留白，避免视觉拥挤
- 不得更改徽章颜色
- 不得更改徽标比例或排版
- 不得替换或修改徽章内文字
- 徽章尺寸不得大于合作品牌徽标

## “Powered by Dify” 使用规范

“Powered by Dify” 徽章用于展示项目、产品或内容中集成了 Dify 的开源能力或平台服务。它是一种轻量表达，用于强调构建工具的来源，而非合作或背书关系。

### 适用场景

- 在网页、应用或系统中集成 Dify 功能时
- 在开源项目的文档页、README、演示界面或页脚处
- 在教学、演讲、博客等内容中展示使用了 Dify 技术栈

### 徽章使用规则

- 使用 Dify 提供的标准徽章，不得更改颜色、字体、比例或内容
- 徽章应清晰可辨，避免压缩变形或放置在干扰背景上

### 使用限制

- 不得暗示与 Dify 有官方认证、合作或商业支持关系
- 不得将徽章用于商业营销、收费课程、培训项目等涉及商业利益的场景，除非获得书面授权

## 下载资源

[下载 Dify 设计套件](https://assets-docs.dify.ai/2025/05/5f547d3718bf32067849d9a83d9c92cf.zip)。

---

© LangGenius, Inc. 保留所有权利。严禁未经授权使用 Dify 品牌资产。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/resources/about-dify/dify-brand-guidelines.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Dify 品牌使用条款
> 来源：`zh-hans/resources/about-dify/dify-brand-usage-terms.mdx`

这些品牌使用条款（“条款”）规范了对 LangGenius, Inc.（“Dify”、“我们”或“我们的”）拥有的商标、徽标、名称、设计和其他品牌元素（统称为“品牌资产”）的正确使用。通过使用 Dify 品牌资产，你同意遵守这些条款。

---
## 1. 允许的使用（无需事先批准）

在以下情况下，你可以在不事先批准的情况下使用 Dify 品牌资产，前提是你遵守 Dify 品牌指南：

### 社区和内容创作

- 在博客文章、文章、文档、社交媒体、论坛和演示文稿中引用或讨论 Dify。
- 在开源项目（例如 GitHub 存储库、README 文件和代码示例）中表明对 Dify 的集成或支持，只要明确说明你的项目不是与 Dify 正式关联或获得 Dify 认可。
- 在 YouTube 视频、播客和开发者演讲中用于教育或信息目的。

### 开源项目

- 你可以在非商业开源项目中显示“由 Dify 提供支持”以表示对 Dify 的使用。
- 鼓励链接到官方 Dify 网站或 GitHub 存储库。

### 媒体和新闻报道

- 记者、博客作者和媒体机构可以在新闻文章或报道中使用 Dify 品牌资产，前提是内容真实准确且不暗示 Dify 的认可或赞助。

---

## 2. 受限使用（需要批准）

以下使用需要 Dify 的事先书面批准：

### 商业使用和营销

- 将 Dify 集成到商业产品或服务中的转售商、合作伙伴和 SaaS 平台。
- 在广告、宣传材料或销售材料中使用 Dify 品牌资产。
- 在暗示官方认可的付费培训、咨询或课程中使用 Dify 品牌资产。

### 官方合作伙伴关系和认可

- 除非获得 Dify 的书面授权，任何情况下均不得以暗示 Dify 认可、认证、赞助或合作的方式使用 Dify 品牌资产。
- Dify 合作伙伴徽章仅对正式签约的合作伙伴开放。每一等级的徽章（如 Partner、Preferred Partner、Elite Partner）均需单独获得书面授权，仅限获得该等级资格的合作伙伴使用。严禁未授权使用徽章，或使用非本人所属等级的徽章。

### 商品和实物商品

- 未经书面许可，你不得在 T 恤、贴纸、海报或任何商品上使用 Dify 品牌资产。

### 修改和品牌组合

- 你不得更改 Dify 徽标，包括更改颜色、字体、比例或效果。
- 你不得将 Dify 徽标与其他徽标或符号组合以创建新的或复合的标记。

---

## 3. 品牌使用指南

使用 Dify 品牌资产时，你必须遵守我们的品牌指南，其中包括：

- 保持徽标完整性：不要扭曲、拉伸或旋转徽标。
- 使用官方徽标版本：不要使用非官方或过时的版本。
- 提供足够的间距：确保徽标周围有清晰的视觉分离。
- 不要更改颜色：徽标必须使用官方的 Dify 配色方案。

---

## 4. 商标和版权声明

- “Dify”以及所有相关徽标和品牌元素是 LangGenius, Inc. 的商标或注册商标。
- 这些条款不授予你任何所有权或许可权。Dify 保留对其品牌资产的所有权利。

---

## 5. 滥用和执行

- Dify 保留随时撤销使用权的权利，如果品牌资产使用不当，可能要求你停止使用品牌资产。
- 未经授权或误导性使用品牌资产可能导致法律诉讼。

---

## 6. 如何申请许可？

如果你的用例需要批准（例如商业用途、合作伙伴关系、商品销售），请提交申请至：[business@dify.ai](mailto:business@dify.ai )

你的申请应包括：

- 你的姓名/公司名称
- 你打算如何使用 Dify 品牌资产的详细说明
- 相关材料（例如样品、网站链接）

---

## 7. 举报品牌滥用

如果你认为 Dify 品牌资产正在被滥用，违反了这些条款——例如未经授权的商业使用、误导性认可或假冒商品——你可以向我们举报。

要提交举报，请联系 [brand@dify.ai](mailto:brand@dify.ai) 并提供以下详细信息：

- 问题描述（例如未经授权的商业使用、误导性品牌、假冒产品）
- 相关证据（例如截图、链接、文件）
- 你的联系信息（可选，以便我们需要更多详细信息时联系）
Dify 将审查所有举报并采取适当行动，这可能包括法律执行或要求违规方停止未经授权的使用。我们感谢你对保护 Dify 品牌的支持。

---

## 8. 这些条款的更新

Dify 可能会定期更新这些品牌使用条款。任何更改将在此页面上发布，通过继续使用品牌资产，你同意最新版本。

最新版本：2025/03/04

---

© LangGenius, Inc. 保留所有权利。严禁未经授权使用 Dify 品牌资产。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/resources/about-dify/dify-brand-usage-terms.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 术语表
> 来源：`zh-hans/resources/termbase.mdx`

## A
### 智能代理（Agent）
智能代理是一种自主 AI 系统，能够根据环境信息做出决策并执行任务。在 Dify 平台中，智能代理结合大语言模型的理解能力与外部工具的交互能力，可以自动完成从简单到复杂的一系列操作，如搜索信息、调用 API 或生成内容。

### 智能体工作流（Agentic Workflow）
智能体工作流是一种任务编排方法，允许 AI 系统通过多个步骤自主解决复杂问题。例如，一个智能体工作流可以先理解用户问题，然后查询知识库，接着调用计算工具，最后整合信息生成完整回答，全程无需人工干预。

### 自动语音识别（ASR, Automatic Speech Recognition）
自动语音识别技术将人类语音转换为文本，是语音交互应用的基础。这项技术使用户可以通过说话而非打字与 AI 系统交互，广泛应用于语音助手、会议记录和无障碍服务等场景。

## B
### 思维骨架（BoT, Backbone of Thought）
思维骨架是一种结构化思考框架，为大语言模型提供推理的主干结构。它帮助模型在处理复杂问题时保持清晰的思考路径，类似于论文的提纲或决策树的骨架。

## C
## 对话流（Chatflow）
对话流是一种面向对话场景的工作流编排模式，专为需要多步逻辑处理的交互式应用设计。与普通工作流相比，对话流额外支持对话历史记忆、问题理解和上下文管理等功能，使大模型能够在多轮对话中保持连贯性。

### 分段（Chunking）
分段是将长文本拆分成较小内容块的处理技术，使检索系统能更精准地找到相关信息。合理的分段策略既要考虑内容的语义完整性，也要满足语言模型的上下文窗口限制，从而提高检索和生成质量。

### 引用与归属（Citation and Attribution）
引用与归属功能让 AI 系统能够清晰标明信息来源，提高响应的可信度和透明度。当系统基于知识库内容生成回答时，可以自动标注引用的文档名称、页码或 URL，让用户了解信息的出处。

### 思维链（CoT, Chain of Thought）
思维链是一种提示技术，引导大语言模型展示其逐步思考过程。例如，解决数学问题时，模型会先列出已知条件，然后按照推理步骤一步步求解，最后得出结论，整个过程类似人类的思考方式。

## D
### 领域特定语言（DSL, Domain-Specific Language）
领域特定语言是为特定应用领域设计的编程语言或配置格式。Dify DSL 是一种基于 YAML 格式的应用工程文件标准，用于定义 AI 应用的各项配置，包括模型参数、提示词设计和工作流编排，使非专业开发者也能构建复杂 AI 应用。

## E
### 提取、转换、加载（ETL, Extract, Transform, Load）
ETL 是数据处理的经典流程：提取原始数据，转换为适合分析的格式，然后加载到目标系统。在 AI 文档处理中，ETL 可能包括从 PDF 提取文本、清理格式、分割内容、计算嵌入向量，最后加载到向量数据库中，为 RAG 系统做准备。

## F
### 全文检索（Full-text Search）
全文检索是索引文档中的所有词汇，从而允许用户查询任意词汇，并返回包含这些词汇的文本片段。这种技术是现代搜索引擎的基础，能够扫描整个文档集合，无论内容规模多大，都能快速定位包含特定字词或短语的内容。全文检索通常结合倒排索引等数据结构实现高效查询，适用于各类文档库、知识库和搜索系统。

### 频率惩罚（Frequency Penalty）
频率惩罚是一种文本生成控制参数，通过降低频繁出现词汇的生成概率来增加输出的多样性。值越高，模型越倾向于使用多样化的词汇和表达方式；值为 0 时，模型不会特意避免重复使用相同词汇。

### 函数调用（Function Calling）
函数调用是大型语言模型的能力，允许模型识别何时需要调用特定函数并提供所需参数。例如，当用户询问天气时，模型可以自动调用天气 API，构造正确的参数格式（城市、日期），然后根据 API 返回结果生成回答。

## G
### 通用分段模式（General Chunking Pattern）
通用分段模式是一种简单的文本分割策略，将文档拆分为相互独立的内容块。这种模式适合结构清晰、段落相对独立的文档，如产品说明书或百科条目，每个分段可以独立理解而不严重依赖上下文。

### 思维图（GoT, Graph of Thought）
思维图是一种将思考过程表示为网络结构的方法，捕捉概念之间的复杂关系。不同于线性的思维链，思维图可以表达分支、循环和多路径的思考模式，适合处理有多个相互关联因素的复杂问题。

## H
### 混合检索（Hybrid Search）
混合检索结合关键词匹配和语义搜索的优势，提供更全面的检索结果。例如，当搜索"苹果营养成分"时，混合检索既能找到包含"苹果"和"营养"关键词的文档，也能找到讨论"水果健康价值"等相关语义的内容，通过权重调整或重排序选出最优结果。

## I
### 倒排索引（Inverted Index）
倒排索引是搜索引擎的核心数据结构，它记录每个词出现在哪些文档中。与传统索引从文档找内容不同，倒排索引从词汇出发找文档，大幅提高全文检索速度。例如，"人工智能"一词的索引项会列出所有包含这个词的文档 ID 和位置。

## K
### 关键词检索（Keyword Search）
关键词检索是基于精确匹配的搜索方法，查找包含特定词汇的文档。这种方法计算效率高，适合用户明确知道要查找的术语的场景，如产品型号、专有名词或特定命令，但可能会漏掉使用同义词或相关概念表达的内容。

### 知识库（Knowledge Base）
知识库是 AI 应用中存储结构化信息的数据库，为模型提供专业知识来源。在 Dify 平台中，知识库可以包含各种文档（PDF、Word、网页等），经过处理后供 AI 检索并用于生成准确、有根据的回答，特别适合构建领域专家型应用。

### 知识检索（Knowledge Retrieval）
知识检索是从知识库中找出与用户问题最相关信息的过程，是 RAG 系统的关键环节。有效的知识检索不仅要找到相关内容，还要控制返回的信息量，避免无关内容干扰模型，同时提供足够背景确保回答准确完整。

## L
### 大型语言模型（LLM, Large Language Model）
大型语言模型是通过海量文本训练的 AI 模型，能够理解和生成人类语言。现代 LLM（如 GPT 系列、Claude 等）可以撰写文章、回答问题、编写代码，甚至进行推理，它们是各种 AI 应用的核心引擎，尤其适合需要语言理解和生成的场景。

### 本地模型推理（Local Model Inference）
本地模型推理是在用户自己的设备上运行 AI 模型的过程，而非依赖云服务。这种方式提供更好的隐私保护（数据不离开本地）和更低的延迟（无需网络传输），适合处理敏感数据或需要离线工作的场景，但通常受限于本地设备的计算能力。

## M
### 模型即服务（MaaS, Model-as-a-Service）
模型即服务是一种云服务模式，提供商通过 API 提供预训练模型的访问。用户无需关心模型的训练、部署和维护，只需调用 API 并支付使用费用，大幅降低了 AI 应用的开发门槛和基础设施成本，适合快速验证想法或构建原型。

### 最大标记数（Max Tokens）
最大标记数控制模型在单次响应中生成的最大字符量。一个标记大约相当于 4 个字符或 3/4 个英文单词。设置合理的最大标记数可以控制回答的长度，避免过于冗长的输出，同时确保完整表达必要信息。例如，一篇简短摘要可能设为 200 标记，而详细报告可能需要 2000 标记。

### 记忆（Memory）
记忆是 AI 系统保存和使用历史交互信息的能力，使多轮对话保持连贯。有效的记忆机制让 AI 能够理解上下文引用、记住用户偏好、追踪长期目标，从而提供个性化且有连续性的用户体验，避免重复询问已提供的信息。

### 元数据（Metadata）
元数据是描述数据的数据，提供关于内容的结构化信息，如文档的创建时间、作者、标题、标签、文件格式等属性信息等。这些信息可用于组织、分类和检索内容。通过元数据，系统可以实现更精确的内容管理和检索，例如按时间范围筛选文档、按作者分类或根据文件类型过滤搜索结果。

### 元数据筛选（Metadata Filtering）
元数据筛选利用文档属性信息（如标题、作者、日期、分类标签）进行内容过滤。例如，用户可以限定只检索特定日期范围内的技术文档，或只查询特定部门的报告，从而在检索前缩小范围，提高查找效率和结果相关性。

### 多模态模型（Multimodal Model）
多模态模型能处理多种类型的输入数据，如文本、图像、音频等。这类模型打破了传统 AI 的单一感知限制，可以理解图片内容、分析视频场景、识别声音情绪，为更全面的信息理解创造可能，适用于需要跨媒体理解的复杂应用场景。

### 多工具调用（Multi-tool-call）
多工具调用是模型在单次响应中调用多个不同工具的能力。例如，处理"比较北京和上海明天的天气并推荐适合的衣着"这样的请求时，模型可以同时调用两个城市的天气 API，然后基于返回结果给出合理建议，提高处理复杂任务的效率。

### 多路召回（Multi-path Retrieval）
多路召回是通过多种检索方法并行获取信息的策略。例如，系统可以同时使用关键词搜索、语义匹配和知识图谱查询，然后合并筛选结果，提高信息获取的覆盖面和准确性，特别适合处理复杂或模糊的用户查询。

## P
### 父子分段模式（Parent-Child Chunking）
父子分段模式是一种高级文本分割策略，创建两层级的内容块：父区块保留完整上下文，子区块提供精确匹配点。系统先通过子区块确定相关内容位置，再获取对应父区块以提供完整背景，同时兼顾检索精度和上下文完整性，适合处理复杂文档如研究论文或技术手册。

### 存在惩罚（Presence Penalty）
存在惩罚是防止语言模型重复内容的参数设置。它通过降低已出现词汇的生成概率，鼓励模型探索新的表达方式。参数值越高，模型越不倾向于重复之前生成的内容，有助于避免 AI 回答中常见的循环论证或重复叙述问题。

### 预定义模型（Predefined Model）
预定义模型是由 AI 厂商训练并提供的现成模型，用户可以直接调用而无需自行训练。这些闭源模型（如 GPT-4、Claude 等）通常经过大规模训练和优化，能力强大且易于使用，适合快速开发应用或缺乏自主训练资源的团队。

### 提示词（Prompt）
提示词是引导 AI 模型生成特定响应的输入文本。精心设计的提示词能显著提高输出质量，包括明确指令、提供示例、设定格式要求等元素。例如，不同的提示词可以引导同一模型生成学术文章、创意故事或技术分析，是影响 AI 输出的最关键因素之一。

## Q
### 问答模式（Q&A Mode）
问答模式是一种特殊索引策略，为文档内容自动生成问答对，实现"问题到问题"的匹配。当用户提问时，系统会寻找语义相似的预生成问题，然后返回对应答案。这种模式特别适合 FAQ 内容或结构化知识点，能提供更精准的问答体验。

## R
### 检索增强生成（RAG, Retrieval-Augmented Generation）
检索增强生成是结合外部知识检索和语言生成的技术架构。系统首先从知识库检索与用户问题相关的信息，然后将这些信息作为上下文提供给语言模型，生成有依据、准确的回答。RAG 克服了语言模型知识有限和幻觉问题，特别适合需要最新或专业知识的应用场景。

### 推理与行动（ReAct, Reasoning and Acting）
推理与行动是一种 AI 代理框架，使模型能够交替进行思考和执行操作。在解决问题过程中，模型先分析当前状态，制定计划，然后调用合适工具（如搜索引擎、计算器），根据工具返回结果进行下一步思考，形成思考-行动-思考的循环，直到解决问题，适合处理需要多步骤和外部工具的复杂任务。

### 重排序（ReRank）
重排序是对初步检索结果进行二次排序的技术，提高最终结果的相关性。例如，系统可能先通过高效算法快速检索出大量候选内容，然后使用更复杂但精准的模型对这些结果重新评分排序，将最相关的内容置前，平衡了检索效率和结果质量。

### 重新排序模型（Rerank Model）
重新排序模型专门用于评估检索结果与查询的相关性并重新排序。与初步检索不同，这类模型通常采用更复杂的算法，考虑更多语义因素，能更精确地判断内容与用户意图的匹配度。例如，Cohere Rerank 和 BGE Reranker 等模型可显著提升搜索和推荐系统的结果质量。

### 响应格式（Response Format）
响应格式指定模型输出的结构类型，如纯文本、JSON 或 HTML。设置特定的响应格式可以使 AI 输出更容易被程序处理或集成到其他系统。例如，要求模型以 JSON 格式回答可以确保输出具有一致的结构，便于前端应用直接解析和展示。

### 反向调用（Reverse Calling）
反向调用是插件与平台交互的双向机制，允许插件主动调用平台功能。在 Dify 中，这意味着第三方插件不仅能被 AI 调用，还能反过来使用 Dify 的核心功能，如触发工作流或调用其他插件，极大增强了系统的扩展性和灵活性。

### 召回测试（Retrieval Test）
召回测试是验证知识库检索效果的功能，开发者可以模拟用户查询并评估系统返回结果。这种测试帮助开发者了解系统的检索能力边界，发现并修复潜在问题，如漏检、误检或相关度不佳的情况，是优化 RAG 系统不可或缺的工具。

## S
### 分数阈值（Score Threshold）
分数阈值是过滤检索结果的相似度门槛，只有评分超过设定值的内容才会被返回。设置合理的阈值可以避免无关信息干扰模型生成，提高回答的精确性。例如，如果阈值设为 0.8（满分 1.0），则只有高度相关的内容会被采用，但可能导致信息不全；降低阈值则会纳入更多内容但可能引入噪音。

### 软件开发工具包（SDK, Software Development Kit）
软件开发工具包是一组用于开发特定平台或服务应用程序的工具集合。在 Dify 中，SDK 提供了各种编程语言的接口库，使开发者能够方便地集成和调用 Dify 的功能，包括对话管理、知识库操作、应用配置等。通过使用 SDK，开发者可以在自己的应用中快速实现 AI 能力，而无需深入了解底层 API 细节。

### 语义检索（Semantic Search）
语义检索基于理解和匹配文本意义而非简单关键词匹配的检索方法。它利用向量嵌入技术将文本转换为数学表示，然后计算查询与文档的语义相似度。这种方法能够找到表达方式不同但含义相近的内容，理解同义词和上下文关系，甚至支持跨语言检索，特别适合复杂或自然语言形式的查询。

### 会话变量（Session Variables）
会话变量是存储多轮对话上下文信息的机制，使 AI 能维持连贯交互。例如，系统可以记住用户的偏好（如"简洁回答"）、身份信息或交互历史状态，避免重复询问，提供个性化体验。在 Dify 中，开发者可以定义和管理这些变量，建立真正记住用户的"有记忆"应用。

### 语音转文字（STT, Speech-to-Text）
语音转文字技术将用户的语音输入转换为文本数据。这项技术让用户可以通过说话而非打字与 AI 系统交互，提高了交互的自然性和便捷性，特别适合移动设备、驾驶场景或无障碍应用，是语音助手和实时转录等应用的基础。

### 流式工具调用（Stream-tool-call）
流式工具调用是一种实时处理模式，允许 AI 系统在生成响应的同时调用外部工具，而不必等待完整回答生成后再处理。这种方式大大提高了处理复杂任务的响应速度，让用户体验更加流畅，适合需要多次工具调用的交互场景。

### 流式结果返回（Streaming Response）
流式结果返回是一种实时响应机制，AI 系统边生成内容边返回给用户，而不是等所有内容生成完毕再一次性展示。这种方式显著改善用户等待体验，特别是对于长回答，用户可以立即看到部分内容并开始阅读，提供更自然的交互感受，类似于人类对话中的即时反馈。

## T
### 温度（Temperature）
温度是控制语言模型输出随机性的参数，通常在 0-1 之间。温度越低（接近 0），模型输出越确定和保守，倾向于高概率词汇，适合事实性回答；温度越高（接近 1），输出越多样和创造性，适合创意写作。例如，天气预报可能使用 0.1 的低温度，而故事创作可能使用 0.8 的高温度。

### 文本嵌入（Text Embedding）
文本嵌入是将文本转换为数值向量的过程，使 AI 系统能够理解和处理语言。这些向量捕捉了词汇和句子的语义特征，使计算机可以测量文本间的相似度、聚类相关内容或检索匹配信息。不同的嵌入模型（如 OpenAI 的 text-embedding-ada-002 或 Cohere 的 embed-multilingual）针对不同语言和应用场景进行了优化。

### 工具调用（Tool Calling）
工具调用是 AI 系统识别并使用外部功能的能力，极大扩展了模型的能力边界。例如，语言模型本身不能访问实时数据，但通过调用天气 API，它可以提供当前天气信息；通过调用数据库查询工具，它可以获取最新产品库存；通过调用计算器，它可以执行复杂计算，这使 AI 能够解决超出其训练数据范围的问题。

### TopK
TopK 是控制检索返回结果数量的参数，指定保留相似度最高的前 K 个文本片段。合理设置 TopK 值对 RAG 系统性能至关重要：值太小可能丢失关键信息，值太大则可能引入噪音并增加语言模型处理负担。例如，简单问题可能只需 TopK=3，而复杂问题可能需要 TopK=10 以获取足够背景。

### 核采样（TopP, Nucleus Sampling）
核采样是一种文本生成控制方法，只从累积概率达到阈值 P 的最可能词汇中选择下一个词。与固定选择最高概率词或完全随机不同，TopP 在确定性和创造性间取得平衡。例如，TopP=0.9 意味着模型只考虑概率和占 90% 的词汇，忽略低概率选项，既避免了完全可预测的输出，又不会生成过于随机的内容。

### 思维树（ToT, Tree of Thought）
思维树是一种探索多个推理路径的思考方法，允许模型从不同角度分析问题。类似于人类的"如果...那么..."思考模式，思维树让模型生成多个可能的思考分支，评估每个分支的可行性，然后选择最优路径继续，特别适合解决需要试错或考虑多种可能性的复杂问题。

### 文本转语音（TTS, Text-to-Speech）
文本转语音是将书面文本转换为自然语音的技术，使 AI 系统能以语音方式与用户交流。现代 TTS 系统能生成接近人类的自然语音，支持多种语言、音色和情感表达，广泛应用于有声读物、导航系统、语音助手和无障碍服务，为不同场景和用户提供更自然的交互体验。

## V
### 向量数据库（Vector Database）
向量数据库是专门存储和搜索向量嵌入的数据库系统，是高效语义检索的基础设施。与传统数据库不同，向量数据库针对高维向量相似度搜索进行了优化，能快速从数百万文档中找出语义相近的内容。常见的向量数据库包括 Pinecone、Milvus、Qdrant 等，它们在 RAG 系统、推荐引擎和内容分析中发挥关键作用。

### 向量检索（Vector Retrieval）
向量检索是基于文本向量嵌入相似度的搜索方法，是语义搜索的技术核心。系统首先将用户查询转换为向量，然后在预先计算的文档向量中查找最相似的内容。这种方法能够捕捉深层语义关系，找到表达不同但意思相近的内容，克服了关键词搜索的局限，特别适合处理自然语言查询和概念性问题。

### 视觉能力（Vision）
视觉能力是多模态 LLM 理解和处理图像的功能，允许模型分析用户上传的图片并结合文本生成回答。例如，用户可以上传产品照片询问使用方法，上传菜单照片请求翻译，或上传图表要求分析数据趋势。这种能力大大拓展了 AI 应用场景，使交互更加直观和多样化。

## W
### 工作流（Workflow）
工作流是一种任务编排方式，将复杂 AI 应用拆分为多个独立节点并按特定顺序执行。在 Dify 平台中，开发者可以可视化设计工作流，组合多个处理步骤（如用户输入处理、知识检索、多模型协作、条件分支），构建能处理复杂业务逻辑的 AI 应用，使应用开发既灵活又直观。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/resources/termbase.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 如何搭建 AI 图片生成应用
> 来源：`zh-hans/workshop/basic/build-ai-image-generation-app.mdx`

> 作者：Steven Lynn。Dify Technical Writer。

随着图像生成技术的兴起，涌现了许多优秀的图像生成产品，比如 Dall-e、Flux、Stable Diffusion 等。

本文将使用图像生成模型，指导你使用 Dify 快速开发一个 AI 图片生成应用。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/05ff829cf382e82c9ece2676032d2383.png)

### 本实验中你将掌握的知识点

* 使用 Dify 构建 Agent 的方法
* Agent 的基本概念
* 提示词工程的基础知识
* 工具的使用
* 大模型的幻觉的概念

### 1. 获取和填入 Stablility API 密钥

[点击这里](https://platform.stability.ai/account/keys) 即可跳转至 Stability 的 API 密钥管理页。

如果你尚未注册，会被要求先注册再进入管理页。

进入管理页后，点击复制密钥即可。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/f73d82756bdf93c8863ac0b1f55fa5af.png)

接下来，你需要通过以下步骤把密钥填入 [Dify - 工具 - Stability](https://cloud.dify.ai/tools) 中：

* 登录 Dify
* 进入工具
* 选择 Stability
* 点击授权

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/c943c374a89b5ba08683f0eb6c501664.png)

* 填入密钥并保存

### 2. 配置模型供应商

为了优化交互，我们需要LLM来将用户的指令具体化，也就是让LLM来撰写生成图片的提示词（Prompt）。接下来，我们按照如下的步骤在 Dify 配置模型供应商。

Free 版本的 Dify 提供了免费 200 条 OpenAI 的消息额度

如果消息额度不够用，你可以参考下图步骤, 自定义其它模型供应商:

点击**右上角头像 - 设置 - 模型供应商**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/52f3f299b05ff94ee0421604dd810e35.png)

如果尚未找到合适的模型供应商，groq 平台提供了 Llama 等 LLM 的免费调用额度。

登录 [groq API 管理页](https://console.groq.com/keys)

点击 **Create API Key**，设置一个想要的名称并且复制 API Key。

回到**Dify - 模型供应商**，选择**groqcloud**，点击 **设置**。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/1c4f0a7081fc6f5644203baf2f703b49.png)

粘贴 API Key 并保存。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/0a0593676651be79b9b322c48938f042.png)

### 3. 构建 Agent

回到**Dify - 工作室**，选择**创建空白应用**。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/494bd8427dce548ce56b5b1cd52bffbd.png)

在本实验中，我们只需要了解 Agent 的基础用法即可。

> **信息提示：**

**什么是 Agent**
Agent 是一种模拟人类行为和能力的 AI 系统，它通过自然语言处理与环境交互，能够理解输入信息并生成相应的输出。Agent 还具有 "感知" 能力，可以处理和分析各种形式的数据。此外，Agent 能够调用和使用各种外部工具和 API 来完成任务，扩展其功能范围。这种设计使 Agent 能够更灵活地应对复杂情况，在一定程度上模拟人类的思考和行为模式。
因此，很多人都会将 Agent 称为“智能体”。

选择 **Agent**，填写名称即可。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/c428f040fe117670abbc0e268227fcc9.png)

接下来你会进入到如下图的 Agent 编排界面

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/c24024b10f76b5a2bf416c9411f3cc55.png)

我们选择 LLM，本篇教程中我们使用 groq 提供的 Llama-3.1-70B 为例：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/5f6c6837cbee213d8adbc71ce41467c2.png)

在**工具**中添加 AI 绘图工具 Stability：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/c963eb9ae55b035631f32ebd6ad23f4b.png)

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/20f37184597aac61463297cae9485055.png)

#### 撰写提示词

提示词（Prompt）是 Agent 的灵魂，直接影响到输出的效果。通常来说越具体的提示词输出的效果越好，但是过冗长的提示词也会导致一些负面效果。

调整提示词的工程，我们称之为提示词工程（Prompt Engineering）

在本次实验中，你不必担心没有掌握提示词工程，我们会在后面循序渐进地学习它。

让我们从最简单的提示词开始：

```
根据用户的提示，使用工具 stability_text2image 绘画指定内容
```

用户每次输入命令的时候，Agent 都会知晓这样的系统级的指令，从而了解要执行用户绘画的任务的时候需要调用一个叫 stability 的工具。

例如：画一个女孩，手中拿着一本打开的书

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/5a1742b0580a960bfc476651720662c4.png)

#### 不想撰写提示词？当然可以！

点击提示词的右上角**生成**。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/145ce8b15faff3b116ecc48086a12dcb.png)

在**指令**中输入你的需求，点击**生成**，右侧生成的提示词中会出现由AI生成的提示词。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/efcb66dc935f5d5d954c936847af2496.png)

不过，为了养成对提示词良好的理解，我们在初期最好不要依赖这一项功能。

### 发布

点击右上角的发布按钮，发布后选择**运行**就可以获得一个在线运行的 Agent 的网页。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/bd178b3530f90400a1eeb0ca824ccbd2.png)

复制这个网页的 URL，可以分享给其他好友使用。

### 思考题 1：如何指定生成图片的画风？

我们可以在用户输入的命令中加上画风的指令，例如：二次元风格，画一个女孩，手中拿着一本打开的书

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/ebed02c8f6643427f0ba83e63c9fcaa8.png)

但是如果我们希望风格默认都是二次元风格呢，那么我们加在系统提示词里就行了，因为我们之前了解到系统提示词是每次执行用户命令都会知晓的，优先级更高。

```
根据用户的提示，使用工具 stability_text2image 绘画指定内容，画面是二次元风格
```

### 思考题 2: 如何拒绝部分用户的某些请求？

在许多业务场景中，我们需要避免输出一些不合理的内容，但是 LLM 很多时候比较 “傻”，用户下指令时会照做不误，即使输出的内容是错的，这种模型为了努力回答用户而编造虚假内容的现象称为模型幻觉（Hallucinations），那么我们需要让模型必要的时候拒绝用户的请求。

此外，用户也可能提一些和业务无关的内容，我们也需要让 Agent 这个时候拒绝请求。

我们可以使用 markdown 格式给不同的提示词进行划分，将上述教 Agent 拒绝不合理内容的提示词写到 “约束” 标题下。当然，这样的格式仅仅是为了规范化，你可以有自己的格式。

```
## 任务
根据用户的提示，使用工具 stability_text2image 绘画指定内容，画面是二次元风格。

## 约束
如果用户在请求和绘画无关的内容，回复：“对不起，我不明白你在说什么”
```

例如，我们尝试提问：今晚吃什么

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/ad342ddc00acc1aa0ad81f335e32a625.png)

在一些更正式的业务场景中，我们可以调用敏感词库来拒绝用户的请求。

在**添加功能 - 内容审查**中添加关键词 “晚饭”，当用户输入关键词时，则 Agent 应用输出 “对不起，我不明白你在说什么”。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/e9d6e1a7f3a13c88dc98eef89f221949.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/workshop/basic/build-ai-image-generation-app.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## Markdown 的正确使用方式
> 来源：`zh-hans/workshop/basic/the-right-way-of-markdown.mdx`

[Markdown](https://www.markdownguide.org/basic-syntax/) 可以将你在 Dify 应用中的输出从纯文本转化为格式良好、专业美观的响应内容。在 Answer 和 End 节点中使用 Markdown，可以渲染标题、列表、代码块、表格等元素，为终端用户创造清晰的视觉层次结构。

## Dify 中的基本 Markdown 语法

你可以在 Answer / End 节点中使用 Markdown 渲染以下内容：

* 标题
* 加粗、斜体、删除线
* 列表
* 表格
* 多行代码块
* 音频和视频

![](images/CleanShot2025-07-14at00.34.54.png)

### 标题

使用 `#` 来表示标题，`#` 的数量表示标题级别：

```markdown
# 一级标题
## 二级标题
### 三级标题
```

### 加粗、斜体、删除线

你可以使用以下方式设置文本样式：

```markdown
**加粗文本**
*斜体文本*
~~删除线文本~~
```

### 列表

可以创建有序和无序列表：

```markdown
- 无序列表项 1
- 无序列表项 2
  - 嵌套无序项
1. 有序列表项 1
2. 有序列表项 2
   1. 嵌套有序项
```

### 表格

使用竖线和短横线创建表格：

```markdown
| 表头 1 | 表头 2 |
|--------|--------|
| 第 1 行第 1 列 | 第 1 行第 2 列 |
| 第 2 行第 1 列 | 第 2 行第 2 列 |
```

### 多行代码块

使用三个反引号 <code>\`\`\`python</code> 创建多行代码块：

```python
def hello_world():
    print("Hello, World!")
```

### 音频和视频

可以通过以下语法插入音频和视频：

```markdown
<video controls>
  <source src="https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerBlazes.mp4" type="video/mp4">
</video>
<audio controls>
  <source src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3" type="audio/mpeg">
</audio>
```

  如果你希望了解更多关于 Markdown 的使用方式，可以参考 [Markdown Guide](https://www.markdownguide.org/basic-syntax/)。

## Dify 中的高级 Markdown 功能

### 按钮和链接

你可能不喜欢默认由大模型生成的后续问题，此时你可以使用按钮和链接，引导对话朝特定方向发展。

![](images/screenshot-20250714-134035.png)

你可以使用以下语法创建按钮和链接：

```
<button data-message="Hello Dify" data-variant="primary">Hello Dify</button>
<button data-message="Hello Dify" data-variant="danger">Hello Dify</button>
```

按钮需要定义两个属性：

* `data-variant`：按钮样式，可选值包括 `primary`、`secondary`、`warning`、`secondary-accent`、`ghost`、`ghost-accent`、`tertiary`
* `data-message`：点击按钮时发送的消息内容

链接的用法更为简单：

```
<a href="https://dify.ai" target="_blank">Dify</a>
```

你也可以使用 `abbr` 语法创建交互链接，用于对话中触发特定交互：

```
[特殊链接](abbr:special-link)
```

---

### 表单（Form）

表单需要设置 `data-format` 属性，支持 `json` 和 `text` 两种格式，默认是 `text`。当设置为 `data-format="json"` 时，表单会以 JSON 对象提交。

![](images/screenshot-20250714-134150.png)

#### 支持的输入类型

Dify 支持多种表单输入类型：

* text（文本）
* textarea（多行文本）
* password（密码）
* time（时间）
* date（日期）
* datetime（日期时间）
* select（下拉选择）
* checkbox（复选框）
* hidden（隐藏字段）

如果你想在对话中渲染一个表单，可以使用如下语法：

```
<form data-format="json"> // 默认为 text
  <label for="username">用户名：</label>
  <input type="text" name="username" />
  <label for="hidden_input">隐藏字段：</label>
  <input type="hidden" name="hidden_input" value="hidden_value" />
  <label for="password">密码：</label>
  <input type="password" name="password" />
  <label for="content">内容：</label>
  <textarea name="content"></textarea>
  <label for="date">日期：</label>
  <input type="date" name="date" />
  <label for="time">时间：</label>
  <input type="time" name="time" />
  <label for="datetime">日期时间：</label>
  <input type="datetime" name="datetime" />
  <label for="select">选择：</label>
  <input type="select" name="select" data-options='["hello","world"]'/>
  <input type="checkbox" name="check" data-tip="勾选表示你已同意"/>
  <button data-variant="primary">登录</button>
</form>
```

  Hidden 隐藏字段不会显示给用户，可以用来在不经用户输入的情况下传递数据。

---

### 图表（Chart）

你可以在 Markdown 中使用 [echarts](https://dify.ai/docs/guides/tools/chart) 渲染图表。语法如下：

![](images/screenshot-20250714-134238.png)

  要渲染图表，使用以 <code>\`\`\`echarts</code> 开头的代码块，并将配置写入其中。

```echarts
{
  "title": {
    "text": "ECharts 入门示例"
  },
  "tooltip": {},
  "legend": 
    "data": ["销量"]
  ,
  "xAxis": 
    "data": ["衬衫", "羊毛衫", "雪纺衫", "裤子", "高跟鞋", "袜子"]
  ,
  "yAxis": {},
  "series": [
    "name": "销量",
    "type": "bar",
    "data": [5, 20, 36, 10, 10, 20]
  ]
}
```

---

### 音乐（乐谱）

除了图表，你还可以在 Markdown 中渲染乐谱。我们支持 [ABC notation](https://paulrosen.github.io/abcjs/) 乐谱标准，使用以下语法：

![](images/screenshot-20250714-134431.png)

  要渲染乐谱，使用以 <code>\`\`\`abc</code> 开头的代码块，并将 ABC 记谱内容写入其中。

```abc
X: 1
T: Cooley's
M: 4/4
L: 1/8
K: Emin
|:D2|EBcBA B2 EB|~B2 AB dBAG|FDAD BDAD|FDAD dAFD|
EBBA B2 EB|B2 AB defg|afe^c dBAF|DEFD E2:|
|:gf|eB B2 efge|eB B2 gedB|A2 FA DAFA|A2 FA defg|
eB B2 eBgB|eB B2 defg|afe^c dBAF|DEFD E2:|
```

---

## 最佳实践

如果你希望提前定义 Markdown 内容，可以使用 Dify 的 [模板功能](./en/guides/workflow/node/template)。这可以让你在后续节点中复用模板内容，提高效率与一致性。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/workshop/basic/the-right-way-of-markdown.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## AI Agent 实战：搭建个人在线旅游助手
> 来源：`zh-hans/workshop/basic/travel-assistant.mdx`

> 作者: Steven Lynn。 Dify Technical Writer。

在上一个实验 [如何搭建 AI 图片生成应用](build-ai-image-generation-app) 中，我们已初步了解了 Agent 的概念，并且尝试动手写了系统提示词。

本次实验中，我们将继续探索 Agent 的提示词，学习更加规范的提示词撰写方法。

### 本实验中你将掌握的知识点

* 使用 Dify 构建 Agent 的方法
* 结构化的提示词撰写技巧
* 变量的使用方法

### 1. 准备

在新建 Agent 之前，请先确保以下步骤已经完成：

* 注册和登录 [Dify](https://dify.ai)，如果你想要进行本地部署，可以参考 [社区版 - Docker Compose 部署](../../getting-started/install-self-hosted/docker-compose)
* 至少配置一个模型供应商（Dify 赠送 200 条 OpenAI 消息额度，但为了确保实验顺利建议自行配置 LLM 的 API Key）

### 2. 配置工具

#### Google

搭建在线旅游助手需要使用联网的搜索引擎作为参考资料来源，本文中将以 Google 作为示例。

当然，你也可以使用其他的搜索引擎，例如[必应](https://docs.dify.ai/zh-hans/guides/tools/tool-configuration/bing)，甚至是由 AI 驱动的 [Perplexity](https://docs.dify.ai/zh-hans/guides/tools/tool-configuration/perplexity)。

Dify 提供的 Google 工具基于 SerpAPI，因此需要提前进入 SerpAPI 的 API Key 管理页申请 API Key 并粘贴到 `Dify - 工具` 的对应位置。

具体操作步骤如下：

1. 新增 SerpAPI 的 API Key：

进入[SerpAPI - API Key](https://serpapi.com/manage-api-key)，如果你尚未注册，会被跳转至进入注册页。

SerpAPI提供一个月100次的免费调用次数，这足够我们完成本次实验了。如果你需要更多的额度，可以增加余额，或者使用其他的开源方案。

点击复制

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/cf8870ff01bfb944da7ddbd073e9cc41.png)

2. 前往 **Dify - 工具 - Google**：

点击 `去授权` ，填入API Key并保存。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/e9726a2e68cbe8f957f8394b5ca47049.png)

#### webscraper

本次实验中，我们需要一个爬虫工具从指定的网页中抓取内容，Dify 已提供内置工具，无需额外配置。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/516c649bc0d8f2d1c81ba8b5bb28638c.png)

#### Wikipedia

我们还希望 Agent 能够准确介绍目的地知识，Wikipedia 是一个比较好知识来源，Dify 也内置了该工具，无需额外配置。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/53ebce24e49543b83d6c5581525d4e30.png)

### 3. 构建 Agent

首先我们选择 `创建空白应用 - Agent`：

添加工具：`Google`、`webscraper`和`wikipedia`并启用。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/6799204e6259ab41f22f85e285466c22.png)

4. **示例输出**

示例输出不是必要的部分。示例输出的目的是为了给 Agent 一个书写格式的参考，以确保 Agent 的输出更接近我们的期望。

以下是旅游助手的示例输出：

```
## 示例

### 详细旅行计划

**酒店推荐**
1. 肯辛顿酒店 (了解更多：www.doylecollection.com/hotels/the-kensington-hotel)
- 评分：4.6⭐
- 价格：每晚约350美元
- 简介：坐落在一座摄政时期的联排别墅中，这家优雅的酒店距离南肯辛顿地铁站5分钟步行路程，距离维多利亚和阿尔伯特博物馆10分钟步行路程。

2. 伦勃朗酒店 (了解更多：www.sarova-rembrandthotel.com)
- 评分：4.3⭐
- 价格：每晚约130美元
- 简介：建于1911年，最初是哈罗德百货公司（距离0.4英里）的公寓，这家现代化酒店坐落在维多利亚和阿尔伯特博物馆对面，距离南肯辛顿地铁站（直达希思罗机场）5分钟步行路程。

**第1天 - 抵达和安顿**
- **上午**：抵达机场。欢迎来到你的冒险之旅！我们的代表将在机场迎接你，确保你顺利入住。
- **下午**：入住酒店，稍作休息，恢复精力。
- **晚上**：在住宿周边进行轻松的步行游览，熟悉当地环境。发现附近的用餐选择，享受愉快的第一顿晚餐。

**第2天 - 文化与自然之旅**
- **上午**：从帝国理工学院开始你的一天，这是世界顶尖的学府之一。享受一次校园导览。
- **下午**：选择参观自然历史博物馆（以其引人入胜的展览而闻名）或维多利亚和阿尔伯特博物馆（庆祝艺术和设计）。之后，在宁静的海德公园放松，也许还可以在蛇形湖上乘船游览。
- **晚上**：探索当地美食。我们推荐你在传统的英国酒吧享用晚餐。

**附加服务：**
- **礼宾服务**：在你停留期间，我们的礼宾服务随时可以协助预订餐厅、购买门票、安排交通，以及满足任何特殊要求，以提升你的体验。
- **24/7支持**：我们提供全天候支持，以解决你在旅行中可能遇到的任何问题或需求。

祝你旅途愉快，满载丰富经历和美好回忆！
```

### 思考题 1: 如何规范化用户输入？

通常我们输入 Agent 内容都是自然语言，而自然语言的一个缺点是很难规范化，有可能包含了一些 Agent不需要的信息或者没有价值的信息，这个时候我们可以引入变量来规范化输入。

Dify 目前支持`文本`、`段落`、`下拉选项`、`数字`、`基于 API 的变量`这几种类型的变量。

在本实验中，我们只需要选用`文本`类型的变量即可。

在**变量**中，选择合适的变量类型，我们可以询问用户目的地、旅行天数、预算。

<table>
  <thead>
    <tr>
      <th>变量Key</th>
      <th>变量类型</th>
      <th>字段名称</th>
      <th>可选</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>destination</td>
      <td>文本</td>
      <td>目的地</td>
      <td>是</td>
    </tr>
    <tr>
      <td>day</td>
      <td>文本</td>
      <td>旅行天数</td>
      <td>是</td>
    </tr>
    <tr>
      <td>budget</td>
      <td>文本</td>
      <td>旅行预算</td>
      <td>是</td>
    </tr>
  </tbody>
</table>
需要注意的是，`变量 Key`，也就是变量的名称，仅支持大小写英文、数字、下划线。`字段名称`是用户可以看到的提示内容。

添加变量后，用户可以按照应用开发者的意图向应用提供必要的背景信息，实现的效果如下：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/basic/927260e8e6198b98f3b9406f856c0240.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/workshop/basic/travel-assistant.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 使用文件上传搭建文章理解助手
> 来源：`zh-hans/workshop/intermediate/article-reader.mdx`

> 作者：Steven Lynn。Dify Technical Writer。

在 Dify ，你可以使用知识库工具让 Agent 从大量的文本内容中获取准确的信息。然而，很多情况下需要理解的本地文件并不是很大，不至于用上知识库。这种情况下可以使用文件上传功能直接把本地文件作为上下文给 LLM 理解。

本次实验中，我们将以文章理解助手为案例。这个文章理解助手将会根据上传的文档进行提问，协助用户带着问题去阅读论文等材料。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/4bdead58ba499a3fd7df130073533a80.png)

## 本实验中你将掌握的知识点

* 文件上传功能
* Chatflow的基本操作
* 提示词撰写
* 迭代的使用
* 文档解析器和列表操作节点

## 前提条件

在 Dify 中创建一个 Chatflow。请确保你已添加模型供应商并有足够额度。

## 添加节点

在本次实验中至少需要涉及四种节点：开始节点、文档提取器节点、LLM 节点、回复节点。

### 开始节点

在开始节点需要添加文件变量。在 0.10.0 版本的 Dify 中支持了文件上传功能，你可以将文件作为变量加入。

有关文件上传的更多文档内容请阅读：[文件上传](../../guides/workflow/file-upload)

在开始节点需要增加一个文件变量，在**支持的文件类型**中，需要勾选**文档。**

一些读者可能会注意到在系统变量中有 `sys.files`，这个变量是用户在对话框中上传的文件或者文件列表。

和自己创建文件变量的区别在于，这个功能需要在**功能**中打开**文件上传**并且设置上传文件类型，并且在对话中每次上传新的文件都会将这个变量覆写。

请需要根据业务场景选取合适的文件上传方式。

### 文档提取器

**LLM 是无法直接读取文件的。** 这是很多用户在第一次使用文件上传功能的一个误区，会认为直接把文件作为变量在 LLM 节点应用就可以了，实际上 LLM 读到的内容为空。

所以，Dify 引入了**文档提取器**，这个节点可以从文件变量中提取文本，输出文本格式的变量。

将开始节点的文件变量作为输入变量，文档提取器会将文档格式的文件转为文本变量输出。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/cccd81ef0814ff6218e09c288a2423dd.png)

### LLM

本次实验中需要设计两个 LLM 节点，分别是结构提取和问题抛出。

#### 结构提取

结构提取节点能够从原文内容中提取文章结构，总结关键内容。

提示词内容如下：

```text
阅读以下文章内容并执行任务
{{文档提取器结果的变量}}
# 任务

- **主要目标**：全面解析文章的结构。
- **目标**：详细说明文章每个部分的内容。
- **要求**：尽可能详细地分析。
- **限制**：无特别的格式限制，但需要保持解析的条理性和逻辑性。
- **预期输出**：文章结构的详细解析，包括每个部分的主要内容和作用。

# 推理顺序

- **推理部分**：通过仔细阅读文章，识别和解析其结构。
- **结论部分**：提供每个部分的具体内容和作用。

# 输出格式

- **解析格式**：每个部分应以标题形式列出，后跟对该部分内容的详细说明。
- **结构形式**：Markdown，以增强可读性。
- **具体说明**：每个部分的内容和作用，包括但不限于引言、正文、结论、引用等。

# 示例输出

## 示例文章解析

### 引言
- **内容**：介绍研究的背景、目的和重要性。
- **作用**：吸引读者的注意力，为文章内容提供上下文。

### 方法
- **内容**：描述研究的具体方法和步骤，包括实验设计、数据收集和分析技术。
- **作用**：使读者了解研究的科学性和可重复性。

### 结果
- **内容**：展示研究的主要发现和数据。
- **作用**：提供研究结论的证据基础。

### 讨论
- **内容**：解释结果的意义，对比其他研究，提出可能的改进方向。
- **作用**：帮助读者理解结果的广泛影响和未来研究的潜力。

### 结论
- **内容**：总结研究的主要发现和贡献。
- **作用**：强化文章的核心信息，提供明确的结论。

### 引用
- **内容**：列出文章中引用的所有文献。
- **作用**：提供进一步阅读的资源，确保学术诚信。

# 备注

- **边缘情况**：如果文章结构不典型（例如，缺少某些部分或有额外的部分），应在解析中明确指出这些特殊情况。
- **重要考虑事项**：解析时应关注文章的逻辑性和连贯性，确保每个部分的内容与文章的整体目标一致。
```

#### 问题抛出

问题抛出节点能够从结构提取节点总结的内容中总结文章的问题，协助读者在阅读的过程中带着问题去思考。

提示词如下：

```text
阅读以下文章内容并执行任务
{{结构提取的输出}}
# 任务

- **主要目标**：全面阅读上文，针对文章各个部分提出尽可能多的问题。
- **要求**：问题要有意义和价值，值得思考。
- **限制**：无特定限制。
- **预期输出**：一系列针对文章各个部分的问题，每个问题都应有深度和思考价值。

# 推理顺序

- **推理部分**：全面阅读文章，分析文章各个部分的内容，思考每个部分可能引发的深层次问题。
- **结论部分**：提出有意义和有价值的问题，确保问题能够引发深入的思考。

# 输出格式

- **格式**：每个问题单独成行，编号列出。
- **内容**：针对文章的各个部分（如引言、背景、方法、结果、讨论、结论等）提出问题。
- **数量**：尽可能多，但每个问题都应有意义和价值。

# 备注

- **边缘情况**：如果文章的某些部分内容较少，可以适当调整问题的数量和深度，但每个问题都应有思考价值。
- **重要考虑事项**：确保问题能够引导读者深入理解文章内容，而不仅仅是表面的疑问。
```

## 思考题 1 : 处理多个上传文件

为了处理多个上传文件，需要用到**迭代**节点。

迭代节点类似于许多编程语言中的 while，区别在于 Dify 中没有条件限制，且**输入变量只能是 `array` 类型（列表）**。原因是 Dify 会将列表中的全部内容都执行完为止。

因此，你需要把开始节点中的文件变量调整为`array`类型，也就是文件列表。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/bf8069bff56e6f36b718dc787d2c5cba.png)

在开始节点之后需要加入迭代节点，并且设置输入变量和输出变量。在迭代节点内部，设置每次循环执行的内容，这部分和前文内容完全一致。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/93a3ea37ac863f037c6f2262081f1c5b.png)

## 思考题 2 : 针对思考题 1，只处理文件列表的特定文件

在思考题 1 中，有的读者可能会注意到 Dify 会把所有文件处理完才会结束循环，而有些情况下只要操作其中一部分的文件而非全部。对于这个问题，可以对文件列表进行处理，在 Dify 中对列表进行操作的节点叫做**列表操作**。列表操作可以对所有`array`类型的变量进行操作，不光是文件列表。

例如，限定只对文档类型的文件进行分析，并且把要处理的文件顺序按文件名称排序。

在迭代节点前加入列表操作，调整**过滤条件**、**排序**，然后将迭代节点的输入改为列表操作节点的输出。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/9acd0bf90a2bc40d9214bba00d5e26c2.png)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/workshop/intermediate/article-reader.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 使用知识库搭建智能客服机器人
> 来源：`zh-hans/workshop/intermediate/customer-service-bot.mdx`

> 作者：Steven Lynn。Dify Technical Writer。

上一个实验中，我们学习了文件上传的基本用法。然而，当我们需要读取的文本超出 LLM 的上下文窗口时，就需要用到知识库了。

> **什么是上下文？**
>
> 上下文窗口是指 LLM 在处理文本时能够“看到”和“记住”的文字范围。它决定了模型在生成回答或继续文本时，能够参考多少之前的文字信息。窗口越大，模型能利用的上下文信息越多，生成的内容通常更准确和连贯。

在之前，我们了解到 LLM 的幻觉的概念，很多情况下 LLM 知识库可以让 Agent 从中定位到准确的信息，从而准确地回答问题。在一些特定领域，比如客服、检索工具等有应用。

传统的客服机器人往往是基于关键词检索的，当用户输入了关键词以外的问题，机器人就无法解决。知识库正是为了解决这样一个问题，能够做到语义级别上的检索，降低人工的负担。

在实验开始之前，请记住知识库的核心是检索而非 LLM，是 LLM 增强了输出的过程，但真正的需求仍然是生成答案。

## 本实验中你将掌握的知识点

* Chatflow 的基础使用
* 知识库、外部知识库的使用
* embedding 的概念

## 前提条件

### 创建应用

在 Dify 中选择**创建空白应用 - 工作流编排。**

### 添加模型供应商

本次实验中需要涉及使用 embedding 模型，目前支持 embedding 的模型提供商中有 OpenAI、Cohere 等，在 Dify 的模型供应商中有标注 `TEXT EMBEDDING` ，请确保至少添加了一个并且有充足余额。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/31d4f5cac17f1f699084d28abe186313.png)

> **什么是 embedding？**
>
> " Embedding "是一种将离散型变量（如单词、句子或者整个文档）转化为连续的向量表示的技术。
>
> 直白地说，在我们将自然语言处理为数据时会将文本转为向量，这个过程被称作 embedding。语义相似的文本的向量会位置相近，语义相反的文本的向量位置相反。LLM 使用这样的数据做训练，预测出后续的向量，从而生成文本。

## 创建知识库

登录 Dify -> 知识库 -> 选择数据源

Dify 支持三种数据源：上传文本文件、Notion、网页。

其中，本地文本文件需要注意文件类型的限制以及文件大小的限制；同步 Notion 内容需要绑定 Notion 账号；同步 Web 站点需要使用 Jina 或者 Firecrawl 的 API。

下面将先以本地文件为例。

### 分段设置

上传文档后，会进入以下页面：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/a7d53306d454c3518dee7380d1711ca5.png)

可以看到右侧有分段预览。当前默认选择的是自动分段与清洗，Dify 会根据文本内容的不同自动将文章切分为许多个段落。你也可以在自定义中设置其他的切分规则。

### 索引方式

通常情况下选择 **高质量**，但是需要额外消耗 token。选择 **经济** 无需消耗 token。

在社区版 Dify 里有采用 Q\&A 分段模式，选择对应的语言可以将文本内容整理为问答格式，需要额外消耗 token。

### Embedding 模型

请在使用前查阅模型供应商的使用文档、模型定价等信息。

不同的 embedding 模型适用场景不同。例如 Cohere 的 `embed-english` 适用于英语文档，`embed-multilingual` 适用于多语言文档。

### 检索设置

Dify 提供了向量检索、全文检索、混合检索三种检索功能，其中常用的检索是混合检索。

混合检索中可以设置权重或者使用重新排序（Rerank）模型。使用权重设置时，可以设置检索更侧重语义还是关键词，例如下图中语义占 70% 的权重，关键词占30%的权重。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/68dff8bc8c8adf5a3fabc9d22c49172b.png)

点击**保存并处理**将会处理文档，完成处理后文档就可以在应用中使用了。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/607afc8c80b8cd512488614258c41850.png)

### 同步自 Web 站点

很多情况下，我们需要根据帮助文档构建智能客服，以 Dify 为例，我们可以将 [Dify 的帮助文档](https://docs.dify.ai)转为知识库。

目前 Dify 支持最多 50 个页面的处理，请注意限制数量的设置。如果超出，可以再创建新的知识库。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/bda671bc8e94f8477a2ef433b4354d59.png)

### 调整知识库内容

在知识库处理完所有文档后，最好前往知识库确认分段的连贯性。如果不连贯将会影响检索的效果，需要手动调整。

点击文档内容，对分段内容进行浏览，如果有无关的内容可以禁用或删除。

如果有内容被分段到了另外一个段落，也需要调整回来。

### 召回测试

在知识库的文档页，左侧边栏中点击召回测试，可以输入关键词来测试检索结果的准确性。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/949e47271243bd107b82217cbfc84efb.png)

## 添加节点

进入创建好的 APP ，下面开始构建智能客服机器人。

### 问题分类节点

你需要使用问题分类节点将用户的不同需求分离开。有的情况下用户甚至会聊无关的话题，对此也需要设置一个分类。

为了让分类更准确，你需要选择更优秀的 LLM，分类需要写的足够具体、区分度足够大。

以下是一个参考分类：

* 用户询问无关问题
* 用户询问和 Dify 相关问题
* 用户请求对技术名词的解释
* 用户询问社群加入方式

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/78556651f204f3c68315f35b4470ded8.png)

### 直接回复节点

问题分类中，“用户询问无关问题” 和 “用户询问社群加入方式” 这两个问题是不需要经过 LLM 的处理就能回复的。因此你可以直接在这两个问题后面连接直接回复节点。

“用户询问无关问题”：

可以将用户引导到帮助文档，让用户先尝试自己解决，例如：

```text
很抱歉，我不能回答你的问题。如果你需要更多帮助，请查看[帮助文档](https://docs.dify.ai)。
```

Dify 支持 Markdown 格式的文本的输出。你可以在输出中用 Markdown 来丰富文本的格式。甚至可以用 Markdown 格式在文中插入图片，效果如下：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/6ab45c7935eb2feb91718bd91a6d2371.png)

### 知识检索节点

在 “用户询问和 Dify 相关问题”后增加知识检索节点，勾选需要使用的知识库。

### LLM 节点

在知识检索节点的下一个节点，你需要选择 LLM 节点来整理知识库召回的内容。

LLM 需要根据用户的提问，调整回复，使得回复内容更加得体。

上下文：需要将知识检索节点的输出作为 LLM 节点的上下文。

你可以在提示词书写区域输入 `/` 或者 `{` 来引用变量。在变量中，`sys.` 开头的变量是系统变量，请查询[帮助文档](../../guides/workflow/variables#xi-tong-bian-liang)相关说明。

此外，你可以打开 LLM 记忆让用户的对话体验更加连贯。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/e6973701fcb109642fcb6fd258505825.png)

## 思考题 1: 如何连接外部知识库

在知识库功能中，你可以通过外部知识库 API 来连接外部知识库，例如 AWS Bedrock 知识库。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/4c14bb53802f6e732f0f455c608944e8.png)

有关 AWS Bedrock 知识库的最佳实践，请阅读：[如何连接 AWS Bedrock 知识库？](../../learn-more/use-cases/how-to-connect-aws-bedrock)

## 思考题 2: 如何通过 API 管理知识库

无论是社区版还是 SaaS 版 Dify，你都可以通过知识库 API 增加、删除、查询状态等。

在搭载知识库的实例中，进入 **知识库 -> API**，并且创建 API 密钥。请妥善保管 API 密钥。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/71d5b7ad150fb2019af83aeb79eb5d76.png)

## 思考题 3: 如何将客服机器人嵌入网页

应用发布后，选择嵌入网页，选择一种合适的嵌入形式，将代码粘贴到网页的合适位置即可。

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/workshop/intermediate/customer-service-bot.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## ChatFlow 实战：搭建 Twitter 账号分析助手
> 来源：`zh-hans/workshop/intermediate/twitter-chatflow.mdx`

> 作者： Steven Lynn。 Dify Technical Writer。

## 简介

Dify 内置了一些网络爬虫工具例如 Jina ，它可以将网页转换为 LLM 可以读取的 markdown 格式。

然而，X（以前叫 Twitter）自 2023 年 2 月 2 日起停止提供免费 API 访问，并且升级了其反爬虫措施。像 Jina 这样的工具无法直接访问 X 的内容。

> Starting February 9, we will no longer support free access to the Twitter API, both v2 and v1.1. A paid basic tier will be available instead 🧵
>
> — Developers (@XDevelopers) [February 2, 2023](https://twitter.com/XDevelopers/status/1621026986784337922?ref\_src=twsrc%5Etfw)

好在 Dify 有 HTTP 工具，我们可以通过发送 HTTP 请求来调用外部爬虫工具。下面让我们开始吧！

## 本实验中你将掌握的知识点

* ChatFlow 的基础知识
* 如何在 Dify 中避免明文密钥
* HTTP 工具的使用

## **前提条件**

### 注册 Crawlbase

Crawlbase 是一个为企业和开发者设计的全方位数据爬取和抓取平台，Crawlbase Scraper 可以从 X、Facebook 和 Instagram 等社交平台抓取数据。

点击注册：[crawlbase.com](https://crawlbase.com)

### Dify 平台

[Dify](https://cloud.dify.ai/) 是一个开源的 LLM 应用开发平台。你可以选择[云服务](https://cloud.dify.ai/)（开箱即用）或参考 [docker compose 本地](https://docs.dify.ai/getting-started/install-self-hosted)自建 Dify 平台。我们需要使用 LLM 处理由 Crawlbase 抓取的社交平台数据。

Free 版本的 Dify 提供了免费 200 条 OpenAI 的消息额度，如果消息额度不够用，你可以参考下图步骤, 自定义其它模型供应商。

点击**右上角头像 - 设置 - 模型供应商**

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/52f3f299b05ff94ee0421604dd810e35.png)

## 创建 ChatFlow 应用

现在，让我们开始创建 ChatFlow。点击`创建空白应用 - 工作流编排`：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/82f9f17b80fb3755efff0a260c0aeb81.png)

初始化的 Chatflow 应用如下：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/5e71089affe0d284e67388e47c92e324.png)

## 添加节点

### 开始节点

在开始节点中，我们可以在聊天开始时添加一些系统变量。在本文中，我们需要一个 Twitter 用户的 ID 作为字符串变量。让我们将其命名为`id`。

点击开始节点并添加一个新变量：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/cb4bccf4ad0496c7b0dec18dcca738b6.png)

### 代码节点

根据[Crawlbase文档](https://crawlbase.com/docs/crawling-api/scrapers/#twitter-profile)所述，变量`url`（将在下一个节点中使用）为 `https://twitter.com/` + `user id`，例如 Elon Musk 应当是[`https%3A%2F%2Ftwitter.com%2Felonmusk`](https://twitter.com/elonmusk)。

为了将用户ID转换为完整URL，我们可以使用以下Python代码将前缀`https://twitter.com/`与用户 ID 整合：

```python
def main(id: str) -> dict:
    return 
        "url": "https%3A%2F%2Ftwitter.com%2F"+id,

```

添加一个代码节点并选择 Python ，然后设置输入和输出变量名：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/0a371db2f178f1ddd2f4355327630cc4.png)

### HTTP 请求节点

根据 [Crawlbase文档](https://crawlbase.com/docs/crawling-api/scrapers/#twitter-profile)，如果以 HTTP 请求格式抓取 Twitter 用户的个人资料，我们需要按以下格式填写 HTTP 请求节点：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/ebb1a2bfd4f219d4184056009f9f30dc.png)

出于安全考虑，最好不要直接将 API Key 作为明文输入。在 Dify 最新版本中，可以在`环境变量`中设置令牌值。点击 `env` - `添加变量`来设置 API Key，这样就不会以明文出现在节点中。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/e4a8de831404946ca91b6c06f31d0769.png)

点击[此处](https://crawlbase.com/dashboard/account/docs)获取 Crawlbase API Key。输入 `/`插入为变量。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/f8c6cdb35b7a2b0565be663cf1e731ea.png)

点击此节点的开始按钮，输入Elon Musk 的 URL 进行测试：

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/257690ab83c3ad5515262a71ce228749.png)

### LLM 节点

现在，我们可以使用 LLM 来分析 Crawlbase 抓取的结果并执行我们的命令。

变量 `context` 的值为 HTTP 请求节点的 `body`。

以下是一个提示词示例。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/8c51fbbe32e95c892a407f8d177fe86a.png)

## 测试运行

点击 `预览`开始测试运行，并在`id`中输入 Twitter 用户 ID：

例如，我想分析 Elon Musk 的推文，并以他的语气写一条关于全球变暖的推文。

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/workshop/intermediate/835a01082e74723138d9f97bee0c6c4b.png)

点击右上角的`发布`，并将其添加到你的网站中。

## 写在最后

Crawlbase 应该是目前最便宜的 Twitter 爬虫服务，但有时它可能无法正确抓取用户推文的内容，具体效果请以实际调用为准。

## 链接

* [X@dify\_ai](https://x.com/dify\_ai)
* Dify 的 [GitHub 仓库](https://github.com/langgenius/dify)

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/workshop/intermediate/twitter-chatflow.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)


## 简介
> 来源：`zh-hans/workshop/readme.mdx`

欢迎来到 Dify 动手实验室！本教程专为那些想要从零开始学习 Dify 的初学者设计。无论你是否有编程或 AI 相关的背景知识，我们都将毫无保留地指导你逐步掌握 Dify 的核心概念和使用方法。

在本教程中，我们将通过一系列实验来帮助你深入理解 Dify 的各个方面。每个实验都将包含详细的步骤和解释，确保你能够轻松跟上并掌握所学内容。我们会在实验中穿插知识的教学，让你在实践中学习，逐步建立起对 Dify 的全面理解。

无需担心需要任何前置知识，我们会从最基础的概念开始，逐步引导你进入更高级的主题。无论你是完全的新手，还是有一些编程经验但想学习 AI 技术，本教程都将为你提供所需的一切。

让我们一起开始这段学习之旅，探索 Dify 的无限可能吧！

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/workshop/readme.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)
